{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Omicsoft believes that besides providing the best products, it is important to provide the best support as well. From our rapidly expanding knowledge base to the ability to easily get one-on-one personal web meetings, Omicsoft aims to provide the user with a top support experience. Tutorials The Omicsoft website offers tutorials for the various Array Studio modules including SNP Data Analysis, Affymetrix Data Analysis, CNV Analysis, ExonArray Data Analysis as well as Next Generation Sequencing (NGS) modules such as RNA-seq, DNA-seq and miRNA-seq. These tutorials are a great beginning guide to use Array Studio. They include links to download sample datasets, along with step-by-step directions for carrying out the various analysis methods. http://www.arrayserver.com/wiki/index.php?title=Tutorials ArraySuite Wiki The Omicsoft wiki site is a user-friendly information center. Our support team keeps the wiki articles up-to-date with common and complex questions that we receive from our customers. If you need a place to start when you have questions or for troubleshooting, you can start searching there with a term of interest or you can browse by pre-defined categories. Moreover, in addition to our tutorials on individual modules available in Array Studio, we provide videos to demonstrate the usage and simplicity of Array Studio in exploring Land data. http://arrayserver.com/wiki/ Help Documents Help documents are available to provide context for many of the analysis modules in Array Studio and can be accessed by simply selecting the \"Help\" button on each analysis menu. Contact Us Our regular support hours are Monday through Friday 9:00 AM through 5:00 PM Eastern Time. Emailed technical support requests are responded to on the same business day, and in most cases within a few hours. Email: support@omicsoft.com Phone: 1-888-259-OMIC (1-888-259-6642) Option 1","title":"Home"},{"location":"#home","text":"Omicsoft believes that besides providing the best products, it is important to provide the best support as well. From our rapidly expanding knowledge base to the ability to easily get one-on-one personal web meetings, Omicsoft aims to provide the user with a top support experience.","title":"Home"},{"location":"#tutorials","text":"The Omicsoft website offers tutorials for the various Array Studio modules including SNP Data Analysis, Affymetrix Data Analysis, CNV Analysis, ExonArray Data Analysis as well as Next Generation Sequencing (NGS) modules such as RNA-seq, DNA-seq and miRNA-seq. These tutorials are a great beginning guide to use Array Studio. They include links to download sample datasets, along with step-by-step directions for carrying out the various analysis methods. http://www.arrayserver.com/wiki/index.php?title=Tutorials","title":"Tutorials"},{"location":"#arraysuite-wiki","text":"The Omicsoft wiki site is a user-friendly information center. Our support team keeps the wiki articles up-to-date with common and complex questions that we receive from our customers. If you need a place to start when you have questions or for troubleshooting, you can start searching there with a term of interest or you can browse by pre-defined categories. Moreover, in addition to our tutorials on individual modules available in Array Studio, we provide videos to demonstrate the usage and simplicity of Array Studio in exploring Land data. http://arrayserver.com/wiki/","title":"ArraySuite Wiki"},{"location":"#help-documents","text":"Help documents are available to provide context for many of the analysis modules in Array Studio and can be accessed by simply selecting the \"Help\" button on each analysis menu.","title":"Help Documents"},{"location":"#contact-us","text":"Our regular support hours are Monday through Friday 9:00 AM through 5:00 PM Eastern Time. Emailed technical support requests are responded to on the same business day, and in most cases within a few hours. Email: support@omicsoft.com Phone: 1-888-259-OMIC (1-888-259-6642) Option 1","title":"Contact Us"},{"location":"about/","text":"Satus tuae non si ita sudor tramite Ita de veri quas aves finierat voce Lorem markdownum vento, quas texerat nato nona resolvite pictos inque dextraeque cantu et. Hunc meritis ipsa lunae illis videre blandas. Quod cum peregit insula. Silet ferinae fuerat inmane adducere multis oraque iuvat est hinc quae, nutritaque o extrema ultima: quoque. Aut scelus arcumque bracchia ponderibus redeuntem. Esse refert Per lumina Rima petuntur aegide Iovis Maeandri nec invidia illa In tale Resupino se condi morsibus, dummodo: possunt, nisi. Tostos fiducia, sed viro nobis nivea et noviens alium Byblis facinus honore fuerat deus salutant. Circe per demittitur vade tamen, tibi, et si ut. Vincinaque stupuit Phyleus validisne remanente, quodsi vulnusque quanta colorem vocem, in viris. Qui ecce verti tremuere, ossa fatur ossibus, iuga nisi. Antissa nec latet funera, est exegit colorque amplexa in. Tectus ponit , mares levat, et sparsaque numerem auras quae inplent, mihi. Non oleaster siquidem sine. Succedit fiducia timebant: natis lacrimantia Tyrrhena: nec ille ait ardua calcare serta Niobe Orphne adfectus. Id licet annos; spicula Troia auditaque et mediis cruoris meae, hic Thebas status virili et in tenuissimus. Dedimus undas faciem portus annosam, maxima fulmina meditataque domui devastata illa. Esse vultu? Plura gaudens alligat hic facit hinc antistite Gerens pluvio Dryopen flectitur roges palantesque fratri quinque vides, si. Serpens ingemuit nefandis; precor, ac medio vultusque feruntur arcanis, est leve! In videt, turba auxilium quicquid cognatumque Tyriis Paraetonium equis iactatis nisi decebat qua! Stipes silvis auro laterum bracchia simulat inserui voco, incandescit summa : vivo caeli hospitis mariti quid imis moenia. Eo Ecce unda parentem aetas. Dea imitata Zancleia illa foliis orbem, sit heres ululavit; ab matrona gelidi, semina aut humani priscum bovis. Dixit ita, illa mirantes profugi, commissaque est insopitumque oblitus si officioque stant silvas quidem socero, qui. Claros sequente potentia tenuem. Fera medii sensit, quod per, erat artus lutea, diffamatamque habentia. Illas palustris clivo, nam genu tamquam potiar ventis, est, constitit iacet, velamina. Vivat hoc est ulnis molles; his in non sanguineam et in arbore, rapacibus partes fumida modo. Rerum olim fas exhausto creditur et haberet pereat. Pectore pendentem tellus, robora et sumpto velamina sumite, classe?","title":"Satus tuae non si ita sudor tramite"},{"location":"about/#satus-tuae-non-si-ita-sudor-tramite","text":"","title":"Satus tuae non si ita sudor tramite"},{"location":"about/#ita-de-veri-quas-aves-finierat-voce","text":"Lorem markdownum vento, quas texerat nato nona resolvite pictos inque dextraeque cantu et. Hunc meritis ipsa lunae illis videre blandas. Quod cum peregit insula. Silet ferinae fuerat inmane adducere multis oraque iuvat est hinc quae, nutritaque o extrema ultima: quoque. Aut scelus arcumque bracchia ponderibus redeuntem. Esse refert Per lumina Rima petuntur aegide Iovis Maeandri nec invidia illa","title":"Ita de veri quas aves finierat voce"},{"location":"about/#in-tale","text":"Resupino se condi morsibus, dummodo: possunt, nisi. Tostos fiducia, sed viro nobis nivea et noviens alium Byblis facinus honore fuerat deus salutant. Circe per demittitur vade tamen, tibi, et si ut. Vincinaque stupuit Phyleus validisne remanente, quodsi vulnusque quanta colorem vocem, in viris. Qui ecce verti tremuere, ossa fatur ossibus, iuga nisi. Antissa nec latet funera, est exegit colorque amplexa in. Tectus ponit , mares levat, et sparsaque numerem auras quae inplent, mihi. Non oleaster siquidem sine. Succedit fiducia timebant: natis lacrimantia Tyrrhena: nec ille ait ardua calcare serta Niobe Orphne adfectus. Id licet annos; spicula Troia auditaque et mediis cruoris meae, hic Thebas status virili et in tenuissimus. Dedimus undas faciem portus annosam, maxima fulmina meditataque domui devastata illa. Esse vultu?","title":"In tale"},{"location":"about/#plura-gaudens-alligat-hic-facit-hinc-antistite","text":"Gerens pluvio Dryopen flectitur roges palantesque fratri quinque vides, si. Serpens ingemuit nefandis; precor, ac medio vultusque feruntur arcanis, est leve! In videt, turba auxilium quicquid cognatumque Tyriis Paraetonium equis iactatis nisi decebat qua! Stipes silvis auro laterum bracchia simulat inserui voco, incandescit summa : vivo caeli hospitis mariti quid imis moenia. Eo Ecce unda parentem aetas. Dea imitata Zancleia illa foliis orbem, sit heres ululavit; ab matrona gelidi, semina aut humani priscum bovis. Dixit ita, illa mirantes profugi, commissaque est insopitumque oblitus si officioque stant silvas quidem socero, qui. Claros sequente potentia tenuem. Fera medii sensit, quod per, erat artus lutea, diffamatamque habentia. Illas palustris clivo, nam genu tamquam potiar ventis, est, constitit iacet, velamina. Vivat hoc est ulnis molles; his in non sanguineam et in arbore, rapacibus partes fumida modo. Rerum olim fas exhausto creditur et haberet pereat. Pectore pendentem tellus, robora et sumpto velamina sumite, classe?","title":"Plura gaudens alligat hic facit hinc antistite"},{"location":"about/Contributing/","text":"Team Support team Gary Ge Joseph Pearson","title":"Contributing"},{"location":"about/Contributing/#team","text":"","title":"Team"},{"location":"about/Contributing/#support-team","text":"Gary Ge Joseph Pearson","title":"Support team"},{"location":"about/Release-notes/","text":"Release Notes ArraySuite 10.0 Array Suite 10.0: Accelerating Bioinformatics Research For Ten Years OmicSoft, now a QIAGEN company, is excited to announce Array Suite 10.0, the ten year anniversary release to its flagship software product. Array Suite provides the backbone of OmicSoft's software and data service offerings, including OncoLand, DiseaseLand and GeneticsLand. In the past ten years, Array Suite has helped numerous users from major pharma and biotech companies (as well as research instutitions) accelerate their bioinformatics and genomics research. Founded in 2007, OmicSoft had a vision to focus on biomarker data management, visualization, and analysis. Array Suite (Array Studio and Array Server) differs from standard desktop solutions or open source solutions, with Array Studio providing the graphical user interface for NGS and OMIC analysis and visualization and Array Server providing the enterprise back-end solution for pipelines, project management, sample/file management, data storage and OMIC data warehouse (Land database). In January 2017, QIAGEN enhanced its portfolio with the acquisition of OmicSoft, allowing us to imagine new possibilities for integration with the larger QIAGEN bioinformatics portfolio. We will update everyone on these enhancements, and how they will benefit our users, in the near future. \"Although much has changed in the past ten years, in both software and the company itself, I'm proud that OmicSoft Corporation has remained unchanged it it's fundamental desire to implement useful tools, driven by our customer's needs, in the -OMICS space. I am confident that this will continue into the future with our acquisition by QIAGEN, and I look forward to many more years of Array Studio helping to drive exciting breakthroughs and research by our customers\" - Matt Newman, VP Business Development OmicSoft is extremely proud of it's customer-centric product development and customer support, and we look to continue this into the future, as we have for the past 10 years. With our latest update, this trend continues. Array Suite 10.0 includes revolutionary updates, with multiple technology breakthroughs including: Cloud-Based Lands, Single Cell RNA-Seq support, ENCODE integration and many other updates to both analytics and framework. Here is a list of some of our exciting updates: Cloud-Based Lands Single Cell RNA-Seq support ENCODE integration in Omicsoft genome browser New gene set analysis Streaming large tables Smart labeling in multi-charts Smart caching for cloud/HTTP bam sources New analytic modules including variable selection and prediction Significant improvements on plasmid-host integration Various genome browser improvements","title":"Release Notes"},{"location":"about/Release-notes/#release-notes","text":"","title":"Release Notes"},{"location":"about/Release-notes/#arraysuite-100","text":"Array Suite 10.0: Accelerating Bioinformatics Research For Ten Years OmicSoft, now a QIAGEN company, is excited to announce Array Suite 10.0, the ten year anniversary release to its flagship software product. Array Suite provides the backbone of OmicSoft's software and data service offerings, including OncoLand, DiseaseLand and GeneticsLand. In the past ten years, Array Suite has helped numerous users from major pharma and biotech companies (as well as research instutitions) accelerate their bioinformatics and genomics research. Founded in 2007, OmicSoft had a vision to focus on biomarker data management, visualization, and analysis. Array Suite (Array Studio and Array Server) differs from standard desktop solutions or open source solutions, with Array Studio providing the graphical user interface for NGS and OMIC analysis and visualization and Array Server providing the enterprise back-end solution for pipelines, project management, sample/file management, data storage and OMIC data warehouse (Land database). In January 2017, QIAGEN enhanced its portfolio with the acquisition of OmicSoft, allowing us to imagine new possibilities for integration with the larger QIAGEN bioinformatics portfolio. We will update everyone on these enhancements, and how they will benefit our users, in the near future. \"Although much has changed in the past ten years, in both software and the company itself, I'm proud that OmicSoft Corporation has remained unchanged it it's fundamental desire to implement useful tools, driven by our customer's needs, in the -OMICS space. I am confident that this will continue into the future with our acquisition by QIAGEN, and I look forward to many more years of Array Studio helping to drive exciting breakthroughs and research by our customers\" - Matt Newman, VP Business Development OmicSoft is extremely proud of it's customer-centric product development and customer support, and we look to continue this into the future, as we have for the past 10 years. With our latest update, this trend continues. Array Suite 10.0 includes revolutionary updates, with multiple technology breakthroughs including: Cloud-Based Lands, Single Cell RNA-Seq support, ENCODE integration and many other updates to both analytics and framework. Here is a list of some of our exciting updates: Cloud-Based Lands Single Cell RNA-Seq support ENCODE integration in Omicsoft genome browser New gene set analysis Streaming large tables Smart labeling in multi-charts Smart caching for cloud/HTTP bam sources New analytic modules including variable selection and prediction Significant improvements on plasmid-host integration Various genome browser improvements","title":"ArraySuite 10.0"},{"location":"about/example/","text":"First For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Images, videos and table Simple image Test a large image lightbox image Test large image with lightbox using extend theme_dir lightbox gallery lightbox Youtube OmicSoft Single Cell RNASeq Analysis TestTable Header One Header Two Header One Header Two Item One Item Two Item One Item Two Extensions Admonition use below !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. will have: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. more to find in squidfunk Open styled details Nested details! And more content again. Tip: we can add code here \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Seealso Ref1: Ref2: Summary Summary style Done I am done Warning my warning Failure A fail case Danger be careful Bug It is a bug Quote someone said so. More details Details Open styled details Nested details! And more content again. styled details Note Danger Nested details! And more content again. Footnotes Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 Code highlight import tensorflow as tf Code highlight the 3 rd and 4 th lines \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] More examples of code highlight smart symbols \u2122 \u00ae more meta See the meta and description above. Task list Task List item 1 item A item B more text item a item b item c item C item 2 item 3 emoji EmojiOne emoji are very useful . You can also escape : characters to escape the emoji: :smile:. Super and sub using caret and tilde, and mark underline me H 2 0 text a superscript delete me CH 3 CH 2 OH text a subscript mark me mark me Keyboard using keys To copy, press Ctrl + Alt + C for Windows or Linux or Cmd + Alt + C for Mac. You can also use custom key labels: Ctrl + Alt + \u00dc . Mathjax Some Block Equations: When a \\ne 0 a \\ne 0 , there are two solutions to ax^2 + bx + c = 0 ax^2 + bx + c = 0 and they are x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}. x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}. Where \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} E(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j E(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j 3 < 4 3 < 4 \\begin{align} p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right)\\\\ p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right) \\end{align} \\begin{align} p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right)\\\\ p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right) \\end{align} Inline equations: p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} Reference http://squidfunk.github.io/mkdocs-material/extensions/pymdown/ Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"Example"},{"location":"about/example/#first","text":"For full documentation visit mkdocs.org .","title":"First"},{"location":"about/example/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"about/example/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"about/example/#images-videos-and-table","text":"","title":"Images, videos and table"},{"location":"about/example/#simple-image","text":"Test a large image","title":"Simple image"},{"location":"about/example/#lightbox-image","text":"Test large image with lightbox using extend theme_dir","title":"lightbox image"},{"location":"about/example/#lightbox-gallery","text":"","title":"lightbox gallery"},{"location":"about/example/#lightbox-youtube","text":"OmicSoft Single Cell RNASeq Analysis","title":"lightbox Youtube"},{"location":"about/example/#testtable","text":"Header One Header Two Header One Header Two Item One Item Two Item One Item Two","title":"TestTable"},{"location":"about/example/#extensions","text":"","title":"Extensions"},{"location":"about/example/#admonition","text":"use below !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. will have: Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. more to find in squidfunk Open styled details Nested details! And more content again. Tip: we can add code here \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Seealso Ref1: Ref2: Summary Summary style Done I am done Warning my warning Failure A fail case Danger be careful Bug It is a bug Quote someone said so. More details","title":"Admonition"},{"location":"about/example/#details","text":"Open styled details Nested details! And more content again. styled details Note Danger Nested details! And more content again.","title":"Details"},{"location":"about/example/#footnotes","text":"Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2","title":"Footnotes"},{"location":"about/example/#code-highlight","text":"import tensorflow as tf Code highlight the 3 rd and 4 th lines \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] More examples of code highlight","title":"Code highlight"},{"location":"about/example/#smart-symbols","text":"\u2122 \u00ae more","title":"smart symbols"},{"location":"about/example/#meta","text":"See the meta and description above.","title":"meta"},{"location":"about/example/#task-list","text":"Task List item 1 item A item B more text item a item b item c item C item 2 item 3","title":"Task list"},{"location":"about/example/#emoji","text":"EmojiOne emoji are very useful . You can also escape : characters to escape the emoji: :smile:.","title":"emoji"},{"location":"about/example/#super-and-sub-using-caret-and-tilde-and-mark","text":"underline me H 2 0 text a superscript delete me CH 3 CH 2 OH text a subscript mark me mark me","title":"Super and sub using caret and tilde, and mark"},{"location":"about/example/#keyboard-using-keys","text":"To copy, press Ctrl + Alt + C for Windows or Linux or Cmd + Alt + C for Mac. You can also use custom key labels: Ctrl + Alt + \u00dc .","title":"Keyboard using keys"},{"location":"about/example/#mathjax","text":"Some Block Equations: When a \\ne 0 a \\ne 0 , there are two solutions to ax^2 + bx + c = 0 ax^2 + bx + c = 0 and they are x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}. x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}. Where \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} E(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j E(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j 3 < 4 3 < 4 \\begin{align} p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right)\\\\ p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right) \\end{align} \\begin{align} p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right)\\\\ p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right) \\end{align} Inline equations: p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)}","title":"Mathjax"},{"location":"about/example/#reference","text":"http://squidfunk.github.io/mkdocs-material/extensions/pymdown/ Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. \u21a9","title":"Reference"},{"location":"tutorials/ArrayStudio/ArrayStudio/","text":"Introduction What is Array Studio? Array Studio is a software package that provides state of the art statistics and visualization for the analysis of high dimensional quantification data (e.g. Microarray or RT-PCR/Taqman data), genotype data (e.g. SNP or Copy Number data) and Next Generation Sequencing data. It provides the fastest, easiest and most powerful solution for \"-omic\" and \"NGS\" data analysis on the market. More than 400 features have been implemented based on feedback provided by industrial and academic users. Features Array Studio includes over 40 unique views, all of which are fully interactive (e.g. selection, zoom, etc.) and highly customizable (e.g. change axis, colors, shapes, etc.). Most of these views also have trellis support. All the views can be exported as images or PowerPoint slides by a single mouse click. More than 50 analytical modules were designed for ease of use so that biologists can function at near the level of informatics specialists. The high dimensional linear modeling module provides the complete statistical analysis for multiple ANOVA, ANCOVA, repeated measure, split plot and a variety of other experimental designs. Non-negative matrix factorization and spectral map analysis are two of the many data exploration modules in the software. Data mining modules provide comprehensive support for classification (e.g. SVM and KNN) and regression (e.g. LASSO and Neural Network), with built-in variable selection and honest cross validation. Takes seconds or minutes instead of hours to do an analysis on a regular laptop computer! Array Studio also provides comprehensive support for project management, data manipulation, quality control, pathway analysis, gene ontology analysis, and power analysis. For industrial users, an internal audit trail and scripting are useful for data integration and customized analysis pipeline. Array Studio will automatically save all analysis logs to text file and provide a link to this file in the \"Audit Trail Description\" tab. Array Studio integrates with Array Server, Omicsoft's enterprise solution for Microarray/CNV/SNP/NGS data storage, search and integration. Easily retrieve projects from Array Server, and/or publish back to the server for storage and searching purposes. Benefits Fastest data analysis and visualization on the market General linear model benchmarked with SAS Automatic project management, annotation support and script generation One-Click exporting of tables to Excel and all visualizations to PowerPoint One-Click downloading of data from the Gene Expression Omnibus (GEO) website, including the ability to automatically parse both design (sample information) and annotation, so that the project is immediately in the correct form for further analysis and visualization. One-Click downloading of data from the Sequence Read Archive (SRA) website, including the ability to automatically convert sra files into fastq files. VariableView, for looking at expression values on a per-gene basis General Linear Model for performing complicated analysis, including the ability to analyze mixed models, continuous and class covariates, nested factors, etc. Quality Control Modules, including generating Correlation Heatmap, Kernel density views, Principal Component Analysis, and more. Stunning performance: Most modules in Array Studio take seconds, not minutes to run. Array Studio has been shown to handle 20,000 samples and millions of rows on an average laptop computer. A top-tier workstation is not necessary to run Array Studio effectively. Interactive GenomeView and RegionView for visualizing CNV segmentation results. Ability to easily import 1000s of microarray, SNP, or CNV chips on a regular computer Fast and powerful segmentation algorithm for Copy Number analysis. GenomeView allows easy editing of copy number segments, as well as visualization of segments in relationship to Log2Ratio and AlleleDifference (B Allele Frequency) The Taqman/RT-PCR Import and Normalization wizard is industry leading. The module was designed for use by top statisticians and bioinformaticians at a leading pharmaceutical company, and includes the ability to import directly from ABI Result Text files, normalize the data using a number of statistical methods, and visualize the results using the same visualizations used elsewhere in Array Studio. Comprehensive statistical support for SNP, Genotyping, and Copy Number analysis, including the analysis of basic association studies, quantitative traits, categorical traits, survival trait analysis, repeated measure traits, Linkage disequilibrium analysis, Dose data association, probability association analysis, and more. Automatic annotation support and built-in annotation browser-For most leading microarray and genetic products, Array Studio automatically downloads gene annotation and links it to every dataset and result created by users. Web Details on Demand allows users to quickly link to public resources that relate to selected probe sets or markers in a dataset. Single deployment with automatic update support ensures that users will always be running the latest version. With Omicsoft's commitment to implementing reasonable user requests, this allows users to always have the newest software, including any and all modules released since users purchased the software. NGS workflows for DNA-seq, RNA-seq and miRNA-seq. The workflows include our high performance alignment modules (works for both single end and paired end) and many downstream analysis. For oncology users, we also developed the full gene fusion modules for both single-end and paired end modes. Papers and white papers on NGS are available upon request for existing users. Array Studio provides an integrated environment for analyzing and visualizing high-dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer, which organizes each project into two main sections (-Omic data and Table data), as well as different folders:, QC, Inference, List, Cluster, Text, Attachments and other categories. The Solution Explorer can contain multiple projects, and data can be shared among projects. Each view is controlled by a View Controller, which performs view customization, applies filtering, and displays legends; Furthermore, its interactive visualization technique provides the details of data with the Details Window and the Web Details Window. Installation Requirements Array Studio requires Microsoft .NET 3.5 framework. As a result, most versions of Array Studio require that users have administrative privileges to install .NET 3.5 Framework, or the ability to do so before installing Array Studio. By default, the installation page for Array Studio will automatically install .NET 3.5 Framework if users do not have this installed previously. While Array Studio does not have any specific requirements for memory or processor speed, it is recommended that users have at least 1gb of RAM for microarray analysis, and at least 2gb of RAM for ExonArray, SNP/Genotyping, and CNV analysis. For microarray analysis, hard drive space is not an issue, however users should ensure that they have sufficient hard drive space for larger ExonArray, SNP/Genotyping, and CNV analysis. Extremely large datasets, such as Dose or Probability SNP data, utilize a large amount of hard drive space. The user should ensure that there is sufficient space on the hard drive for such analyses. For NGS analysis in 64-bit mode 8 GB of RAM is recommended, for 32-bit mode 2 GB of RAM is recommended. For hard drive space, both your Omicsoft temp folder and the data for the analysis must reside on a hard drive that has 3-times the amount of free space as the size of the raw data files. The Omicsoft software home directory is typically located in users' My Documents folder, under the Omicsoft folder. This folder contains all of users' annotations, favorites, Ontology, Refseq, Ensembl, Hapmap data, and more. In addition, this folder is used as the temporary working directory. If users are concerned about space on the hard drive containing this folder, the Omicsoft home directory can be changed by going to Tools | Preferences | Advanced | Omicsoft . Installing Array Studio Bioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The software is updated frequently. We do have a stable Array Studio version 10.0. Please contact support@omicsoft.com if you wish to use the stable version for data analysis. ArrayStudio can be installed/launched using ArrayStudio Launcher. Launcher is installed through ClickOnce deployment. On an an internet-connected computer, open the following link in Internet Explorer, click install in the page below: http://omicsoft.com/software/ArrayStudioLauncher/publish.htm It will create a desktop icon \"ArrayStudio Launcher\". User can then click the icon and launch ArrayStudio regardless which default internet browser has been set on your computer. The Launcher will check whether there is any software update available and ask user to decide whether to update studio or not. Array Studio GUI When Array Studio is first installed, it will look similar to below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. Notice at the top there will be four tabs: Analysis, Server, Land, and Browser.","title":"Array Studio"},{"location":"tutorials/ArrayStudio/ArrayStudio/#introduction","text":"","title":"Introduction"},{"location":"tutorials/ArrayStudio/ArrayStudio/#what-is-array-studio","text":"Array Studio is a software package that provides state of the art statistics and visualization for the analysis of high dimensional quantification data (e.g. Microarray or RT-PCR/Taqman data), genotype data (e.g. SNP or Copy Number data) and Next Generation Sequencing data. It provides the fastest, easiest and most powerful solution for \"-omic\" and \"NGS\" data analysis on the market. More than 400 features have been implemented based on feedback provided by industrial and academic users. Features Array Studio includes over 40 unique views, all of which are fully interactive (e.g. selection, zoom, etc.) and highly customizable (e.g. change axis, colors, shapes, etc.). Most of these views also have trellis support. All the views can be exported as images or PowerPoint slides by a single mouse click. More than 50 analytical modules were designed for ease of use so that biologists can function at near the level of informatics specialists. The high dimensional linear modeling module provides the complete statistical analysis for multiple ANOVA, ANCOVA, repeated measure, split plot and a variety of other experimental designs. Non-negative matrix factorization and spectral map analysis are two of the many data exploration modules in the software. Data mining modules provide comprehensive support for classification (e.g. SVM and KNN) and regression (e.g. LASSO and Neural Network), with built-in variable selection and honest cross validation. Takes seconds or minutes instead of hours to do an analysis on a regular laptop computer! Array Studio also provides comprehensive support for project management, data manipulation, quality control, pathway analysis, gene ontology analysis, and power analysis. For industrial users, an internal audit trail and scripting are useful for data integration and customized analysis pipeline. Array Studio will automatically save all analysis logs to text file and provide a link to this file in the \"Audit Trail Description\" tab. Array Studio integrates with Array Server, Omicsoft's enterprise solution for Microarray/CNV/SNP/NGS data storage, search and integration. Easily retrieve projects from Array Server, and/or publish back to the server for storage and searching purposes. Benefits Fastest data analysis and visualization on the market General linear model benchmarked with SAS Automatic project management, annotation support and script generation One-Click exporting of tables to Excel and all visualizations to PowerPoint One-Click downloading of data from the Gene Expression Omnibus (GEO) website, including the ability to automatically parse both design (sample information) and annotation, so that the project is immediately in the correct form for further analysis and visualization. One-Click downloading of data from the Sequence Read Archive (SRA) website, including the ability to automatically convert sra files into fastq files. VariableView, for looking at expression values on a per-gene basis General Linear Model for performing complicated analysis, including the ability to analyze mixed models, continuous and class covariates, nested factors, etc. Quality Control Modules, including generating Correlation Heatmap, Kernel density views, Principal Component Analysis, and more. Stunning performance: Most modules in Array Studio take seconds, not minutes to run. Array Studio has been shown to handle 20,000 samples and millions of rows on an average laptop computer. A top-tier workstation is not necessary to run Array Studio effectively. Interactive GenomeView and RegionView for visualizing CNV segmentation results. Ability to easily import 1000s of microarray, SNP, or CNV chips on a regular computer Fast and powerful segmentation algorithm for Copy Number analysis. GenomeView allows easy editing of copy number segments, as well as visualization of segments in relationship to Log2Ratio and AlleleDifference (B Allele Frequency) The Taqman/RT-PCR Import and Normalization wizard is industry leading. The module was designed for use by top statisticians and bioinformaticians at a leading pharmaceutical company, and includes the ability to import directly from ABI Result Text files, normalize the data using a number of statistical methods, and visualize the results using the same visualizations used elsewhere in Array Studio. Comprehensive statistical support for SNP, Genotyping, and Copy Number analysis, including the analysis of basic association studies, quantitative traits, categorical traits, survival trait analysis, repeated measure traits, Linkage disequilibrium analysis, Dose data association, probability association analysis, and more. Automatic annotation support and built-in annotation browser-For most leading microarray and genetic products, Array Studio automatically downloads gene annotation and links it to every dataset and result created by users. Web Details on Demand allows users to quickly link to public resources that relate to selected probe sets or markers in a dataset. Single deployment with automatic update support ensures that users will always be running the latest version. With Omicsoft's commitment to implementing reasonable user requests, this allows users to always have the newest software, including any and all modules released since users purchased the software. NGS workflows for DNA-seq, RNA-seq and miRNA-seq. The workflows include our high performance alignment modules (works for both single end and paired end) and many downstream analysis. For oncology users, we also developed the full gene fusion modules for both single-end and paired end modes. Papers and white papers on NGS are available upon request for existing users. Array Studio provides an integrated environment for analyzing and visualizing high-dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer, which organizes each project into two main sections (-Omic data and Table data), as well as different folders:, QC, Inference, List, Cluster, Text, Attachments and other categories. The Solution Explorer can contain multiple projects, and data can be shared among projects. Each view is controlled by a View Controller, which performs view customization, applies filtering, and displays legends; Furthermore, its interactive visualization technique provides the details of data with the Details Window and the Web Details Window.","title":"What is Array Studio?"},{"location":"tutorials/ArrayStudio/ArrayStudio/#installation","text":"","title":"Installation"},{"location":"tutorials/ArrayStudio/ArrayStudio/#requirements","text":"Array Studio requires Microsoft .NET 3.5 framework. As a result, most versions of Array Studio require that users have administrative privileges to install .NET 3.5 Framework, or the ability to do so before installing Array Studio. By default, the installation page for Array Studio will automatically install .NET 3.5 Framework if users do not have this installed previously. While Array Studio does not have any specific requirements for memory or processor speed, it is recommended that users have at least 1gb of RAM for microarray analysis, and at least 2gb of RAM for ExonArray, SNP/Genotyping, and CNV analysis. For microarray analysis, hard drive space is not an issue, however users should ensure that they have sufficient hard drive space for larger ExonArray, SNP/Genotyping, and CNV analysis. Extremely large datasets, such as Dose or Probability SNP data, utilize a large amount of hard drive space. The user should ensure that there is sufficient space on the hard drive for such analyses. For NGS analysis in 64-bit mode 8 GB of RAM is recommended, for 32-bit mode 2 GB of RAM is recommended. For hard drive space, both your Omicsoft temp folder and the data for the analysis must reside on a hard drive that has 3-times the amount of free space as the size of the raw data files. The Omicsoft software home directory is typically located in users' My Documents folder, under the Omicsoft folder. This folder contains all of users' annotations, favorites, Ontology, Refseq, Ensembl, Hapmap data, and more. In addition, this folder is used as the temporary working directory. If users are concerned about space on the hard drive containing this folder, the Omicsoft home directory can be changed by going to Tools | Preferences | Advanced | Omicsoft .","title":"Requirements"},{"location":"tutorials/ArrayStudio/ArrayStudio/#installing-array-studio","text":"Bioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The software is updated frequently. We do have a stable Array Studio version 10.0. Please contact support@omicsoft.com if you wish to use the stable version for data analysis. ArrayStudio can be installed/launched using ArrayStudio Launcher. Launcher is installed through ClickOnce deployment. On an an internet-connected computer, open the following link in Internet Explorer, click install in the page below: http://omicsoft.com/software/ArrayStudioLauncher/publish.htm It will create a desktop icon \"ArrayStudio Launcher\". User can then click the icon and launch ArrayStudio regardless which default internet browser has been set on your computer. The Launcher will check whether there is any software update available and ask user to decide whether to update studio or not.","title":"Installing Array Studio"},{"location":"tutorials/ArrayStudio/ArrayStudio/#array-studio-gui","text":"When Array Studio is first installed, it will look similar to below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. Notice at the top there will be four tabs: Analysis, Server, Land, and Browser.","title":"Array Studio GUI"},{"location":"tutorials/CNV/","text":"Copy Number Variation Analysis Tutorial .. toctree:: :maxdepth: 2 Introduction Visualization_of_Data Summarization_of_CNV_Data Advanced_Visualization Analysis_Modules Save_Close_Project","title":"Home"},{"location":"tutorials/CNV/Advanced_Visualization/","text":"Genome Browser Visualization Processed data from CNV analyses performed in this tutorial can also be viewed directly in the Genome Broswer tab. To access the browser, simply click the Browser tab at the top of your screen: If you have not already done so, create a New Genome Browser by clicking new. You will see the following prompt: Choose the default reference and gene models and select and output folder and name. Click \"OK\". Go to Add Track | Add Track from Analysis : First, try choosing the option Segment track: segment data and click \"OK\". Find your open segment table from this tutorial and click \"OK\": Choose the default options and click \"OK\" again: You will see two additional tracks appear in your Genome Browser : Log2RatioMean and CNStatus . Browse to chromosome 13 within the toolbar and notice that the Beta2 sample we examined earlier has a log2RatioMean of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome: User can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding Shift and left-clicking to highlight a region. In addition to the segment tracks, one can upload additional CNV tracks. Go to Add Track | Add Track from Analysis : This time, choose the option Numeric track with multiple series: CNV data : Find your CNV analysis output and click OK . Select the data you want to visualize and click OK . Here, we choose all the data and set all other parameters to default: In this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view: As you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more:","title":"Advanced Visulization"},{"location":"tutorials/CNV/Advanced_Visualization/#genome-browser-visualization","text":"Processed data from CNV analyses performed in this tutorial can also be viewed directly in the Genome Broswer tab. To access the browser, simply click the Browser tab at the top of your screen: If you have not already done so, create a New Genome Browser by clicking new. You will see the following prompt: Choose the default reference and gene models and select and output folder and name. Click \"OK\". Go to Add Track | Add Track from Analysis : First, try choosing the option Segment track: segment data and click \"OK\". Find your open segment table from this tutorial and click \"OK\": Choose the default options and click \"OK\" again: You will see two additional tracks appear in your Genome Browser : Log2RatioMean and CNStatus . Browse to chromosome 13 within the toolbar and notice that the Beta2 sample we examined earlier has a log2RatioMean of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome: User can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding Shift and left-clicking to highlight a region. In addition to the segment tracks, one can upload additional CNV tracks. Go to Add Track | Add Track from Analysis : This time, choose the option Numeric track with multiple series: CNV data : Find your CNV analysis output and click OK . Select the data you want to visualize and click OK . Here, we choose all the data and set all other parameters to default: In this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view: As you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more:","title":"Genome Browser Visualization"},{"location":"tutorials/CNV/Analysis_Modules/","text":"Analysis Modules Besides visualization and summarization, Array Studio includes a number of different association analysis modules. However, for this tutorial, we will not use these modules, as the sample data does not fit with that type of analysis. Array Studio includes modules for analyzing CNV data association under the CNV Menu as shown below. These include General Linear Model , Quantitative Trait , Categorical Trait , Survival Trait , and Repeated Measure Trait analysis modules. If user has quantitative trait, categorical trait, survival trait or repeated measure trait in the experiment, they can use appropriate modules for the association analysis. For more information on what type of analysis should be performed on your data, consult a statistician or feel free to contact the Omicsoft support staff. You can always get details about every module in Array Studio by opening that module and clicking on the Help button on the bottom left of the window. Congratulations! You have finished learning about the capabilities for analysis that can be done for CNV data in Array Studio . Feel free to contact Omicsoft support for help with any particular module.","title":"Analysis"},{"location":"tutorials/CNV/Analysis_Modules/#analysis-modules","text":"Besides visualization and summarization, Array Studio includes a number of different association analysis modules. However, for this tutorial, we will not use these modules, as the sample data does not fit with that type of analysis. Array Studio includes modules for analyzing CNV data association under the CNV Menu as shown below. These include General Linear Model , Quantitative Trait , Categorical Trait , Survival Trait , and Repeated Measure Trait analysis modules. If user has quantitative trait, categorical trait, survival trait or repeated measure trait in the experiment, they can use appropriate modules for the association analysis. For more information on what type of analysis should be performed on your data, consult a statistician or feel free to contact the Omicsoft support staff. You can always get details about every module in Array Studio by opening that module and clicking on the Help button on the bottom left of the window. Congratulations! You have finished learning about the capabilities for analysis that can be done for CNV data in Array Studio . Feel free to contact Omicsoft support for help with any particular module.","title":"Analysis Modules"},{"location":"tutorials/CNV/Introduction/","text":"Introduction Array studio Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to basic usage, data structure and standard visualization in Array Studio. Downloading the Copy Number Sample Data For this tutorial, the following materials will be required: the 10 .CEL files and the CopyNumber.design.txt file. The Copy Number Sample Data is available at: link The Copy Number sample data contains 10 samples and 1,855,448 CNVs from the Affymetrix platform. The 10 observations include cases of UPD on chromosome 15, DMD-del Xp21.1, Williams Syndrome, Mosaic Trisomy, Turner Mosaic, Trisomy 13, Smith-Magenis, Angelman/Prader-Willi, and a normal sample. An additional file that includes covariate information, relating the chip name to the type of syndrome, as well as the source of the chip, has been included as well. While this tutorial only includes 10 observations, Array Studio is easily capable of handling experiments with thousands of observations and millions of rows. The CopyNumber.Design.txt file contains the design information for the tutorial\u2019s study, including columns for ID , Abnormality , and Source . A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed ID , that contains the exact file names of the arrays used in the experiment, without the extension (e.g. .CEL). That is, the IDs have to match the names of the Affymetrix .CEL files, or the names listed in the Illumina text file, etc. Additional columns usually include disease status , quantitative traits , etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because design factors can be added or edited after importing the design into Array Studio . An example design table is shown below. After downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial). Creating a New Project When Array Studio is first installed, it will look similar to below. If you have previously had projects opened in Array Studio, just click Cancel so as to not reopen those projects now. Notice at the top there will be multiple tabs: Analysis, Server, Land, and Browser. This tutorial will concentrate on the Local Analysis. A separate tutorial is available for accessing Omicsoft\u2019s Array Server, and that tutorial can be used for the Server Explorer tab. Note This tutorial is done in Local mode, but can just as easily be completed using Server mode if Array Server is installed. Array Server allows a user to perform analyses on a high performance computing cluster with job management capabilities, greatly accelerating the speed at which analysis, data visualization and file transfer can occur. To create a new project, click the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window. Array Studio allows the user to create two different project types: A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects). With a simple project, all data will be saved in a single file. In a distributed project, data will be saved in separate files, stored in a folder of the project\u2019s name, and also includes a small project file .osprj (used for re-opening of the project). Choose the Create a distributed project option. Click the Browse button to choose a location to save the project, and enter the project name. The Data folder information is automatically filled in based on the location of the Project file. Click OK to continue. The Solution Explorer will now be empty, containing a TutorialCNV Project and slots for List, Cluster, Text, and Attachments . You can right-click on List, Cluster , and Text for additional options for each. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (SNP data), or Observations (Chips or SNP arrays). If you cannot see the Solution Explorer , switch to it now by clicking it on the bottom left of the screen, or going to the View Menu | Show Solution Explorer . In the next section, we will import the downloaded CNV data into Array Studio. Importing CNV Data and Attaching Design Table To import our sample CNV data, click Add Data | Add Omic Data | Add CNV/CGH Data . This opens the Specify CNV Data Source window. In this window, the user can choose the CNV Data Source for input. Choices include: The sample data for this tutorial is in Affymetrix .CEL file format. Choose Affymetrix .CEL files now. This brings up the Extract Affymetrix CEL Files window. The first step for this window is to add the files to be extracted by clicking the Add button. Navigate to the location of the downloaded 10 .CEL files, and then click Open to continue. Options include: Import sample information from .ARR files will automatically import sample/design table information if the user has previously generated .ARR files). Note: Import sample information from ARR files can be selected but will have no effect for this tutorial, as that information was not generated with the sample files ( Array Studio looks in the same directory of the CNCHP files for the .ARR sample information files). Estimate B-Allele Frequency , which should be selected. import the CEL images into design , which should be left unchecked. Click Submit to begin the extraction. The extraction process may take up to 15 minutes (the first time a specific chip type is used, annotation is automatically downloaded from Omicsoft\u2019s web server, and this may increase the time it takes for extraction as well. However, a standard computer with 2 Gigabytes of memory should have no problem extracting a large number of CEL files (1000 files can be easily extracted). Note Array Studio uses an algorithm similar to the Birdseed/Birdsuite algorithms for the SNP 6.0 and 500K Mapping chips (Tests have shown a 99.98% concordance between Omicsoft\u2019s algorithm and Birdseed/Birdsuite). Array Studio achieves this by previously generating the model, based on the HapMap 270 dataset. For more questions on the exact details of the algorithm, please read the following white paper on our wiki page: link Upon completion of import, Array Studio will prompt the user to attach a Design table to the data. If the user wishes to attach a design table at a later time, this can be done as well (by right-clicking the Design section of the dataset in the Solution Explorer ), however, it is recommended to build and have your design table ready for use upon import of the data. Click Yes to begin the Design import process. Array Studio will prompt the user to specify a table source. As the design table for the sample data is in a Tab delimited file format, choose that option now, and click OK . When prompted, choose the CopyNumber .design.txt file that was unzipped earlier, and click Open to attach the design table to the dataset. When the \"Specify Options\" window appears, just select \"OK\": Once imported, Array Studio should look similar to the following screenshot. By default, a TableView is created for the imported dataset (Log2Ratio). Also, note that a new item has been added under the Omic Data section of the Solution Explorer (on the left-hand side of the screen). The Solution Explorer can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset, Log2Ratio , Array Studio lists the number of rows and columns (or variables and observations) in the dataset. In this case, there are 1,855,448 variables and 10 observations in each of the datasets. The Solution Explorer also provides the user with information on the different views that have been created. Notice that the Project, CNVTutorial , contains a dataset Log2Ratio . There is a TableView under the Design section, as well as a TableView in the main section. This indicates that if the user was to double-click either of these views (named Table), these would open up in the main view window. Expand the nodes (they are collapsed by default) to see something similar to below. Congratulations! You have successfully imported your first CNV dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.","title":"Introduction"},{"location":"tutorials/CNV/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/CNV/Introduction/#array-studio","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to basic usage, data structure and standard visualization in Array Studio.","title":"Array studio"},{"location":"tutorials/CNV/Introduction/#downloading-the-copy-number-sample-data","text":"For this tutorial, the following materials will be required: the 10 .CEL files and the CopyNumber.design.txt file. The Copy Number Sample Data is available at: link The Copy Number sample data contains 10 samples and 1,855,448 CNVs from the Affymetrix platform. The 10 observations include cases of UPD on chromosome 15, DMD-del Xp21.1, Williams Syndrome, Mosaic Trisomy, Turner Mosaic, Trisomy 13, Smith-Magenis, Angelman/Prader-Willi, and a normal sample. An additional file that includes covariate information, relating the chip name to the type of syndrome, as well as the source of the chip, has been included as well. While this tutorial only includes 10 observations, Array Studio is easily capable of handling experiments with thousands of observations and millions of rows. The CopyNumber.Design.txt file contains the design information for the tutorial\u2019s study, including columns for ID , Abnormality , and Source . A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed ID , that contains the exact file names of the arrays used in the experiment, without the extension (e.g. .CEL). That is, the IDs have to match the names of the Affymetrix .CEL files, or the names listed in the Illumina text file, etc. Additional columns usually include disease status , quantitative traits , etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because design factors can be added or edited after importing the design into Array Studio . An example design table is shown below. After downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial).","title":"Downloading the Copy Number Sample Data"},{"location":"tutorials/CNV/Introduction/#creating-a-new-project","text":"When Array Studio is first installed, it will look similar to below. If you have previously had projects opened in Array Studio, just click Cancel so as to not reopen those projects now. Notice at the top there will be multiple tabs: Analysis, Server, Land, and Browser. This tutorial will concentrate on the Local Analysis. A separate tutorial is available for accessing Omicsoft\u2019s Array Server, and that tutorial can be used for the Server Explorer tab. Note This tutorial is done in Local mode, but can just as easily be completed using Server mode if Array Server is installed. Array Server allows a user to perform analyses on a high performance computing cluster with job management capabilities, greatly accelerating the speed at which analysis, data visualization and file transfer can occur. To create a new project, click the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window. Array Studio allows the user to create two different project types: A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects). With a simple project, all data will be saved in a single file. In a distributed project, data will be saved in separate files, stored in a folder of the project\u2019s name, and also includes a small project file .osprj (used for re-opening of the project). Choose the Create a distributed project option. Click the Browse button to choose a location to save the project, and enter the project name. The Data folder information is automatically filled in based on the location of the Project file. Click OK to continue. The Solution Explorer will now be empty, containing a TutorialCNV Project and slots for List, Cluster, Text, and Attachments . You can right-click on List, Cluster , and Text for additional options for each. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (SNP data), or Observations (Chips or SNP arrays). If you cannot see the Solution Explorer , switch to it now by clicking it on the bottom left of the screen, or going to the View Menu | Show Solution Explorer . In the next section, we will import the downloaded CNV data into Array Studio.","title":"Creating a New Project"},{"location":"tutorials/CNV/Introduction/#importing-cnv-data-and-attaching-design-table","text":"To import our sample CNV data, click Add Data | Add Omic Data | Add CNV/CGH Data . This opens the Specify CNV Data Source window. In this window, the user can choose the CNV Data Source for input. Choices include: The sample data for this tutorial is in Affymetrix .CEL file format. Choose Affymetrix .CEL files now. This brings up the Extract Affymetrix CEL Files window. The first step for this window is to add the files to be extracted by clicking the Add button. Navigate to the location of the downloaded 10 .CEL files, and then click Open to continue. Options include: Import sample information from .ARR files will automatically import sample/design table information if the user has previously generated .ARR files). Note: Import sample information from ARR files can be selected but will have no effect for this tutorial, as that information was not generated with the sample files ( Array Studio looks in the same directory of the CNCHP files for the .ARR sample information files). Estimate B-Allele Frequency , which should be selected. import the CEL images into design , which should be left unchecked. Click Submit to begin the extraction. The extraction process may take up to 15 minutes (the first time a specific chip type is used, annotation is automatically downloaded from Omicsoft\u2019s web server, and this may increase the time it takes for extraction as well. However, a standard computer with 2 Gigabytes of memory should have no problem extracting a large number of CEL files (1000 files can be easily extracted). Note Array Studio uses an algorithm similar to the Birdseed/Birdsuite algorithms for the SNP 6.0 and 500K Mapping chips (Tests have shown a 99.98% concordance between Omicsoft\u2019s algorithm and Birdseed/Birdsuite). Array Studio achieves this by previously generating the model, based on the HapMap 270 dataset. For more questions on the exact details of the algorithm, please read the following white paper on our wiki page: link Upon completion of import, Array Studio will prompt the user to attach a Design table to the data. If the user wishes to attach a design table at a later time, this can be done as well (by right-clicking the Design section of the dataset in the Solution Explorer ), however, it is recommended to build and have your design table ready for use upon import of the data. Click Yes to begin the Design import process. Array Studio will prompt the user to specify a table source. As the design table for the sample data is in a Tab delimited file format, choose that option now, and click OK . When prompted, choose the CopyNumber .design.txt file that was unzipped earlier, and click Open to attach the design table to the dataset. When the \"Specify Options\" window appears, just select \"OK\": Once imported, Array Studio should look similar to the following screenshot. By default, a TableView is created for the imported dataset (Log2Ratio). Also, note that a new item has been added under the Omic Data section of the Solution Explorer (on the left-hand side of the screen). The Solution Explorer can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset, Log2Ratio , Array Studio lists the number of rows and columns (or variables and observations) in the dataset. In this case, there are 1,855,448 variables and 10 observations in each of the datasets. The Solution Explorer also provides the user with information on the different views that have been created. Notice that the Project, CNVTutorial , contains a dataset Log2Ratio . There is a TableView under the Design section, as well as a TableView in the main section. This indicates that if the user was to double-click either of these views (named Table), these would open up in the main view window. Expand the nodes (they are collapsed by default) to see something similar to below. Congratulations! You have successfully imported your first CNV dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.","title":"Importing CNV Data and Attaching Design Table"},{"location":"tutorials/CNV/Save_Close_Project/","text":"Save & Close Project Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to Copy number analysis and visualization. Feel free to try different options in the Task tab or the CNV menu to get a feel for what Array Studio can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save/Close Project"},{"location":"tutorials/CNV/Save_Close_Project/#save-close-project","text":"Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to Copy number analysis and visualization. Feel free to try different options in the Task tab or the CNV menu to get a feel for what Array Studio can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save &amp; Close Project"},{"location":"tutorials/CNV/Summarization_of_CNV_Data/","text":"Summarization of CNV Data Summary Statistics Array Studio can also provide summary statistics on CNV data using the module, Summary Statistics . This module is available in the CNV Menu | Summary Statistics . Open it now. This brings up the CNV Summary Statistics window. All module windows in Array Studio follow a similar pattern to this one. First, the user can select the Project and Data to be analysed; in this case our Project is Tutorial CNV and our Data is Log2Ratio . Next, if the user has generated a list of variables/markers for analysis, this can be selected through Customized variables . The user can also manually choose particular chromosomes for analysis. For demonstration purposes, let\u2019s only generate statistics on chromosome 13. To do this, check Filtered by chromosomes option and click the Filter button. The Observations section allows the user to choose a list of subjects to analyze. Leave this to All observations (10) . Under Options, the user has a number of choices. The user has the option to summarize either each Observation or each Variable . Here we choose Observation to summarize statistics across all markers on chromosome 13 for each sample. The user can also choose to summarize by a specific annotation table (for observations) or design table (for variables) column as Group . For example, if the user is interested in statistics for each Syndrome group, they could choose that column here. Finally, the Statistics section contains a number of different statistics that can be calculated, including N, Mean, StdDev, Min, Max, MinAbs, MaxAbs, Range, NMissing, NMissingPercentage, NNotMissing, NNotMissingPercentage, Sum, Variance, StdErr, CV, Median, IQR, Skewness, Kurtosis, MAD, NPositive, NNegative, PositivePercentage, NegativePercentage, PositiveChangeSize, NegativeChangeSize, PositiveMean, NegativeMean and GenometricMean. Choose Mean here to summarize the mean of Log2Ratio values of all variables for each observation. User also has the option to Append the summary statistics to the covariate table as new design column. In addition to the table report, user can also choose to generate log2-ratio box plots or distribution plots in correspondence to the table. Leave these unchecked for this tutorial. A new Table is generated under the Table | Summary section of the Solution Explorer , called Log2Ratio.Summary . Note that we may still be filtering for the single chip, so we need to reset all filters in the Filter tab of the View Controller to see all the samples in the table. Once unfiltered, the TableView should include 10 rows and 3 columns. It is clear that for sample Beta 2, which is the patient with Trisomy 13, the mean is 0.32545, significantly higher than for any of the other samples. This module can be used to perform similar analyses as desired, generating other types of statistics.","title":"Data Summarization"},{"location":"tutorials/CNV/Summarization_of_CNV_Data/#summarization-of-cnv-data","text":"","title":"Summarization of CNV Data"},{"location":"tutorials/CNV/Summarization_of_CNV_Data/#summary-statistics","text":"Array Studio can also provide summary statistics on CNV data using the module, Summary Statistics . This module is available in the CNV Menu | Summary Statistics . Open it now. This brings up the CNV Summary Statistics window. All module windows in Array Studio follow a similar pattern to this one. First, the user can select the Project and Data to be analysed; in this case our Project is Tutorial CNV and our Data is Log2Ratio . Next, if the user has generated a list of variables/markers for analysis, this can be selected through Customized variables . The user can also manually choose particular chromosomes for analysis. For demonstration purposes, let\u2019s only generate statistics on chromosome 13. To do this, check Filtered by chromosomes option and click the Filter button. The Observations section allows the user to choose a list of subjects to analyze. Leave this to All observations (10) . Under Options, the user has a number of choices. The user has the option to summarize either each Observation or each Variable . Here we choose Observation to summarize statistics across all markers on chromosome 13 for each sample. The user can also choose to summarize by a specific annotation table (for observations) or design table (for variables) column as Group . For example, if the user is interested in statistics for each Syndrome group, they could choose that column here. Finally, the Statistics section contains a number of different statistics that can be calculated, including N, Mean, StdDev, Min, Max, MinAbs, MaxAbs, Range, NMissing, NMissingPercentage, NNotMissing, NNotMissingPercentage, Sum, Variance, StdErr, CV, Median, IQR, Skewness, Kurtosis, MAD, NPositive, NNegative, PositivePercentage, NegativePercentage, PositiveChangeSize, NegativeChangeSize, PositiveMean, NegativeMean and GenometricMean. Choose Mean here to summarize the mean of Log2Ratio values of all variables for each observation. User also has the option to Append the summary statistics to the covariate table as new design column. In addition to the table report, user can also choose to generate log2-ratio box plots or distribution plots in correspondence to the table. Leave these unchecked for this tutorial. A new Table is generated under the Table | Summary section of the Solution Explorer , called Log2Ratio.Summary . Note that we may still be filtering for the single chip, so we need to reset all filters in the Filter tab of the View Controller to see all the samples in the table. Once unfiltered, the TableView should include 10 rows and 3 columns. It is clear that for sample Beta 2, which is the patient with Trisomy 13, the mean is 0.32545, significantly higher than for any of the other samples. This module can be used to perform similar analyses as desired, generating other types of statistics.","title":"Summary Statistics"},{"location":"tutorials/CNV/Visualization_of_Data/","text":"Visualization of Data The TableView Upon import, Array Studio will automatically generate a TableView for the CNV data. The TableView in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each variable is a row. Copy Number information is shown in each cell. First, take a look at the Log2Ratio data. If you have not already done so, double-click the Table view for the Log2Ratio data from the Solution Explorer . Scroll through the data now to see the speed that Array Studio can display data. Notice that this Tableview contains the Log2Ratio data, extracted from the CNCHP files, for each variable. Please refer to Microarray Tutorial for different options and filters for table view. The ObservationTableView Besides the regular TableView , where each row represents a variable and each column represents an observation, Array Studio also offers the ObservationTableView . In this view, each column represents a variable, while each row represents an observation. Array Studio can easily handle millions of columns in this view. To add an ObservationTableView to the imported dataset, click the Add View button from the toolbar. Alternatively and usually preferred for quick opening of new views for different data or table objects, the user can right click on the dataset or table in the Solution Explorer for the relevant data or table object. For instance, to open a new view for Log2Ratio data, the user could right-click on Log2Ratio and choose Add View , as shown below. Note: for Data object types, the user can also open new views for Annotation or Design as well (see figures below\u2014for information purpose only, not necessary for this tutorial). Similarly, to add a view for the Annotation Table under the Log2Ratio , right click on the Annotation icon in the Solution Explorer and select Add View . The same can be done for adding a view for the Design icon as shown below. If you have not already done so, click the Add View button from the toolbar to open the Select Data window. Select Log2Ratio and click OK . For each different type of imported dataset in Array Studio, different views are available. Some of these different types of views will be discussed in the tutorial. For Log2Ratio data, available views include B-AlleleFrequencyTableView , BoxPlotView , FullTableView , GenomeView , HeatmapView , ObservationTableView , PairwiseScatterView , RBoxPlotView , RegionView , ScatterView , SnpTableView , TableView , VariableTableView , and VariableView . Notice that the preview window shows the user a basic preview of that view as you scroll through each option. Choose ObservationTableView now, and click OK to continue. After adding the view, a new view is called \"ObservationTable\" appears in the Solution Explorer , under the dataset that was selected above. In addition, this new view is opened in the main view window. The user can switch between different opened views by using the tabs at the top of the screen. This provides a fast mechanism for switching between views. As you can see, a new ObservationTableView is now visible, where each column represents a variable, and each row represents an observation. The first several columns show the design information for each subject, as shown below. The View Controller , found on the right-hand side of the screen in Array Studio , contains tabs that allow the user to customize each view, by changing options using the Task tab, or filtering the data (using the Variables or Observations tabs). The Task tab for the ObservationTableView is shown below. To filter for a particular marker, or CNV, click the Variable tab to switch to the Variable filter. The Variable filter will contain one filter for every column in the Annotation Table . By default, Affymetrix .CEL imported files have annotation for ID, Chromosome, Start, End . Expand the ID column, and enter the marker SNP_A-4216564 . Notice that when filtered, the View Controller provides feedback as to how many variables passed filtering. Also, notice that the view has automatically been filtered to only show the variable SNP_A-4216564 , as well as the attached covariate information. This table can easily be exported to Excel or a text file, using the buttons available on the toolbar. To remove any current filters on the dataset, manually click the (no filter) button for each filter (in this case just ID) or click the Reset All Filters button in the toolbar of the View Controller to show all variables. Reset all filters now. Besides filtering for a specific marker, we can also filter by chromosome and base pair position. Expand the Chromosome filter as well as the Start and End filters now. Unlike the ID filter, the Chromosome filter shows radio buttons by default (instead of a string filter). For columns that contain limited number of levels (i.e. chromosome), users will have the choice of using String Filter , Radio , or CheckBox . Right-clicking on Chromosome will bring up a choice so the user can change the type of filter. Now right click on Chromosome and click on Check None , which make it easier to select a few chromosomes. Select Chromosome 1 . Alternatively, you can simply right-click on Chromosome 1 and select the option Check This Only . For the Start filter, enter \">150mbp\" now. Notice that the view is updated to show only the variables that correspond to this filter. Switch back to the regular TableView for the Log2Ratio dataset to see that every view for that dataset has been updated for the filter. This is an important feature in Array Studio. Filtering one view of a dataset will also filter the other views of that same dataset. In other words, the Filtering is linked among views. Reset any filters by clicking the Reset All Filters button in View Controller now. The Details Window Array Studio includes a feature called Details on Demand . In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the Details Window (at the bottom of the screen). Click on a marker in the row header of the TableView , and notice that the variable name changes to green. This indicates that this row has been selected, and information is available in the Details window. The Details Window should be visible at the bottom of the screen, but if it is not, switch to it by selecting Show Details Window from the View menu. Note that all of the annotation information for the selected row or rows is shown in the Details Window . The Details Window can also be used to show information about a particular subject. Click the header row of one of the subjects now. Note that the Details Window is automatically updated with the design information about that subject. Segmenting Data Before continuing the investigation of the GenomeView data, we are going to take a moment and generate segment data for our Log2Ratio ratio. To begin segmentation, go to the CNV Menu | CNV Segmentation . This brings up the Segmentation window. The user has the option of fine-tuning the segmentation algorithm, although Omicsoft recommends the set of parameters that have been tested to work effectively. Make sure that the Project is Tutorial CNV and that the Data is Log2Ratio . The user can select from the following Options: Heuristic search p-value cutoff the initial search for segments\u2014decreasing this will decrease the number of segments, while increasing this will increase the number of segments). After finding all possible boundaries, the segmentation algorithm will merge contiguous regions if the difference between regions does not meet or exceed the Significant segment p-value cutoff (decreasing this will decrease the number of segments, while increasing this will increase the number of segments). A new segment will be created only if the difference is larger than Minimal difference of log2Ratios . A new segment will be created only if the number of markers is larger than the threshold set by Minimal marker number . The user can choose to Identify copy neutral LOH segments , and can set criteria: Homozygosity rate cutoff (%) Minimal marker number Minimal span (MB) The user can optionally Append design columns to the output table (useful for filtering or if exporting the segment report). User can decide whether to use start position for segmentation end coordinates. The end coordinate of a segment can either be the start or the end position of the last marker. The user can predict copy number based on one of the following three choices: Estimate based on Log2Ratio value: Copy Number = round(2^(Log2RatioMean + 1), example: When Log2RatioMean = 0, Copy Number =2 When Log2RatioMean = -1, Copy Number = 1 When Log2RatioMean = 0.32, Copy Number = 3 (rounded) When Log2RatioMean = 1, Copy Number = 4 Estimate based on B-Allele Frequency . This option will only work well for Illumina data. Call Loss/Gain/Amplification/Deletion based on Log2Ratio values, see details here link Under the More Options tab, the following window is presented: Calling Options include: If the Log2Ratio is close to zero, then there is No Change? in copy number. User can set the cutoff for positive Log2Ratio or negative Log2Ratio Minimal supporting marker# for BAF based calling Minimal supporting marker% for BAF based calling Log2Ratio Threshold to call amplification and deletion Calling options for B-Allele Frequency is only effective when a user chooses to estimate copy number based on B-Allele Frequency Click Submit to begin the segmentation. This should take approximately 10 seconds per sample (100 seconds). After the segmentation is complete, a new Genome view will be generated under -Omic Data section and new data will be generated under Table | Segment | Log2Ratio.Segment . Also, a ScatterView will be created showing Log2Ratio.Mean vs. AlleleDifference.Mean, and this scatter view can be used to examine the segmentation patterns and calls. Double-click the Table view for Segment data now to make it visible in the main view window. Each row of the table corresponds to a segment and includes detailed annotation information for each segment. This table will be used in other visualizations and analysis. It can also be edited to create new segments, using some of the visualizations and analysis in Array Studio . Next, click on the Scatter view for Log2Ratio.Segment in the Solution Explorer to open the Scatter View showing the Log2Ratio.Mean vs. BAlleleFrequencyDeviation.Mean . By default, this graph is trellised by observation, so there should initially be 10 charts shown, one for each observation in the experiment. The user can change the trellising by using the Task tab in the View Controller , and choosing Trellis by Row Covariate . Switching to the Legend in the View Controller will show a Legend for the different colors. Individual segments can be selected, and the segment can be removed using the Remove Segment option under Task tab of the View Controller . Note: The user can easily change the colors of the points in the plot or the column properties by right clicking in the Legend. The GenomeView and Loss of Heterozygosity The GenomeView can be used to interrogate regions for Loss of Heterozygosity, and the sample dataset provides a nice demonstration of these features. First, switch to the Genome view under the Solution Explorer | Omic data section. The initial view shows the Log2Ratio data and the segment data, for the chip 080207_LC_F2_U141_BETA6 on chromosome 1, plotted against the chromosomal location of each data point on the X-axis. This view is completely interactive, so selecting an individual point on the graph will show information about that CNV in the Details Window . Notice that there are 500 charts in this view. This is because the GenomeView includes both a Log2Ratio chart and a B-Allele Frequency chart for each of the 25 chromosomes and each of the 10 samples. A third chart, for visualizing LOH scores, is also available but not shown by default. Note: to have the B-Allele Frequency chart generated, the option to \"Estimate B-Allele Frequency\" must have been selected when initially uploading the data to the CNV module. Using the View Controller and the Variable and Observation filters, we can filter for specific chips and chromosomes. We know from our design information that the chip UC_2_R2271, contains a Copy-Neutral LOH, or uniparental disomy (UPD), on chromosome 15. So, let\u2019s filter for this now. First, switch to the Observation tab in the View Controller . Expand the ID filter, and type UC_2_R2271 to filter the views to only include that chip. Next, go to the Variable filter. Set the Chromosome filter to Chromosome 15 . By default, our segmentation table has been automatically attached to our Log2Ratio data, and segments are indicated by different colors (use the Legend to see what each color represents. Right-click in the legend to change the coloring scheme). It is very clear that a large section of this chromosome has copy-neutral LOH, or UPD. Any view in Array Studio can be easily opened in PowerPoint or Excel using one click. Click the Open Current View in PowerPoint button on the toolbar in the main view window to open the current chart in PowerPoint. GenomeView and Copy Number Gain To better visualize segments of copy number gain or loss, we will now take a look at sample Beta 2 , and chromosome 13. Sample Beta 2 is a patient with Trisomy 13 , so it should show an increased Log2Ratio across chromosome 13. To do this, we will need to change our Observation and Variable filters to this sample and chromosome. First, switch to the Variable Filter in the View Controller to filter chromosome 13. Next, switch to the Observation Filter in the View Controller to filter sample Beta 2 . This immediately updates the main view window, as shown below. First, more than half of the chromosome is colored in a light red. Checking the legend, this indicates that there is a gain in copy number (Copy Number =3) for this segment. This makes sense since this patient has the disorder Trisomy 13 . Notice that for each segment, there is a red line across the entire chromosome. This indicates the average Log2Ratio . It\u2019s clear in this example that the average Log2Ratio and B Allele Frequency are much higher than that in other samples. As stated before, this view is completely interactive. Select all data points in a segment by just one clicking an empty portion of that segment: Notice that the Details Window is updated with information about the selected segment. Summary information about the selected region can be shown on demand. In the Task tab of the View Controller , click the Summary On Demand option now. This opens the CNV Summary On Demand window. This provides basic statistical information about the selected region. For this particular region, we can clearly see that the Log2 Ratio mean is 0.3573, which is well above the expected value of 0. Array Studio also supports editing of the segments using drag-and drop. Drag the side of a segment to expand or contract that segment. Merge multiple segments together by dragging across boundaries. ChromosomeView For Segmentation Data Array Studio also provides Chromosome View for visualizing segment data. This view is trellised by chip, by default. So, there are initially 10 charts visible. For each chart, it shows any chromosome that has a segment (gain/loss). The legend indicates whether the segment contains a gain or loss (by default, red indicates gain, green loss, and blue indicates LOH). Scroll through the charts until the chart for Beta 2 is visible, as shown below. Once again, it is very clear that this patient has trisomy 13, as most of chromosome 13 shows a gain (CN 3). As with all views in Array Studio , this view is interactive. Selecting a particular region of a chromosome will give additional information about that region. Now click on any region to select (highlighted in purple) and see the details in the Details window below. In the example shown below, the segment from chromosome 13 was selected, and information about those segments is shown in the Details Window .","title":"Data Visulization"},{"location":"tutorials/CNV/Visualization_of_Data/#visualization-of-data","text":"","title":"Visualization of Data"},{"location":"tutorials/CNV/Visualization_of_Data/#the-tableview","text":"Upon import, Array Studio will automatically generate a TableView for the CNV data. The TableView in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each variable is a row. Copy Number information is shown in each cell. First, take a look at the Log2Ratio data. If you have not already done so, double-click the Table view for the Log2Ratio data from the Solution Explorer . Scroll through the data now to see the speed that Array Studio can display data. Notice that this Tableview contains the Log2Ratio data, extracted from the CNCHP files, for each variable. Please refer to Microarray Tutorial for different options and filters for table view.","title":"The TableView"},{"location":"tutorials/CNV/Visualization_of_Data/#the-observationtableview","text":"Besides the regular TableView , where each row represents a variable and each column represents an observation, Array Studio also offers the ObservationTableView . In this view, each column represents a variable, while each row represents an observation. Array Studio can easily handle millions of columns in this view. To add an ObservationTableView to the imported dataset, click the Add View button from the toolbar. Alternatively and usually preferred for quick opening of new views for different data or table objects, the user can right click on the dataset or table in the Solution Explorer for the relevant data or table object. For instance, to open a new view for Log2Ratio data, the user could right-click on Log2Ratio and choose Add View , as shown below. Note: for Data object types, the user can also open new views for Annotation or Design as well (see figures below\u2014for information purpose only, not necessary for this tutorial). Similarly, to add a view for the Annotation Table under the Log2Ratio , right click on the Annotation icon in the Solution Explorer and select Add View . The same can be done for adding a view for the Design icon as shown below. If you have not already done so, click the Add View button from the toolbar to open the Select Data window. Select Log2Ratio and click OK . For each different type of imported dataset in Array Studio, different views are available. Some of these different types of views will be discussed in the tutorial. For Log2Ratio data, available views include B-AlleleFrequencyTableView , BoxPlotView , FullTableView , GenomeView , HeatmapView , ObservationTableView , PairwiseScatterView , RBoxPlotView , RegionView , ScatterView , SnpTableView , TableView , VariableTableView , and VariableView . Notice that the preview window shows the user a basic preview of that view as you scroll through each option. Choose ObservationTableView now, and click OK to continue. After adding the view, a new view is called \"ObservationTable\" appears in the Solution Explorer , under the dataset that was selected above. In addition, this new view is opened in the main view window. The user can switch between different opened views by using the tabs at the top of the screen. This provides a fast mechanism for switching between views. As you can see, a new ObservationTableView is now visible, where each column represents a variable, and each row represents an observation. The first several columns show the design information for each subject, as shown below. The View Controller , found on the right-hand side of the screen in Array Studio , contains tabs that allow the user to customize each view, by changing options using the Task tab, or filtering the data (using the Variables or Observations tabs). The Task tab for the ObservationTableView is shown below. To filter for a particular marker, or CNV, click the Variable tab to switch to the Variable filter. The Variable filter will contain one filter for every column in the Annotation Table . By default, Affymetrix .CEL imported files have annotation for ID, Chromosome, Start, End . Expand the ID column, and enter the marker SNP_A-4216564 . Notice that when filtered, the View Controller provides feedback as to how many variables passed filtering. Also, notice that the view has automatically been filtered to only show the variable SNP_A-4216564 , as well as the attached covariate information. This table can easily be exported to Excel or a text file, using the buttons available on the toolbar. To remove any current filters on the dataset, manually click the (no filter) button for each filter (in this case just ID) or click the Reset All Filters button in the toolbar of the View Controller to show all variables. Reset all filters now. Besides filtering for a specific marker, we can also filter by chromosome and base pair position. Expand the Chromosome filter as well as the Start and End filters now. Unlike the ID filter, the Chromosome filter shows radio buttons by default (instead of a string filter). For columns that contain limited number of levels (i.e. chromosome), users will have the choice of using String Filter , Radio , or CheckBox . Right-clicking on Chromosome will bring up a choice so the user can change the type of filter. Now right click on Chromosome and click on Check None , which make it easier to select a few chromosomes. Select Chromosome 1 . Alternatively, you can simply right-click on Chromosome 1 and select the option Check This Only . For the Start filter, enter \">150mbp\" now. Notice that the view is updated to show only the variables that correspond to this filter. Switch back to the regular TableView for the Log2Ratio dataset to see that every view for that dataset has been updated for the filter. This is an important feature in Array Studio. Filtering one view of a dataset will also filter the other views of that same dataset. In other words, the Filtering is linked among views. Reset any filters by clicking the Reset All Filters button in View Controller now.","title":"The ObservationTableView"},{"location":"tutorials/CNV/Visualization_of_Data/#the-details-window","text":"Array Studio includes a feature called Details on Demand . In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the Details Window (at the bottom of the screen). Click on a marker in the row header of the TableView , and notice that the variable name changes to green. This indicates that this row has been selected, and information is available in the Details window. The Details Window should be visible at the bottom of the screen, but if it is not, switch to it by selecting Show Details Window from the View menu. Note that all of the annotation information for the selected row or rows is shown in the Details Window . The Details Window can also be used to show information about a particular subject. Click the header row of one of the subjects now. Note that the Details Window is automatically updated with the design information about that subject.","title":"The Details Window"},{"location":"tutorials/CNV/Visualization_of_Data/#segmenting-data","text":"Before continuing the investigation of the GenomeView data, we are going to take a moment and generate segment data for our Log2Ratio ratio. To begin segmentation, go to the CNV Menu | CNV Segmentation . This brings up the Segmentation window. The user has the option of fine-tuning the segmentation algorithm, although Omicsoft recommends the set of parameters that have been tested to work effectively. Make sure that the Project is Tutorial CNV and that the Data is Log2Ratio . The user can select from the following Options: Heuristic search p-value cutoff the initial search for segments\u2014decreasing this will decrease the number of segments, while increasing this will increase the number of segments). After finding all possible boundaries, the segmentation algorithm will merge contiguous regions if the difference between regions does not meet or exceed the Significant segment p-value cutoff (decreasing this will decrease the number of segments, while increasing this will increase the number of segments). A new segment will be created only if the difference is larger than Minimal difference of log2Ratios . A new segment will be created only if the number of markers is larger than the threshold set by Minimal marker number . The user can choose to Identify copy neutral LOH segments , and can set criteria: Homozygosity rate cutoff (%) Minimal marker number Minimal span (MB) The user can optionally Append design columns to the output table (useful for filtering or if exporting the segment report). User can decide whether to use start position for segmentation end coordinates. The end coordinate of a segment can either be the start or the end position of the last marker. The user can predict copy number based on one of the following three choices: Estimate based on Log2Ratio value: Copy Number = round(2^(Log2RatioMean + 1), example: When Log2RatioMean = 0, Copy Number =2 When Log2RatioMean = -1, Copy Number = 1 When Log2RatioMean = 0.32, Copy Number = 3 (rounded) When Log2RatioMean = 1, Copy Number = 4 Estimate based on B-Allele Frequency . This option will only work well for Illumina data. Call Loss/Gain/Amplification/Deletion based on Log2Ratio values, see details here link Under the More Options tab, the following window is presented: Calling Options include: If the Log2Ratio is close to zero, then there is No Change? in copy number. User can set the cutoff for positive Log2Ratio or negative Log2Ratio Minimal supporting marker# for BAF based calling Minimal supporting marker% for BAF based calling Log2Ratio Threshold to call amplification and deletion Calling options for B-Allele Frequency is only effective when a user chooses to estimate copy number based on B-Allele Frequency Click Submit to begin the segmentation. This should take approximately 10 seconds per sample (100 seconds). After the segmentation is complete, a new Genome view will be generated under -Omic Data section and new data will be generated under Table | Segment | Log2Ratio.Segment . Also, a ScatterView will be created showing Log2Ratio.Mean vs. AlleleDifference.Mean, and this scatter view can be used to examine the segmentation patterns and calls. Double-click the Table view for Segment data now to make it visible in the main view window. Each row of the table corresponds to a segment and includes detailed annotation information for each segment. This table will be used in other visualizations and analysis. It can also be edited to create new segments, using some of the visualizations and analysis in Array Studio . Next, click on the Scatter view for Log2Ratio.Segment in the Solution Explorer to open the Scatter View showing the Log2Ratio.Mean vs. BAlleleFrequencyDeviation.Mean . By default, this graph is trellised by observation, so there should initially be 10 charts shown, one for each observation in the experiment. The user can change the trellising by using the Task tab in the View Controller , and choosing Trellis by Row Covariate . Switching to the Legend in the View Controller will show a Legend for the different colors. Individual segments can be selected, and the segment can be removed using the Remove Segment option under Task tab of the View Controller . Note: The user can easily change the colors of the points in the plot or the column properties by right clicking in the Legend.","title":"Segmenting Data"},{"location":"tutorials/CNV/Visualization_of_Data/#the-genomeview-and-loss-of-heterozygosity","text":"The GenomeView can be used to interrogate regions for Loss of Heterozygosity, and the sample dataset provides a nice demonstration of these features. First, switch to the Genome view under the Solution Explorer | Omic data section. The initial view shows the Log2Ratio data and the segment data, for the chip 080207_LC_F2_U141_BETA6 on chromosome 1, plotted against the chromosomal location of each data point on the X-axis. This view is completely interactive, so selecting an individual point on the graph will show information about that CNV in the Details Window . Notice that there are 500 charts in this view. This is because the GenomeView includes both a Log2Ratio chart and a B-Allele Frequency chart for each of the 25 chromosomes and each of the 10 samples. A third chart, for visualizing LOH scores, is also available but not shown by default. Note: to have the B-Allele Frequency chart generated, the option to \"Estimate B-Allele Frequency\" must have been selected when initially uploading the data to the CNV module. Using the View Controller and the Variable and Observation filters, we can filter for specific chips and chromosomes. We know from our design information that the chip UC_2_R2271, contains a Copy-Neutral LOH, or uniparental disomy (UPD), on chromosome 15. So, let\u2019s filter for this now. First, switch to the Observation tab in the View Controller . Expand the ID filter, and type UC_2_R2271 to filter the views to only include that chip. Next, go to the Variable filter. Set the Chromosome filter to Chromosome 15 . By default, our segmentation table has been automatically attached to our Log2Ratio data, and segments are indicated by different colors (use the Legend to see what each color represents. Right-click in the legend to change the coloring scheme). It is very clear that a large section of this chromosome has copy-neutral LOH, or UPD. Any view in Array Studio can be easily opened in PowerPoint or Excel using one click. Click the Open Current View in PowerPoint button on the toolbar in the main view window to open the current chart in PowerPoint.","title":"The GenomeView and Loss of Heterozygosity"},{"location":"tutorials/CNV/Visualization_of_Data/#genomeview-and-copy-number-gain","text":"To better visualize segments of copy number gain or loss, we will now take a look at sample Beta 2 , and chromosome 13. Sample Beta 2 is a patient with Trisomy 13 , so it should show an increased Log2Ratio across chromosome 13. To do this, we will need to change our Observation and Variable filters to this sample and chromosome. First, switch to the Variable Filter in the View Controller to filter chromosome 13. Next, switch to the Observation Filter in the View Controller to filter sample Beta 2 . This immediately updates the main view window, as shown below. First, more than half of the chromosome is colored in a light red. Checking the legend, this indicates that there is a gain in copy number (Copy Number =3) for this segment. This makes sense since this patient has the disorder Trisomy 13 . Notice that for each segment, there is a red line across the entire chromosome. This indicates the average Log2Ratio . It\u2019s clear in this example that the average Log2Ratio and B Allele Frequency are much higher than that in other samples. As stated before, this view is completely interactive. Select all data points in a segment by just one clicking an empty portion of that segment: Notice that the Details Window is updated with information about the selected segment. Summary information about the selected region can be shown on demand. In the Task tab of the View Controller , click the Summary On Demand option now. This opens the CNV Summary On Demand window. This provides basic statistical information about the selected region. For this particular region, we can clearly see that the Log2 Ratio mean is 0.3573, which is well above the expected value of 0. Array Studio also supports editing of the segments using drag-and drop. Drag the side of a segment to expand or contract that segment. Merge multiple segments together by dragging across boundaries.","title":"GenomeView and Copy Number Gain"},{"location":"tutorials/CNV/Visualization_of_Data/#chromosomeview-for-segmentation-data","text":"Array Studio also provides Chromosome View for visualizing segment data. This view is trellised by chip, by default. So, there are initially 10 charts visible. For each chart, it shows any chromosome that has a segment (gain/loss). The legend indicates whether the segment contains a gain or loss (by default, red indicates gain, green loss, and blue indicates LOH). Scroll through the charts until the chart for Beta 2 is visible, as shown below. Once again, it is very clear that this patient has trisomy 13, as most of chromosome 13 shows a gain (CN 3). As with all views in Array Studio , this view is interactive. Selecting a particular region of a chromosome will give additional information about that region. Now click on any region to select (highlighted in purple) and see the details in the Details window below. In the example shown below, the segment from chromosome 13 was selected, and information about those segments is shown in the Details Window .","title":"ChromosomeView For Segmentation Data"},{"location":"tutorials/Cloud/","text":"Array Studio on Cloud Tutorial .. toctree:: :maxdepth: 2 Introduction Connecting_to_Cloud_and_Uploading_Files Creatinga_Cloud_Project Managing_Cloud_Instance_and_Proxy","title":"Home"},{"location":"tutorials/Cloud/Array_Server_on_Cloud/","text":"Array Server on Cloud The user can also run server jobs on cloud. This tutorial is drafted for standard users. For how-to configure Server with Cloud, please contact Omicsoft Support to get the manual for Server on Cloud admin. After ArrayServer admin configured the Server with Cloud, standard users do not need to set up Cloud Preferences but only need to connect to the server with cloud integration through Server tab: When connected, the window looks the same as the server window: Notice that the Cloud tab will not appear. Uploading Files to server cloud To run server jobs on cloud, the users should upload the data files on specific cloud folder that assigned in advance. Go to Server File | Browse Files window: Then go to the cloud folder configured in advance. Please contact the admin person if the user does not know where the folder is configured as Cloud folder. In the folder, the users can create their own folder and upload the data the same way as running a server project: Run server project on cloud To run server project on cloud, make sure that you already upload your files to the cloud folder. Please create a server project in Analysis tab first. The analysis window and analysis steps are same as running a server project. When adding data to project, remember to browse the right cloud folder for your files: After sending the data to queue, the job progress could be monitored the same way as server project: Run multiple jobs on cloud When running multiple jobs (For example, multiple samples sequencing data alignment), multiple cloud instances will be allocated. This makes it much faster to perform the analyses. To test this, please download the RNA-seq demo dataset from: link More detailed description of the dataset can be found in RNA-Seq Analysis Tutorial. For illustration purpose, we will only use two samples to reduce the process time. Again, remember to go to the right cloud folder to load the data: The demo dataset is paired-end sequencing data; please check the Reads are paired check box. For Server project to run on cloud, the users must specify output folder. The directory should be under the cloud folder. Upon job submission, again, the job could be monitored: The users can right click on the job and select View Full Log : In the Log window, as you can see, the jobs are being submitted to cloud NGS instances, 2 cloud instances will be started as we have two samples to align: As a general user, you cannot monitor the Cloud Instances for Server Cloud this time. The users could go back to Analysis tab and continue any downstream analyses and visualization: Congratulations! Now you can successfully run server project on cloud!","title":"Array Server on Cloud"},{"location":"tutorials/Cloud/Array_Server_on_Cloud/#array-server-on-cloud","text":"The user can also run server jobs on cloud. This tutorial is drafted for standard users. For how-to configure Server with Cloud, please contact Omicsoft Support to get the manual for Server on Cloud admin. After ArrayServer admin configured the Server with Cloud, standard users do not need to set up Cloud Preferences but only need to connect to the server with cloud integration through Server tab: When connected, the window looks the same as the server window: Notice that the Cloud tab will not appear.","title":"Array Server on Cloud"},{"location":"tutorials/Cloud/Array_Server_on_Cloud/#uploading-files-to-server-cloud","text":"To run server jobs on cloud, the users should upload the data files on specific cloud folder that assigned in advance. Go to Server File | Browse Files window: Then go to the cloud folder configured in advance. Please contact the admin person if the user does not know where the folder is configured as Cloud folder. In the folder, the users can create their own folder and upload the data the same way as running a server project:","title":"Uploading Files to server cloud"},{"location":"tutorials/Cloud/Array_Server_on_Cloud/#run-server-project-on-cloud","text":"To run server project on cloud, make sure that you already upload your files to the cloud folder. Please create a server project in Analysis tab first. The analysis window and analysis steps are same as running a server project. When adding data to project, remember to browse the right cloud folder for your files: After sending the data to queue, the job progress could be monitored the same way as server project:","title":"Run server project on cloud"},{"location":"tutorials/Cloud/Array_Server_on_Cloud/#run-multiple-jobs-on-cloud","text":"When running multiple jobs (For example, multiple samples sequencing data alignment), multiple cloud instances will be allocated. This makes it much faster to perform the analyses. To test this, please download the RNA-seq demo dataset from: link More detailed description of the dataset can be found in RNA-Seq Analysis Tutorial. For illustration purpose, we will only use two samples to reduce the process time. Again, remember to go to the right cloud folder to load the data: The demo dataset is paired-end sequencing data; please check the Reads are paired check box. For Server project to run on cloud, the users must specify output folder. The directory should be under the cloud folder. Upon job submission, again, the job could be monitored: The users can right click on the job and select View Full Log : In the Log window, as you can see, the jobs are being submitted to cloud NGS instances, 2 cloud instances will be started as we have two samples to align: As a general user, you cannot monitor the Cloud Instances for Server Cloud this time. The users could go back to Analysis tab and continue any downstream analyses and visualization: Congratulations! Now you can successfully run server project on cloud!","title":"Run multiple jobs on cloud"},{"location":"tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/","text":"Connecting to Cloud and Uploading Files Connecting to Cloud Before creating a cloud project, first the user needs to connect to the cloud. Go to Analysis | Tools tab on the top of Array Studio and click on Cloud Preferences . In the Cloud Preferences window, type in the Access/API key, Secret key, Omicsoft cloud directory, Cloud user name and Email : Now, a new tab, Cloud , should appear on top of the Array Studio: Upon successful login, the default Cloud window will look like this: Uploading Files One requirement for performing cloud-based analysis is that the raw data ( e.g. cel, fastq or bam files) has to be located on the cloud. One can use Array Studio to transfer local files to the cloud easily, similar to uploading file to Server, if one is familiar with running Server projects. Click on Cloud Files . The window will appear with a listing of the current folders in the /Users/username directory: In the example above, we are in the user folder /omicsoft.test.vivian/OmicsoftHome/Vivianzh and with the user id as Vivianzh . The user folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting Create New Folder from the dropdown menu. Create a new folder and name it SampleData . Enter the SampleData folder and click Upload to transfer files from local computer to the cloud. Select the ServerTest.bam file and click Open . As the files load, the progress is monitored in the lower portion of the ServerFiles window. Once the uploading has finished, the files will appear in the SampleData folder:","title":"Cloud Connection"},{"location":"tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/#connecting-to-cloud-and-uploading-files","text":"","title":"Connecting to Cloud and Uploading Files"},{"location":"tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/#connecting-to-cloud","text":"Before creating a cloud project, first the user needs to connect to the cloud. Go to Analysis | Tools tab on the top of Array Studio and click on Cloud Preferences . In the Cloud Preferences window, type in the Access/API key, Secret key, Omicsoft cloud directory, Cloud user name and Email : Now, a new tab, Cloud , should appear on top of the Array Studio: Upon successful login, the default Cloud window will look like this:","title":"Connecting to Cloud"},{"location":"tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/#uploading-files","text":"One requirement for performing cloud-based analysis is that the raw data ( e.g. cel, fastq or bam files) has to be located on the cloud. One can use Array Studio to transfer local files to the cloud easily, similar to uploading file to Server, if one is familiar with running Server projects. Click on Cloud Files . The window will appear with a listing of the current folders in the /Users/username directory: In the example above, we are in the user folder /omicsoft.test.vivian/OmicsoftHome/Vivianzh and with the user id as Vivianzh . The user folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting Create New Folder from the dropdown menu. Create a new folder and name it SampleData . Enter the SampleData folder and click Upload to transfer files from local computer to the cloud. Select the ServerTest.bam file and click Open . As the files load, the progress is monitored in the lower portion of the ServerFiles window. Once the uploading has finished, the files will appear in the SampleData folder:","title":"Uploading Files"},{"location":"tutorials/Cloud/Creatinga_Cloud_Project/","text":"Creating a Cloud Project To create a cloud project, in Analysis tab go to File | New Cloud Project . A Cloud Project Information window should appear: Enter Project ID and Title , and an optional description. Click the Create button. Now an empty project will be created (below): Notice that the project name includes Cloud Project - Distributed in the name so that the user can quickly see that this is a cloud project and the type is Distributed . Distributed indicates that data objects are saved in separate files. By default, a cloud project is a distributed project. From here, we can perform all the analysis tasks on the cloud using the interface of Array Studio. For example, we can add the alignment analysis file(the test dataset) by going to the toolbar Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads : Choose the file uploaded in previous section ( ServerTest.bam ). Then click Send to Queue . After a few seconds to minutes, depending on the project, CloudQueue window will show up, listing all the jobs running on cloud by the user: Now we switch back to the Analysis tab. Once the job is completed, we will see an Update Project on the far right in the menu selection of Array Studio (below): Clicking Update Project will show the results of finished job: one NgsData object is created for this BAM file. If we would like to see the parameters used for the alignment, select the data set name NgsData and right click, then choose View Source Users can run all data analysis based on this NgsData in the same way as they run in Array Studio locally. Congratulations! You have successfully created a cloud project. Remember to save the project through the Save button: You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc..","title":"Cloud Project"},{"location":"tutorials/Cloud/Creatinga_Cloud_Project/#creating-a-cloud-project","text":"To create a cloud project, in Analysis tab go to File | New Cloud Project . A Cloud Project Information window should appear: Enter Project ID and Title , and an optional description. Click the Create button. Now an empty project will be created (below): Notice that the project name includes Cloud Project - Distributed in the name so that the user can quickly see that this is a cloud project and the type is Distributed . Distributed indicates that data objects are saved in separate files. By default, a cloud project is a distributed project. From here, we can perform all the analysis tasks on the cloud using the interface of Array Studio. For example, we can add the alignment analysis file(the test dataset) by going to the toolbar Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads : Choose the file uploaded in previous section ( ServerTest.bam ). Then click Send to Queue . After a few seconds to minutes, depending on the project, CloudQueue window will show up, listing all the jobs running on cloud by the user: Now we switch back to the Analysis tab. Once the job is completed, we will see an Update Project on the far right in the menu selection of Array Studio (below): Clicking Update Project will show the results of finished job: one NgsData object is created for this BAM file. If we would like to see the parameters used for the alignment, select the data set name NgsData and right click, then choose View Source Users can run all data analysis based on this NgsData in the same way as they run in Array Studio locally. Congratulations! You have successfully created a cloud project. Remember to save the project through the Save button: You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc..","title":"Creating a Cloud Project"},{"location":"tutorials/Cloud/Introduction/","text":"Introduction Omicsoft Cloud Studio/Server On Cloud is OmicSoft's solution to manage and analyze large Omics data using cloud computing. The standalone edition of Array Studio on the Cloud allows you to seamlessly run all Array Studio analytics from Amazon, combining the storage of S3 with the analytical power of EC2. Easily scale up any number of instances for every analysis. Array Server with Cloud will handle security credentials on server and submit/manage cloud files/jobs as seamlessly as running on ArrayServer. This tutorial only covers the Array Studio on the Cloud. For Server on Cloud, please read \"Server Analysis (Basics)\" tutorial. Array Studio on the Cloud Array Studio on the Cloud is a cloud solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. The users can easily share analyzed data with clients and colleagues. Cloud computing can remove the limitation of on-site computing capacity and dramatically improve computing efficacy. Array Studio can handle: pinning up the correct number of instances Accessing the data from S3 Running the analysis with the optimal EC2 configuration (storage, memory, and CPUs) Spinning down the instances Storing the generated data back on S3 Genome browser integration with S3 Cloud-based analysis allows the user to run jobs on cloud, which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the cloud. Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. All the Array Studio modules available for local analysis are also accessible for could-based analysis. The graphic interfaces are almost the same. Cloud Project A \"Cloud Project\" is a project that is created on the cloud, rather than on the user\u2019s client machine. This project is cached locally on the client machine, in case of loss of connection to the cloud, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user\u2019s home folder, typically My Documents/Omicsoft/Cloud Projects?. A Server Project, when stored locally in the cache folder, has a different filename suffix (.oscprj) as compared to a regular project (.osprj) and can only be opened when the user is connected to the cloud. The concept behind the Cloud Project is that any data that is added to a project, must first be stored on the cloud. When the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Studio on Cloud instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the cloud file system. All data addition and extraction is done on the cloud, instead of the users client machine. It allows the user to use the power of the cloud, instead of their individual client machine for the importing of data. This is extremely important for some memory/cpu intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, minimal data will be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc. Test Dataset In this tutorial, we will show how to create a cloud project for cloud-based analysis. To demonstrate, we will use the same dataset for server testing to test cloud. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be access from here","title":"Introduction"},{"location":"tutorials/Cloud/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/Cloud/Introduction/#omicsoft-cloud","text":"Studio/Server On Cloud is OmicSoft's solution to manage and analyze large Omics data using cloud computing. The standalone edition of Array Studio on the Cloud allows you to seamlessly run all Array Studio analytics from Amazon, combining the storage of S3 with the analytical power of EC2. Easily scale up any number of instances for every analysis. Array Server with Cloud will handle security credentials on server and submit/manage cloud files/jobs as seamlessly as running on ArrayServer. This tutorial only covers the Array Studio on the Cloud. For Server on Cloud, please read \"Server Analysis (Basics)\" tutorial.","title":"Omicsoft Cloud"},{"location":"tutorials/Cloud/Introduction/#array-studio-on-the-cloud","text":"Array Studio on the Cloud is a cloud solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. The users can easily share analyzed data with clients and colleagues. Cloud computing can remove the limitation of on-site computing capacity and dramatically improve computing efficacy. Array Studio can handle: pinning up the correct number of instances Accessing the data from S3 Running the analysis with the optimal EC2 configuration (storage, memory, and CPUs) Spinning down the instances Storing the generated data back on S3 Genome browser integration with S3 Cloud-based analysis allows the user to run jobs on cloud, which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the cloud. Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. All the Array Studio modules available for local analysis are also accessible for could-based analysis. The graphic interfaces are almost the same.","title":"Array Studio on the Cloud"},{"location":"tutorials/Cloud/Introduction/#cloud-project","text":"A \"Cloud Project\" is a project that is created on the cloud, rather than on the user\u2019s client machine. This project is cached locally on the client machine, in case of loss of connection to the cloud, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user\u2019s home folder, typically My Documents/Omicsoft/Cloud Projects?. A Server Project, when stored locally in the cache folder, has a different filename suffix (.oscprj) as compared to a regular project (.osprj) and can only be opened when the user is connected to the cloud. The concept behind the Cloud Project is that any data that is added to a project, must first be stored on the cloud. When the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Studio on Cloud instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the cloud file system. All data addition and extraction is done on the cloud, instead of the users client machine. It allows the user to use the power of the cloud, instead of their individual client machine for the importing of data. This is extremely important for some memory/cpu intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, minimal data will be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc.","title":"Cloud Project"},{"location":"tutorials/Cloud/Introduction/#test-dataset","text":"In this tutorial, we will show how to create a cloud project for cloud-based analysis. To demonstrate, we will use the same dataset for server testing to test cloud. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be access from here","title":"Test Dataset"},{"location":"tutorials/Cloud/Managing_Cloud_Instance_and_Proxy/","text":"Managing Cloud Instances and Proxy Managing cloud Instances is similar to managing server jobs. For Studio on the Cloud, the user can manage proxy instances in Cloud tab | Cloud Instances if the cloud is enabled as standalone upgrade. The user can Stop/Terminate cloud instances: Admin can SSH to running instances directly by clicking \"Open SSH\". Before you use it for the first time, please put the cloud key file \"Omicsoft.Launching.pem\" in the following folder: C : \\ Users \\ & lt ; UserID & gt ; \\ Documents \\ Omicsoft \\ Cloud \\ Amazon For Array Server with cloud integration, only admin can manage proxy instance in Server tab | Manage | Manage Cloud Instances . The users can also manage proxy through Cloud Tools tab:","title":"Proxy Instance"},{"location":"tutorials/Cloud/Managing_Cloud_Instance_and_Proxy/#managing-cloud-instances-and-proxy","text":"Managing cloud Instances is similar to managing server jobs. For Studio on the Cloud, the user can manage proxy instances in Cloud tab | Cloud Instances if the cloud is enabled as standalone upgrade. The user can Stop/Terminate cloud instances: Admin can SSH to running instances directly by clicking \"Open SSH\". Before you use it for the first time, please put the cloud key file \"Omicsoft.Launching.pem\" in the following folder: C : \\ Users \\ & lt ; UserID & gt ; \\ Documents \\ Omicsoft \\ Cloud \\ Amazon For Array Server with cloud integration, only admin can manage proxy instance in Server tab | Manage | Manage Cloud Instances . The users can also manage proxy through Cloud Tools tab:","title":"Managing Cloud Instances and Proxy"},{"location":"tutorials/Cloud/SetCloudInstanceToPrivate/Introduction/","text":"ArrayServer Cloud Installation Tutorial Set ArrayServer Job EC2 instances to Private ArrayServer may launch EC2 instances for various analysis jobs. There is a parameter (AssociatePublicIpAddress) in ArrayServer.cfg that controls whether to allow AWS to assign public IP address to the EC2 instances. Setting AssociatePublicIpAddress to False would request AWS to not assign IP address to the instances, therefore make the instance private. It requires proper configuration of AWS Virtual Cloud and ArrayServer.cfg file in order to Array Server to launch private EC2 instances. This is because the instances needs to communicate with Omicsoft during its lifetime. This requires the private instances to reside in a private subnet with NAT gateway in the VPC to communicate with internet. Below we show the steps to configure AWS VPC and ArrayServer.cfg to allow the instances that ArrayServer launches to be private: Set up an Amazon Virtual Private Cloud (VPC) with a public and private subnet and NAT gateway. Set up VPC Endpoint Gateway to free-of-charge data transfer between the EC2 instances and S3 buckets. Modify ArrayServer.cfg (SubnetID and AssociatePublicIpAddress). 1. Set up a VPC with a public and private subnet and NAT gateway Create VPC in AWS VPC with public and private subnets using VPC Wizard Select VPC with Public and Private Subnets Choose VPC name, Availability Zones, Public and Private subnet name, and Specify the Elastic IP Allocation ID of your NAT Gateway Please note that the NAT gateway set up is necessary because it enables ECs machines in private subnet to communicate with outside world. Obtain the ID of the subnet 2. Set up VPC Endpoint Gateway to free-of-charge data transfer between the EC2 instances and S3 buckets Create VPC Endpoint, and choose service S3 to allow free-of-charge data transfer between AWS EC2 and S3 services. Add the endpoint to the private subnet's route table 3. Modify ArrayServer.cfg (SubnetID and AssociatePublicIpAddress) Users need to modify the SubnetID and AssociatePublicIpAddress parameters in ArrayServer.cfg in order for ArrayServer to launch private instances to the specified private subset. Modify ArrayServer.cfg Run a cloud job in ArrayServer, and check in AWS Console if the new instance has Public IP","title":"ArrayServer Cloud Installation Tutorial"},{"location":"tutorials/Cloud/SetCloudInstanceToPrivate/Introduction/#arrayserver-cloud-installation-tutorial","text":"","title":"ArrayServer Cloud Installation Tutorial"},{"location":"tutorials/Cloud/SetCloudInstanceToPrivate/Introduction/#set-arrayserver-job-ec2-instances-to-private","text":"ArrayServer may launch EC2 instances for various analysis jobs. There is a parameter (AssociatePublicIpAddress) in ArrayServer.cfg that controls whether to allow AWS to assign public IP address to the EC2 instances. Setting AssociatePublicIpAddress to False would request AWS to not assign IP address to the instances, therefore make the instance private. It requires proper configuration of AWS Virtual Cloud and ArrayServer.cfg file in order to Array Server to launch private EC2 instances. This is because the instances needs to communicate with Omicsoft during its lifetime. This requires the private instances to reside in a private subnet with NAT gateway in the VPC to communicate with internet. Below we show the steps to configure AWS VPC and ArrayServer.cfg to allow the instances that ArrayServer launches to be private: Set up an Amazon Virtual Private Cloud (VPC) with a public and private subnet and NAT gateway. Set up VPC Endpoint Gateway to free-of-charge data transfer between the EC2 instances and S3 buckets. Modify ArrayServer.cfg (SubnetID and AssociatePublicIpAddress).","title":"Set ArrayServer Job EC2 instances to Private"},{"location":"tutorials/Cloud/SetCloudInstanceToPrivate/Introduction/#1-set-up-a-vpc-with-a-public-and-private-subnet-and-nat-gateway","text":"Create VPC in AWS VPC with public and private subnets using VPC Wizard Select VPC with Public and Private Subnets Choose VPC name, Availability Zones, Public and Private subnet name, and Specify the Elastic IP Allocation ID of your NAT Gateway Please note that the NAT gateway set up is necessary because it enables ECs machines in private subnet to communicate with outside world. Obtain the ID of the subnet","title":"1. Set up a VPC with a public and private subnet and NAT gateway"},{"location":"tutorials/Cloud/SetCloudInstanceToPrivate/Introduction/#2-set-up-vpc-endpoint-gateway-to-free-of-charge-data-transfer-between-the-ec2-instances-and-s3-buckets","text":"Create VPC Endpoint, and choose service S3 to allow free-of-charge data transfer between AWS EC2 and S3 services. Add the endpoint to the private subnet's route table","title":"2. Set up VPC Endpoint Gateway to free-of-charge data transfer between the EC2 instances and S3 buckets"},{"location":"tutorials/Cloud/SetCloudInstanceToPrivate/Introduction/#3-modify-arrayservercfg-subnetid-and-associatepublicipaddress","text":"Users need to modify the SubnetID and AssociatePublicIpAddress parameters in ArrayServer.cfg in order for ArrayServer to launch private instances to the specified private subset. Modify ArrayServer.cfg Run a cloud job in ArrayServer, and check in AWS Console if the new instance has Public IP","title":"3. Modify ArrayServer.cfg (SubnetID and AssociatePublicIpAddress)"},{"location":"tutorials/ComparisonLand/AddExpressionData/","text":"Convert Expression Data to ALV The first step in creating your own ComparisonLand is to import your data into Array Studio and attach Annotation and Design metadata. The resulting .osobj file will be converted to Land-compatible .alv files. Create Array Studio Project First, open Array Studio , and create a new distributed project: Import Expression Data into Array Studio The tutorial data are expression intensity measurements from an Affymetrix array for ~100 probesets (genes). Each row contains all of the measurements for one probeset, with each sample in columns. To import these data, click Add Data | Expression Data : The tutorial data are tab-delimited, one gene per row, but Array Studio can import data from a variety of sources: If your data have additional annotation columns (besides the ProbeSetID in the first column), you can specify them, and they will be automatically added as metadata. The tutorial data do not have any extra columns, so do not select anything, and press OK : You will be prompted to add a Design metadata file, but you may add one later if you prefer: For this tutorial, select Yes , then select Tab delimited File , navigate to \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and click OK without appending to the existing covariate table. You will now be prompted to add Annotation metadata. Again, you may add one later, but for the tutorial dataset you can add it immediately: The tutorial dataset probesets are from Affymetrix HG-U133A , which is one of many online annotations available from Array Studio. Select source Online annotation file and search for HG-U133A , which will list all matching annotations: Select OK , which will automatically retrieve the annotation and attach it to the data. Click OK on the subsequent window without selecting either option. Now you will see the tutorial data imported as an -Omic data type, which is a tabular dataset with associated Design and Annotation data: In the Solution Explorer , right-click on MicroArrayData and select Rename , then rename the -Omic object to \"Brawndocin_Slurmycin.Expression\": Your Solution Explorer will update the object name: Now save the project. The .osobj file \"Brawndocin_Slurmycin.Expression.osobj\" will be used to create ComparisonLand .alv files. Convert Expression .OSOBJ file to Land-compatible .ALV files Now you can convert the .osobj file to .alv files, which can be added to your ComparisonLand. To do this, you will run an OmicScript ( Oscript ) from Array Studio . Oscripts are text-format files that instruct Array Studio to perform commands. All Array Studio GUI functions have associated .Oscript functions. There are additional \"Oscript-only\" functions (such as ConvertExpressionOsobj), which do not have a GUI module window in Array Studio. An example Oscript is ExtractExpressionOsobjToAlv.oscript , which you will find in the zipped tutorial set: :: Begin LandTools / Namespace = NgsLib ; Files \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ ComparisonLandFromExternal\\ Brawndocin_Slurmycin.Expression.osobj\" ; Reference Human . B37 . 3 ; GeneModel OmicsoftGene20130723 ; Options / Action = ConvertExpressionOsobj / SampleIDColumn = \"Observation\" / MappingID = Affymetrix . HG-U133A_Human . B37 . 3 / IsRatio = False / MedianNormalization = False / TargetMedian = 0 / OutputFolder = \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ALV\" ; End ; For the tutorial, will need to change the input and output paths to match where your .osobj file is located, and where you want to output the .ALV files. Once you have modified and saved the Oscript file, Select Tools | Run Script : Navigate to your modified ExtractExpressionOsobjToAlv.oshell.oscript file, and click OK . The output .ALV files will be found in the folder you specified. You will find one file per sample:","title":"Add Expression Data"},{"location":"tutorials/ComparisonLand/AddExpressionData/#convert-expression-data-to-alv","text":"The first step in creating your own ComparisonLand is to import your data into Array Studio and attach Annotation and Design metadata. The resulting .osobj file will be converted to Land-compatible .alv files.","title":"Convert Expression Data to ALV"},{"location":"tutorials/ComparisonLand/AddExpressionData/#create-array-studio-project","text":"First, open Array Studio , and create a new distributed project:","title":"Create Array Studio Project"},{"location":"tutorials/ComparisonLand/AddExpressionData/#import-expression-data-into-array-studio","text":"The tutorial data are expression intensity measurements from an Affymetrix array for ~100 probesets (genes). Each row contains all of the measurements for one probeset, with each sample in columns. To import these data, click Add Data | Expression Data : The tutorial data are tab-delimited, one gene per row, but Array Studio can import data from a variety of sources: If your data have additional annotation columns (besides the ProbeSetID in the first column), you can specify them, and they will be automatically added as metadata. The tutorial data do not have any extra columns, so do not select anything, and press OK : You will be prompted to add a Design metadata file, but you may add one later if you prefer: For this tutorial, select Yes , then select Tab delimited File , navigate to \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and click OK without appending to the existing covariate table. You will now be prompted to add Annotation metadata. Again, you may add one later, but for the tutorial dataset you can add it immediately: The tutorial dataset probesets are from Affymetrix HG-U133A , which is one of many online annotations available from Array Studio. Select source Online annotation file and search for HG-U133A , which will list all matching annotations: Select OK , which will automatically retrieve the annotation and attach it to the data. Click OK on the subsequent window without selecting either option. Now you will see the tutorial data imported as an -Omic data type, which is a tabular dataset with associated Design and Annotation data: In the Solution Explorer , right-click on MicroArrayData and select Rename , then rename the -Omic object to \"Brawndocin_Slurmycin.Expression\": Your Solution Explorer will update the object name: Now save the project. The .osobj file \"Brawndocin_Slurmycin.Expression.osobj\" will be used to create ComparisonLand .alv files.","title":"Import Expression Data into Array Studio"},{"location":"tutorials/ComparisonLand/AddExpressionData/#convert-expression-osobj-file-to-land-compatible-alv-files","text":"Now you can convert the .osobj file to .alv files, which can be added to your ComparisonLand. To do this, you will run an OmicScript ( Oscript ) from Array Studio . Oscripts are text-format files that instruct Array Studio to perform commands. All Array Studio GUI functions have associated .Oscript functions. There are additional \"Oscript-only\" functions (such as ConvertExpressionOsobj), which do not have a GUI module window in Array Studio. An example Oscript is ExtractExpressionOsobjToAlv.oscript , which you will find in the zipped tutorial set: :: Begin LandTools / Namespace = NgsLib ; Files \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ ComparisonLandFromExternal\\ Brawndocin_Slurmycin.Expression.osobj\" ; Reference Human . B37 . 3 ; GeneModel OmicsoftGene20130723 ; Options / Action = ConvertExpressionOsobj / SampleIDColumn = \"Observation\" / MappingID = Affymetrix . HG-U133A_Human . B37 . 3 / IsRatio = False / MedianNormalization = False / TargetMedian = 0 / OutputFolder = \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ALV\" ; End ; For the tutorial, will need to change the input and output paths to match where your .osobj file is located, and where you want to output the .ALV files. Once you have modified and saved the Oscript file, Select Tools | Run Script : Navigate to your modified ExtractExpressionOsobjToAlv.oshell.oscript file, and click OK . The output .ALV files will be found in the folder you specified. You will find one file per sample:","title":"Convert Expression .OSOBJ file to Land-compatible .ALV files"},{"location":"tutorials/ComparisonLand/ConvertInferenceData/","text":"Convert Inference Data to .TLV If you have statistical inference data for your expression data, such as fold-change and P-value calculations, you can convert these into ComparisonLand-compatible .tlv files. You can also calculate statistical inferences using multiple modules within Array Studio, including DESeq, ANOVA and General Linear Model. Formatting the Comparison Data File For this tutorial, the expression data were tested by One-Way ANOVA of the six treatment sample groups (Brawndocin at 0.3, 1, 3.3, and 10uM, and Slurmycin at 1 and 10uM) compared to a common group of vehicle samples. The resulting inference table was converted to the following tab-delimited format: The first column should be the probeset/GeneID. Subsequent columns should be in the following order: treat1 .log2FC treat1 .rawPValue treat1 .adjPValue treat1 .caseMean treat1 .controlMean treat2 .log2FC treat2 .rawPValue ... treat100 .adjPValue treat100 .caseMean treat100 .controlMean The full file for this tutorial is \"Brawndocin_Slurmycin.V2.Comparison.Data.txt\". Each row should contain all comparisons for a single gene/probeset. Also, each treat name should be unique among the entire dataset. Once you have converted your inference data into the proper format, you can proceed to formatting the comparison metadata file. Formatting the Comparison Metadata file The Comparison Metadata file is a tab-delimited file that contains the information that groups together all of the samples (in the .alv files), extracts sample metadata for filtering/grouping of comparisons, adds additional comparison metadata, and connects these to the Comparison Data that you prepared in the previous section. Thus, it is essentially that you carefully plan the metadata that should be included in your comparisons. The minimum data for the Comparison Metadata file are as follows: ComparisonName : This should be the first column, and the names in this column should match the comparisonNames in your Comparison Data file (without \".log2FC\", \"PValue\", etc). MetaColumns : A list of Sample Metadata column names, indicating the metadata to include in the comparison metadata. \"Treatment\",\"CellType\", and \"Tissue\" Must be included in this column (and as columns in the Sample Metadata file). \"DiseaseCategory\" is not absolutely required, but some Views group samples by this column, so will not work properly without this column. Any additional Sample Metadata columns that are included must be consistent within a sample group. For example, if your Case samples include both HCC4006 and HCC827 cells in the CellLine column, you cannot include CellLine in your Comparison metadata. CaseSampleIDs : A delimited (',' or ';') list of Sample IDs included in this comparison, matching your Sample Metadata files Sample IDs. ControlSampleIDs : A delimited (',' or ';') list of Sample IDs included in this comparison, matching your Sample Metadata files Sample IDs. TestCategory : A description of the type of comparison being made. Standard Test Categories include \"Disease vs. Normal\", \"Treatment vs. Control\", \"Treatment1 vs Treatment2\", \"Tissue1 vs. Tissue2\", \"Responder vs. Non-Responder\", \"Disease vs. Normal\", \"Disease1 vs. Disease2\", \"CellType1 vs. CellType2\", and \"Other Comparisons\". TlvID : A unique name for your comparison (i.e. unique across your entire ComparisonLand, not just the project). ProjectName : A name that groups the set of comparisons. PlatformName : A description of the source NGS or Microarray platform. ComparisonSoftware : The name of the software that calculated the inferences, such as \"DEseq\" or \"limma\" StatsModel : A description of the statistical model. SampleDataMode : A description of the type of underlying measured data, such as \"Expression_Intensity_Probes\" or \"RnaSeq_Transcript\". Please see the tutorial file \"Brawndocin_Slurmycin.Comparison.MetaFile.txt\" for a properly-formatted example. Running the Oscript to Convert Inference data to Tlv Once you have formatted your comparison data and metadata files, you should edit the Oscript file to specify the input locations for the following files: Comparison Data File (Brawndocin_Slurmycin.V2.Comparison.Data.txt). Comparison MetaData File (Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt). Sample MetaData File (Brawndocin_Slurmycin.Expression.Design.txt). Also, specify the output location for the .tlv files. The following Oscript file can be found as \"ExtractExternalInferenceReport.oscript\": :: Begin ComparisonLandTools /Namespace=NgsLib; Files \"\"; Reference Human.B37.3; GeneModel OmicsoftGene20130723; Options /Action=ExtractExternalInferenceReport /ComparisonDataFile= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ InputFiles\\Brawndocin_Slurmycin.V2.Comparison.Data.txt\" /SampleMetaDataFile= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ InputFiles\\Brawndocin_Slurmycin.V2.Expression.Design.txt\" /ComparisonMetaFile= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ InputFiles\\Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt\" /OutputFolder= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\TLV\" /MappingID=\"Affymetrix.HT_HG-U133A_Human.B37.3\" ; End; Update the oscript paths to indicate where the files are located on your local computer, then run the Oscript as before in Array Studio , and check that the .tlv files have been generated in the specified folder:","title":"Convert Inference Data"},{"location":"tutorials/ComparisonLand/ConvertInferenceData/#convert-inference-data-to-tlv","text":"If you have statistical inference data for your expression data, such as fold-change and P-value calculations, you can convert these into ComparisonLand-compatible .tlv files. You can also calculate statistical inferences using multiple modules within Array Studio, including DESeq, ANOVA and General Linear Model.","title":"Convert Inference Data to .TLV"},{"location":"tutorials/ComparisonLand/ConvertInferenceData/#formatting-the-comparison-data-file","text":"For this tutorial, the expression data were tested by One-Way ANOVA of the six treatment sample groups (Brawndocin at 0.3, 1, 3.3, and 10uM, and Slurmycin at 1 and 10uM) compared to a common group of vehicle samples. The resulting inference table was converted to the following tab-delimited format: The first column should be the probeset/GeneID. Subsequent columns should be in the following order: treat1 .log2FC treat1 .rawPValue treat1 .adjPValue treat1 .caseMean treat1 .controlMean treat2 .log2FC treat2 .rawPValue ... treat100 .adjPValue treat100 .caseMean treat100 .controlMean The full file for this tutorial is \"Brawndocin_Slurmycin.V2.Comparison.Data.txt\". Each row should contain all comparisons for a single gene/probeset. Also, each treat name should be unique among the entire dataset. Once you have converted your inference data into the proper format, you can proceed to formatting the comparison metadata file.","title":"Formatting the Comparison Data File"},{"location":"tutorials/ComparisonLand/ConvertInferenceData/#formatting-the-comparison-metadata-file","text":"The Comparison Metadata file is a tab-delimited file that contains the information that groups together all of the samples (in the .alv files), extracts sample metadata for filtering/grouping of comparisons, adds additional comparison metadata, and connects these to the Comparison Data that you prepared in the previous section. Thus, it is essentially that you carefully plan the metadata that should be included in your comparisons. The minimum data for the Comparison Metadata file are as follows: ComparisonName : This should be the first column, and the names in this column should match the comparisonNames in your Comparison Data file (without \".log2FC\", \"PValue\", etc). MetaColumns : A list of Sample Metadata column names, indicating the metadata to include in the comparison metadata. \"Treatment\",\"CellType\", and \"Tissue\" Must be included in this column (and as columns in the Sample Metadata file). \"DiseaseCategory\" is not absolutely required, but some Views group samples by this column, so will not work properly without this column. Any additional Sample Metadata columns that are included must be consistent within a sample group. For example, if your Case samples include both HCC4006 and HCC827 cells in the CellLine column, you cannot include CellLine in your Comparison metadata. CaseSampleIDs : A delimited (',' or ';') list of Sample IDs included in this comparison, matching your Sample Metadata files Sample IDs. ControlSampleIDs : A delimited (',' or ';') list of Sample IDs included in this comparison, matching your Sample Metadata files Sample IDs. TestCategory : A description of the type of comparison being made. Standard Test Categories include \"Disease vs. Normal\", \"Treatment vs. Control\", \"Treatment1 vs Treatment2\", \"Tissue1 vs. Tissue2\", \"Responder vs. Non-Responder\", \"Disease vs. Normal\", \"Disease1 vs. Disease2\", \"CellType1 vs. CellType2\", and \"Other Comparisons\". TlvID : A unique name for your comparison (i.e. unique across your entire ComparisonLand, not just the project). ProjectName : A name that groups the set of comparisons. PlatformName : A description of the source NGS or Microarray platform. ComparisonSoftware : The name of the software that calculated the inferences, such as \"DEseq\" or \"limma\" StatsModel : A description of the statistical model. SampleDataMode : A description of the type of underlying measured data, such as \"Expression_Intensity_Probes\" or \"RnaSeq_Transcript\". Please see the tutorial file \"Brawndocin_Slurmycin.Comparison.MetaFile.txt\" for a properly-formatted example.","title":"Formatting the Comparison Metadata file"},{"location":"tutorials/ComparisonLand/ConvertInferenceData/#running-the-oscript-to-convert-inference-data-to-tlv","text":"Once you have formatted your comparison data and metadata files, you should edit the Oscript file to specify the input locations for the following files: Comparison Data File (Brawndocin_Slurmycin.V2.Comparison.Data.txt). Comparison MetaData File (Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt). Sample MetaData File (Brawndocin_Slurmycin.Expression.Design.txt). Also, specify the output location for the .tlv files. The following Oscript file can be found as \"ExtractExternalInferenceReport.oscript\": :: Begin ComparisonLandTools /Namespace=NgsLib; Files \"\"; Reference Human.B37.3; GeneModel OmicsoftGene20130723; Options /Action=ExtractExternalInferenceReport /ComparisonDataFile= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ InputFiles\\Brawndocin_Slurmycin.V2.Comparison.Data.txt\" /SampleMetaDataFile= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ InputFiles\\Brawndocin_Slurmycin.V2.Expression.Design.txt\" /ComparisonMetaFile= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ InputFiles\\Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt\" /OutputFolder= \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\TLV\" /MappingID=\"Affymetrix.HT_HG-U133A_Human.B37.3\" ; End; Update the oscript paths to indicate where the files are located on your local computer, then run the Oscript as before in Array Studio , and check that the .tlv files have been generated in the specified folder:","title":"Running the Oscript to Convert Inference data to Tlv"},{"location":"tutorials/ComparisonLand/CreateLand/","text":"Add Expression and Comparison Data to Land After you have successfully created .alv and .tlv files containing your expression and comparison data, respectively, you can add these data to an existing or new ArrayLand. Create a New Land If these data will be added to a new Land, you must create this Land first. Connect to Array Server with administrator privileges, then click on the Land tab: Switch to the Land tab, then click Tools | Create Land : In the window, give your Land a unique name for the server, and enter additional settings: In the tutorial data set, you will find a file \"TutorialLandSettings.cfg\" that contains some basic settings. When successful, you will get the following message: Add Sample and Project MetaData to Land Before you add your actual data to your new Land, you can add the Sample and Project MetaData. In the tutorial dataset, the Sample Metadata are in \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and the Project Metadata are in \"Brawndocin_Slurmycin.V2.ProjectMetaFile.txt\". In the Land tab, click Manage | Samples | Manage Sample Meta Data or Manage Project Meta Data : In the Sample Metadata and Project Metadata windows, you can add, replace, clear, and remove metadata for samples. To add new sample metadata, click Add/Replace , and navigate to the Sample Metadata file. If properly imported, the window will look similar to this: You should also import the project metadata file, which should result in a window like this: Add .alv and .tlv files to server If you are processing the tutorial data, you will have generated 6 .tlv files (one per comparison between sample groups) and 56 .alv files (one per sample). Upload these to your Array Server, by clicking on the Server tab, then clicking Server File | Browse Files : Navigate to a location to store your files, and click Upload : Navigate to your .alv and .tlv files, and upload them to the server. Now switch back to the Land tab, and click Tools | Publish To Land : Navigate to your server files and click Send To Queue : Note: You can only publish data one job at a time, so if you have submitted a set of files to the server for publishing, you must wait for that job to complete before submitting the next job. When all of your .alv and .tlv data have been published, the ServerJobs queue will say \"Finished\", and you can start exploring your Land.","title":"Create Land"},{"location":"tutorials/ComparisonLand/CreateLand/#add-expression-and-comparison-data-to-land","text":"After you have successfully created .alv and .tlv files containing your expression and comparison data, respectively, you can add these data to an existing or new ArrayLand.","title":"Add Expression and Comparison Data to Land"},{"location":"tutorials/ComparisonLand/CreateLand/#create-a-new-land","text":"If these data will be added to a new Land, you must create this Land first. Connect to Array Server with administrator privileges, then click on the Land tab: Switch to the Land tab, then click Tools | Create Land : In the window, give your Land a unique name for the server, and enter additional settings: In the tutorial data set, you will find a file \"TutorialLandSettings.cfg\" that contains some basic settings. When successful, you will get the following message:","title":"Create a New Land"},{"location":"tutorials/ComparisonLand/CreateLand/#add-sample-and-project-metadata-to-land","text":"Before you add your actual data to your new Land, you can add the Sample and Project MetaData. In the tutorial dataset, the Sample Metadata are in \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and the Project Metadata are in \"Brawndocin_Slurmycin.V2.ProjectMetaFile.txt\". In the Land tab, click Manage | Samples | Manage Sample Meta Data or Manage Project Meta Data : In the Sample Metadata and Project Metadata windows, you can add, replace, clear, and remove metadata for samples. To add new sample metadata, click Add/Replace , and navigate to the Sample Metadata file. If properly imported, the window will look similar to this: You should also import the project metadata file, which should result in a window like this:","title":"Add Sample and Project MetaData to Land"},{"location":"tutorials/ComparisonLand/CreateLand/#add-alv-and-tlv-files-to-server","text":"If you are processing the tutorial data, you will have generated 6 .tlv files (one per comparison between sample groups) and 56 .alv files (one per sample). Upload these to your Array Server, by clicking on the Server tab, then clicking Server File | Browse Files : Navigate to a location to store your files, and click Upload : Navigate to your .alv and .tlv files, and upload them to the server. Now switch back to the Land tab, and click Tools | Publish To Land : Navigate to your server files and click Send To Queue : Note: You can only publish data one job at a time, so if you have submitted a set of files to the server for publishing, you must wait for that job to complete before submitting the next job. When all of your .alv and .tlv data have been published, the ServerJobs queue will say \"Finished\", and you can start exploring your Land.","title":"Add .alv and .tlv files to server"},{"location":"tutorials/ComparisonLand/ExploreComparisonLand/","text":"Explore ComparisonLand ArrayLands with comparisons will have different Views that are customized for different types of data: Gene Gene Sets Samples SampleSets Comparisons/ComparisonSets In ComparisonLands, even Gene-Level data can show special Views using your Comparison inferences. Gene-Level data When you connect to your new Land, the default View will display the number of samples, as derived from the Sample metadata, which should be the same as the number of .alv files you added. While this is a nice overview of your Land data, especially as you add hundreds or thousands of samples, for multiple projects or tissues, it is not very informative now. Instead, search for the gene CD58 . The default View will display the log2-fold change data from the comparisons, separated by Treatment: Click Select View , where you can see additional Views available for Land Gene-Level data: These Views are explained in more detail in the ImmunoLand and OncoLand tutorials, in addition to the many ways to customize Views, so will not be described in detail here. However, one View to check is the Expression Intensity View: In contrast to the default GeneLevel View (Comparison.Treatment vs. Control), which is displaying the log2-fold change values from the comparison data, the Expression Intensity View is displaying the expression data for each sample. As you explore your ComparisonLand, it will be clearer where each source dataset is being used. Furthermore, you will identify additional Sample and Comparison metadata columns that will be useful for grouping and filtering your data. This is important to note before you begin constructing a large ComparisonLand, because the comparison metadata are contained within the .tlv files, so cannot be updated as easily as Sample Metadata; you must re-process your comparisons and over-write the .tlv files, then re-publish them to Land. Thus, you should plan ahead for including important information about different sample groups. Comparison-Level Data In addition to viewing Comparisons at the single-gene-level, you can also view all measured genes for a given comparison. Search for \"Slurmycin_10um_htb-57.test1\" in the Search Bar ; you will notice that matching hits (genes, comparisons, samples) will be dynamically displayed as you type: The default View is a Volcano plot, with Estimate (log2-Fold Change) on the X-axis and Raw P-value on the Y-axis. However, you can change the X- and Y-axis values, change display of the View, and add Cutoff Lines in the Task tab of the View Controller : You can identify similar Comparisons to your Comparison-of-Interest under Select View | Gene Set Analysis (plot) . This analysis performs a Wilcoxon test, separating all significantly up- and down-regulated genes in your selected Comparison from insignificant genes, and compares these two lists to the set of significant genes in all other Comparisons in your Land, to identify the Comparisons that share a large number of significant genes. If you did not add DiseaseCategory in your Sample Metadata file, and did not include DiseaseCategory in your comparison Metadatafile MetaColumns , the default plot will be blank, because ArrayLand is attempting to profile by a non-existant column. This demonstrates one way that Sample and Comparison metadata columns can affect Views. However, this is a simple issue to fix. In the View Controller: Task tab , simply select Specify Profile Column : Then select another Comparison Metadata column, such as Case.TreatmentLevel or Case.CellLine : If using TreatmentLabel , all Comparisons with Slurmycin will be displayed in one row, and Brawndocin columns will be displayed in another. Comparisons that are most similar to Slurmycin_10um_htb-57.test1 will be further to the right (lower P-value). In the View Controller:Task tab , select Change Symbol , and change Labels to Selected By ID . Now select the two significant comparisons: You will see that the most significantly similar comparison to Slurmycin_10um_htb-57.test1 is Slurmycin_10um_htb-57.test1. However, the second-most similar comparison is Slurmycin_1um_htb-57.test1. Comparisons of Comparisons In ComparisonLand, Comparisons can be grouped together, in the same way that genes or samples can be grouped. To make a ComparisonSet, you can either generate a text list of ComparisonIDs, then load them into your Land as a ComparisonSet, or you can select multiple Comparisons in a View, and select \"Create ComparisonSet\" in the Action Window . For example, in the main ComparisonLand Comparisons View ( Select View | Overview | Comparisons ), click Specify Histogram Columns in the Task tab of the View Controller : and specify \"Case.Treatment\" as the Histogram column: Now the histogram will list each comparison, so you can easily select the four Brawndocin comparisons with your mouse: In the Action Window, you can either choose to Create ComparisonSet , or you can simply Browse Selected Comparisons : If you click Browse Selected Comparisons , a new tab will open, displaying a Volcano Plot of each Comparison's up- and down-regulated genes. First, change the layout of charts to \"2 * 2\", then click the \"Toggle Uniform Scale\": You will see all four Comparisons in a single window, with the same X- and Y-axis scaling. It is clear that increasing the dose of Brawndocin also increases the number of up- and down-regulated genes. Select some of the up-regulated genes in the Brawndocin_10uM plot to see those same genes in the other plots, as well as details in the Details Window . If you wish, you can create a GeneSet of your selected genes, in the Action Window: Further Directions As you build your ComparisonLand with real data, you will be able to identify Comparisons (e.g. treatments, diseases, cell types) that are most similar to each other, and directly visualize this similarities with Venn Diagrams, Heatmaps, and more; see the ImmunoLand tutorial for more details on these. Congratulations, you have successfully built your own Land from raw expression and inference data, converting text quantifications to rich visualizations, ready for analysis! For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Explore ComparisonLand"},{"location":"tutorials/ComparisonLand/ExploreComparisonLand/#explore-comparisonland","text":"ArrayLands with comparisons will have different Views that are customized for different types of data: Gene Gene Sets Samples SampleSets Comparisons/ComparisonSets In ComparisonLands, even Gene-Level data can show special Views using your Comparison inferences.","title":"Explore ComparisonLand"},{"location":"tutorials/ComparisonLand/ExploreComparisonLand/#gene-level-data","text":"When you connect to your new Land, the default View will display the number of samples, as derived from the Sample metadata, which should be the same as the number of .alv files you added. While this is a nice overview of your Land data, especially as you add hundreds or thousands of samples, for multiple projects or tissues, it is not very informative now. Instead, search for the gene CD58 . The default View will display the log2-fold change data from the comparisons, separated by Treatment: Click Select View , where you can see additional Views available for Land Gene-Level data: These Views are explained in more detail in the ImmunoLand and OncoLand tutorials, in addition to the many ways to customize Views, so will not be described in detail here. However, one View to check is the Expression Intensity View: In contrast to the default GeneLevel View (Comparison.Treatment vs. Control), which is displaying the log2-fold change values from the comparison data, the Expression Intensity View is displaying the expression data for each sample. As you explore your ComparisonLand, it will be clearer where each source dataset is being used. Furthermore, you will identify additional Sample and Comparison metadata columns that will be useful for grouping and filtering your data. This is important to note before you begin constructing a large ComparisonLand, because the comparison metadata are contained within the .tlv files, so cannot be updated as easily as Sample Metadata; you must re-process your comparisons and over-write the .tlv files, then re-publish them to Land. Thus, you should plan ahead for including important information about different sample groups.","title":"Gene-Level data"},{"location":"tutorials/ComparisonLand/ExploreComparisonLand/#comparison-level-data","text":"In addition to viewing Comparisons at the single-gene-level, you can also view all measured genes for a given comparison. Search for \"Slurmycin_10um_htb-57.test1\" in the Search Bar ; you will notice that matching hits (genes, comparisons, samples) will be dynamically displayed as you type: The default View is a Volcano plot, with Estimate (log2-Fold Change) on the X-axis and Raw P-value on the Y-axis. However, you can change the X- and Y-axis values, change display of the View, and add Cutoff Lines in the Task tab of the View Controller : You can identify similar Comparisons to your Comparison-of-Interest under Select View | Gene Set Analysis (plot) . This analysis performs a Wilcoxon test, separating all significantly up- and down-regulated genes in your selected Comparison from insignificant genes, and compares these two lists to the set of significant genes in all other Comparisons in your Land, to identify the Comparisons that share a large number of significant genes. If you did not add DiseaseCategory in your Sample Metadata file, and did not include DiseaseCategory in your comparison Metadatafile MetaColumns , the default plot will be blank, because ArrayLand is attempting to profile by a non-existant column. This demonstrates one way that Sample and Comparison metadata columns can affect Views. However, this is a simple issue to fix. In the View Controller: Task tab , simply select Specify Profile Column : Then select another Comparison Metadata column, such as Case.TreatmentLevel or Case.CellLine : If using TreatmentLabel , all Comparisons with Slurmycin will be displayed in one row, and Brawndocin columns will be displayed in another. Comparisons that are most similar to Slurmycin_10um_htb-57.test1 will be further to the right (lower P-value). In the View Controller:Task tab , select Change Symbol , and change Labels to Selected By ID . Now select the two significant comparisons: You will see that the most significantly similar comparison to Slurmycin_10um_htb-57.test1 is Slurmycin_10um_htb-57.test1. However, the second-most similar comparison is Slurmycin_1um_htb-57.test1.","title":"Comparison-Level Data"},{"location":"tutorials/ComparisonLand/ExploreComparisonLand/#comparisons-of-comparisons","text":"In ComparisonLand, Comparisons can be grouped together, in the same way that genes or samples can be grouped. To make a ComparisonSet, you can either generate a text list of ComparisonIDs, then load them into your Land as a ComparisonSet, or you can select multiple Comparisons in a View, and select \"Create ComparisonSet\" in the Action Window . For example, in the main ComparisonLand Comparisons View ( Select View | Overview | Comparisons ), click Specify Histogram Columns in the Task tab of the View Controller : and specify \"Case.Treatment\" as the Histogram column: Now the histogram will list each comparison, so you can easily select the four Brawndocin comparisons with your mouse: In the Action Window, you can either choose to Create ComparisonSet , or you can simply Browse Selected Comparisons : If you click Browse Selected Comparisons , a new tab will open, displaying a Volcano Plot of each Comparison's up- and down-regulated genes. First, change the layout of charts to \"2 * 2\", then click the \"Toggle Uniform Scale\": You will see all four Comparisons in a single window, with the same X- and Y-axis scaling. It is clear that increasing the dose of Brawndocin also increases the number of up- and down-regulated genes. Select some of the up-regulated genes in the Brawndocin_10uM plot to see those same genes in the other plots, as well as details in the Details Window . If you wish, you can create a GeneSet of your selected genes, in the Action Window:","title":"Comparisons of Comparisons"},{"location":"tutorials/ComparisonLand/ExploreComparisonLand/#further-directions","text":"As you build your ComparisonLand with real data, you will be able to identify Comparisons (e.g. treatments, diseases, cell types) that are most similar to each other, and directly visualize this similarities with Venn Diagrams, Heatmaps, and more; see the ImmunoLand tutorial for more details on these. Congratulations, you have successfully built your own Land from raw expression and inference data, converting text quantifications to rich visualizations, ready for analysis! For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Further Directions"},{"location":"tutorials/ComparisonLand/Introduction/","text":"Introduction ArrayStudio Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local microarray analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM. The tutorial dataset is small and does not require these hardware specifications; However, processing of large numbers of whole-transcriptome table data, with thousands of samples and comparisons, can be memory-intensive. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes minimal working knowledge of Array Studio. However, an understanding of Array Studio data types, as well as the Views and Analysis modules within ArrayLands, will significantly improve your custom ComparisonLand design. This tutorial also assumes a basic understanding of absolute and relative file paths, for editing .oscript files to find files on your local computer. Test Dataset This ComparisonLand tutorial will cover the importing and analysis of a small synthetic dataset of microarray expression, from 7 sample groups (56 samples). A .zip file containing all required text files for this analysis can be found at the following URL: http://omicsoft.com/downloads/data/Tutorial/Help/ComparisonLand.Tutorial.zip simply unzip this file into a local folder, and proceed with the tutorial.","title":"Introduction"},{"location":"tutorials/ComparisonLand/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/ComparisonLand/Introduction/#arraystudio","text":"Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local microarray analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM. The tutorial dataset is small and does not require these hardware specifications; However, processing of large numbers of whole-transcriptome table data, with thousands of samples and comparisons, can be memory-intensive. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes minimal working knowledge of Array Studio. However, an understanding of Array Studio data types, as well as the Views and Analysis modules within ArrayLands, will significantly improve your custom ComparisonLand design. This tutorial also assumes a basic understanding of absolute and relative file paths, for editing .oscript files to find files on your local computer.","title":"ArrayStudio"},{"location":"tutorials/ComparisonLand/Introduction/#test-dataset","text":"This ComparisonLand tutorial will cover the importing and analysis of a small synthetic dataset of microarray expression, from 7 sample groups (56 samples). A .zip file containing all required text files for this analysis can be found at the following URL: http://omicsoft.com/downloads/data/Tutorial/Help/ComparisonLand.Tutorial.zip simply unzip this file into a local folder, and proceed with the tutorial.","title":"Test Dataset"},{"location":"tutorials/DNASeq/","text":"DNA-Seq Analysis Tutorial .. toctree:: :maxdepth: 2 Introduction Create_Array_Studio_Project QC_of_Raw_Data_Files Alignment_to_the_Genome QC_of_Aligned_Data DNA-Seq_Fusion_Gene_Detection DNA-SeqMutation_Detection DNA-Seq_Copy_Number_Analysis Save___Close_Project","title":"Home"},{"location":"tutorials/DNASeq/Alignment_to_the_Genome/","text":"Alignment to the Genome The second step in most DNA-Seq analysis is the alignment of the reads to the genome. Alternatively, if the data have already been aligned, the alignment (BAM/SAM) files can be imported through Add NGS Data | Add DNA-Seq Data | Add Genome Mapped Reads . For this experiment, we will align the data using Array Studio. To add aligned NGS data, go to the Add Data dropdown menu on the toolbar, then choose Add NGS Data | Add DNA-Seq Data | Map Reads to Genome (Illumina) . At this point, the Map DNA-Seq Reads to Genome module appears. The first step is to click the Add button to specify the location of the files. Choose the 6 files that were downloaded from SRA or the subset of the dataset downloaded from OmicSoft website. Note that these files are in .gz (gzip) format. The alignment process takes this into account and it is an effective way to save some space when importing files, as there is no need to extract all files. As this is a paired experiment, click the Reads are paired checkbox . This will ensure that the pairing information is used in the alignment and counting process. Choose the Genome for the experiment. In this case, use Human.B37.3 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Leave the quality encoding set to automatic. However for your information, these files were encoded using the Sanger quality scoring system. Total penalty should be left on automatic, and is described completely in Omicsoft's white paper on alignment. Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many ties? for non-unique reads should be reported, or if they should be excluded all together. Output folder allows the user to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder , so that BAM files can be found easily in next step (for fusion detection). There are a few options in the Advanced Tab (e.g. detailed parameter settings for Indel detection). In general the default values have been tuned and should work well in most cases. Leave the Exclude unmapped reads in BAM file unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input to the single-end fusion detection algorithm (see the fusion chapter in this tutorial). Click Submit to Submit the analysis. This could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc. After the alignment, you will see a NgsData object and an alignment report table in the solution explorer:","title":"Alignment"},{"location":"tutorials/DNASeq/Alignment_to_the_Genome/#alignment-to-the-genome","text":"The second step in most DNA-Seq analysis is the alignment of the reads to the genome. Alternatively, if the data have already been aligned, the alignment (BAM/SAM) files can be imported through Add NGS Data | Add DNA-Seq Data | Add Genome Mapped Reads . For this experiment, we will align the data using Array Studio. To add aligned NGS data, go to the Add Data dropdown menu on the toolbar, then choose Add NGS Data | Add DNA-Seq Data | Map Reads to Genome (Illumina) . At this point, the Map DNA-Seq Reads to Genome module appears. The first step is to click the Add button to specify the location of the files. Choose the 6 files that were downloaded from SRA or the subset of the dataset downloaded from OmicSoft website. Note that these files are in .gz (gzip) format. The alignment process takes this into account and it is an effective way to save some space when importing files, as there is no need to extract all files. As this is a paired experiment, click the Reads are paired checkbox . This will ensure that the pairing information is used in the alignment and counting process. Choose the Genome for the experiment. In this case, use Human.B37.3 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Leave the quality encoding set to automatic. However for your information, these files were encoded using the Sanger quality scoring system. Total penalty should be left on automatic, and is described completely in Omicsoft's white paper on alignment. Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many ties? for non-unique reads should be reported, or if they should be excluded all together. Output folder allows the user to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder , so that BAM files can be found easily in next step (for fusion detection). There are a few options in the Advanced Tab (e.g. detailed parameter settings for Indel detection). In general the default values have been tuned and should work well in most cases. Leave the Exclude unmapped reads in BAM file unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input to the single-end fusion detection algorithm (see the fusion chapter in this tutorial). Click Submit to Submit the analysis. This could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc. After the alignment, you will see a NgsData object and an alignment report table in the solution explorer:","title":"Alignment to the Genome"},{"location":"tutorials/DNASeq/Create_Array_Studio_Project/","text":"Create Array Studio Project Create New Project Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. In this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project (distributed) and analysis steps are almost the same as described in this tutorial. The interface of creating of new local project is different from creating a new server project, but the rest of the steps, such as data import, and data analysis share the same interface. Different project types tell Array Studio where to run the analysis: If it is a local project, Array Studio will run the analysis in local machine; if it is a server project, Array Studio will run the analysis on server. Once Array Studio has been opened, click File | New Server Project from the File Menu (also can be accessed via the New button on the toolbar). Note: For a local project, it is required that the user have approximately 10GB of available space on their hard drive for this tutorial. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft\" home folder using Tools Menu | Preferences | Advanced . This will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. The reference library and index will take ~10Gb of space. Users may enter some basic metadata and click Create to create an empty server project: Another way to create a new project is by this icon: Once a project is created, users can choose to follow the DNA-Seq Analysis Pipeline module (all-in-one, Chapter 3) or perform QC/filtering/alignment/mutation analyses (Chapters 4-6,8) all as individual steps. DNA-Seq Analysis Pipeline Array studio provides an easy way for new users to do all analyses in one module: This function has a similar interface to the DNAseq alignment module. Users need to provide the DNA seq files and choose the genome. Then in the reporting section, users can choose which related analysis want to perform. The available analysis include Perform raw data QC Filter Raw data Perform post alignment QC Summarize mutation + SNP Generate BAM Summary (.bas Files) Each analysis is done by default setting and will generate data objects in the Solution Explorer when the entire pipeline is complete. Users can perform step-by-step analysis with customized settings as described in later chapters.","title":"Create Project"},{"location":"tutorials/DNASeq/Create_Array_Studio_Project/#create-array-studio-project","text":"","title":"Create Array Studio Project"},{"location":"tutorials/DNASeq/Create_Array_Studio_Project/#create-new-project","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. In this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project (distributed) and analysis steps are almost the same as described in this tutorial. The interface of creating of new local project is different from creating a new server project, but the rest of the steps, such as data import, and data analysis share the same interface. Different project types tell Array Studio where to run the analysis: If it is a local project, Array Studio will run the analysis in local machine; if it is a server project, Array Studio will run the analysis on server. Once Array Studio has been opened, click File | New Server Project from the File Menu (also can be accessed via the New button on the toolbar). Note: For a local project, it is required that the user have approximately 10GB of available space on their hard drive for this tutorial. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft\" home folder using Tools Menu | Preferences | Advanced . This will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. The reference library and index will take ~10Gb of space. Users may enter some basic metadata and click Create to create an empty server project: Another way to create a new project is by this icon: Once a project is created, users can choose to follow the DNA-Seq Analysis Pipeline module (all-in-one, Chapter 3) or perform QC/filtering/alignment/mutation analyses (Chapters 4-6,8) all as individual steps.","title":"Create New Project"},{"location":"tutorials/DNASeq/Create_Array_Studio_Project/#dna-seq-analysis-pipeline","text":"Array studio provides an easy way for new users to do all analyses in one module: This function has a similar interface to the DNAseq alignment module. Users need to provide the DNA seq files and choose the genome. Then in the reporting section, users can choose which related analysis want to perform. The available analysis include Perform raw data QC Filter Raw data Perform post alignment QC Summarize mutation + SNP Generate BAM Summary (.bas Files) Each analysis is done by default setting and will generate data objects in the Solution Explorer when the entire pipeline is complete. Users can perform step-by-step analysis with customized settings as described in later chapters.","title":"DNA-Seq Analysis Pipeline"},{"location":"tutorials/DNASeq/DNA-SeqMutation_Detection/","text":"DNA-Seq Mutation Detection Mutation data can be generated from DNA-Seq data. This allows the user to compare frequencies of mutation, for individual sites, between groups of samples. All mutation functions can be found in NGS | Variation . In this tutorial, we will cover three mutation detection workflows: Summarize Variant Data + Annotated Variant Report Generate VCF files + Annotated VCF files Summarize Matched Pair Variation Data + Annotated Mutation/SNP Report User can find the documentation for other functions by clicking the Help button in each function menu. Summarize/Annotate Variant Summarize Variant Data is developed by OmicSoft. Variant (Mutations and SNPs) are reported based on the pileup data from alignment data ( NgsData ). Choose the NGS data. In the reference section, all references are selected by default. User can select a list of regions to summarize mutations. Selections can be on Gene list (a list of gene symbols from project lists), Customized regions (load a bed file), or Filtered by region (e.g. chr9:133710831-133763062, or more regions separated by |). Keep the default selection for this tutorial. Specify the base and mapping quality cutoff; choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20 reads, # of reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%. Note: you should lower the coverage cutoff if you are using the subset (10%) tutorial dataset. In the Advanced tab, user can adjust quality by neighbours at each position, check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the next step) at this step. Users can also adjust Score cutoff and maximal ratio for the SNP calls. Also, Omicsoft provides the options to generate VCF files (both merged VCF and individual VCF files). Those generated VCF files can be used for futher annotation by Array Studio or other tools. Leave all settings as their defaults and click Submit to run the module. The output is a mutation2Snp report table listed under Table in solution explorer: In the mutation2Snp report table, there are four columns for each sample: MutationFrequency ; Coverage at this genomic location; Percentage of mutation detected on the plus strand (MutationReadOnPlus/MutationReadTotal). Genotype for this mutation allele. If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff. The variants are then annotated with gene coding information, known SNPs and functional prediction databases. Open NGS | Variation | Annotate Variant Table Report module; choose the mutation2Snp report in Data , OmicsoftGene20130723 as gene model in Gene model . Leave all settings as their defaults in this tab. The first time the user specifies a reference/gene model, it will download files from Omicsoft. In the Annotation Sources and Additional Sources tab, user can specify more annotation sources such as functional prediction and COSMIC annotation, or custom mutation annotators built using NGS | Build Mutation Annotator . User also has the option to write the annotated mutation result directly to a text file. Leave all settings as their defaults and click Submit to run the module. The output is a MutationAnnotation report table listed under Table in solution explorer: Besides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the Annotation Sources prior to running the analysis. Using the View Controller , choose filters to focus on items of interest. Generate VCF files + Annotated VCF files With Summarize Variant Data , user can choose to export VCF file on both merged file and individual file for further analysis. The user can specify to generate a VCF for each observation or generate a merged VCF file under Advanced tab. Also the user can change the output result folder by providing a directory path to the option Output folder . Leave the options as defaults, and click Submit . Both individual VCF files and a merged VCF file would be generated in specified output folder: Next, the user might want to further annotate the VCF variation. This can be accomplished by using NGS | Variation | Annotate Variant Files(VCF/BED/GTT/RS_ID) module. Here, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the Annotation Source Tab, users can choose extra annotator to further annotate VCF file. Leave all other settings as-is, choosing to extract genotype only, and click Submit to continue. A new table is output to the Solution Explorer. Each gene that shows variation in the mutation report is returned in the resulting table, along with further annotation for that gene, including any known dbSNPs at that position, annotation type, amino acid position (if AA change), AA Change, transcript ID, transcript name, transcript strand, and distance to 5'/3' ends and closest exon boundary. Summarize/Annotate Matched Pair Variation Summarize Matched Pair Variation Data is implemented based on the principle of VarScan2, so the options are the same as in VarScan2, including a few pileup and filtering options. The module requires a matched normal sample during the analysis. The module was initially designed to detect somatic mutation in tumor comparing to matched normal samples. It can also be applied to detect mutation in other cases, such as comparing induced pluripotent stem cells (iPSC) vs. somatic cells. To incorporate the sample information, user has to prepare a design table and import for NgsData . Double click the Table under Design to show design table. To import new design table, right click on the Design Folder under NgsData and choose Import : The design file for this tutorial is located in the downloaded zip file. Once a design file (usually it is a tab delimited file) is selected and imported, user can choose to replace or append to existing design table: Click OK , the design table is imported. In this tutorial, only SRR097848 and SRR097849 are paired: SRR097849 is from breast cancer cell line MCF7 while SRR097848 is from non-tumor breast cell line MCF10A. Left click and select two NGS samples: Both sample IDs will be highlighted; then open NGS | Variation | Summarize Matched Pair Variation Data module: Choose the NGS data, change the Observations to Selected observations only. The analysis will use two NGS samples selected in the design table. Specify the Pair based on Tissue column (Breast for both), Tumor status based on cell type column, and choose Non-tumor epithelium cell lines factor level to be Normal . There are more pileup, variation calling and filtering options in the Advanced tab. Leave all settings as their defaults and click Submit to run the module. The output is a matched pair variation (MPV) report table listed under Table in solution explorer: In the MPV report table, there are ten columns for each sample: Minor allele MutationFrequency in normal Coverage in normal Minor allele MutationFrequency in tumor Coverage in tumor Somatic P value for somatic or LOH events Variant P value from testing whether the variant allele exists in at least one of the (two) samples Filters for the status of mutation calling, such as strandness and mapping quality difference Somatic status call (Germline, Somatic, LOH, or Unknown) Predicted genotype in normal Predicted genotype in tumor If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with basic annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion). In this tutorial, we only analyzed one pair of samples. If multiple pairs are analyzed in the same run, the whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff. As with the mutation table, the MPV table can also be annotated by NGS | Variation | Annotate Variant Table Report module. Open the module; choose the MPV mutation report in Data , UCSC gene model in Gene model , v137 in DBSNP version . The user also needs to select the data columns in the mutation report; however Array Studio should in most cases select them automatically. Users can also specify an Output name such as MPV?. Leave all other settings as-is and click Submit to continue. An annotated MPV mutation table with the name specified (MPV) is output to the Solution Explorer: Besides the columns in MPV mutation table, there are following annotation columns: gene/transcript name, dbSNP name, mutation type, mutation position in the open reading frame, amino acid position and change in the transcript, distance to 5', 3' of the transcript and to the closest exon boundary. Annotation columns from functional prediction and COSMIC are also attached if these options are checked in the Advanced tab.","title":"Variant Detection"},{"location":"tutorials/DNASeq/DNA-SeqMutation_Detection/#dna-seq-mutation-detection","text":"Mutation data can be generated from DNA-Seq data. This allows the user to compare frequencies of mutation, for individual sites, between groups of samples. All mutation functions can be found in NGS | Variation . In this tutorial, we will cover three mutation detection workflows: Summarize Variant Data + Annotated Variant Report Generate VCF files + Annotated VCF files Summarize Matched Pair Variation Data + Annotated Mutation/SNP Report User can find the documentation for other functions by clicking the Help button in each function menu.","title":"DNA-Seq Mutation Detection"},{"location":"tutorials/DNASeq/DNA-SeqMutation_Detection/#summarizeannotate-variant","text":"Summarize Variant Data is developed by OmicSoft. Variant (Mutations and SNPs) are reported based on the pileup data from alignment data ( NgsData ). Choose the NGS data. In the reference section, all references are selected by default. User can select a list of regions to summarize mutations. Selections can be on Gene list (a list of gene symbols from project lists), Customized regions (load a bed file), or Filtered by region (e.g. chr9:133710831-133763062, or more regions separated by |). Keep the default selection for this tutorial. Specify the base and mapping quality cutoff; choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20 reads, # of reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%. Note: you should lower the coverage cutoff if you are using the subset (10%) tutorial dataset. In the Advanced tab, user can adjust quality by neighbours at each position, check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the next step) at this step. Users can also adjust Score cutoff and maximal ratio for the SNP calls. Also, Omicsoft provides the options to generate VCF files (both merged VCF and individual VCF files). Those generated VCF files can be used for futher annotation by Array Studio or other tools. Leave all settings as their defaults and click Submit to run the module. The output is a mutation2Snp report table listed under Table in solution explorer: In the mutation2Snp report table, there are four columns for each sample: MutationFrequency ; Coverage at this genomic location; Percentage of mutation detected on the plus strand (MutationReadOnPlus/MutationReadTotal). Genotype for this mutation allele. If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff. The variants are then annotated with gene coding information, known SNPs and functional prediction databases. Open NGS | Variation | Annotate Variant Table Report module; choose the mutation2Snp report in Data , OmicsoftGene20130723 as gene model in Gene model . Leave all settings as their defaults in this tab. The first time the user specifies a reference/gene model, it will download files from Omicsoft. In the Annotation Sources and Additional Sources tab, user can specify more annotation sources such as functional prediction and COSMIC annotation, or custom mutation annotators built using NGS | Build Mutation Annotator . User also has the option to write the annotated mutation result directly to a text file. Leave all settings as their defaults and click Submit to run the module. The output is a MutationAnnotation report table listed under Table in solution explorer: Besides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the Annotation Sources prior to running the analysis. Using the View Controller , choose filters to focus on items of interest.","title":"Summarize/Annotate Variant"},{"location":"tutorials/DNASeq/DNA-SeqMutation_Detection/#generate-vcf-files-annotated-vcf-files","text":"With Summarize Variant Data , user can choose to export VCF file on both merged file and individual file for further analysis. The user can specify to generate a VCF for each observation or generate a merged VCF file under Advanced tab. Also the user can change the output result folder by providing a directory path to the option Output folder . Leave the options as defaults, and click Submit . Both individual VCF files and a merged VCF file would be generated in specified output folder: Next, the user might want to further annotate the VCF variation. This can be accomplished by using NGS | Variation | Annotate Variant Files(VCF/BED/GTT/RS_ID) module. Here, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the Annotation Source Tab, users can choose extra annotator to further annotate VCF file. Leave all other settings as-is, choosing to extract genotype only, and click Submit to continue. A new table is output to the Solution Explorer. Each gene that shows variation in the mutation report is returned in the resulting table, along with further annotation for that gene, including any known dbSNPs at that position, annotation type, amino acid position (if AA change), AA Change, transcript ID, transcript name, transcript strand, and distance to 5'/3' ends and closest exon boundary.","title":"Generate VCF files + Annotated VCF files"},{"location":"tutorials/DNASeq/DNA-SeqMutation_Detection/#summarizeannotate-matched-pair-variation","text":"Summarize Matched Pair Variation Data is implemented based on the principle of VarScan2, so the options are the same as in VarScan2, including a few pileup and filtering options. The module requires a matched normal sample during the analysis. The module was initially designed to detect somatic mutation in tumor comparing to matched normal samples. It can also be applied to detect mutation in other cases, such as comparing induced pluripotent stem cells (iPSC) vs. somatic cells. To incorporate the sample information, user has to prepare a design table and import for NgsData . Double click the Table under Design to show design table. To import new design table, right click on the Design Folder under NgsData and choose Import : The design file for this tutorial is located in the downloaded zip file. Once a design file (usually it is a tab delimited file) is selected and imported, user can choose to replace or append to existing design table: Click OK , the design table is imported. In this tutorial, only SRR097848 and SRR097849 are paired: SRR097849 is from breast cancer cell line MCF7 while SRR097848 is from non-tumor breast cell line MCF10A. Left click and select two NGS samples: Both sample IDs will be highlighted; then open NGS | Variation | Summarize Matched Pair Variation Data module: Choose the NGS data, change the Observations to Selected observations only. The analysis will use two NGS samples selected in the design table. Specify the Pair based on Tissue column (Breast for both), Tumor status based on cell type column, and choose Non-tumor epithelium cell lines factor level to be Normal . There are more pileup, variation calling and filtering options in the Advanced tab. Leave all settings as their defaults and click Submit to run the module. The output is a matched pair variation (MPV) report table listed under Table in solution explorer: In the MPV report table, there are ten columns for each sample: Minor allele MutationFrequency in normal Coverage in normal Minor allele MutationFrequency in tumor Coverage in tumor Somatic P value for somatic or LOH events Variant P value from testing whether the variant allele exists in at least one of the (two) samples Filters for the status of mutation calling, such as strandness and mapping quality difference Somatic status call (Germline, Somatic, LOH, or Unknown) Predicted genotype in normal Predicted genotype in tumor If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with basic annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion). In this tutorial, we only analyzed one pair of samples. If multiple pairs are analyzed in the same run, the whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff. As with the mutation table, the MPV table can also be annotated by NGS | Variation | Annotate Variant Table Report module. Open the module; choose the MPV mutation report in Data , UCSC gene model in Gene model , v137 in DBSNP version . The user also needs to select the data columns in the mutation report; however Array Studio should in most cases select them automatically. Users can also specify an Output name such as MPV?. Leave all other settings as-is and click Submit to continue. An annotated MPV mutation table with the name specified (MPV) is output to the Solution Explorer: Besides the columns in MPV mutation table, there are following annotation columns: gene/transcript name, dbSNP name, mutation type, mutation position in the open reading frame, amino acid position and change in the transcript, distance to 5', 3' of the transcript and to the closest exon boundary. Annotation columns from functional prediction and COSMIC are also attached if these options are checked in the Advanced tab.","title":"Summarize/Annotate Matched Pair Variation"},{"location":"tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/","text":"DNA-Seq Copy Number Analysis DNA-Seq Copy number analysis requires a matched normal sample during the analysis. The module was initially designed to detect copy number changes in tumor comparing to matched normal samples from Exon captured DNA-Seq data. There are two steps in copy number analysis: Summarize Copy Number (Whole Exome Sequencing or Target Sequencing) and Segment Copy Number : Summarize Copy Number Check that the two samples are still selected in the NgsData Design Table . Summarize Copy Number will summarize the copy number log2ratio between two samples. In Summarize Copy Number , choose the NGS data, choose the Observations to Selected observations only. The analysis will use two NGS samples selected in the design table. If user does not follow the instruction for Observations option in this tutorial data, there will be an error: Observation number cannot be divided by two (expecting matched pairs). Specify the Pair based on Tissue column (Breast for both), Tumor status based on cell type column, and choose Non-tumor epithelium cell lines factor level to be Normal . There are more pileup and copy number options in the Advanced tab. Leave all other settings as their defaults and click Submit to run the module. The output is a copy number report table listed under Table in solution explorer: The report contains observation ID, copy number log2Ratio, predicted copy number (normally having 2 copies in human), coverage in tumor and normal sample, and genomic bin start/end. As shown in the GUI, user can also select a base line sample to be a common control and summarize copy number by comparing every other sample to the same control. Users can sort data by Log2 Ratio or Copy Number to find some regions with significant differences in copy number. Right-click the rowID of a CNV to visualize the pileup in the Genome Browser. Segment Copy Number The CNV Segmentation command will generate segmentation results for Log2Ratio copy number Data. The contiguous small segments/regions are processed and joined by a segmentation algorithm (similar to circular binary segmentation). In NGS | Copy Number | Segment Copy Number , choose the CopyNumberReport data. Leave all other settings as their defaults and click Submit to run the module. The output is a segment report table listed under Table | Segment in solution explorer: By default, there are table , scatter , Segment and SegmentChromosome views for the report. Open the SegmentChromosome view and click on any segment to show details.","title":"Copy Number Analysis"},{"location":"tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/#dna-seq-copy-number-analysis","text":"DNA-Seq Copy number analysis requires a matched normal sample during the analysis. The module was initially designed to detect copy number changes in tumor comparing to matched normal samples from Exon captured DNA-Seq data. There are two steps in copy number analysis: Summarize Copy Number (Whole Exome Sequencing or Target Sequencing) and Segment Copy Number :","title":"DNA-Seq Copy Number Analysis"},{"location":"tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/#summarize-copy-number","text":"Check that the two samples are still selected in the NgsData Design Table . Summarize Copy Number will summarize the copy number log2ratio between two samples. In Summarize Copy Number , choose the NGS data, choose the Observations to Selected observations only. The analysis will use two NGS samples selected in the design table. If user does not follow the instruction for Observations option in this tutorial data, there will be an error: Observation number cannot be divided by two (expecting matched pairs). Specify the Pair based on Tissue column (Breast for both), Tumor status based on cell type column, and choose Non-tumor epithelium cell lines factor level to be Normal . There are more pileup and copy number options in the Advanced tab. Leave all other settings as their defaults and click Submit to run the module. The output is a copy number report table listed under Table in solution explorer: The report contains observation ID, copy number log2Ratio, predicted copy number (normally having 2 copies in human), coverage in tumor and normal sample, and genomic bin start/end. As shown in the GUI, user can also select a base line sample to be a common control and summarize copy number by comparing every other sample to the same control. Users can sort data by Log2 Ratio or Copy Number to find some regions with significant differences in copy number. Right-click the rowID of a CNV to visualize the pileup in the Genome Browser.","title":"Summarize Copy Number"},{"location":"tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/#segment-copy-number","text":"The CNV Segmentation command will generate segmentation results for Log2Ratio copy number Data. The contiguous small segments/regions are processed and joined by a segmentation algorithm (similar to circular binary segmentation). In NGS | Copy Number | Segment Copy Number , choose the CopyNumberReport data. Leave all other settings as their defaults and click Submit to run the module. The output is a segment report table listed under Table | Segment in solution explorer: By default, there are table , scatter , Segment and SegmentChromosome views for the report. Open the SegmentChromosome view and click on any segment to show details.","title":"Segment Copy Number"},{"location":"tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/","text":"DNA-Seq Fusion Gene Detection In DNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events. In paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion. Two fusion detection functions for DNAseq data can be found in NGS | Fusion menu: Map Fusion Reads (Illumina) and Report Fusion Genes (Paired End) . Note that the first function, Combined Fusion Analysis , is only designed for RNAseq data. Report Paired-End Fusion Genes Report Fusion Genes (Paired End) module will detect fusion genes from inter-transcript paired-end reads based on DNA-Seq alignment ( NgsData ). Choose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check Output fusion reads option and specify the directory path, supporting fusion reads will be saved as BAM files, which can be used for visual check in genome browser. Leave all other settings as their defaults and click Submit to run the module. The output is a paired fusion report table listed under Table in solution explorer: The information in Filter column in the report table comes from a fusion black list. For more information about the blacklist, please read the following wiki article: link In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from reads in Gene1 , the second columns shows the number of unique mapping positions from reads in Gene2 , while the third column shows the total count of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*3=9 columns of data, and annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs. Below are rows for identified known fusion BCR-ABL1 fusion in SRR064173 (K562) samples at the genomic level: Report Fusion Genes (Paired End) module reports fusion events by grouping gene pairs by rows in one table. It provides an easy way to detect recurrent fusion events when the analysis was run on multiple samples. Map Fusion Reads Map Fusion Reads module will detect fusion genes from fusion junction-spanning reads, which can characterize fusion genes at base pair resolution. It is the preferred approach to detect fusion events, using OmicSoft's fusion alignment method ( FusionMap, Ge, H, et al. Bioinformatics (2011): 1922-1928 ). It is not recommend to run Map Fusion Reads module on multiple samples with different read lengths. In this tutorial, the read length of SRR064173 is 38bp and one of SRR097848/SRR097849 is 50bp. Thus, this tutorial step will focus on the fusion junction detection in data SRR064173, since it is enrichment on BCR-ABL1 fusion regions. Fusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM). If the user is using the original FASTQ files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click Reads are paired option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample. If user is using BAM files, potential fusion reads (such as reads spanning two nearby genes) in alignment and unmapped reads will be extracted for fusion detection. It is the preferred approach, which saves running time at the filtering step. Remember to uncheck Reads are RNA-Seq reads . By default, this module is used for RNA-Seq data. Choose the Gene model to be OmicsoftGene20130723. Minimal cut size is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners. For details, see wiki page: link The default Cut size is to use value min(25, max(18, readLength/3). However, the read length for dataset SRR064173 (K562) is 38. For this tutorial dataset, we use a Fixed cut size of 16 to require at least 16 nucleotides to match each of the two genomic location, allowing 6 nucleotides in the middle of each read to detect fusion breakpoints. There are more fusion alignment options. Leave all settings as their defaults and click Submit to run the module. The output is a fusion report table listed under Table in solution explorer: In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion seed reads, while the third column shows number of fusion rescued reads. There are 3 columns of data, and 11 annotation columns for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predict fusion gene. Below is the result for identified known fusion BCR-ABL1 in K562 samples at genomic level:","title":"Fusion Detection"},{"location":"tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/#dna-seq-fusion-gene-detection","text":"In DNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events. In paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion. Two fusion detection functions for DNAseq data can be found in NGS | Fusion menu: Map Fusion Reads (Illumina) and Report Fusion Genes (Paired End) . Note that the first function, Combined Fusion Analysis , is only designed for RNAseq data.","title":"DNA-Seq Fusion Gene Detection"},{"location":"tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/#report-paired-end-fusion-genes","text":"Report Fusion Genes (Paired End) module will detect fusion genes from inter-transcript paired-end reads based on DNA-Seq alignment ( NgsData ). Choose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check Output fusion reads option and specify the directory path, supporting fusion reads will be saved as BAM files, which can be used for visual check in genome browser. Leave all other settings as their defaults and click Submit to run the module. The output is a paired fusion report table listed under Table in solution explorer: The information in Filter column in the report table comes from a fusion black list. For more information about the blacklist, please read the following wiki article: link In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from reads in Gene1 , the second columns shows the number of unique mapping positions from reads in Gene2 , while the third column shows the total count of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*3=9 columns of data, and annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs. Below are rows for identified known fusion BCR-ABL1 fusion in SRR064173 (K562) samples at the genomic level: Report Fusion Genes (Paired End) module reports fusion events by grouping gene pairs by rows in one table. It provides an easy way to detect recurrent fusion events when the analysis was run on multiple samples.","title":"Report Paired-End Fusion Genes"},{"location":"tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/#map-fusion-reads","text":"Map Fusion Reads module will detect fusion genes from fusion junction-spanning reads, which can characterize fusion genes at base pair resolution. It is the preferred approach to detect fusion events, using OmicSoft's fusion alignment method ( FusionMap, Ge, H, et al. Bioinformatics (2011): 1922-1928 ). It is not recommend to run Map Fusion Reads module on multiple samples with different read lengths. In this tutorial, the read length of SRR064173 is 38bp and one of SRR097848/SRR097849 is 50bp. Thus, this tutorial step will focus on the fusion junction detection in data SRR064173, since it is enrichment on BCR-ABL1 fusion regions. Fusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM). If the user is using the original FASTQ files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click Reads are paired option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample. If user is using BAM files, potential fusion reads (such as reads spanning two nearby genes) in alignment and unmapped reads will be extracted for fusion detection. It is the preferred approach, which saves running time at the filtering step. Remember to uncheck Reads are RNA-Seq reads . By default, this module is used for RNA-Seq data. Choose the Gene model to be OmicsoftGene20130723. Minimal cut size is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners. For details, see wiki page: link The default Cut size is to use value min(25, max(18, readLength/3). However, the read length for dataset SRR064173 (K562) is 38. For this tutorial dataset, we use a Fixed cut size of 16 to require at least 16 nucleotides to match each of the two genomic location, allowing 6 nucleotides in the middle of each read to detect fusion breakpoints. There are more fusion alignment options. Leave all settings as their defaults and click Submit to run the module. The output is a fusion report table listed under Table in solution explorer: In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion seed reads, while the third column shows number of fusion rescued reads. There are 3 columns of data, and 11 annotation columns for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predict fusion gene. Below is the result for identified known fusion BCR-ABL1 in K562 samples at genomic level:","title":"Map Fusion Reads"},{"location":"tutorials/DNASeq/Introduction/","text":"Introduction Array Studio Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on Windows Server based NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 40GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial, the Microarray tutorial, as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool. Test Dataset This DNA-Seq tutorial will cover the importing and some analysis of three public datasets. We have selected three SRR run .fastq files. The full dataset is available on the SRA archive: SRR097848 (MCF10A cell line): link SRR097849 (MCF7 cell line): link SRR064173 (K562 cell line): link The whole dataset is ~2.5GB. For convenience, we provide a subset (10% of reads) of the dataset which can be downloaded at: link Note Note: The tutorial is based on the whole dataset; results will be somewhat different if you are using the subset dataset. Also, Omicsoft keeps updating algorithms and data to make sure that users have the most accurate results. Therefore, you may have slightly different results when you compare your results with the results shown in this tutorial. DNA-Seq Analysis Workflow In this tutorial, we will introduce the DNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for DNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, detection of fusion and mutation, and copy number analysis, as shown in the schematic chart below:","title":"Introduction"},{"location":"tutorials/DNASeq/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/DNASeq/Introduction/#array-studio","text":"Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on Windows Server based NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 40GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial, the Microarray tutorial, as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.","title":"Array Studio"},{"location":"tutorials/DNASeq/Introduction/#test-dataset","text":"This DNA-Seq tutorial will cover the importing and some analysis of three public datasets. We have selected three SRR run .fastq files. The full dataset is available on the SRA archive: SRR097848 (MCF10A cell line): link SRR097849 (MCF7 cell line): link SRR064173 (K562 cell line): link The whole dataset is ~2.5GB. For convenience, we provide a subset (10% of reads) of the dataset which can be downloaded at: link Note Note: The tutorial is based on the whole dataset; results will be somewhat different if you are using the subset dataset. Also, Omicsoft keeps updating algorithms and data to make sure that users have the most accurate results. Therefore, you may have slightly different results when you compare your results with the results shown in this tutorial.","title":"Test Dataset"},{"location":"tutorials/DNASeq/Introduction/#dna-seq-analysis-workflow","text":"In this tutorial, we will introduce the DNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for DNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, detection of fusion and mutation, and copy number analysis, as shown in the schematic chart below:","title":"DNA-Seq Analysis Workflow"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/","text":"QC of Aligned Data Alignment Report By default, an alignment report is generated anytime an alignment is done in Array Studio. If it is not already open, go to your Solution Explorer and double click on Report from the AlignmentReport table. This will show, for each pair (or single file if the user did not do a paired alignment), some information regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired). DNA-Seq Aligned QC This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. Also generates a ProfileView showing a chart for each metric. Here we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to Add Data | Add NGS Data | Add DNA-Seq Data | Add Genome-Mapped Reads . To run the DNA-Seq QC module, go to NGS | Aligned Data QC | DNA-Seq QC Metrics now. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. Profile metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723. The analysis returns a Table View of QC metrics and Profile view in the Aligned Data QC folder: In the Table view, you will find the following sections: Alignment Metrics These metrics can be used to give an overall idea of the quality of the alignment for your samples. Duplication Metrics The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an DNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values. FeatureMetrics Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by DNA-Seq data. Flag Metrics Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags. Genome Coverage Metrics Genome coverage metrics provides metrics for genome coverage with different depth, from 1X to 100X. Insert Size Metrics Insert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values such as mean insert sizes that are significantly different from the library's size-selection range. Profile Metrics Profile Metrics provide important overall statistics based on the provided gene model. It is usually used for RNA-Seq data, but it is also a useful metric for exon capture DNA-Seq sequencing, since DNA regions fragments are captured based on a gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling. Strand Metrics The strand metrics give you the rates at which reads are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case. Individual Aligned Data QC DNA-Seq QC Metrics provides comprehensive assessment of the alignment data. We also provide metrics such as Flag Summary Statistics , Mapping Summary Statistics and Paired End Insert Size as separate functions, where users can specify more analysis options. Coverage Summary Statistics Additional coverage summary statistics can be generated by going to NGS | Coverage | Coverage Summary Statistics now. The user can set the size of the coverage for each bin , and whether to output bedGraph files for use in outside programs. Leave options as-is and click Submit to continue. This generates a new table, NgsCoverageReport , which can be used for downstream analysis and visualization. Open the histogram; filter to Chromosome=22 only under View Controller|Row ; layout three charts in 3*1 mode. You can get: There is a clear enrichment at chr22:23600001-23700000 in SRR064173, which is expected since this sample is a targeted sequencing experiment of BCR-ABL1 fusion DNA fragment. In the detail window, users can further check read information in the Genome browser by right clicking the row:","title":"Aligned QC"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#qc-of-aligned-data","text":"","title":"QC of Aligned Data"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#alignment-report","text":"By default, an alignment report is generated anytime an alignment is done in Array Studio. If it is not already open, go to your Solution Explorer and double click on Report from the AlignmentReport table. This will show, for each pair (or single file if the user did not do a paired alignment), some information regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired).","title":"Alignment Report"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#dna-seq-aligned-qc","text":"This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. Also generates a ProfileView showing a chart for each metric. Here we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to Add Data | Add NGS Data | Add DNA-Seq Data | Add Genome-Mapped Reads . To run the DNA-Seq QC module, go to NGS | Aligned Data QC | DNA-Seq QC Metrics now. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. Profile metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723. The analysis returns a Table View of QC metrics and Profile view in the Aligned Data QC folder: In the Table view, you will find the following sections:","title":"DNA-Seq Aligned QC"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#alignment-metrics","text":"These metrics can be used to give an overall idea of the quality of the alignment for your samples.","title":"Alignment Metrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#duplication-metrics","text":"The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an DNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.","title":"Duplication Metrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#featuremetrics","text":"Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by DNA-Seq data.","title":"FeatureMetrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#flag-metrics","text":"Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.","title":"Flag Metrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#genome-coverage-metrics","text":"Genome coverage metrics provides metrics for genome coverage with different depth, from 1X to 100X.","title":"Genome Coverage Metrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#insert-size-metrics","text":"Insert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values such as mean insert sizes that are significantly different from the library's size-selection range.","title":"Insert Size Metrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#profile-metrics","text":"Profile Metrics provide important overall statistics based on the provided gene model. It is usually used for RNA-Seq data, but it is also a useful metric for exon capture DNA-Seq sequencing, since DNA regions fragments are captured based on a gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling.","title":"Profile Metrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#strand-metrics","text":"The strand metrics give you the rates at which reads are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case.","title":"Strand Metrics"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#individual-aligned-data-qc","text":"DNA-Seq QC Metrics provides comprehensive assessment of the alignment data. We also provide metrics such as Flag Summary Statistics , Mapping Summary Statistics and Paired End Insert Size as separate functions, where users can specify more analysis options.","title":"Individual Aligned Data QC"},{"location":"tutorials/DNASeq/QC_of_Aligned_Data/#coverage-summary-statistics","text":"Additional coverage summary statistics can be generated by going to NGS | Coverage | Coverage Summary Statistics now. The user can set the size of the coverage for each bin , and whether to output bedGraph files for use in outside programs. Leave options as-is and click Submit to continue. This generates a new table, NgsCoverageReport , which can be used for downstream analysis and visualization. Open the histogram; filter to Chromosome=22 only under View Controller|Row ; layout three charts in 3*1 mode. You can get: There is a clear enrichment at chr22:23600001-23700000 in SRR064173, which is expected since this sample is a targeted sequencing experiment of BCR-ABL1 fusion DNA fragment. In the detail window, users can further check read information in the Genome browser by right clicking the row:","title":"Coverage Summary Statistics"},{"location":"tutorials/DNASeq/QC_of_Raw_Data_Files/","text":"QC of Raw Data Files Array Studio contains several modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard , which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function individually, which offers more options to specify, such as adapter stripping and max read position. Click Add to find all 6 files for the three samples. The Array Studio Raw Data QC Wizard provides lots of different QC metrics such as Basic statistics , Base Distribution etc. Users can select each QC metric they want to run. Optionally, for a quicker analysis, the user can choose preview mode to only generate QC on the 5% sampled reads. This is, in most cases, good enough to get an assessment of quality. Leave Quality encoding as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Click Submit to begin the analysis. The Raw Data QC module returns multiple raw data QC results/reports in Raw Data QC folder, which are described in the following subsections. Basic Statistics The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. Base distribution QC results are located in the Raw Data QC folder with name BasicStats . Double-click the table view to open if you do not see the basic statistics table in the middle window: Base Distribution Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the Raw Data QC folder with name BaseDistribution . By default, the BaseDistribution ProfileView should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer. Switch to the Legend in the View Controller to see the percentages of A, G, C, and T for each base pair position. Notice that there are a total of 6 charts (scroll through them to look at each sample), one for each file that was QC'ed. Selecting points on the chart will also show additional details in the Details Window, as shown below. One can also switch to line plot view by going to View Controller | Task | Customize | Change To Line Type . Read Quality QC The QC results include a PerSequenceQuality (view and table), a QualityBoxPlot (view and table) and a OverallQualityReport (view and table) in the Solution Explorer. Per Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file. In Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. From the QualityBoxPlot view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR097848. Scroll through each of the 6 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the Details Window below the plot. The Overall Quality Report summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score. K-Mer analysis The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of a kmer in a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short ( e.g. miRNA-seq) and unfiltered adapter dimers. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.01 means 1%) that contain each KMer. There is no significant (all less than 1.5%) enrichment of k mer in this tutorial dataset.","title":"Raw Data QC"},{"location":"tutorials/DNASeq/QC_of_Raw_Data_Files/#qc-of-raw-data-files","text":"Array Studio contains several modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard , which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function individually, which offers more options to specify, such as adapter stripping and max read position. Click Add to find all 6 files for the three samples. The Array Studio Raw Data QC Wizard provides lots of different QC metrics such as Basic statistics , Base Distribution etc. Users can select each QC metric they want to run. Optionally, for a quicker analysis, the user can choose preview mode to only generate QC on the 5% sampled reads. This is, in most cases, good enough to get an assessment of quality. Leave Quality encoding as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Click Submit to begin the analysis. The Raw Data QC module returns multiple raw data QC results/reports in Raw Data QC folder, which are described in the following subsections.","title":"QC of Raw Data Files"},{"location":"tutorials/DNASeq/QC_of_Raw_Data_Files/#basic-statistics","text":"The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. Base distribution QC results are located in the Raw Data QC folder with name BasicStats . Double-click the table view to open if you do not see the basic statistics table in the middle window:","title":"Basic Statistics"},{"location":"tutorials/DNASeq/QC_of_Raw_Data_Files/#base-distribution","text":"Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the Raw Data QC folder with name BaseDistribution . By default, the BaseDistribution ProfileView should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer. Switch to the Legend in the View Controller to see the percentages of A, G, C, and T for each base pair position. Notice that there are a total of 6 charts (scroll through them to look at each sample), one for each file that was QC'ed. Selecting points on the chart will also show additional details in the Details Window, as shown below. One can also switch to line plot view by going to View Controller | Task | Customize | Change To Line Type .","title":"Base Distribution"},{"location":"tutorials/DNASeq/QC_of_Raw_Data_Files/#read-quality-qc","text":"The QC results include a PerSequenceQuality (view and table), a QualityBoxPlot (view and table) and a OverallQualityReport (view and table) in the Solution Explorer. Per Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file. In Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. From the QualityBoxPlot view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR097848. Scroll through each of the 6 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the Details Window below the plot. The Overall Quality Report summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.","title":"Read Quality QC"},{"location":"tutorials/DNASeq/QC_of_Raw_Data_Files/#k-mer-analysis","text":"The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of a kmer in a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short ( e.g. miRNA-seq) and unfiltered adapter dimers. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.01 means 1%) that contain each KMer. There is no significant (all less than 1.5%) enrichment of k mer in this tutorial dataset.","title":"K-Mer analysis"},{"location":"tutorials/DNASeq/Save___Close_Project/","text":"Save & Close Project Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don't hesitate to contact Omicsoft's support team ( support@omicsoft.com ). Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) if you have any questions questions.","title":"Save/Close Project"},{"location":"tutorials/DNASeq/Save___Close_Project/#save-close-project","text":"Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don't hesitate to contact Omicsoft's support team ( support@omicsoft.com ). Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) if you have any questions questions.","title":"Save &amp; Close Project"},{"location":"tutorials/DiseaseLand/","text":"DiseaseLand Tutorial .. toctree:: :maxdepth: 2 Introduction BodyMap DiseaseLand scLand","title":"Home"},{"location":"tutorials/DiseaseLand/BodyMap/","text":"Body Map GTEx GTEx shows data from tissue profiling experiments, and is a good tool to visualize gene expression variation within and across tissues. In this section, we will provide an overview of GTEx, including how to search a gene in GTEx, how to restrict gene expression queries to certain tissues, and how to visualize this gene expression in Genome Browser. General View Once the GTEx data are loaded, users can select the Samples view under the \"select view\" tab. This displays the number of samples for each tissue, colored by Tissue Detail Type. Some of the tissues are broken down by color to show the detailed type of tissues. If you want to see the sample numbers for detailed tissue types, click Grouping - Tissue, and select Tissue Detail Type: The view will plot each sample by detailed tissue type category: Gene Search Let\u2019s search for a gene to see its expression across different tissues. The gene used in this tutorial is serpinb7 , which encodes a member of a family of proteins functioning as protease inhibitors. When you start to input a gene name, the search box will show the auto-complete feature (more than 2 letters): Select serpinB7 from the list, or complete the entry and select Search . The user can see the expression level of serpinb7 across all the GTEx tissues: It is clear that serpinb7 is highly expressed in Skin. The user can use the Filter pane (left-hand side) to select Skin as the only Tissue type in Meta Data: This will leads to a gene expression view focused on Skin Tissue: Then user can group the data by tissue detail type to take a further look, The view will show serpinb7 expression in both Sun Exposed Skin and Not Sun Exposed Skin: Transcript and Exon View The RNA-Seq data on this Land is not only available at the gene level, but also available at the exon and transcript level. If the user wants to figure out which transcript has a high level of expression for the serpinb7 gene, it can be done with the Transcript FPKM (Multi-Transcript Chart)?: The results demonstrate that there are four transcripts for serpinb7, among which the second one has very high expression level in skin tissue (uc010dqg4). Then if user wants to quickly visualize the expression of these transcripts at the exon level, just select the GenomeBrowser view: The GenomeBrowser view plots coverage level of each exon for visible samples, by the specified Grouping . All transcripts in the gene model for the gene are shown at the top of the view, ranked by expression (highest expression on the top). Opacity of the transcripts indicates relative level of expression. In this view, we can tell that uc010dqg.4 is the most highly expressed: You can also directly visualize RNAseq coverage, in the OmicSoft Genome Browser . Switch back to the Gene FPKM View, and select some samples of interest in the plot (e.g. some samples near median); multiple groups of samples can be selected by holding down Ctrl . Click on Browse Selected Samples? in the Action pane, and select Open RNA Seq BAS files For Selection? (see the OmicSoft wiki to learn more about BAS files): Then select SubjectID? (View data from each Subject as a separate track) and click OK: Now the user can see expression of the gene SERPINB7 in these samples: Move the mouse to the subject ID label on the left, and click on Show Exon Junction?, Then the Exon junction will be available in the genome browser view: This also reveals the differential expression of splice variants. Blueprint The data in Blueprint land are categorized by different haematopoietic cell lineages, so it\u2019s a great tool to look into the gene expression variation across related cell types. The ChIP-Seq data from Blueprint are not available yet in Blueprint Land, but we have processed all of the RNA-Seq data from Blueprint, and new data will be updated every quarter. For this section, we will search for a gene named BLK in Blueprint Land. (the Blk gene is involved in B-lymphocyte development, differentiation and signaling.) The Gene FPKM view shows that BLK gene has a very high expression level in B cells, which makes sense as it plays an important role in B-lymphocyte development, differentiation and signaling. Similar to GTEx Land, you can also select samples and browse them in the Genome Browser to visualize the gene expression across different cell lines.","title":"Body Map"},{"location":"tutorials/DiseaseLand/BodyMap/#body-map","text":"","title":"Body Map"},{"location":"tutorials/DiseaseLand/BodyMap/#gtex","text":"GTEx shows data from tissue profiling experiments, and is a good tool to visualize gene expression variation within and across tissues. In this section, we will provide an overview of GTEx, including how to search a gene in GTEx, how to restrict gene expression queries to certain tissues, and how to visualize this gene expression in Genome Browser.","title":"GTEx"},{"location":"tutorials/DiseaseLand/BodyMap/#general-view","text":"Once the GTEx data are loaded, users can select the Samples view under the \"select view\" tab. This displays the number of samples for each tissue, colored by Tissue Detail Type. Some of the tissues are broken down by color to show the detailed type of tissues. If you want to see the sample numbers for detailed tissue types, click Grouping - Tissue, and select Tissue Detail Type: The view will plot each sample by detailed tissue type category:","title":"General View"},{"location":"tutorials/DiseaseLand/BodyMap/#gene-search","text":"Let\u2019s search for a gene to see its expression across different tissues. The gene used in this tutorial is serpinb7 , which encodes a member of a family of proteins functioning as protease inhibitors. When you start to input a gene name, the search box will show the auto-complete feature (more than 2 letters): Select serpinB7 from the list, or complete the entry and select Search . The user can see the expression level of serpinb7 across all the GTEx tissues: It is clear that serpinb7 is highly expressed in Skin. The user can use the Filter pane (left-hand side) to select Skin as the only Tissue type in Meta Data: This will leads to a gene expression view focused on Skin Tissue: Then user can group the data by tissue detail type to take a further look, The view will show serpinb7 expression in both Sun Exposed Skin and Not Sun Exposed Skin:","title":"Gene Search"},{"location":"tutorials/DiseaseLand/BodyMap/#transcript-and-exon-view","text":"The RNA-Seq data on this Land is not only available at the gene level, but also available at the exon and transcript level. If the user wants to figure out which transcript has a high level of expression for the serpinb7 gene, it can be done with the Transcript FPKM (Multi-Transcript Chart)?: The results demonstrate that there are four transcripts for serpinb7, among which the second one has very high expression level in skin tissue (uc010dqg4). Then if user wants to quickly visualize the expression of these transcripts at the exon level, just select the GenomeBrowser view: The GenomeBrowser view plots coverage level of each exon for visible samples, by the specified Grouping . All transcripts in the gene model for the gene are shown at the top of the view, ranked by expression (highest expression on the top). Opacity of the transcripts indicates relative level of expression. In this view, we can tell that uc010dqg.4 is the most highly expressed: You can also directly visualize RNAseq coverage, in the OmicSoft Genome Browser . Switch back to the Gene FPKM View, and select some samples of interest in the plot (e.g. some samples near median); multiple groups of samples can be selected by holding down Ctrl . Click on Browse Selected Samples? in the Action pane, and select Open RNA Seq BAS files For Selection? (see the OmicSoft wiki to learn more about BAS files): Then select SubjectID? (View data from each Subject as a separate track) and click OK: Now the user can see expression of the gene SERPINB7 in these samples: Move the mouse to the subject ID label on the left, and click on Show Exon Junction?, Then the Exon junction will be available in the genome browser view: This also reveals the differential expression of splice variants.","title":"Transcript and Exon View"},{"location":"tutorials/DiseaseLand/BodyMap/#blueprint","text":"The data in Blueprint land are categorized by different haematopoietic cell lineages, so it\u2019s a great tool to look into the gene expression variation across related cell types. The ChIP-Seq data from Blueprint are not available yet in Blueprint Land, but we have processed all of the RNA-Seq data from Blueprint, and new data will be updated every quarter. For this section, we will search for a gene named BLK in Blueprint Land. (the Blk gene is involved in B-lymphocyte development, differentiation and signaling.) The Gene FPKM view shows that BLK gene has a very high expression level in B cells, which makes sense as it plays an important role in B-lymphocyte development, differentiation and signaling. Similar to GTEx Land, you can also select samples and browse them in the Genome Browser to visualize the gene expression across different cell lines.","title":"Blueprint"},{"location":"tutorials/DiseaseLand/DiseaseLand/","text":"DiseaseLand While the GTEx and Blueprint collections serve as atlases of gene expression, DiseaseLand provides expression data from thousands of curated studies focusing on diverse diseases. In addition, you have access to precomputed comparisons from each study: Treated vs Control, Disease vs Normal, Responder vs Non-Responder, where each comparison includes fold changes, raw p-values, adjusted p-values, sample IDs that generated the comparison, ranks, etc. DiseaseLand studies are separated by whether the study was performed in Human (HumanDisease_B37) or Mouse (MouseDisease_B38); the B37/B38 extension indicates the genome build used as the reference library. In this tutorial, HumanDisease_B37 will be used, but many more studies can be found in MouseDisease_B38. Sample View After opening DiseaseLand, the Sample Distribution view will be available, from which you can see how many samples are available for each disease. By default, each sample is grouped by DiseaseCategory , which uses a controlled vocabulary to categorize each sample in Land by the type of disease (for more detailed categorization of diseases, use DiseaseState ). Each sample is colored by TissueCategory ( Tissue provides a more specific description of the tissue source of each sample). In the Sample Meta Data, we have a fully controlled vocabulary for most fields: ProjectName, PlatformName, Organism, SampleSource, SampleType TissueCategory, Tissue, CellType DiseaseCategory, DiseaseState, DiseaseStage, Symptom, SamplePathology Treatment, Response, Transfection, SamplingTime Ethnicity, Gender, Title, Description, etc. With these data, user can easily filter the data by each categories, for instance, data can be filtered by different DiseaseCategory. Comparison View Nearly every DiseaseLand project includes at least one comparison between samples within the project, comparing groups of Case and Control samples across all genes, to identify differentially expressed genes. A comparison is based on grouping of samples based one or more metadata columns (e.g. DiseaseState or Treatment ), so that all Case samples in a Comparison will share the same metadata term (factor), but will differ from the Control samples. To see an overview of available comparisons, Select the comparisons View in the Land: The user will be able to see all comparisons, classified by Case.TissueCategory : Select the samples for Case.Skin . The detailed comparison table will appear in the detail window, from which you can find the comparison details, like Comparison Type , Category , Contrast , etc . Instead of using t-test for all comparisons, Omicsoft statisticians/bioinformaticians work with curation scientists and select the best experimental factors to include in the analysis for each project. We also consider block effects, match samples, and random effects during mathematical modeling. For microarray expression data, linear models are used for log2 transformed intensity and DESeq2 is used for RNA-Seq counting data. Download Comparison Data If the user is interested in particular comparisons, they can download the comparison set to local projects or text files for further analysis. DiseaseLand provides the option to download a set of comparison data for several interesting genes, or for all genes. For instance, if you are interested in comparisons related to diabetes, use the main Comparison View to identify interesting comparisons, then create a comparison set for diabetes first, and then download the comparison data. Here are the steps to create a comparison set. Open the Comparison view (from the main Land View), and filter the Case.Diseasecategory for diabetes: The Comparisons View will show a bar plot of comparisons that used Diabetes samples in the Case set. Select the \"Disease vs. Normal\" comparisons for hematopoietic system. The details window shows the number of comparisons available related to diabetes. Click on Create ComparisonSet , and choose \"Create Comparison Set From Selection\": Input the name and tags for this comparison set (you can input whatever content you like): Once the comparison set is created, it should be able to be seen from Manage | Comparisons | Manage Comparison Sets: The next step is to download the comparison data. As the following image shows, users can download the data to local analysis or text files, both with the option to download selected genes across all comparisons, or download selected comparisons across all genes: And In this tutorial we will just show the example of downloading selected genes across all comparisons (in the comparison set) to local analysis. Be sure to open a local project in Analysis first. Choose the comparison set just created; Select the data format you want to downland; Input the genes you are interested in (here we used genes associated with developing type 2 diabetes, including TCF7L2, PPARG, FTO, KCNJ11, NOTCH2, WFS1, IGF2BP2, SLC30A8, JAZF1, HHEX); Input the output name and click Download . Once the download is finished, switch to the Analysis tab, and the table view will show the relative gene expression value for the selected genes across all of the comparisons: Be sure to try the other options to download comparison data to text file, or download all genes for these comparisons. Gene Views If we do a gene search for serpinb7 in DiseaseLand, the default view that appears is the Comparison - Disease vs. Normal view, which quickly shows all Disease vs. Normal comparisons ( e.g. Psoriasis vs. Normal Control), categorized by different diseases. As shown in the figure below, each circle indicates one Comparison: Log2 Fold Change between Case and Control is plotted on the X-axis, and the size of the circle indicates the P-value (significance) (larger circles are more significant). From the comparison view, it should be clear to the user that this gene is upregulated in several comparisons related to IBD (inflammatory bowel disease), but down-regulated in several cancers. Drag the mouse over one or more spots and select them. This will bring up the comparison details at sample level, which shows the comparisons, genes, meta data information, and a box-plot that shows the sample-level comparison, in this case for ulcerative colitis (UC) vs. normal control. Double-click on the box plot in the right corner to expand the plot so that user can see a full window of the expression profile for serpinb7 in this sample, which demonstrates the original comparison data composing the dot in comparison view. There is an obvious up-regulation for this gene in ulcerative colitis (UC) samples vs. normal control: If the user clicks on the \"+\" symbol to the left of the Details window, a \"Selection Details\" window will pop out from the left corner, and you can view additional details at Gene level, probeset level, and project level. If you select gene level, you can see table view for the comparison in the Details window, as you can see below, we also have a fully controlled vocabulary for the comparison data: The data includes ProjectName, PlatformName, ComparisonType, ComparisonCategory, ComparisonContrast, Fold Change [log2], PValue, Adjusted PValue, ComparisonModel, SampleDataMode, Case.DiseaseState, Case.SampleSource, Case.Tissue, Case.CellType, Case.SampleIDs, Control.DiseaseState, Control.SampleSource, Control.Tissue, Control.CellType, Control.SampleIDs, etc. Click on the Comparison Details (ProbeSet Level), the detailed information will show which probe set was displayed for this gene: Click on Comparison Details (Project Level) to get more information regarding the project itself: And the detail window will show all the information related to the project, like authors, study type, title of the project, etc. In the Filter pane, Click on the Comparison tab. All of the displayed data can be filtered by various types of categories for categorical data (e.g. Case.DiseaseState, Control.Tissue, etc), and by different Cutoffs for numerical data (Fold-Change, Sample Size, P-value, etc): Now click on the Select View Tab. By default, the Disease vs. Control comparisons are displayed, but there are many comparison types available in ImmunoLand: Disease vs. Normal, Disease1 vs. Disease2, CellType1 vs. CellType2, Treatment vs. Control, Treatment1 vs. Treatment2, Responder vs. NonResponder, etc. Explore these different Comparison Views to learn more about the different comparison types. Project View for all samples If the user is interested in a specific microarray project, it can be selected in the view for Expression Intensity (project View)?: Initially, the view will show one chart for each available array project: The user can click on the sample tab, then expand the filter categories to view Meta Data, and click on the symbol to the left of \"DiseaseCategory\". The user can filter for diseases by keywords, for example \"skin\", which will show \"skin and connective tissue disease\". The data will be immediately filtered down to only show charts matching the filter criteria: Besides project information, there are also other filters available for the comparison, like project Description, contact information, platform information, publication information, and project name. Click on the Reset All Filters button to reset all the filters: Similarly, users can browse RNA-seq data and filter to studies of choice: This opens >150 charts in the project view for RNA-seq, with the project and platform name in the title of each chart: You can also view RNAseq and microarray expression data across projects, grouped by one or more metadata columns. As we demonstrated in GTEx and blueprint, the user can get views for DiseaseLand RNA-seq data like Gene FPKM, Transcript FPKM, and Genome Browser view for Exon Details: Select Gene FPKM view: The view will show gene expression levels across different disease categories: And ArrayStudio allows the user to compare the gene expression across different datasets. Select skin disease to filter the disease again: And then group the data by Sample Pathology: These samples will be separated to lesional and non-lesional, from which we can see a pattern for increased expression of serpinb7 in lesional samples. Samples can be profiled by multiple metadata factors, using Specify Multiple Profile Columns : Select DiseaseState and SamplePathology . The Gene FPKM plot will now subset expression of each sample by the Disease (e.g. psoriasis, atopic dermatitis, etc.) and the pathology of the sample (lesional or non-lesional): Alternative Splicing Detection With the former result, you might be interested to find a list of genes with alternative splicing between the lesional and non-lesional samples. How can you find these genes? The basic logic is to create a Sample Set including lesional and non-lesional samples, upload this sample set to the Land, and analyze the alternative splicing through the sample grouping => splicing function in the analysis: The first step is to create the right sample set. Recreate the View made in an earlier section (Gene FPKM view for serpinb7), where the samples were filtered by skin and connective tissue disease, and the view was grouped by sample pathology (filtering for lesional and non-lesional): Then we can choose Create SampleSet , then select all samples and Create SampleSet from Selection (This will create a SampleSet containing all selected samples that passed your filter criteria). Give the SampleSet a name, and provide at least one tag for the sample set, then click Upload: Now go back to do the analysis. Select Analytics | Integration Analysis | Sample Grouping=>Splicing : Select the SampleSet you just created (restrict the analysis to these samples) Choose SamplePathology from the meta data (compare samples by this metadata column) Use RNASeq_Transcript as the data (contains transcript-level information) Provide a name for the result set click on Send To Queue?: This analysis will be submitted for a server job: When complete, this analysis will return a result table. Open the results in Analytics | Open Result Sets . Find the one with your output name. The results should look similar to below: By sorting with Transcript PValue, SerpinB7 appeared as one of the most significant high level splicing genes: And the alternative splicing can be visualized in Genome Browser. Go back to the Gene FPKM view and select several samples from lesional and non-lesional (hold the 'ctrl' keyboard button to select multiple sample groups): These results can be visualized in the browser: And select SamplePathology as the grouping factor: Based on the genome browser view, user can easily tell the alternative splicing pattern compared between lesional and non-lesional transcripts (marked in green circle): Actually, as we can see from the Integration Analysis view, besides alternative splicing, similar methods can be applied to compare the Expression level, Copy Number, and Mutation between the pre-defined sample sets, based on the corresponding data availability: These Analytic functions can be used to quickly identify differences between customized sample groups. Clinical Association For DiseaseCategory Clinical Significance - Group Association can quickly scan all clinical variables in DiseaseLand to find the association of each clinical variable with your selected grouping metadata column. Because this calculation can be quite complicated, it is recommended that you first filter down to samples of interest (e.g. DiseaseCategory or TissueCategory), then open this View. The association table is dynamic. Using SampleSets and Omic Data Queries, you can create a custom cohort to separate the groups to compare. Here are the steps to create a custom query: Separate Expression intensity of Serpinb7 into three groups based on percentile. Specifically, specify two breakpoints (33% and 67%, separated by commas), then label the three groups that are created by the two breakpoints (low,mid,high) (You can specify any number of breakpoints, as long as you provide a label for each group): Then group the association with the custom query: User can also filter the metadata to get a more specific correlation: Find Genes with Similar Expression Pattern In order to find genes with similar expression pattern with the searched gene, the user can either compare genes at the Comparison level (i.e. fold-change between case and control) or the Expression level (e.g. compare Gene FPKM levels in each sample). To look for genes that have similar patterns of up- and down-regulation with your gene of interest, select Comparison Correlations view: For instance, this is the dynamic correlation comparison view for serpinb7 gene, which shows that IL12B is the most highly correlated gene to serpinb7 (As additional data are added to DiseaseLand, these correlations may change in rank): Click on View Correlation Table, for the detailed information for these genes: Users can also specify the disease type for a smaller sample, for instance, just focus on the disease type related to Psoriasis: Filtering for psoriasis samples reveals several genes with strong correlations with SerpinB7. Besides the dynamic correlation at the comparison level, DiseaseLand also can correlate at the gene expression level, using Integration|RNA-Seq-Expression => RNA-Seq-Expression : This view will show the genes with similar expression levels compared to serpinb7: Explore Related Comparisons After searching for a gene of interest, such as Serpinb7, certain Comparisons may show significant differential expression of this gene. You can explore these Comparisons to see the up- and down-regulation of all genes, to get a global perspective on these results. Select view of Disease vs. Normal for serpinb7 gene: Group the data by Case.DiseaseCategory: From the comparison view we can find that an upregulation of gene expression for the samples related to IBD. What other genes are upregulated in these samples besides serpinb7? What else is changing in IBD? Select several comparisons for IBD (or comparisons from IBD and from other diseases), then go to Browse Selected Comparisons? on the bottom-left corner: The default view is a set of volcano plots , one per Comparison, with log2(fold change) on the X-axis and -log10(RawPValue) as the Y-axis (for each project): For each comparison, genes that are significantly differentially expressed will be higher on the Y-axis, with up-regulation to the right, and down-regulation to the left. Go to the Select View tab, where there are several options: Venn Diagram shows how the significant genes correlated with each comparison (up to four comparisons per Venn Diagram): Use the Cutoff Filter tab to control the significance cutoffs (fold-change, P-value, etc) for genes in the Venn Diagram view, as well as the Gene, pathway, project, etc. The Comparison Table contains the full Inference Report for selected comparisons; the user can see a matrix with all the PValue and fold changes, for all the genes curated for the selected samples. (Not all the platforms have every gene, so some of them are missing in the table). This is a useful table if the user wants to analyze it outside of the software. For example, users with a license for QIAGEN Ingenuity Pathway Analysis (IPA) can directly send these results to IPA with a single click: The principal component view shows a generalized distribution of all comparisons selected: The Summary Statistics view shows which gene is most up/down-regulated, how many genes have significant changes for their expressions, etc: The Significant Genes view shows each gene whose expression is up- or down- regulated; and user can sort to organize the result, such as by Up-Regulated Count : Then user can select the genes with the highest up-regulated count and create a gene set from the selection: Input names and tags for the GeneSet: GeneSets are a convenient way to group collections of interesting genes. The user can search with the newly created gene set: And filter the result with IBD disease in Case.DiseaseCategory: Then heatmap of comparison clearly shows an up-regulation pattern for these genes: Gene Set Analysis If user has followed the previous step (Gene Expression Based on Disease/Comparison) to generate a gene set (named as IBD upregulation), user can directly search in the land: If there is no gene set already created, the user can also directly search with multiple genes: And paste genes: CHI3L1,CD55,CFB,IL8,TIMP1,PLAU,NAMPT,CXCL1,ADM,IL1RN Following the Gene set search or searching with multiple genes, ArrayStudio provides a function for identifying Comparisons within the Land that share lists of significant genes with the input set, named Gene Set Analysis : For each Land Comparison, a set of significant genes are identified, and Gene Set Analysis performs a Fisher-exact test for the overlap of your input GeneSet and each Land GeneSet to generate p-values for each comparison. Significant overlaps will be plotted to the right, which might reveal unexpected similarities between your input GeneSet and Land Comparisons. In this view, the X-axis represents the Log10 of P-Value resulted from Fisher-exact test, and Y-axis stands for the Disease Category (the user can also use Specify Profile Column? under Task tab to regroup the comparisons with other metadata columns): If the user selects one of the dots, the detailed window will show the P-value, up/down-regulated gene#, and the project information. DiseaseLand also allows for the creation of GeneSets with other columns, like \"Fold Change\", \"Raw PValue\", \"Adjusted PValue\", etc. An example gene set is shown here: Users can save an inference table from their local analysis as a .txt file and load them to the Land as a gene set, by going to Manage|Genes|Manage Gene Sets : Then Add the Geneset like this: In the MetaData section, load the txt file saved earlier (you can use your own table): Once it's done, go to DiseaseLand without searching any gene, and open the view of Gene Set Analysis (Plot or Table), And choose the Geneset just created. Because P-value and/or Fold-change was provided, GeneSet Analysis uses a Wilcoxon test. For detailed information of the Geneset analysis and the underlying statistics, please refer to our wiki: http://www.arrayserver.com/wiki/index.php?title=Comparison.GeneSetAnalysis . Pathway Search Users can also search with Pathways in DiseaseLand for a list of genes: As the window shows, we provide Positional gene sets, Curated gene sets, Motif gene set, Computational gene sets, GO gene sets, Oncogenic signatures, and Immunologic signatures: Select the gene set of interest, and click OK. Genes in this curated pathway will be searched, and the view will show a Heatmap of Comparison for Disease vs. normal for all the genes in the gene set, categorized by disease type and tissue type.","title":"DiseaseLand"},{"location":"tutorials/DiseaseLand/DiseaseLand/#diseaseland","text":"While the GTEx and Blueprint collections serve as atlases of gene expression, DiseaseLand provides expression data from thousands of curated studies focusing on diverse diseases. In addition, you have access to precomputed comparisons from each study: Treated vs Control, Disease vs Normal, Responder vs Non-Responder, where each comparison includes fold changes, raw p-values, adjusted p-values, sample IDs that generated the comparison, ranks, etc. DiseaseLand studies are separated by whether the study was performed in Human (HumanDisease_B37) or Mouse (MouseDisease_B38); the B37/B38 extension indicates the genome build used as the reference library. In this tutorial, HumanDisease_B37 will be used, but many more studies can be found in MouseDisease_B38.","title":"DiseaseLand"},{"location":"tutorials/DiseaseLand/DiseaseLand/#sample-view","text":"After opening DiseaseLand, the Sample Distribution view will be available, from which you can see how many samples are available for each disease. By default, each sample is grouped by DiseaseCategory , which uses a controlled vocabulary to categorize each sample in Land by the type of disease (for more detailed categorization of diseases, use DiseaseState ). Each sample is colored by TissueCategory ( Tissue provides a more specific description of the tissue source of each sample). In the Sample Meta Data, we have a fully controlled vocabulary for most fields: ProjectName, PlatformName, Organism, SampleSource, SampleType TissueCategory, Tissue, CellType DiseaseCategory, DiseaseState, DiseaseStage, Symptom, SamplePathology Treatment, Response, Transfection, SamplingTime Ethnicity, Gender, Title, Description, etc. With these data, user can easily filter the data by each categories, for instance, data can be filtered by different DiseaseCategory.","title":"Sample View"},{"location":"tutorials/DiseaseLand/DiseaseLand/#comparison-view","text":"Nearly every DiseaseLand project includes at least one comparison between samples within the project, comparing groups of Case and Control samples across all genes, to identify differentially expressed genes. A comparison is based on grouping of samples based one or more metadata columns (e.g. DiseaseState or Treatment ), so that all Case samples in a Comparison will share the same metadata term (factor), but will differ from the Control samples. To see an overview of available comparisons, Select the comparisons View in the Land: The user will be able to see all comparisons, classified by Case.TissueCategory : Select the samples for Case.Skin . The detailed comparison table will appear in the detail window, from which you can find the comparison details, like Comparison Type , Category , Contrast , etc . Instead of using t-test for all comparisons, Omicsoft statisticians/bioinformaticians work with curation scientists and select the best experimental factors to include in the analysis for each project. We also consider block effects, match samples, and random effects during mathematical modeling. For microarray expression data, linear models are used for log2 transformed intensity and DESeq2 is used for RNA-Seq counting data.","title":"Comparison View"},{"location":"tutorials/DiseaseLand/DiseaseLand/#download-comparison-data","text":"If the user is interested in particular comparisons, they can download the comparison set to local projects or text files for further analysis. DiseaseLand provides the option to download a set of comparison data for several interesting genes, or for all genes. For instance, if you are interested in comparisons related to diabetes, use the main Comparison View to identify interesting comparisons, then create a comparison set for diabetes first, and then download the comparison data. Here are the steps to create a comparison set. Open the Comparison view (from the main Land View), and filter the Case.Diseasecategory for diabetes: The Comparisons View will show a bar plot of comparisons that used Diabetes samples in the Case set. Select the \"Disease vs. Normal\" comparisons for hematopoietic system. The details window shows the number of comparisons available related to diabetes. Click on Create ComparisonSet , and choose \"Create Comparison Set From Selection\": Input the name and tags for this comparison set (you can input whatever content you like): Once the comparison set is created, it should be able to be seen from Manage | Comparisons | Manage Comparison Sets: The next step is to download the comparison data. As the following image shows, users can download the data to local analysis or text files, both with the option to download selected genes across all comparisons, or download selected comparisons across all genes: And In this tutorial we will just show the example of downloading selected genes across all comparisons (in the comparison set) to local analysis. Be sure to open a local project in Analysis first. Choose the comparison set just created; Select the data format you want to downland; Input the genes you are interested in (here we used genes associated with developing type 2 diabetes, including TCF7L2, PPARG, FTO, KCNJ11, NOTCH2, WFS1, IGF2BP2, SLC30A8, JAZF1, HHEX); Input the output name and click Download . Once the download is finished, switch to the Analysis tab, and the table view will show the relative gene expression value for the selected genes across all of the comparisons: Be sure to try the other options to download comparison data to text file, or download all genes for these comparisons.","title":"Download Comparison Data"},{"location":"tutorials/DiseaseLand/DiseaseLand/#gene-views","text":"If we do a gene search for serpinb7 in DiseaseLand, the default view that appears is the Comparison - Disease vs. Normal view, which quickly shows all Disease vs. Normal comparisons ( e.g. Psoriasis vs. Normal Control), categorized by different diseases. As shown in the figure below, each circle indicates one Comparison: Log2 Fold Change between Case and Control is plotted on the X-axis, and the size of the circle indicates the P-value (significance) (larger circles are more significant). From the comparison view, it should be clear to the user that this gene is upregulated in several comparisons related to IBD (inflammatory bowel disease), but down-regulated in several cancers. Drag the mouse over one or more spots and select them. This will bring up the comparison details at sample level, which shows the comparisons, genes, meta data information, and a box-plot that shows the sample-level comparison, in this case for ulcerative colitis (UC) vs. normal control. Double-click on the box plot in the right corner to expand the plot so that user can see a full window of the expression profile for serpinb7 in this sample, which demonstrates the original comparison data composing the dot in comparison view. There is an obvious up-regulation for this gene in ulcerative colitis (UC) samples vs. normal control: If the user clicks on the \"+\" symbol to the left of the Details window, a \"Selection Details\" window will pop out from the left corner, and you can view additional details at Gene level, probeset level, and project level. If you select gene level, you can see table view for the comparison in the Details window, as you can see below, we also have a fully controlled vocabulary for the comparison data: The data includes ProjectName, PlatformName, ComparisonType, ComparisonCategory, ComparisonContrast, Fold Change [log2], PValue, Adjusted PValue, ComparisonModel, SampleDataMode, Case.DiseaseState, Case.SampleSource, Case.Tissue, Case.CellType, Case.SampleIDs, Control.DiseaseState, Control.SampleSource, Control.Tissue, Control.CellType, Control.SampleIDs, etc. Click on the Comparison Details (ProbeSet Level), the detailed information will show which probe set was displayed for this gene: Click on Comparison Details (Project Level) to get more information regarding the project itself: And the detail window will show all the information related to the project, like authors, study type, title of the project, etc. In the Filter pane, Click on the Comparison tab. All of the displayed data can be filtered by various types of categories for categorical data (e.g. Case.DiseaseState, Control.Tissue, etc), and by different Cutoffs for numerical data (Fold-Change, Sample Size, P-value, etc): Now click on the Select View Tab. By default, the Disease vs. Control comparisons are displayed, but there are many comparison types available in ImmunoLand: Disease vs. Normal, Disease1 vs. Disease2, CellType1 vs. CellType2, Treatment vs. Control, Treatment1 vs. Treatment2, Responder vs. NonResponder, etc. Explore these different Comparison Views to learn more about the different comparison types.","title":"Gene Views"},{"location":"tutorials/DiseaseLand/DiseaseLand/#project-view-for-all-samples","text":"If the user is interested in a specific microarray project, it can be selected in the view for Expression Intensity (project View)?: Initially, the view will show one chart for each available array project: The user can click on the sample tab, then expand the filter categories to view Meta Data, and click on the symbol to the left of \"DiseaseCategory\". The user can filter for diseases by keywords, for example \"skin\", which will show \"skin and connective tissue disease\". The data will be immediately filtered down to only show charts matching the filter criteria: Besides project information, there are also other filters available for the comparison, like project Description, contact information, platform information, publication information, and project name. Click on the Reset All Filters button to reset all the filters: Similarly, users can browse RNA-seq data and filter to studies of choice: This opens >150 charts in the project view for RNA-seq, with the project and platform name in the title of each chart: You can also view RNAseq and microarray expression data across projects, grouped by one or more metadata columns. As we demonstrated in GTEx and blueprint, the user can get views for DiseaseLand RNA-seq data like Gene FPKM, Transcript FPKM, and Genome Browser view for Exon Details: Select Gene FPKM view: The view will show gene expression levels across different disease categories: And ArrayStudio allows the user to compare the gene expression across different datasets. Select skin disease to filter the disease again: And then group the data by Sample Pathology: These samples will be separated to lesional and non-lesional, from which we can see a pattern for increased expression of serpinb7 in lesional samples. Samples can be profiled by multiple metadata factors, using Specify Multiple Profile Columns : Select DiseaseState and SamplePathology . The Gene FPKM plot will now subset expression of each sample by the Disease (e.g. psoriasis, atopic dermatitis, etc.) and the pathology of the sample (lesional or non-lesional):","title":"Project View for all samples"},{"location":"tutorials/DiseaseLand/DiseaseLand/#alternative-splicing-detection","text":"With the former result, you might be interested to find a list of genes with alternative splicing between the lesional and non-lesional samples. How can you find these genes? The basic logic is to create a Sample Set including lesional and non-lesional samples, upload this sample set to the Land, and analyze the alternative splicing through the sample grouping => splicing function in the analysis: The first step is to create the right sample set. Recreate the View made in an earlier section (Gene FPKM view for serpinb7), where the samples were filtered by skin and connective tissue disease, and the view was grouped by sample pathology (filtering for lesional and non-lesional): Then we can choose Create SampleSet , then select all samples and Create SampleSet from Selection (This will create a SampleSet containing all selected samples that passed your filter criteria). Give the SampleSet a name, and provide at least one tag for the sample set, then click Upload: Now go back to do the analysis. Select Analytics | Integration Analysis | Sample Grouping=>Splicing : Select the SampleSet you just created (restrict the analysis to these samples) Choose SamplePathology from the meta data (compare samples by this metadata column) Use RNASeq_Transcript as the data (contains transcript-level information) Provide a name for the result set click on Send To Queue?: This analysis will be submitted for a server job: When complete, this analysis will return a result table. Open the results in Analytics | Open Result Sets . Find the one with your output name. The results should look similar to below: By sorting with Transcript PValue, SerpinB7 appeared as one of the most significant high level splicing genes: And the alternative splicing can be visualized in Genome Browser. Go back to the Gene FPKM view and select several samples from lesional and non-lesional (hold the 'ctrl' keyboard button to select multiple sample groups): These results can be visualized in the browser: And select SamplePathology as the grouping factor: Based on the genome browser view, user can easily tell the alternative splicing pattern compared between lesional and non-lesional transcripts (marked in green circle): Actually, as we can see from the Integration Analysis view, besides alternative splicing, similar methods can be applied to compare the Expression level, Copy Number, and Mutation between the pre-defined sample sets, based on the corresponding data availability: These Analytic functions can be used to quickly identify differences between customized sample groups.","title":"Alternative Splicing Detection"},{"location":"tutorials/DiseaseLand/DiseaseLand/#clinical-association-for-diseasecategory","text":"Clinical Significance - Group Association can quickly scan all clinical variables in DiseaseLand to find the association of each clinical variable with your selected grouping metadata column. Because this calculation can be quite complicated, it is recommended that you first filter down to samples of interest (e.g. DiseaseCategory or TissueCategory), then open this View. The association table is dynamic. Using SampleSets and Omic Data Queries, you can create a custom cohort to separate the groups to compare. Here are the steps to create a custom query: Separate Expression intensity of Serpinb7 into three groups based on percentile. Specifically, specify two breakpoints (33% and 67%, separated by commas), then label the three groups that are created by the two breakpoints (low,mid,high) (You can specify any number of breakpoints, as long as you provide a label for each group): Then group the association with the custom query: User can also filter the metadata to get a more specific correlation:","title":"Clinical Association For DiseaseCategory"},{"location":"tutorials/DiseaseLand/DiseaseLand/#find-genes-with-similar-expression-pattern","text":"In order to find genes with similar expression pattern with the searched gene, the user can either compare genes at the Comparison level (i.e. fold-change between case and control) or the Expression level (e.g. compare Gene FPKM levels in each sample). To look for genes that have similar patterns of up- and down-regulation with your gene of interest, select Comparison Correlations view: For instance, this is the dynamic correlation comparison view for serpinb7 gene, which shows that IL12B is the most highly correlated gene to serpinb7 (As additional data are added to DiseaseLand, these correlations may change in rank): Click on View Correlation Table, for the detailed information for these genes: Users can also specify the disease type for a smaller sample, for instance, just focus on the disease type related to Psoriasis: Filtering for psoriasis samples reveals several genes with strong correlations with SerpinB7. Besides the dynamic correlation at the comparison level, DiseaseLand also can correlate at the gene expression level, using Integration|RNA-Seq-Expression => RNA-Seq-Expression : This view will show the genes with similar expression levels compared to serpinb7:","title":"Find Genes with Similar Expression Pattern"},{"location":"tutorials/DiseaseLand/DiseaseLand/#explore-related-comparisons","text":"After searching for a gene of interest, such as Serpinb7, certain Comparisons may show significant differential expression of this gene. You can explore these Comparisons to see the up- and down-regulation of all genes, to get a global perspective on these results. Select view of Disease vs. Normal for serpinb7 gene: Group the data by Case.DiseaseCategory: From the comparison view we can find that an upregulation of gene expression for the samples related to IBD. What other genes are upregulated in these samples besides serpinb7? What else is changing in IBD? Select several comparisons for IBD (or comparisons from IBD and from other diseases), then go to Browse Selected Comparisons? on the bottom-left corner: The default view is a set of volcano plots , one per Comparison, with log2(fold change) on the X-axis and -log10(RawPValue) as the Y-axis (for each project): For each comparison, genes that are significantly differentially expressed will be higher on the Y-axis, with up-regulation to the right, and down-regulation to the left. Go to the Select View tab, where there are several options: Venn Diagram shows how the significant genes correlated with each comparison (up to four comparisons per Venn Diagram): Use the Cutoff Filter tab to control the significance cutoffs (fold-change, P-value, etc) for genes in the Venn Diagram view, as well as the Gene, pathway, project, etc. The Comparison Table contains the full Inference Report for selected comparisons; the user can see a matrix with all the PValue and fold changes, for all the genes curated for the selected samples. (Not all the platforms have every gene, so some of them are missing in the table). This is a useful table if the user wants to analyze it outside of the software. For example, users with a license for QIAGEN Ingenuity Pathway Analysis (IPA) can directly send these results to IPA with a single click: The principal component view shows a generalized distribution of all comparisons selected: The Summary Statistics view shows which gene is most up/down-regulated, how many genes have significant changes for their expressions, etc: The Significant Genes view shows each gene whose expression is up- or down- regulated; and user can sort to organize the result, such as by Up-Regulated Count : Then user can select the genes with the highest up-regulated count and create a gene set from the selection: Input names and tags for the GeneSet: GeneSets are a convenient way to group collections of interesting genes. The user can search with the newly created gene set: And filter the result with IBD disease in Case.DiseaseCategory: Then heatmap of comparison clearly shows an up-regulation pattern for these genes:","title":"Explore Related Comparisons"},{"location":"tutorials/DiseaseLand/DiseaseLand/#gene-set-analysis","text":"If user has followed the previous step (Gene Expression Based on Disease/Comparison) to generate a gene set (named as IBD upregulation), user can directly search in the land: If there is no gene set already created, the user can also directly search with multiple genes: And paste genes: CHI3L1,CD55,CFB,IL8,TIMP1,PLAU,NAMPT,CXCL1,ADM,IL1RN Following the Gene set search or searching with multiple genes, ArrayStudio provides a function for identifying Comparisons within the Land that share lists of significant genes with the input set, named Gene Set Analysis : For each Land Comparison, a set of significant genes are identified, and Gene Set Analysis performs a Fisher-exact test for the overlap of your input GeneSet and each Land GeneSet to generate p-values for each comparison. Significant overlaps will be plotted to the right, which might reveal unexpected similarities between your input GeneSet and Land Comparisons. In this view, the X-axis represents the Log10 of P-Value resulted from Fisher-exact test, and Y-axis stands for the Disease Category (the user can also use Specify Profile Column? under Task tab to regroup the comparisons with other metadata columns): If the user selects one of the dots, the detailed window will show the P-value, up/down-regulated gene#, and the project information. DiseaseLand also allows for the creation of GeneSets with other columns, like \"Fold Change\", \"Raw PValue\", \"Adjusted PValue\", etc. An example gene set is shown here: Users can save an inference table from their local analysis as a .txt file and load them to the Land as a gene set, by going to Manage|Genes|Manage Gene Sets : Then Add the Geneset like this: In the MetaData section, load the txt file saved earlier (you can use your own table): Once it's done, go to DiseaseLand without searching any gene, and open the view of Gene Set Analysis (Plot or Table), And choose the Geneset just created. Because P-value and/or Fold-change was provided, GeneSet Analysis uses a Wilcoxon test. For detailed information of the Geneset analysis and the underlying statistics, please refer to our wiki: http://www.arrayserver.com/wiki/index.php?title=Comparison.GeneSetAnalysis .","title":"Gene Set Analysis"},{"location":"tutorials/DiseaseLand/DiseaseLand/#pathway-search","text":"Users can also search with Pathways in DiseaseLand for a list of genes: As the window shows, we provide Positional gene sets, Curated gene sets, Motif gene set, Computational gene sets, GO gene sets, Oncogenic signatures, and Immunologic signatures: Select the gene set of interest, and click OK. Genes in this curated pathway will be searched, and the view will show a Heatmap of Comparison for Disease vs. normal for all the genes in the gene set, categorized by disease type and tissue type.","title":"Pathway Search"},{"location":"tutorials/DiseaseLand/Introduction/","text":"Introduction In this tutorial we will explore several Lands in the \"DiseaseLand\" collection: Body Map (GTEx and Blueprint), DiseaseLand (Human and Mouse curated disease-centric studies), scLand (Human and Mouse single-cell RNA studies), and LINCS (Cell line pharmacologic perturbation using the Broad L1000 profiling system). Each Land has its own advantages, and all serve as great tools for exploring high impact disease-centric studies. Further details are available in the DiseaseLand release White Paper. To get the access to these lands, user should first connect to a server: And then click the Land tab and click on \"Select Land\": Body Map Collection In the current release, Body Map includes two lands: GTEx and Blueprint. Samples in the Body Map collection are from normal tissue; these Lands are great for answering questions such as: * In what tissue is my gene expressed? * Which transcripts are usually expressed from that gene for my tissue of my interest? * Are there any genes with differential transcript usage between tissues, etc. GTEx The data in GTEx Land come from the Genotype Tissue Expression (GTEx) program, which aims to study human gene expression and regulation in multiple tissues. GTEx is a map of normal tissue, revealing the genetic variation, gene expression, and other molecular phenotypes in specific human tissues. It is a great tool to provide biological interpretations of disease related genetic variations. Currently, GTEx covers microarray and RNA-Seq expression data for nearly 10,000 samples. Blueprint The Blueprint dataset contains RNA-Seq data from a European epigenetic study link , which focused on distinct types of haematopoietic cells from healthy individuals and on their malignant leukaemic counterparts. Blueprint Land has 258 samples from 57 cell types in the latest release. It is still in expansion and we will continue to add data to this Land (including eventually the ChIP-seq data). Blueprint Land is a great tool to look into different gene expression categorized by different cell lines. DiseaseLand Collection ImmunoLand and CVMLand Historically, ImmunoLand (focused on immunological and inflammatory disease) and CVMLand (cardiovascular and metabolic disease) were maintained as separate \"Lands\". As OmicSoft continued to add content, including projects focusing on neurological diseases, mood disorders, infectious diseases, etc., this explicit division became less meaningful. Now, all non-oncology disease studies are in DiseaseLand , and sub-stratified by \"collection\" (Immuno or CVM). Subscribers to DiseaseLand may choose to subscribe to either collection, or both, but will always find the data in DiseaseLand . Hundreds of new projects are added to DiseaseLand every quarter, and it is a customer-driven expanding database (If you have other disease areas that you are interested to add into ImmunoLand, please let us know by e-mailing Omicsoft support at support@omicsoft.com ). Currently, DiseaseLand has more than 85,000 human samples and 25,000 mouse samples, across different cell types and tissues. Omicsoft has carefully curated both sample level data and \"comparison\" level data, allowing users to easily search and visualize data using common queries: Treated vs Control, Disease vs Normal, Responder vs Non-Responder, etc. Expression data are reprocessed from raw files and normalized to a common standard, which dramatically improves cross-project comparisons. ImmunoLand Collection The ImmunoLand collection contains datasets retrieved from several public projects, including GEO (Gene Expression Omnibus), SRA (Sequence Read Archive), and ArrayExpress. As the name implies, ImmunoLand is an immune-focused database containing data from multiple data types (RNA-Seq, Expression, more), with a focus on immune-related diseases: Asthma/Respiratory Diseases, Arthritis, Allergies, COPD, IBD, Psoriasis, SLE (systemic lupus erythematosus), Multiple Sclerosis, Neurodegenerative Diseases, and Infectious Diseases. CVMLand CVMLand mainly focuses on Cardiovascular and metabolic disease: diabetes mellitus, glucose intolerance, infectious disease, islet autoantibody positive, lipid metabolism disorder, and nutrition disorders.","title":"Introduction"},{"location":"tutorials/DiseaseLand/Introduction/#introduction","text":"In this tutorial we will explore several Lands in the \"DiseaseLand\" collection: Body Map (GTEx and Blueprint), DiseaseLand (Human and Mouse curated disease-centric studies), scLand (Human and Mouse single-cell RNA studies), and LINCS (Cell line pharmacologic perturbation using the Broad L1000 profiling system). Each Land has its own advantages, and all serve as great tools for exploring high impact disease-centric studies. Further details are available in the DiseaseLand release White Paper. To get the access to these lands, user should first connect to a server: And then click the Land tab and click on \"Select Land\":","title":"Introduction"},{"location":"tutorials/DiseaseLand/Introduction/#body-map-collection","text":"In the current release, Body Map includes two lands: GTEx and Blueprint. Samples in the Body Map collection are from normal tissue; these Lands are great for answering questions such as: * In what tissue is my gene expressed? * Which transcripts are usually expressed from that gene for my tissue of my interest? * Are there any genes with differential transcript usage between tissues, etc.","title":"Body Map Collection"},{"location":"tutorials/DiseaseLand/Introduction/#gtex","text":"The data in GTEx Land come from the Genotype Tissue Expression (GTEx) program, which aims to study human gene expression and regulation in multiple tissues. GTEx is a map of normal tissue, revealing the genetic variation, gene expression, and other molecular phenotypes in specific human tissues. It is a great tool to provide biological interpretations of disease related genetic variations. Currently, GTEx covers microarray and RNA-Seq expression data for nearly 10,000 samples.","title":"GTEx"},{"location":"tutorials/DiseaseLand/Introduction/#blueprint","text":"The Blueprint dataset contains RNA-Seq data from a European epigenetic study link , which focused on distinct types of haematopoietic cells from healthy individuals and on their malignant leukaemic counterparts. Blueprint Land has 258 samples from 57 cell types in the latest release. It is still in expansion and we will continue to add data to this Land (including eventually the ChIP-seq data). Blueprint Land is a great tool to look into different gene expression categorized by different cell lines.","title":"Blueprint"},{"location":"tutorials/DiseaseLand/Introduction/#diseaseland-collection","text":"","title":"DiseaseLand Collection"},{"location":"tutorials/DiseaseLand/Introduction/#immunoland-and-cvmland","text":"Historically, ImmunoLand (focused on immunological and inflammatory disease) and CVMLand (cardiovascular and metabolic disease) were maintained as separate \"Lands\". As OmicSoft continued to add content, including projects focusing on neurological diseases, mood disorders, infectious diseases, etc., this explicit division became less meaningful. Now, all non-oncology disease studies are in DiseaseLand , and sub-stratified by \"collection\" (Immuno or CVM). Subscribers to DiseaseLand may choose to subscribe to either collection, or both, but will always find the data in DiseaseLand . Hundreds of new projects are added to DiseaseLand every quarter, and it is a customer-driven expanding database (If you have other disease areas that you are interested to add into ImmunoLand, please let us know by e-mailing Omicsoft support at support@omicsoft.com ). Currently, DiseaseLand has more than 85,000 human samples and 25,000 mouse samples, across different cell types and tissues. Omicsoft has carefully curated both sample level data and \"comparison\" level data, allowing users to easily search and visualize data using common queries: Treated vs Control, Disease vs Normal, Responder vs Non-Responder, etc. Expression data are reprocessed from raw files and normalized to a common standard, which dramatically improves cross-project comparisons.","title":"ImmunoLand and CVMLand"},{"location":"tutorials/DiseaseLand/Introduction/#immunoland-collection","text":"The ImmunoLand collection contains datasets retrieved from several public projects, including GEO (Gene Expression Omnibus), SRA (Sequence Read Archive), and ArrayExpress. As the name implies, ImmunoLand is an immune-focused database containing data from multiple data types (RNA-Seq, Expression, more), with a focus on immune-related diseases: Asthma/Respiratory Diseases, Arthritis, Allergies, COPD, IBD, Psoriasis, SLE (systemic lupus erythematosus), Multiple Sclerosis, Neurodegenerative Diseases, and Infectious Diseases.","title":"ImmunoLand Collection"},{"location":"tutorials/DiseaseLand/Introduction/#cvmland","text":"CVMLand mainly focuses on Cardiovascular and metabolic disease: diabetes mellitus, glucose intolerance, infectious disease, islet autoantibody positive, lipid metabolism disorder, and nutrition disorders.","title":"CVMLand"},{"location":"tutorials/DiseaseLand/LINCS/","text":"LINCS LINCS Land provides access to expression data of 23 cell lines, exposed to over 360 different perturbations at different concentrations, resulting in over 100,000 different samples. Expression profiling was performed using Broad Institute's L1000 platform, which profiles ~1,000 \"Landmark\" genes, and uses expression profiles of these genes to extrapolate the expected expression of all other genes (\"imputed genes\") in the transcriptome. LINCS Sample Grouping As groups of molecules that affect related pathways were tested, each sample was assigned a TreatmentGroup , which allows rapid identification of perturbations of interest, such as kinase inhibitors , Rho signaling inhibitors , epigenetic modifiers , etc. LINCS Comparisons A primary focus of LINCS is comparing expression of each perturbation to a set of control samples, so the Comparisons View is especially useful here. To see an overview of all comparisons in LINCS Land, click Select View | Comparisons . Notice that there are thousands of comparisons between different perturbations (drug treatments and gene over-expression): It might also be useful to Specify Histogram Columns to Case.TreatmentGroup (you can change the Specify Group Column to Control.TreatmentGroup ). Identify a TreatmentGroup of interest, then filter for that group under the Comparison Filter:Case.TreatmentGroup (e.g. MAPK/ERK signaling inhibitor): Select Specify Histogram Columns and choose Case.Treament to see the different MAPK inhibitors that were tested (color by dosage): Further filter for a specific treatment, and a specific dosage (perhaps the highest dosage for that treatment, e.g. 10uM for vemurafenib), then profile by Case.CellType and Color by Case.CellLine: Click on one or more of the comparisons to view the Comparison Details ; note the ComparisonID : Comparisons can be directly searched in the Search bar : But it is more convenient to select one or more comparisons, then click Browse Selected Comparisons . In this case, select all 19 visible comparisons (i.e. 10uM vemurafenib treatments), then Browse Selected Comparisons . One Volcano Plot will be displayed for each comparison. Change the layout from 1*1 to 3*3 (or if you have a large monitor, 5*5 ), and click Toggle Uniform Scale Status , so that all Volcano plots use the same scales. Notice that two Comparisons show exceptional responses to vemurafenib. Click the checkboxes at these plots to view Comparison Details . Notice the two Case.CellLines ; both HT-29 and A375 harbor the V600E mutation in BRAF , which is the target of Vemurafenib . Filter for these two Comparisons in the Filter Pane , then switch to the Venn Diagram (Significant Genes) View: In the Filter Tab, use the Cutoff Filters to identify a relatively stringent cutoff that reduces the number of genes shared by the two comparisons (e.g. an adjusted P-value of 10e-8). Create a GeneSet from this set of genes, then search for the GeneSet: Searching for multiple genes (or a GeneSet) will show a Comparison Heatmap View . Filter down to Case.TreatmentGroup:MAPK/ERK signaling inhibitor , and notice that the comparisons and genes are automatically clustered. |LINCS_Heatmap_MAPKtreatmentGroup_png| Notice the large cluster of comparisons with similar expression dynamics. Select these comparisons with the mouse, and (after syncing the massive amount of information from ArrayServer), click Filter Selection in the Action pane, to filter the Comparison Heatmap to these specific comparisons: In addition to vemurafenib, several other drugs that are used to target tumors with BRAF V600E show a similar gene activation/repression profile, including dabrafenib and trametinib.","title":"LINCs"},{"location":"tutorials/DiseaseLand/LINCS/#lincs","text":"LINCS Land provides access to expression data of 23 cell lines, exposed to over 360 different perturbations at different concentrations, resulting in over 100,000 different samples. Expression profiling was performed using Broad Institute's L1000 platform, which profiles ~1,000 \"Landmark\" genes, and uses expression profiles of these genes to extrapolate the expected expression of all other genes (\"imputed genes\") in the transcriptome.","title":"LINCS"},{"location":"tutorials/DiseaseLand/LINCS/#lincs-sample-grouping","text":"As groups of molecules that affect related pathways were tested, each sample was assigned a TreatmentGroup , which allows rapid identification of perturbations of interest, such as kinase inhibitors , Rho signaling inhibitors , epigenetic modifiers , etc.","title":"LINCS Sample Grouping"},{"location":"tutorials/DiseaseLand/LINCS/#lincs-comparisons","text":"A primary focus of LINCS is comparing expression of each perturbation to a set of control samples, so the Comparisons View is especially useful here. To see an overview of all comparisons in LINCS Land, click Select View | Comparisons . Notice that there are thousands of comparisons between different perturbations (drug treatments and gene over-expression): It might also be useful to Specify Histogram Columns to Case.TreatmentGroup (you can change the Specify Group Column to Control.TreatmentGroup ). Identify a TreatmentGroup of interest, then filter for that group under the Comparison Filter:Case.TreatmentGroup (e.g. MAPK/ERK signaling inhibitor): Select Specify Histogram Columns and choose Case.Treament to see the different MAPK inhibitors that were tested (color by dosage): Further filter for a specific treatment, and a specific dosage (perhaps the highest dosage for that treatment, e.g. 10uM for vemurafenib), then profile by Case.CellType and Color by Case.CellLine: Click on one or more of the comparisons to view the Comparison Details ; note the ComparisonID : Comparisons can be directly searched in the Search bar : But it is more convenient to select one or more comparisons, then click Browse Selected Comparisons . In this case, select all 19 visible comparisons (i.e. 10uM vemurafenib treatments), then Browse Selected Comparisons . One Volcano Plot will be displayed for each comparison. Change the layout from 1*1 to 3*3 (or if you have a large monitor, 5*5 ), and click Toggle Uniform Scale Status , so that all Volcano plots use the same scales. Notice that two Comparisons show exceptional responses to vemurafenib. Click the checkboxes at these plots to view Comparison Details . Notice the two Case.CellLines ; both HT-29 and A375 harbor the V600E mutation in BRAF , which is the target of Vemurafenib . Filter for these two Comparisons in the Filter Pane , then switch to the Venn Diagram (Significant Genes) View: In the Filter Tab, use the Cutoff Filters to identify a relatively stringent cutoff that reduces the number of genes shared by the two comparisons (e.g. an adjusted P-value of 10e-8). Create a GeneSet from this set of genes, then search for the GeneSet: Searching for multiple genes (or a GeneSet) will show a Comparison Heatmap View . Filter down to Case.TreatmentGroup:MAPK/ERK signaling inhibitor , and notice that the comparisons and genes are automatically clustered. |LINCS_Heatmap_MAPKtreatmentGroup_png| Notice the large cluster of comparisons with similar expression dynamics. Select these comparisons with the mouse, and (after syncing the massive amount of information from ArrayServer), click Filter Selection in the Action pane, to filter the Comparison Heatmap to these specific comparisons: In addition to vemurafenib, several other drugs that are used to target tumors with BRAF V600E show a similar gene activation/repression profile, including dabrafenib and trametinib.","title":"LINCS Comparisons"},{"location":"tutorials/DiseaseLand/scLand/","text":"Single Cell Lands Single-Cell RNA sequencing is emerging as a powerful tool for capturing cellular heterogeneity, which is useful in profiling tumors, nervous system development, detection of rare cell types, and more. Cells are sorted or captured in microfluidic devices, and individual cells are sequenced, providing unprecedented insight into the composition of tissues. OmicSoft\u2019s Single Cell Lands (scHuman and scMouse) contain datasets from multiple single-cell RNAseq projects. Because of the special nature of scRNA processing, both the data and metadata processing steps differ somewhat from \"standard\" Land processing. Data are aligned with OmicSoft's OSA aligner, and each sample is analyzed to ensure that it passes certain QC parameters, such as overall alignment rate, mitochondrial mapping rate, mapped reads, and the number of genes covered (the latest filter criteria can be found at the OmicSoft wiki page SCLand Development Notes ). Gene expression for most samples will be quantified by Transcripts Per Million (TPM) . RNA with Unique Molecular Identifiers (UMI) (as well as samples with a severe 3' or 5' gene coverage bias) will be quantified as Reads Per Million (RPM) , which assumes that all transcripts are 1kb long. Metadata are processed and brought in-line with Controlled Vocabularies. Several metadata columns are especially important for single cell data, including ''Cell Number'' (whether the sample is from a single cell, 10 cells, population, etc.), ''Library Strategy'' (the method for generating the sequencing library), ''UMI'' (whether or not UMIs were used), and ''Clinical - Subject ID'' (groups together cells from a single tissue sample). Additional project-specific metadata may also be in the Clinical Variables ; after you have filtered for samples of interest (e.g. an interesting project), be sure to explore the clinical metadata to help you partition samples and subjects by metadata. Gene-level Views scLands contain RNaseq data, so all of the familiar RNAseq-based Views will be available. In this example, we display views when searching for the gene \"egfr\". The default View is the Gene TPM (Project View) , where the RNAseq data are trellised by ProjectName and PlatformName into separate charts: Either scroll down or filter for project GSE57872 , sequencing of five glioblastoma tumors. Select some of the samples from the Treatment: None row, to see the metadata for these samples: Click the + Symbol in the Metadata pane to allow selection of different metadata types. In this case, we are interested in Clinical metadata , specifically Clinical - SubjectID , which uniquely identifies the subject from which the cells were isolated. Filter for CellNumber:1 to only show expression data from single cells (not populations). Under the Task tab on the right, choose Change Symbol Properties . Change Color to Clinical - SubjectID to color each sample by the source tumor: Now choose Task tab: Specify Multiple Profile Columns , and select both Treatment and Clinical -SubjectID : Profiling by multiple metadata columns allows more detailed separation of data. In this case, three tumors show relatively high median expression of EGFR, while two tumors (and the induced sphere-forming culture) show lower expression: !|scLand_TPM_Treatment_SubjectID_png|(images/scLand_TPM_Treatment_SubjectID.png)","title":"Single Cell Lands"},{"location":"tutorials/DiseaseLand/scLand/#single-cell-lands","text":"Single-Cell RNA sequencing is emerging as a powerful tool for capturing cellular heterogeneity, which is useful in profiling tumors, nervous system development, detection of rare cell types, and more. Cells are sorted or captured in microfluidic devices, and individual cells are sequenced, providing unprecedented insight into the composition of tissues. OmicSoft\u2019s Single Cell Lands (scHuman and scMouse) contain datasets from multiple single-cell RNAseq projects. Because of the special nature of scRNA processing, both the data and metadata processing steps differ somewhat from \"standard\" Land processing. Data are aligned with OmicSoft's OSA aligner, and each sample is analyzed to ensure that it passes certain QC parameters, such as overall alignment rate, mitochondrial mapping rate, mapped reads, and the number of genes covered (the latest filter criteria can be found at the OmicSoft wiki page SCLand Development Notes ). Gene expression for most samples will be quantified by Transcripts Per Million (TPM) . RNA with Unique Molecular Identifiers (UMI) (as well as samples with a severe 3' or 5' gene coverage bias) will be quantified as Reads Per Million (RPM) , which assumes that all transcripts are 1kb long. Metadata are processed and brought in-line with Controlled Vocabularies. Several metadata columns are especially important for single cell data, including ''Cell Number'' (whether the sample is from a single cell, 10 cells, population, etc.), ''Library Strategy'' (the method for generating the sequencing library), ''UMI'' (whether or not UMIs were used), and ''Clinical - Subject ID'' (groups together cells from a single tissue sample). Additional project-specific metadata may also be in the Clinical Variables ; after you have filtered for samples of interest (e.g. an interesting project), be sure to explore the clinical metadata to help you partition samples and subjects by metadata.","title":"Single Cell Lands"},{"location":"tutorials/DiseaseLand/scLand/#gene-level-views","text":"scLands contain RNaseq data, so all of the familiar RNAseq-based Views will be available. In this example, we display views when searching for the gene \"egfr\". The default View is the Gene TPM (Project View) , where the RNAseq data are trellised by ProjectName and PlatformName into separate charts: Either scroll down or filter for project GSE57872 , sequencing of five glioblastoma tumors. Select some of the samples from the Treatment: None row, to see the metadata for these samples: Click the + Symbol in the Metadata pane to allow selection of different metadata types. In this case, we are interested in Clinical metadata , specifically Clinical - SubjectID , which uniquely identifies the subject from which the cells were isolated. Filter for CellNumber:1 to only show expression data from single cells (not populations). Under the Task tab on the right, choose Change Symbol Properties . Change Color to Clinical - SubjectID to color each sample by the source tumor: Now choose Task tab: Specify Multiple Profile Columns , and select both Treatment and Clinical -SubjectID : Profiling by multiple metadata columns allows more detailed separation of data. In this case, three tumors show relatively high median expression of EGFR, while two tumors (and the induced sphere-forming culture) show lower expression: !|scLand_TPM_Treatment_SubjectID_png|(images/scLand_TPM_Treatment_SubjectID.png)","title":"Gene-level Views"},{"location":"tutorials/ExonArray/","text":"Exon Array Tutorial .. toctree:: :maxdepth: 2 Introduction Importing_a_Dataset Visualization_of_Data Data_Visualization_and_Quality_Control Differential_Expression__Probeset_Level_ Exon_Level_ANOVA_ExonDiffertialExpression_ Alternative_Splicing_ANOVA Generate_Transcript_Level_Data Save_Close_Project","title":"Home"},{"location":"tutorials/ExonArray/Alternative_Splicing_ANOVA/","text":"Alternative Splicing ANOVA Array Studio includes an Alternative Splicing ANOVA module that detects at the transcript level the transcripts that are alternatively spliced. The model for this ANOVA is slightly different from the previous tests. Instead of tissue_type + patient number, this model is Probeset*tissue_type+patient number + Probeset+tissue_type. Also, the chip effect will be automatically added (random effect nested in tissue_type and patient number). So, when generating the model, we will have to adapt our usual procedure for this. In general, the user is most interested in the interaction between probeset and a factor (factors) of interest. To run the Alternative Splicing ANOVA , click Alternative Splicing ANOVA from the Alternative Splicing section of Workflow or go to the MicroArray Menu | ExonArray | Alternative Splicing ANOVA . This opens the Alternative Splicing ANOVA window. As usual, set the Customized Variables and Customized Observations to the lists we created earlier. Click Specify Model to proceed to Step 1 of the analysis. By default, probeset is already added to the model. To add the interaction between probeset and tissue_type , click tissue_type in the Columns box and ProbeSet in the Construct Model box, then click the Cross button. The interaction is displayed as Probeset:tissue_type . Next, add both tissue_type and patient number to the model, by selecting both, and clicking Add . Set patient number as Random , and click OK to continue. Next, click Specify Test to proceed to step 2. This opens the Specify Test window. Unlike the other ANOVAs performed earlier, there are no estimates (contrasts) to be completed for this module. Instead, the only test is FTest . The user needs to pick the Terms for which to generate p-values. The important term is the interaction between ProbeSet and tissue_type . Click on Probeset:tissue_type and click Add , then click OK to continue. Next, click Change Options to proceed to Step 3. This module contains some of the options as the previous tests, however the point of interest is that by default, the module only runs on transcripts with probeset#<100 , and probesets with max(intensity)<4 will be excluded. For transcripts with more than 100 probesets, there are too many degree of the freedom for the modeling. If a probeset is consistently not expressed (all samples < 4), it will decrease the power of the mixed model. Leave these options as default and click on OK to continue. Once again, leave the Work on core probesets only (level=core) checkbox checked to only run the ANOVA on the core level probesets. Click Submit to continue. This generates an AlternativeSplicingArray.Tests table in the Solution Explorer , as well as a Report Tableview (double-click this to open it, then sort by the first column ascending). Notice now that the table is generated on the transcript level, rather than the probeset or exon level (as in the previous test results). We can filter this table by p values.","title":"Alternative Splicing ANOVA"},{"location":"tutorials/ExonArray/Alternative_Splicing_ANOVA/#alternative-splicing-anova","text":"Array Studio includes an Alternative Splicing ANOVA module that detects at the transcript level the transcripts that are alternatively spliced. The model for this ANOVA is slightly different from the previous tests. Instead of tissue_type + patient number, this model is Probeset*tissue_type+patient number + Probeset+tissue_type. Also, the chip effect will be automatically added (random effect nested in tissue_type and patient number). So, when generating the model, we will have to adapt our usual procedure for this. In general, the user is most interested in the interaction between probeset and a factor (factors) of interest. To run the Alternative Splicing ANOVA , click Alternative Splicing ANOVA from the Alternative Splicing section of Workflow or go to the MicroArray Menu | ExonArray | Alternative Splicing ANOVA . This opens the Alternative Splicing ANOVA window. As usual, set the Customized Variables and Customized Observations to the lists we created earlier. Click Specify Model to proceed to Step 1 of the analysis. By default, probeset is already added to the model. To add the interaction between probeset and tissue_type , click tissue_type in the Columns box and ProbeSet in the Construct Model box, then click the Cross button. The interaction is displayed as Probeset:tissue_type . Next, add both tissue_type and patient number to the model, by selecting both, and clicking Add . Set patient number as Random , and click OK to continue. Next, click Specify Test to proceed to step 2. This opens the Specify Test window. Unlike the other ANOVAs performed earlier, there are no estimates (contrasts) to be completed for this module. Instead, the only test is FTest . The user needs to pick the Terms for which to generate p-values. The important term is the interaction between ProbeSet and tissue_type . Click on Probeset:tissue_type and click Add , then click OK to continue. Next, click Change Options to proceed to Step 3. This module contains some of the options as the previous tests, however the point of interest is that by default, the module only runs on transcripts with probeset#<100 , and probesets with max(intensity)<4 will be excluded. For transcripts with more than 100 probesets, there are too many degree of the freedom for the modeling. If a probeset is consistently not expressed (all samples < 4), it will decrease the power of the mixed model. Leave these options as default and click on OK to continue. Once again, leave the Work on core probesets only (level=core) checkbox checked to only run the ANOVA on the core level probesets. Click Submit to continue. This generates an AlternativeSplicingArray.Tests table in the Solution Explorer , as well as a Report Tableview (double-click this to open it, then sort by the first column ascending). Notice now that the table is generated on the transcript level, rather than the probeset or exon level (as in the previous test results). We can filter this table by p values.","title":"Alternative Splicing ANOVA"},{"location":"tutorials/ExonArray/Data_Visualization_and_Quality_Control/","text":"Data Visualization and Quality Control Array Studio contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter. The VariableView Once a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular probeset or probesets. This can be accomplished in a number of different ways in Array Studio , but the most unique way is the VariableView . The VariableView allows the user to visualize one chart for each of the variables in the dataset. So, for this dataset, there will be 1425647 charts available for visualization. To add a VariableView , go to the Solution Explorer . For the ExonArray dataset, right-click on ExonData and select Add View from the dropdown box. This opens the Add View window, which lists all the different types of views available for a Data object. Choose VariableView from the Choose View Type box. Notice that a preview of the view is shown in the Preview box. Click OK to add the view. After adding it, a new View will appear in the main View window. In addition, this new View will appear in the Solution Explorer , as shown below. Anytime the VariableView needs to be opened, user can double click on the Variable item in the Solution Explorer , and the view will show up in the main window. Scroll through all 1425647 charts in the VariableView to see that Array Studio can easily handle showing the visualizations for all the variables in the dataset. Note: if you don't have 1425647 charts, it is likely that a previously generated filter is still applied. On the X-Axis, each of the 20 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed). Each point on the chart represents the intensity value of that chip for that variable (probeset). However, the power of the VariableView lies in its ability to be customized. The Task tab in the View Controller of the VariableView (below), will be used to customize this view. The first step in customizing the view is to start from the top of the Task tab and work down, completing the customization. In the Data section of the Task tab of the View Controller , click Specify Title Columns now. This opens the Specify Title Columns window. This window allows the user to specify which columns from the attached Annotation table (downloaded automatically for Affymetrix datasets) should be used to identify each chart. Scroll through the Available columns to add , and select Gene Symbol . Move it to the Listed columns box, so that Probe Set ID and Gene Symbol are all listed. Click OK to continue. Notice that the charts have been updated to reflect the additional title information, from the Gene Symbol columns. For the purposes of this tutorial, go to the Variable tab of the View Controller , and once again filter Gene Symbol , using ^EGR1 ** as the filter, as shown below. \"^\" and \" ** as the filter, as shown below. \"^\" and \" \" are RegEx symbols to require that EGR1 is matched *exactly , instead of as part of a longer string ( e.g. FEGR12*). Note: All of the customizations performed on this view apply to all variables; however we will concentrate on visualizing EGR1 for demonstration purposes. Notice that the view is now updated to reflect the filter, and shows 16 charts. Now go back to the Task tab of the View Controller . The next step is to Specify Profile Column . This allows the user to group the data points by a particular column of the Design Table . Remember, the Design Table contained columns for a number of different items, including tissue type . Choose tissue_type and click OK . The chart is updated so that data points are grouped by tissue_type . The user could use Specify Split Column from the Task tab of the View Controller to further split each Profile Column . We will not do so in this tutorial. Please refer to the McroArray Tutorial for more options on customizing a view using View Controller . Before continuing, make sure to Clear all filters in the Variable tab of the View Controller . Visualization of Transcripts Array Studio includes two specialized views for exon data at the transcript level (rather than the probeset level). These views are the TranscriptProfileView and TranscriptHeatmapView . To add a TranscriptProfileView , right-click on ExonData , click Add View and select TranscriptProfileView . Click OK to continue. This view shows one chart for each transcript on the chip. Notice that there are 311971 charts, one for each transcript according to the Transcript ID in annotation. The x-axis represents each probeset belong to this transcript, while the y-axis represents the expression level (on a log2 scale). Each line represents one sample. To make the view more interesting, it is possible to either color or group the samples by a design column. Click Specify Grouping from the Task tab of the View Controller . Choose tissue_type from the window. This groups the view by each tissue type (in this case normal and tumor). The user can further color the two groups by choosing Change Line Properties , then changing the Color By to Categorical and selecting tissue_type . This updates the view colors each line by either tumor or normal. This shows the each probeset in the transcript, and can help to differentiate between transcripts (or genes) that have differential expression. For purposes of alternative splicing, the user would want to remove the gene effect from the view (i.e. subtract the average of the probesets for that gene). This can easily be done by clicking Remove gene effect in the Task tab of the View Controller . This effectively normalizes the data around 0, but helps indicate if there is any differential expression. This gene, in the example shown, clearly does not have any differential expression. To see the known transcripts for a particular gene, click Show Ensembl Entries in the Task tab of the View Controller. This shows each known transcript (from Ensembl) for a particular gene. The user can use this to visualize whether there is any known alternative transcription occurring. If there are multiple probesets for an exon, they will be separated by a space in the view, as shown below. Similarly, to add a TranscriptHeatmapView , right-click on Exon Data , click Add View and select TranscriptHeatmapView . Click OK to continue. This shows the intensity of each probeset in a transcript. User can order samples by tissue_type to see whether there is a different pattern in normal and tumor tissue types. Click on Sort Heatmap Rows in the Task tab in View Controller and select tissue_type to sort. The user can add tissue_type in the Y-axis label, by clicking on Change Y-Axis Labels . After customization, user can easily visualize whether there is any difference between tissue types. Again, this gene clearly does not have any differential expression in any of the probesets. Principal Component Analysis of RMA Signals For quality control purposes, the user may be interested in running a Principal Component Analysis . Principal component analysis can be used to detect outliers in a dataset. To run a principal component analysis on an ExonArray dataset, go to the ExonArray Workflow , and select Principal component analysis from the Quality control section of the Workflow . Alternatively, go to MicroArray | ExonArray | Principal Component Analysis to open the Principal Component Analysis window. The Principal Component Analysis window, like most analysis windows in Array Studio , contains an Input/Output section. In this section, the user picks the Project and Data on which to run the analysis, as well as the Variables and Observations on which to run the analysis. This allows the user to specify if the analysis should be run on all, selected, visible, or particular Customized Lists of Variables or Observations . Ensure that Tutorial ExonArray is selected under the Input/Output Project drop-down box and ExonData is selected under Data drop-down box. Ensure that All variables is selected for Variables . Ensure that All observations is selected for Observations . Leave Output Name blank, as by default the outputted plots will be called (DataName).PcaScores . Under options, change the Group to tissue_type . Ensure that Scale variables , Output scores , and Calculate Hotelling T2 are selected, with an Alpha level of 0.05 . Click Submit . A dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 minutes. When complete, a new view will have been created, as well as a new Table object in the QC tab of the Solution Explorer with associated views. Switch to the view ExonData.PcaScores | PcaScores to look at the score plot. First, notice that on the X and Y axis, the percentage of variance each component can explain (equivalent of R 2 value). Component 1 (x-axis) explains 13.00 % of the variance in the data, while Component 2 represents an additional 7.47% of the variance in the data. At first glance, it is clear that there is one outlier in the chart. SampleID for each data point on the plot can be displayed by customizing the symbol properties. Click on the Change Symbol Properties in the task tab. Change the Labels section to All , then the By drop-down box to ID . Then close the dialog box. The SampleID of the outlier (8_4N) shows up once the plot is updated. Array Studio includes the unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, select sample 8_4N by selecting it on the chart (either click directly on the data point, or left-click and drag, or right-click and use the Lasso to drag around the sample). When selected, the point will turn red. In the View Controller , select the Task tab. Then, under the Update tab, select Exclude Selection . The principal component analysis will re-run on the remaining samples, with a newly generated PCAScores object in the Solution Explorer . Array Studio has also added a new List , called Exon Data.Observation19 . This is a list of the remaining 19 chips (after the outlier, 8_4N, has been removed). This List can be used for all further downstream analysis, to automatically exclude chip 8_4N. Filtering Data For ExonArray data, it is important to filter the data, as many of the probesets have low intensities. Array Studio allows the user to create a filtered List of probeset IDs that can be used for further downstream analysis. This module can be opened by selecting Filter variables/observations from the Preprocess tab of the Workflow window. Alternatively, user can open it by going to the Micro Array Menu | Preprocess | Filter . There are many ways to filter in Array Studio . For instance, one may want a list of all probesets where the Max intensity of that probeset is greater than 4. This, in effect, would only return probesets that had at least one chip over the log2 intensity of 4 (16 on a linear scale). Array Studio also allows filtering using the detection p-values generated in the importation of the .CEL files, which is the recommended way to filter. The user would want to create a list of probesets where at least one sample had a detection p-value of less than 0.05. To do this, set the Criterion to Min < 0.05 , and click Add criterion . Make sure to select the Filter by detection checkbox. An example of this setting is shown above. Click Test to find out how many probesets fit this criterion. If acceptable, click Submit to run the module and generate a list. When completed, a List is generated in the List section of the Solution Explorer , containing the 1,159,411 probesets that fit this criterion. This list will be used for further downstream analysis.","title":"Data Visualization and Quality Control"},{"location":"tutorials/ExonArray/Data_Visualization_and_Quality_Control/#data-visualization-and-quality-control","text":"Array Studio contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter.","title":"Data Visualization and Quality Control"},{"location":"tutorials/ExonArray/Data_Visualization_and_Quality_Control/#the-variableview","text":"Once a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular probeset or probesets. This can be accomplished in a number of different ways in Array Studio , but the most unique way is the VariableView . The VariableView allows the user to visualize one chart for each of the variables in the dataset. So, for this dataset, there will be 1425647 charts available for visualization. To add a VariableView , go to the Solution Explorer . For the ExonArray dataset, right-click on ExonData and select Add View from the dropdown box. This opens the Add View window, which lists all the different types of views available for a Data object. Choose VariableView from the Choose View Type box. Notice that a preview of the view is shown in the Preview box. Click OK to add the view. After adding it, a new View will appear in the main View window. In addition, this new View will appear in the Solution Explorer , as shown below. Anytime the VariableView needs to be opened, user can double click on the Variable item in the Solution Explorer , and the view will show up in the main window. Scroll through all 1425647 charts in the VariableView to see that Array Studio can easily handle showing the visualizations for all the variables in the dataset. Note: if you don't have 1425647 charts, it is likely that a previously generated filter is still applied. On the X-Axis, each of the 20 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed). Each point on the chart represents the intensity value of that chip for that variable (probeset). However, the power of the VariableView lies in its ability to be customized. The Task tab in the View Controller of the VariableView (below), will be used to customize this view. The first step in customizing the view is to start from the top of the Task tab and work down, completing the customization. In the Data section of the Task tab of the View Controller , click Specify Title Columns now. This opens the Specify Title Columns window. This window allows the user to specify which columns from the attached Annotation table (downloaded automatically for Affymetrix datasets) should be used to identify each chart. Scroll through the Available columns to add , and select Gene Symbol . Move it to the Listed columns box, so that Probe Set ID and Gene Symbol are all listed. Click OK to continue. Notice that the charts have been updated to reflect the additional title information, from the Gene Symbol columns. For the purposes of this tutorial, go to the Variable tab of the View Controller , and once again filter Gene Symbol , using ^EGR1 ** as the filter, as shown below. \"^\" and \" ** as the filter, as shown below. \"^\" and \" \" are RegEx symbols to require that EGR1 is matched *exactly , instead of as part of a longer string ( e.g. FEGR12*). Note: All of the customizations performed on this view apply to all variables; however we will concentrate on visualizing EGR1 for demonstration purposes. Notice that the view is now updated to reflect the filter, and shows 16 charts. Now go back to the Task tab of the View Controller . The next step is to Specify Profile Column . This allows the user to group the data points by a particular column of the Design Table . Remember, the Design Table contained columns for a number of different items, including tissue type . Choose tissue_type and click OK . The chart is updated so that data points are grouped by tissue_type . The user could use Specify Split Column from the Task tab of the View Controller to further split each Profile Column . We will not do so in this tutorial. Please refer to the McroArray Tutorial for more options on customizing a view using View Controller . Before continuing, make sure to Clear all filters in the Variable tab of the View Controller .","title":"The VariableView"},{"location":"tutorials/ExonArray/Data_Visualization_and_Quality_Control/#visualization-of-transcripts","text":"Array Studio includes two specialized views for exon data at the transcript level (rather than the probeset level). These views are the TranscriptProfileView and TranscriptHeatmapView . To add a TranscriptProfileView , right-click on ExonData , click Add View and select TranscriptProfileView . Click OK to continue. This view shows one chart for each transcript on the chip. Notice that there are 311971 charts, one for each transcript according to the Transcript ID in annotation. The x-axis represents each probeset belong to this transcript, while the y-axis represents the expression level (on a log2 scale). Each line represents one sample. To make the view more interesting, it is possible to either color or group the samples by a design column. Click Specify Grouping from the Task tab of the View Controller . Choose tissue_type from the window. This groups the view by each tissue type (in this case normal and tumor). The user can further color the two groups by choosing Change Line Properties , then changing the Color By to Categorical and selecting tissue_type . This updates the view colors each line by either tumor or normal. This shows the each probeset in the transcript, and can help to differentiate between transcripts (or genes) that have differential expression. For purposes of alternative splicing, the user would want to remove the gene effect from the view (i.e. subtract the average of the probesets for that gene). This can easily be done by clicking Remove gene effect in the Task tab of the View Controller . This effectively normalizes the data around 0, but helps indicate if there is any differential expression. This gene, in the example shown, clearly does not have any differential expression. To see the known transcripts for a particular gene, click Show Ensembl Entries in the Task tab of the View Controller. This shows each known transcript (from Ensembl) for a particular gene. The user can use this to visualize whether there is any known alternative transcription occurring. If there are multiple probesets for an exon, they will be separated by a space in the view, as shown below. Similarly, to add a TranscriptHeatmapView , right-click on Exon Data , click Add View and select TranscriptHeatmapView . Click OK to continue. This shows the intensity of each probeset in a transcript. User can order samples by tissue_type to see whether there is a different pattern in normal and tumor tissue types. Click on Sort Heatmap Rows in the Task tab in View Controller and select tissue_type to sort. The user can add tissue_type in the Y-axis label, by clicking on Change Y-Axis Labels . After customization, user can easily visualize whether there is any difference between tissue types. Again, this gene clearly does not have any differential expression in any of the probesets.","title":"Visualization of Transcripts"},{"location":"tutorials/ExonArray/Data_Visualization_and_Quality_Control/#principal-component-analysis-of-rma-signals","text":"For quality control purposes, the user may be interested in running a Principal Component Analysis . Principal component analysis can be used to detect outliers in a dataset. To run a principal component analysis on an ExonArray dataset, go to the ExonArray Workflow , and select Principal component analysis from the Quality control section of the Workflow . Alternatively, go to MicroArray | ExonArray | Principal Component Analysis to open the Principal Component Analysis window. The Principal Component Analysis window, like most analysis windows in Array Studio , contains an Input/Output section. In this section, the user picks the Project and Data on which to run the analysis, as well as the Variables and Observations on which to run the analysis. This allows the user to specify if the analysis should be run on all, selected, visible, or particular Customized Lists of Variables or Observations . Ensure that Tutorial ExonArray is selected under the Input/Output Project drop-down box and ExonData is selected under Data drop-down box. Ensure that All variables is selected for Variables . Ensure that All observations is selected for Observations . Leave Output Name blank, as by default the outputted plots will be called (DataName).PcaScores . Under options, change the Group to tissue_type . Ensure that Scale variables , Output scores , and Calculate Hotelling T2 are selected, with an Alpha level of 0.05 . Click Submit . A dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 minutes. When complete, a new view will have been created, as well as a new Table object in the QC tab of the Solution Explorer with associated views. Switch to the view ExonData.PcaScores | PcaScores to look at the score plot. First, notice that on the X and Y axis, the percentage of variance each component can explain (equivalent of R 2 value). Component 1 (x-axis) explains 13.00 % of the variance in the data, while Component 2 represents an additional 7.47% of the variance in the data. At first glance, it is clear that there is one outlier in the chart. SampleID for each data point on the plot can be displayed by customizing the symbol properties. Click on the Change Symbol Properties in the task tab. Change the Labels section to All , then the By drop-down box to ID . Then close the dialog box. The SampleID of the outlier (8_4N) shows up once the plot is updated. Array Studio includes the unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, select sample 8_4N by selecting it on the chart (either click directly on the data point, or left-click and drag, or right-click and use the Lasso to drag around the sample). When selected, the point will turn red. In the View Controller , select the Task tab. Then, under the Update tab, select Exclude Selection . The principal component analysis will re-run on the remaining samples, with a newly generated PCAScores object in the Solution Explorer . Array Studio has also added a new List , called Exon Data.Observation19 . This is a list of the remaining 19 chips (after the outlier, 8_4N, has been removed). This List can be used for all further downstream analysis, to automatically exclude chip 8_4N.","title":"Principal Component Analysis of RMA Signals"},{"location":"tutorials/ExonArray/Data_Visualization_and_Quality_Control/#filtering-data","text":"For ExonArray data, it is important to filter the data, as many of the probesets have low intensities. Array Studio allows the user to create a filtered List of probeset IDs that can be used for further downstream analysis. This module can be opened by selecting Filter variables/observations from the Preprocess tab of the Workflow window. Alternatively, user can open it by going to the Micro Array Menu | Preprocess | Filter . There are many ways to filter in Array Studio . For instance, one may want a list of all probesets where the Max intensity of that probeset is greater than 4. This, in effect, would only return probesets that had at least one chip over the log2 intensity of 4 (16 on a linear scale). Array Studio also allows filtering using the detection p-values generated in the importation of the .CEL files, which is the recommended way to filter. The user would want to create a list of probesets where at least one sample had a detection p-value of less than 0.05. To do this, set the Criterion to Min < 0.05 , and click Add criterion . Make sure to select the Filter by detection checkbox. An example of this setting is shown above. Click Test to find out how many probesets fit this criterion. If acceptable, click Submit to run the module and generate a list. When completed, a List is generated in the List section of the Solution Explorer , containing the 1,159,411 probesets that fit this criterion. This list will be used for further downstream analysis.","title":"Filtering Data"},{"location":"tutorials/ExonArray/Differential_Expression__Probeset_Level_/","text":"Differential Expression (Probeset Level) Array Studio contains a number of different modules for performing univariate analysis/differential expression on the probeset level, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others. For probeset level, the differential expression analysis is similar to that discussed in MicroArray Tutorial. We will only provide an example of General Linear Model in this tutorial. Probeset Level Linear Model The design of the experiment in this tutorial is set-up so that the user should perform a Probeset Level Linear Model . The first factor in the ANOVA is tissue_type while the second factor is patient_id . For each patient, there is a tumor and a normal sample, and we are interested in the difference between the two. To run the Probeset Level Linear Module , go to the Statistical Inference section of the workflow , and select Probeset Level Linear model . Alternatively, the same module can be selected by going to the MicroArray Menu | Inference | General Linear Model . This opens the General Linear Model window. As with other analysis windows, the user must first set the Project and Data on which to run the analysis, in the Input/Output section. Make sure Tutorial ExonArray is chosen as the project and Exon Data is chosen as the input data. For Variables , choose Customized variables and click Select . Choose the list that was generated earlier by the Filter command. For Observations , choose Customized Observations , and then click the Select button to choose the list ExonData.Observation19 . This ensures that the statistical tests are only run on the good 19 observations, ignoring the one outlier chip. Go to Step 1: Specify Model . The two factors in this model are tissue_type and patient number . Use ctrl + click to select both of them and click the Add button. Patient is random effect, so click the Random checkbox for patient number . Click OK to return to the General Linear Model window. Notice that the information of the specified model is displayed in the box under step 1. Next, click Specify Test for comparisons. This opens the Specify Test window, which allows the user to manually or automatically specify the tests (or comparisons). In this case, the user is interested in the difference between tumor samples and normal. The easiest way to specify the comparison is to ensure that the Term box is set to tissue_type , click the For each box to set to (none) , and set Compare to as Normal . In effect, this says that for every level of tissue_type , compare it to normal. Since there are only two levels (tumor and normal), there will be one comparison. Make sure that Estimate , Fold Change , Raw p-values and Adjusted p-values are checked, and then click Add to add the test. Add test will be displayed in the TTests box. Click OK to return to the original General Linear Model window. Step 3 is optional, and includes a number of options that can be set for the General Linear Model . Please refer to MicroArray Tutorial for more details on the options. The Linear Model option is now complete. If the user is familiar with SAS code, clicking Show SAS Code will show the equivalent SAS code. Click Submit to run the module. This module should take approximately 6 minutes (Note: the length of time is dependent on the number of variables in this case over 1 million, as well as the type of model). The Volcano Plot View and Inference Report After running the General Linear Model (the computing time should be a few minutes), a Table is generated under the Inference tab of the Solution Explorer , named ExonData.Tests . This table contains the statistics report generated by the General Linear Model, together with a VolcanoPlot visualizing the pvalues vs. estimate. Also notice that a new List has been automatically generated by the General Linear Model . This List can be used for purposes of filtering, and any other downstream analysis. However, for this experiment, there are actually no probesets that pass the adjusted p-value criteria of 0.05, so this list contains 0 probesets. Double click on VolcanoPlot to open it. Notice that one volcano plot has been created in this view, for the comparison Tumor vs. Normal . The VolcanoPlotView shows the -Log10 (Raw P-value) on the y-axis and the Estimate ( Estimate is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the mostly differentially expressed probesets can be found at the extremes of the x-axis. Similar to all views in Array Studio, the VolcanoPlotView is fully interactive. Please refer to MicroArray Tutorial for more details on these options.","title":"Differential Expression Probeset Level"},{"location":"tutorials/ExonArray/Differential_Expression__Probeset_Level_/#differential-expression-probeset-level","text":"Array Studio contains a number of different modules for performing univariate analysis/differential expression on the probeset level, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others. For probeset level, the differential expression analysis is similar to that discussed in MicroArray Tutorial. We will only provide an example of General Linear Model in this tutorial.","title":"Differential Expression (Probeset Level)"},{"location":"tutorials/ExonArray/Differential_Expression__Probeset_Level_/#probeset-level-linear-model","text":"The design of the experiment in this tutorial is set-up so that the user should perform a Probeset Level Linear Model . The first factor in the ANOVA is tissue_type while the second factor is patient_id . For each patient, there is a tumor and a normal sample, and we are interested in the difference between the two. To run the Probeset Level Linear Module , go to the Statistical Inference section of the workflow , and select Probeset Level Linear model . Alternatively, the same module can be selected by going to the MicroArray Menu | Inference | General Linear Model . This opens the General Linear Model window. As with other analysis windows, the user must first set the Project and Data on which to run the analysis, in the Input/Output section. Make sure Tutorial ExonArray is chosen as the project and Exon Data is chosen as the input data. For Variables , choose Customized variables and click Select . Choose the list that was generated earlier by the Filter command. For Observations , choose Customized Observations , and then click the Select button to choose the list ExonData.Observation19 . This ensures that the statistical tests are only run on the good 19 observations, ignoring the one outlier chip. Go to Step 1: Specify Model . The two factors in this model are tissue_type and patient number . Use ctrl + click to select both of them and click the Add button. Patient is random effect, so click the Random checkbox for patient number . Click OK to return to the General Linear Model window. Notice that the information of the specified model is displayed in the box under step 1. Next, click Specify Test for comparisons. This opens the Specify Test window, which allows the user to manually or automatically specify the tests (or comparisons). In this case, the user is interested in the difference between tumor samples and normal. The easiest way to specify the comparison is to ensure that the Term box is set to tissue_type , click the For each box to set to (none) , and set Compare to as Normal . In effect, this says that for every level of tissue_type , compare it to normal. Since there are only two levels (tumor and normal), there will be one comparison. Make sure that Estimate , Fold Change , Raw p-values and Adjusted p-values are checked, and then click Add to add the test. Add test will be displayed in the TTests box. Click OK to return to the original General Linear Model window. Step 3 is optional, and includes a number of options that can be set for the General Linear Model . Please refer to MicroArray Tutorial for more details on the options. The Linear Model option is now complete. If the user is familiar with SAS code, clicking Show SAS Code will show the equivalent SAS code. Click Submit to run the module. This module should take approximately 6 minutes (Note: the length of time is dependent on the number of variables in this case over 1 million, as well as the type of model).","title":"Probeset Level Linear Model"},{"location":"tutorials/ExonArray/Differential_Expression__Probeset_Level_/#the-volcano-plot-view-and-inference-report","text":"After running the General Linear Model (the computing time should be a few minutes), a Table is generated under the Inference tab of the Solution Explorer , named ExonData.Tests . This table contains the statistics report generated by the General Linear Model, together with a VolcanoPlot visualizing the pvalues vs. estimate. Also notice that a new List has been automatically generated by the General Linear Model . This List can be used for purposes of filtering, and any other downstream analysis. However, for this experiment, there are actually no probesets that pass the adjusted p-value criteria of 0.05, so this list contains 0 probesets. Double click on VolcanoPlot to open it. Notice that one volcano plot has been created in this view, for the comparison Tumor vs. Normal . The VolcanoPlotView shows the -Log10 (Raw P-value) on the y-axis and the Estimate ( Estimate is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the mostly differentially expressed probesets can be found at the extremes of the x-axis. Similar to all views in Array Studio, the VolcanoPlotView is fully interactive. Please refer to MicroArray Tutorial for more details on these options.","title":"The Volcano Plot View and Inference Report"},{"location":"tutorials/ExonArray/Exon_Level_ANOVA_ExonDiffertialExpression_/","text":"Exon Level General Linear Model (Exon Differential Expression) Array Studio includes the ability to find differential expression at the exon level, rather than the probeset level. This can help for finding differentially expressed exons, or alternatively expressed exons. To open the Exon Level Linear Model , user can click on the Exon Level Linear Model in Alternative Splicing section of the Workflow window. Alternatively, user can go to MicroArray | ExonArray | Exon Level Linear Model . This opens the General Linear Model (Exon Level) window. The first step is to select the Customized variables and Customized observations using the lists created with the Principal Component Analysis and Filter module. Click Specify Model to begin Step 1 . As with the probeset level linear model, the two factors are tissue_type and patient number . Use ctrl + click to select both of them and click the Add button. Patient is random effect, so click the Random checkbox for patient number . Click OK to return to the General Linear Model window. Notice that the information of the specified model is displayed in the box under step 1. Click Specify Test to start Step 2 . Once again, choose tissue_type as the Term , click the For each checkbox, set it to (none) , and set Compare to as Normal . Click Add to add the test. Click OK to continue. For step 3, Change Options , we will leave all the options as the default. For this module, the user has the option to choose how the summarization of the exons will be calculated ( Mean , Median , or Median Polish ). In addition, the Remove gene effect option allows the user to remove the gene effect (i.e. subtract the average of the probesets for that gene) from the data when running the ANOVA. This is useful for detection of exons involved in alternative splicing. Leave the Work on core probesets only (level=core) checkbox on to only run the ANOVA on the core probesets (recommended for the tutorial). Click Submit to run the linear model, which should take 2-3 minutes for over 1 million variables. This module, in effect, summarizes the probesets into the exon level, then looks for differentially expressed exons. This returns ExonData.Tests_2 under the Inference tab of the Solution Explorer . Both a Report and VolcanoPlot are generated. Double-click Report to take a look at the results. This time, p-values and fold changes are generated at the exon level. This data can be sorted by p-value. Right-click on the raw p-value column now and choose Sort Ascending . This sorts the table by p-value, from most significant to least significant. Notice ABCG1 is one of the top transcripts at the top of the list. Switch back to the TranscriptProfileView and filter for this gene. Make sure that the Remove gene effect button has been clicked. You can now look for those exons in this gene that may have alternative splicing using this filtered TranscriptProfile View. The top Exon has ID 993113 and probeset ID 3922532.","title":"Exon Level Differtial Expression"},{"location":"tutorials/ExonArray/Exon_Level_ANOVA_ExonDiffertialExpression_/#exon-level-general-linear-model-exon-differential-expression","text":"Array Studio includes the ability to find differential expression at the exon level, rather than the probeset level. This can help for finding differentially expressed exons, or alternatively expressed exons. To open the Exon Level Linear Model , user can click on the Exon Level Linear Model in Alternative Splicing section of the Workflow window. Alternatively, user can go to MicroArray | ExonArray | Exon Level Linear Model . This opens the General Linear Model (Exon Level) window. The first step is to select the Customized variables and Customized observations using the lists created with the Principal Component Analysis and Filter module. Click Specify Model to begin Step 1 . As with the probeset level linear model, the two factors are tissue_type and patient number . Use ctrl + click to select both of them and click the Add button. Patient is random effect, so click the Random checkbox for patient number . Click OK to return to the General Linear Model window. Notice that the information of the specified model is displayed in the box under step 1. Click Specify Test to start Step 2 . Once again, choose tissue_type as the Term , click the For each checkbox, set it to (none) , and set Compare to as Normal . Click Add to add the test. Click OK to continue. For step 3, Change Options , we will leave all the options as the default. For this module, the user has the option to choose how the summarization of the exons will be calculated ( Mean , Median , or Median Polish ). In addition, the Remove gene effect option allows the user to remove the gene effect (i.e. subtract the average of the probesets for that gene) from the data when running the ANOVA. This is useful for detection of exons involved in alternative splicing. Leave the Work on core probesets only (level=core) checkbox on to only run the ANOVA on the core probesets (recommended for the tutorial). Click Submit to run the linear model, which should take 2-3 minutes for over 1 million variables. This module, in effect, summarizes the probesets into the exon level, then looks for differentially expressed exons. This returns ExonData.Tests_2 under the Inference tab of the Solution Explorer . Both a Report and VolcanoPlot are generated. Double-click Report to take a look at the results. This time, p-values and fold changes are generated at the exon level. This data can be sorted by p-value. Right-click on the raw p-value column now and choose Sort Ascending . This sorts the table by p-value, from most significant to least significant. Notice ABCG1 is one of the top transcripts at the top of the list. Switch back to the TranscriptProfileView and filter for this gene. Make sure that the Remove gene effect button has been clicked. You can now look for those exons in this gene that may have alternative splicing using this filtered TranscriptProfile View. The top Exon has ID 993113 and probeset ID 3922532.","title":"Exon Level General Linear Model (Exon Differential Expression)"},{"location":"tutorials/ExonArray/Generate_Transcript_Level_Data/","text":"Generate Transcript Level Data For users interested in obtaining transcript-level data from the exon array, Array Studio includes the capability to Generate Transcript Level Data by summarizing the probesets from exons level data. From there, any of the standard microarray modules (see the Microarray Tutorial for more information) can be run on this data to differentiate the gene expression (i.e. Genera Linear Model, ontology analysis, clustering, etc.). To run this module, go to Generate Transcript Level Data in the Preprocess section of the workflow . Alternatively, user can open this module by going to the MicroArray menu | ExonArray | Generate Transcript Level Data . This opens the Select Data window. Select the Exon Data and click OK . The Generate Transcript Level Data dialog box appears next. The user can choose the Exon level ( core , core + entended , core + entended + full and all ). The user can choose customized variables and observations (just leave this as default), then choose a Summary method ( Mean , Median , and MedianPolish ), then click OK to continue. This will create a new MicroArray dataset under the -Omic Data section in the Solution Explorer , ExonData.Transcript . The data is based on transcript level. Any of the Microarray modules should work on this data (including running the General Linear Model to find differentially expressed transcripts).","title":"Generate Transcript Level Data"},{"location":"tutorials/ExonArray/Generate_Transcript_Level_Data/#generate-transcript-level-data","text":"For users interested in obtaining transcript-level data from the exon array, Array Studio includes the capability to Generate Transcript Level Data by summarizing the probesets from exons level data. From there, any of the standard microarray modules (see the Microarray Tutorial for more information) can be run on this data to differentiate the gene expression (i.e. Genera Linear Model, ontology analysis, clustering, etc.). To run this module, go to Generate Transcript Level Data in the Preprocess section of the workflow . Alternatively, user can open this module by going to the MicroArray menu | ExonArray | Generate Transcript Level Data . This opens the Select Data window. Select the Exon Data and click OK . The Generate Transcript Level Data dialog box appears next. The user can choose the Exon level ( core , core + entended , core + entended + full and all ). The user can choose customized variables and observations (just leave this as default), then choose a Summary method ( Mean , Median , and MedianPolish ), then click OK to continue. This will create a new MicroArray dataset under the -Omic Data section in the Solution Explorer , ExonData.Transcript . The data is based on transcript level. Any of the Microarray modules should work on this data (including running the General Linear Model to find differentially expressed transcripts).","title":"Generate Transcript Level Data"},{"location":"tutorials/ExonArray/Importing_a_Dataset/","text":"Importing a Dataset Downloading the Exon Array Dataset For this tutorial, the following materials will be required: 20 .CEL files from Affymetrix HuEx-1_0-st-v2 exon array platform, as well as the included .ARR files, which is the design (sample) information for the 20 .CEL files. The Exon data set contains information for 1425647 probe sets in a paired design (each patient has a tumor and normal sample). The experiment measures the intensity of exon expression level of 1425647 probe sets, with 10 samples of normal and 10 samples of tumor. The primary interest of this experiment is to find exons that are differentially expressed between tumor and normal, or to find alternative splicing between tumor and normal. The .ARR files contain the design information for this study, including columns for chip, time, treatment, and group . By default, .ARR files will be imported automatically, upon .CEL file extraction. Optionally, if the user does not have .ARR files, a design table can be created at any time by the user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed Chip for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the .CEL file extension. Additional columns usually include treatment, time, etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into Array Studio . The ExonArray sample dataset (20 Affymetrix .CEL files and 20 .ARR files) is available at: link After downloading the single .zip file, unzip the file to a folder to be used for this tutorial. Creating a New Project When Array Studio is first installed, it will look similar to what is displayed below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window. Array Studio allows the user to create two different project types: A simple project, in which all the project is saved in a single file (recommended for microarray and RT-PCR projects). A distributed project, where data is saved in separate files (recommended for exon array, CNV, or genotyping projects). Choose the Create a distributed project option. Click the Browse button to choose a location and name for the project. Click OK to continue. Switch to the Solution Explorer by clicking on the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, open to it by going to the View Menu | Show Solution Explorer . The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probe sets), or Observations (e.g. chips or samples). Adding Exon Data & Chip Normalization At this point, we are ready to add ExonArray data to the Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the Workflow Window , by selecting the Workflow tab at the bottom of the Solution Explorer . Alternatively, go to View Menu | Show Workflow to show the Workflow Window . Next, choose Add ExonArray Data , from the Manage Data section of the workflow. Alternatively, data can be added by going to the File Menu | Add Data | Add ExonArray Data or by clicking the Add button on the taskbar, and choosing Add ExonArray Data . A dialog box will open asking the user to specify the source of data. Two different sources of data are currently available in Array Studio and can be seen in the dialog window below. For this tutorial, the 20 Affymetrix .CEL files downloaded earlier will be used. Select Affymetrix .CEL files (Exon Arrays) and click OK . The Extract Affymetrix Exon Array CEL file window appears. Click the Add button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click Open to continue. Check that there are 20 .CEL files listed for extraction by looking in the upper left corner of the dialog box. When complete, the window should look similar to the following screenshot. Under Options , the Chip type and Array type of the CEL files automatically recognized. If the user is using Affymetrix Expression Console , the Import Sample Information from ARR files checkbox will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files. Click Submit to start the CEL signal matrix extraction. Data extraction will begin and take approximately 10-20 minutes (about 60 seconds per .CEL file, but the first time an extraction is done annotation has to be downloaded, so the process may be slower). Once data is imported, Array Studio should look similar to the following screenshot. By default, a TableView is created for the imported dataset. Also, note that a new data object (\"ExonData\") has been added under the -Omic Data section of the Solution Explorer (on the left-hand side of the screen). The Solution Explorer can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset, ExonData , Array Studio lists the number of rows and columns (or variables and observations) in the dataset. In this case, there are 1,425,647 variables and 20 observations in each of the datasets. The Solution Explorer also provides the user with information on the different views that have been created. Notice that there is a TableView for dataset ExonData , as well as for Annotation and Design (Expand the nodes to see this). User can double-click either of these views (named Table ), and open them in the main view window.","title":"Importing a Dataset"},{"location":"tutorials/ExonArray/Importing_a_Dataset/#importing-a-dataset","text":"","title":"Importing a Dataset"},{"location":"tutorials/ExonArray/Importing_a_Dataset/#downloading-the-exon-array-dataset","text":"For this tutorial, the following materials will be required: 20 .CEL files from Affymetrix HuEx-1_0-st-v2 exon array platform, as well as the included .ARR files, which is the design (sample) information for the 20 .CEL files. The Exon data set contains information for 1425647 probe sets in a paired design (each patient has a tumor and normal sample). The experiment measures the intensity of exon expression level of 1425647 probe sets, with 10 samples of normal and 10 samples of tumor. The primary interest of this experiment is to find exons that are differentially expressed between tumor and normal, or to find alternative splicing between tumor and normal. The .ARR files contain the design information for this study, including columns for chip, time, treatment, and group . By default, .ARR files will be imported automatically, upon .CEL file extraction. Optionally, if the user does not have .ARR files, a design table can be created at any time by the user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed Chip for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the .CEL file extension. Additional columns usually include treatment, time, etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into Array Studio . The ExonArray sample dataset (20 Affymetrix .CEL files and 20 .ARR files) is available at: link After downloading the single .zip file, unzip the file to a folder to be used for this tutorial.","title":"Downloading the Exon Array Dataset"},{"location":"tutorials/ExonArray/Importing_a_Dataset/#creating-a-new-project","text":"When Array Studio is first installed, it will look similar to what is displayed below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window. Array Studio allows the user to create two different project types: A simple project, in which all the project is saved in a single file (recommended for microarray and RT-PCR projects). A distributed project, where data is saved in separate files (recommended for exon array, CNV, or genotyping projects). Choose the Create a distributed project option. Click the Browse button to choose a location and name for the project. Click OK to continue. Switch to the Solution Explorer by clicking on the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, open to it by going to the View Menu | Show Solution Explorer . The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probe sets), or Observations (e.g. chips or samples).","title":"Creating a New Project"},{"location":"tutorials/ExonArray/Importing_a_Dataset/#adding-exon-data-chip-normalization","text":"At this point, we are ready to add ExonArray data to the Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the Workflow Window , by selecting the Workflow tab at the bottom of the Solution Explorer . Alternatively, go to View Menu | Show Workflow to show the Workflow Window . Next, choose Add ExonArray Data , from the Manage Data section of the workflow. Alternatively, data can be added by going to the File Menu | Add Data | Add ExonArray Data or by clicking the Add button on the taskbar, and choosing Add ExonArray Data . A dialog box will open asking the user to specify the source of data. Two different sources of data are currently available in Array Studio and can be seen in the dialog window below. For this tutorial, the 20 Affymetrix .CEL files downloaded earlier will be used. Select Affymetrix .CEL files (Exon Arrays) and click OK . The Extract Affymetrix Exon Array CEL file window appears. Click the Add button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click Open to continue. Check that there are 20 .CEL files listed for extraction by looking in the upper left corner of the dialog box. When complete, the window should look similar to the following screenshot. Under Options , the Chip type and Array type of the CEL files automatically recognized. If the user is using Affymetrix Expression Console , the Import Sample Information from ARR files checkbox will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files. Click Submit to start the CEL signal matrix extraction. Data extraction will begin and take approximately 10-20 minutes (about 60 seconds per .CEL file, but the first time an extraction is done annotation has to be downloaded, so the process may be slower). Once data is imported, Array Studio should look similar to the following screenshot. By default, a TableView is created for the imported dataset. Also, note that a new data object (\"ExonData\") has been added under the -Omic Data section of the Solution Explorer (on the left-hand side of the screen). The Solution Explorer can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset, ExonData , Array Studio lists the number of rows and columns (or variables and observations) in the dataset. In this case, there are 1,425,647 variables and 20 observations in each of the datasets. The Solution Explorer also provides the user with information on the different views that have been created. Notice that there is a TableView for dataset ExonData , as well as for Annotation and Design (Expand the nodes to see this). User can double-click either of these views (named Table ), and open them in the main view window.","title":"Adding Exon Data &amp; Chip Normalization"},{"location":"tutorials/ExonArray/Introduction/","text":"Introduction Array studio Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.","title":"Introduction"},{"location":"tutorials/ExonArray/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/ExonArray/Introduction/#array-studio","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.","title":"Array studio"},{"location":"tutorials/ExonArray/Save_Close_Project/","text":"Save & Close Project Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to Exon array analysis and visualization. Feel free to try different options in the Task tab or the MicroArray|ExonArray menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft's support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save/Close Project"},{"location":"tutorials/ExonArray/Save_Close_Project/#save-close-project","text":"Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to Exon array analysis and visualization. Feel free to try different options in the Task tab or the MicroArray|ExonArray menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft's support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save &amp; Close Project"},{"location":"tutorials/ExonArray/Visualization_of_Data/","text":"Visualization of Data The TableView At this point, the screen should look similar to below. On the left, the Solution Explorer should be visible. In the center of the screen, a table view called Table should be visible. Scroll through the dataset to see how quickly Array Studio is able to scroll. Array Studio is able to easily handle millions of rows and columns in the TableView . Please refer to Microarray Tutorial for different options and filters for TableView. Details Window/Web Details The TableView , and all other views in Array Studio , are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the Details Window . In the TableView , click the column header cell for 1_1T and 2_1N . Notice that the sample information for these 2 selected sample IDs are shown in the Details window. If the Details Window is not shown at the bottom of the screen, go to View Menu | Show Details Window now to show it. The user can also click on the row header cell to show annotation for any variable. Do this now, and notice that the Details Window updates with the annotation for that particular probeset.","title":"Visualization of Data"},{"location":"tutorials/ExonArray/Visualization_of_Data/#visualization-of-data","text":"","title":"Visualization of Data"},{"location":"tutorials/ExonArray/Visualization_of_Data/#the-tableview","text":"At this point, the screen should look similar to below. On the left, the Solution Explorer should be visible. In the center of the screen, a table view called Table should be visible. Scroll through the dataset to see how quickly Array Studio is able to scroll. Array Studio is able to easily handle millions of rows and columns in the TableView . Please refer to Microarray Tutorial for different options and filters for TableView.","title":"The TableView"},{"location":"tutorials/ExonArray/Visualization_of_Data/#details-windowweb-details","text":"The TableView , and all other views in Array Studio , are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the Details Window . In the TableView , click the column header cell for 1_1T and 2_1N . Notice that the sample information for these 2 selected sample IDs are shown in the Details window. If the Details Window is not shown at the bottom of the screen, go to View Menu | Show Details Window now to show it. The user can also click on the row header cell to show annotation for any variable. Do this now, and notice that the Details Window updates with the annotation for that particular probeset.","title":"Details Window/Web Details"},{"location":"tutorials/GWAS/","text":"GWAS Tutorial .. toctree:: :maxdepth: 2 Introduction Connecting_To_A_Server_And_Uploading_Files Preprocessing QC_of_GWAS_data Imputation Association Annotation Save_Close_Project","title":"Home"},{"location":"tutorials/GWAS/Annotation/","text":"Annotation The annotation feature enables variant-by-variant annotations based on genetic association results file or an input file provided by users that are in GTT, VCF, or BED format. The input can also be a set of RS_IDs. Annotated results will be available in the output folder specified if the Generate text files box is checked. Annotation sources Under the annotation tab, the Variant based annotators 1000GenomesSimple_20170501 and ClinVar_20170501 are selected by default. But, all the available annotation sources are shown and users have the option to make selections. After annotation sources are selected, users can go back to the General tab to confirm all the options selected are as desired before submitting the job to the server. If you would like to include additional annotation sources, please contact Omicsoft support team ( support@omicsoft.com ). Requests will be reviewed and new features may be added in future releases of Array Suite. Please keep other options as default, and click Send To Queue to submit the job. Annotation output After the job is finished, there will be an annotation result table (OSCR) that contains all the annotation information. By right clicking the row ID, users can conveniently go to GeneCard, dbSNP, HaploregV2 and RegulomeDB to view corresponding information of that SNP. Results filtering Please note that for annotated Omicsoft SNP Classification Results ('oscr http://www.arrayserver.com/wiki/index.php?title=Oscr '), variant annotation columns are fully interactive and can be filtered by mutation type, AA position and MAF etc. In the Association chapter,we found the top SNP rs6060535 shown in NCBI eQTL browser also showed significant association with CPNE1 expression in our test Hapmap data. Now we can look for more detailed information about this SNP. By searching the SNP ID and scrolling to the last annotation term (RegulomeDB), we will find rs6060535 is in class 1f, which means this SNP is an eQTL, and also in transcription factor (TF) binding site or a DNase hypersensitive peak. This also provides evidence to support our finding that rs6060535 is significantly associated with CPNE1 gene expression level. We can also find all the significant SNPs associated with CPNE1 gene expression level by setting up a cutoff. For example, we can find all the SNPs which show Bonferroni P-value smaller than 5E-8. From the result, there are 162 SNPs in chr20 that show significant association with CPNE1 expression level in our tutorial Hapmap data in the level of Bonferroni P-value smaller than 5E-8.","title":"Annotation"},{"location":"tutorials/GWAS/Annotation/#annotation","text":"The annotation feature enables variant-by-variant annotations based on genetic association results file or an input file provided by users that are in GTT, VCF, or BED format. The input can also be a set of RS_IDs. Annotated results will be available in the output folder specified if the Generate text files box is checked.","title":"Annotation"},{"location":"tutorials/GWAS/Annotation/#annotation-sources","text":"Under the annotation tab, the Variant based annotators 1000GenomesSimple_20170501 and ClinVar_20170501 are selected by default. But, all the available annotation sources are shown and users have the option to make selections. After annotation sources are selected, users can go back to the General tab to confirm all the options selected are as desired before submitting the job to the server. If you would like to include additional annotation sources, please contact Omicsoft support team ( support@omicsoft.com ). Requests will be reviewed and new features may be added in future releases of Array Suite. Please keep other options as default, and click Send To Queue to submit the job.","title":"Annotation sources"},{"location":"tutorials/GWAS/Annotation/#annotation-output","text":"After the job is finished, there will be an annotation result table (OSCR) that contains all the annotation information. By right clicking the row ID, users can conveniently go to GeneCard, dbSNP, HaploregV2 and RegulomeDB to view corresponding information of that SNP.","title":"Annotation output"},{"location":"tutorials/GWAS/Annotation/#results-filtering","text":"Please note that for annotated Omicsoft SNP Classification Results ('oscr http://www.arrayserver.com/wiki/index.php?title=Oscr '), variant annotation columns are fully interactive and can be filtered by mutation type, AA position and MAF etc. In the Association chapter,we found the top SNP rs6060535 shown in NCBI eQTL browser also showed significant association with CPNE1 expression in our test Hapmap data. Now we can look for more detailed information about this SNP. By searching the SNP ID and scrolling to the last annotation term (RegulomeDB), we will find rs6060535 is in class 1f, which means this SNP is an eQTL, and also in transcription factor (TF) binding site or a DNase hypersensitive peak. This also provides evidence to support our finding that rs6060535 is significantly associated with CPNE1 gene expression level. We can also find all the significant SNPs associated with CPNE1 gene expression level by setting up a cutoff. For example, we can find all the SNPs which show Bonferroni P-value smaller than 5E-8. From the result, there are 162 SNPs in chr20 that show significant association with CPNE1 expression level in our tutorial Hapmap data in the level of Bonferroni P-value smaller than 5E-8.","title":"Results filtering"},{"location":"tutorials/GWAS/Association/","text":"Association The association analysis module provides a high-throughput genetic association analysis pipeline for tens of millions of genetic variants. Users can build genetic association analysis models for continuous, binary and survival endpoints with or without covariates and interaction terms. Stratified analysis is also available for survival model. Throughout, additive genetic models will be used, which means genotype data are coded as 0, 1 or 2, while imputed dosage data will range from 0 to 2 on a continuous scale to reflect the estimates of the imputed dose. To ensure consistent analysis and annotation of the results, 0, 1 or 2 always refer to 0, 1 or 2 copies of the alternative allele. Input file format As shown in the figure below, input files for genetic data can be genotypes in VCF or Plink BED format, or dose data in the VCF format. An input phenotype file needs to be specified separately, where subject IDs need to be in the first column, followed by phenotype and covariates. Subject IDs need to be the same as those in the genetic data file. In the case of the plink format, subject IDs need to match individual IDs if they are different from family IDs. It is possible to specify a region of SNPs for analysis by using a special syntax in the SNP list field. For example, by specifying <15:1-10000> , analysis will only be based on the region on chromosome 15 from base pair position 1 to 10000. In the current version of the analysis module, users need to combine PCA results from the QC step ( PCA_results.txt ) with phenotype data, and provide this combined dataset along with the genotype data, to be used in the association analysis. For the purposes of this tutorial, a combined Phenotype file ( Phenotype.txt ) has been provided, so can be directly used with the imputed genotype data from the previous section. In this tutorial, we use the imputed VCF file (as VCF dose type) as genotype input. The phenotype file in the downloaded zip folder contains the CPNE1 gene expression data downloaded from the Geuvadis RNA sequencing project, gender information, and the first 3 principal components from the previous QC step. Analysis model Currently, three statistical models are supported in the association analysis module: Linear model for continuous traits, logistic regression for binary traits and Cox proportional hazard model for survival endpoints. By clicking Specify Model (Phenotypes and Covariates) , users can specify phenotype trait and covariates in the phenotype file. Phenotype and covariates can be in any order in the phenotype file. The model below shows how to analyze a continuous trait, CPNE1 gene expression data. This analysis is an eQTL analysis to find the SNPs in chr20 that are significantly associated with CPNE1 gene expression. In this step, please first add the file containing imputed dosage vcf data (from the previous step), and the expression file that is in the downloaded zipped folder (\"Phenotype.txt\"). After selecting Specify Model (Phenotypes and Covariates) , the following interface will appear. Columns shown are those included in the phenotype file, which includes gender, first 3 PC scores and CPNE1 expression levels. In this instance, please select CPNE1 expression level as the trait . SNP is automatically selected to include in model. Users can then highlight all the covariates for the model; in this example, they are gender , Eigen1 , Eigen2 and Eigen3 , which represent gender and the first three principle component scores. The phenotype file includes all 210 samples. When performing association analysis, the subjects that are not in input VCF file will be excluded automatically. Once the model is constructed, press OK and General window will appear again. Note now under Specify Model (Phenotypes and Covariates) , the complete model is shown. Users may inspect this model and make sure that this is correct. Users may Specify Model again to make changes to the model shown. In the Options panel, users can specify the following three options prior to analysis. Only markers meeting the pre-specified thresholds will be included in the analysis. R2 cutoff (dose data only): only markers with imputation quality score R2 greater than the specified value will be included in the association analysis. HWE p-value cutoff (1 means no cutoff): only markers with HWE p-value more significant than the specified cutoff value will be included in the association analysis. Allele count cutoff (0 means no cutoff): only markers with at least the specified number of minor alleles will be included in the analysis. For example, when 1 is specified as the cutoff value, all the monomorphic markers will be excluded from the analysis. P-values generated for both genotype and dose data are based on a likelihood test. For binary and survival trait association test, if wald tests are desired, users can uncheck the box Use likelihood test instead of wald test . Likelihood ratio tests can be more robust than wald tests for low frequency and rare markers. A variety of options for multiple testing adjustment are available. Bonferroni correction is often used for a GWAS study where P-value < 5E-08 is considered as statistically significant. The same significance threshold can be applied to genome-wide analysis based on imputed data. As the association analysis is computationally intensive, especially for imputed data, users can specify a large Job number , as long as it is supported by the server. Logistic regression and survival analysis can be carried out similarly. By default, all the variables are numerical. A categorical variable can be specified by checking the box in the Class column by the Term of interest. Below is an example (not in tutorial data). The response variable (Term = binary trait) in the figure below is coded as 1 and 2. By checking the box in the Class column beside it, the trait will be treated as a binary trait with two levels, 1 and 2. Similar to continuous trait analysis, users can add covariates, interactions and nested models. In this tutorial, we keep other options as default, specify an output name and output folder (as in the screenshot shown below), then click Send To Queue to submit the job. Association output Once an association analysis is complete, the results table will be available in the main window. The name of this table will be shown in the Solution Explorer window ending with .AssociationReport(GTT) . In the report, you will find information on chromosome, position, variant ID, reference allele, alternative allele, analyzed subject number (N), alternative allele count (AC), alternative allele frequency (AF), Call Rate (CR), HWE p-value, SNP SE, SNP effect (or SNP Beta), raw p-value, Bonferroni adjusted p-value, etc. In the case of analysis of a binary trait or survival endpoint, reported effect estimates will be OR (Odds Ratio) or HR (Hazards Ratio), SE, 95% CI for OR or HR. These results can be filtered based on SNP ID or chromosome position using the filter feature in the View Controller window. The NCBI eQTL browser link is a browser containing the information of expression quantitative trait loci (eQTL). Users can use NCBI eQTL browser to find out the expression associated SNPs. If we search for CPNE1 eQTL in chr20 in NCBI eQTL browser, We will find the significant SNPs associated with CPNE1 gene expression level. Please note that the positions shown in this browser are 0-based, while in our association result (and the input VCF file), the SNP positions are 1-based. Therefore, the SNP position shown in association result table should be adding 1 base to the position shown in eQTL browser. eQTL browser shows rs6060535 (chr20:34235521) as the top SNP associated with CPNE1 which has the p-value of 2.3233e-28. We can search position of rs6060535 (chr20:34235522) in the association report table. It shows a very significant association with raw p-value in the order of e-27 which is quite comparable to NCBI eQTL browser. Users can also try looking for the p-value of other significant SNPs shown in eQTL browser. Please note that due to different study subjects, sample size, and study tissues, the p-values may show discrepancy when comparing our association result to NCBI eQTL browser. One additional handy feature of the served-based analysis is the availability of the full log information. As with all the served-based jobs, log information is available under the Server Jobs tab. An example is shown below. By right clicking the name of the job, a new window will pop up with the option to View Full Log . Detailed information on the analysis job is outlined in the log file step-by-step. The full path name to the output folder is also listed just in case you forget which Output folder was specified during the analysis step.","title":"Association"},{"location":"tutorials/GWAS/Association/#association","text":"The association analysis module provides a high-throughput genetic association analysis pipeline for tens of millions of genetic variants. Users can build genetic association analysis models for continuous, binary and survival endpoints with or without covariates and interaction terms. Stratified analysis is also available for survival model. Throughout, additive genetic models will be used, which means genotype data are coded as 0, 1 or 2, while imputed dosage data will range from 0 to 2 on a continuous scale to reflect the estimates of the imputed dose. To ensure consistent analysis and annotation of the results, 0, 1 or 2 always refer to 0, 1 or 2 copies of the alternative allele.","title":"Association"},{"location":"tutorials/GWAS/Association/#input-file-format","text":"As shown in the figure below, input files for genetic data can be genotypes in VCF or Plink BED format, or dose data in the VCF format. An input phenotype file needs to be specified separately, where subject IDs need to be in the first column, followed by phenotype and covariates. Subject IDs need to be the same as those in the genetic data file. In the case of the plink format, subject IDs need to match individual IDs if they are different from family IDs. It is possible to specify a region of SNPs for analysis by using a special syntax in the SNP list field. For example, by specifying <15:1-10000> , analysis will only be based on the region on chromosome 15 from base pair position 1 to 10000. In the current version of the analysis module, users need to combine PCA results from the QC step ( PCA_results.txt ) with phenotype data, and provide this combined dataset along with the genotype data, to be used in the association analysis. For the purposes of this tutorial, a combined Phenotype file ( Phenotype.txt ) has been provided, so can be directly used with the imputed genotype data from the previous section. In this tutorial, we use the imputed VCF file (as VCF dose type) as genotype input. The phenotype file in the downloaded zip folder contains the CPNE1 gene expression data downloaded from the Geuvadis RNA sequencing project, gender information, and the first 3 principal components from the previous QC step.","title":"Input file format"},{"location":"tutorials/GWAS/Association/#analysis-model","text":"Currently, three statistical models are supported in the association analysis module: Linear model for continuous traits, logistic regression for binary traits and Cox proportional hazard model for survival endpoints. By clicking Specify Model (Phenotypes and Covariates) , users can specify phenotype trait and covariates in the phenotype file. Phenotype and covariates can be in any order in the phenotype file. The model below shows how to analyze a continuous trait, CPNE1 gene expression data. This analysis is an eQTL analysis to find the SNPs in chr20 that are significantly associated with CPNE1 gene expression. In this step, please first add the file containing imputed dosage vcf data (from the previous step), and the expression file that is in the downloaded zipped folder (\"Phenotype.txt\"). After selecting Specify Model (Phenotypes and Covariates) , the following interface will appear. Columns shown are those included in the phenotype file, which includes gender, first 3 PC scores and CPNE1 expression levels. In this instance, please select CPNE1 expression level as the trait . SNP is automatically selected to include in model. Users can then highlight all the covariates for the model; in this example, they are gender , Eigen1 , Eigen2 and Eigen3 , which represent gender and the first three principle component scores. The phenotype file includes all 210 samples. When performing association analysis, the subjects that are not in input VCF file will be excluded automatically. Once the model is constructed, press OK and General window will appear again. Note now under Specify Model (Phenotypes and Covariates) , the complete model is shown. Users may inspect this model and make sure that this is correct. Users may Specify Model again to make changes to the model shown. In the Options panel, users can specify the following three options prior to analysis. Only markers meeting the pre-specified thresholds will be included in the analysis. R2 cutoff (dose data only): only markers with imputation quality score R2 greater than the specified value will be included in the association analysis. HWE p-value cutoff (1 means no cutoff): only markers with HWE p-value more significant than the specified cutoff value will be included in the association analysis. Allele count cutoff (0 means no cutoff): only markers with at least the specified number of minor alleles will be included in the analysis. For example, when 1 is specified as the cutoff value, all the monomorphic markers will be excluded from the analysis. P-values generated for both genotype and dose data are based on a likelihood test. For binary and survival trait association test, if wald tests are desired, users can uncheck the box Use likelihood test instead of wald test . Likelihood ratio tests can be more robust than wald tests for low frequency and rare markers. A variety of options for multiple testing adjustment are available. Bonferroni correction is often used for a GWAS study where P-value < 5E-08 is considered as statistically significant. The same significance threshold can be applied to genome-wide analysis based on imputed data. As the association analysis is computationally intensive, especially for imputed data, users can specify a large Job number , as long as it is supported by the server. Logistic regression and survival analysis can be carried out similarly. By default, all the variables are numerical. A categorical variable can be specified by checking the box in the Class column by the Term of interest. Below is an example (not in tutorial data). The response variable (Term = binary trait) in the figure below is coded as 1 and 2. By checking the box in the Class column beside it, the trait will be treated as a binary trait with two levels, 1 and 2. Similar to continuous trait analysis, users can add covariates, interactions and nested models. In this tutorial, we keep other options as default, specify an output name and output folder (as in the screenshot shown below), then click Send To Queue to submit the job.","title":"Analysis model"},{"location":"tutorials/GWAS/Association/#association-output","text":"Once an association analysis is complete, the results table will be available in the main window. The name of this table will be shown in the Solution Explorer window ending with .AssociationReport(GTT) . In the report, you will find information on chromosome, position, variant ID, reference allele, alternative allele, analyzed subject number (N), alternative allele count (AC), alternative allele frequency (AF), Call Rate (CR), HWE p-value, SNP SE, SNP effect (or SNP Beta), raw p-value, Bonferroni adjusted p-value, etc. In the case of analysis of a binary trait or survival endpoint, reported effect estimates will be OR (Odds Ratio) or HR (Hazards Ratio), SE, 95% CI for OR or HR. These results can be filtered based on SNP ID or chromosome position using the filter feature in the View Controller window. The NCBI eQTL browser link is a browser containing the information of expression quantitative trait loci (eQTL). Users can use NCBI eQTL browser to find out the expression associated SNPs. If we search for CPNE1 eQTL in chr20 in NCBI eQTL browser, We will find the significant SNPs associated with CPNE1 gene expression level. Please note that the positions shown in this browser are 0-based, while in our association result (and the input VCF file), the SNP positions are 1-based. Therefore, the SNP position shown in association result table should be adding 1 base to the position shown in eQTL browser. eQTL browser shows rs6060535 (chr20:34235521) as the top SNP associated with CPNE1 which has the p-value of 2.3233e-28. We can search position of rs6060535 (chr20:34235522) in the association report table. It shows a very significant association with raw p-value in the order of e-27 which is quite comparable to NCBI eQTL browser. Users can also try looking for the p-value of other significant SNPs shown in eQTL browser. Please note that due to different study subjects, sample size, and study tissues, the p-values may show discrepancy when comparing our association result to NCBI eQTL browser. One additional handy feature of the served-based analysis is the availability of the full log information. As with all the served-based jobs, log information is available under the Server Jobs tab. An example is shown below. By right clicking the name of the job, a new window will pop up with the option to View Full Log . Detailed information on the analysis job is outlined in the log file step-by-step. The full path name to the output folder is also listed just in case you forget which Output folder was specified during the analysis step.","title":"Association output"},{"location":"tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/","text":"Connecting to a Server and Uploading Files Connection to a Server Before creating a server project, first connect to a server by clicking the Server tab at the top of Array Studio. You may need to log off first if you do not see this interface. Fill in the server information (where Server name can be anything given by the user to help remember the server) and log-in credentials. Select the Connect button. In some company server configurations, it will use your computer account to login and it does not require user authorization. Create a server project Upon successful login, go to the Analysis tab and click New to create a New Server Project . You will need to provide Project ID and Title to this new server project. Then click the Create button to complete this step. Once the server project is successfully created, you will see it in the \"Solution Explorer\" window. In the example above, it is called \"Tutorial_GWAS (Server Project Distributed)\". Upload local files After the server project is created, the next step is to upload plink raw data into the project if they are not already on the server. This can be done by using the upload feature under the server tab. You will be prompted to browse folders and select the files that are needed for uploading. You can upload multiple files at a time. In this case, \"plink_all_var_lefted_cleaned.bed\", \"plink_all_var_lefted_cleaned.bim\", \"plink_all_var_lefted_cleaned.fam\" and \"Phenotype.txt\" files should be uploaded at this time. If the ServerFiles tab is not visible, select Server File | Browse Files .","title":"Connecting To A Server And Uploading Files"},{"location":"tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#connecting-to-a-server-and-uploading-files","text":"","title":"Connecting to a Server and Uploading Files"},{"location":"tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#connection-to-a-server","text":"Before creating a server project, first connect to a server by clicking the Server tab at the top of Array Studio. You may need to log off first if you do not see this interface. Fill in the server information (where Server name can be anything given by the user to help remember the server) and log-in credentials. Select the Connect button. In some company server configurations, it will use your computer account to login and it does not require user authorization.","title":"Connection to a Server"},{"location":"tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#create-a-server-project","text":"Upon successful login, go to the Analysis tab and click New to create a New Server Project . You will need to provide Project ID and Title to this new server project. Then click the Create button to complete this step. Once the server project is successfully created, you will see it in the \"Solution Explorer\" window. In the example above, it is called \"Tutorial_GWAS (Server Project Distributed)\".","title":"Create a server project"},{"location":"tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#upload-local-files","text":"After the server project is created, the next step is to upload plink raw data into the project if they are not already on the server. This can be done by using the upload feature under the server tab. You will be prompted to browse folders and select the files that are needed for uploading. You can upload multiple files at a time. In this case, \"plink_all_var_lefted_cleaned.bed\", \"plink_all_var_lefted_cleaned.bim\", \"plink_all_var_lefted_cleaned.fam\" and \"Phenotype.txt\" files should be uploaded at this time. If the ServerFiles tab is not visible, select Server File | Browse Files .","title":"Upload local files"},{"location":"tutorials/GWAS/Imputation/","text":"Imputation Imputation process In the imputation step, it is absolutely essential that you are using the strand-normalized and post-QC data for this step. Genotype imputation makes statistical inferences of unobserved genotypes based on reference haplotypes. Currently, haplotypes from 2504 1000 Genomes Phase 3 subjects are used as reference panel. Future implementation may include larger reference panels to allow more powerful and accurate imputation. The entire process can be divided into two stages. In the first stage, GWAS subjects are pre-phased. To achieve memory and speed efficiency, this pre-phasing step is carried out in parallel for chunks of chromosomes. After pre-phasing, imputation is conducted in parallel for each chunk of the chromosome and imputed data are subsequently combined into one VCF file. Similar to QC pipeline, imputation needs to run on Linux server. During the pre-phasing step, there are three methods to choose HAPI-UR, MaCH and Automatic For automatic method, MaCH is used for studies with less than 1000 subjects and HAPI-UR is used for studies with at least 1000 subjects. The choice of HAPI-UR for bigger studies is primarily due to computational speed reason. Pre-phasing is the most time-consuming step. It is estimated that using MaCH, 40~50 hours on 40-node cluster are needed to phase ~180 subjects based on ~4 million markers. It is highly advisable that users find out the number of nodes available on their servers/clusters to determine an optimal number of jobs (Job number) for this step. Users can also try it out by running imputation for one chromosome region (e.g. 50 mb) to estimate the number needed. This can be achieved by entering in the SNP list field as shown in the figure below. Users can specify a subset of subjects instead of the entire set of subjects available in the plink files for imputation. This allows flexibility to impute data for a subset of subjects should there be a need to exclude certain subjects from the post-QC plink files. The following options can be specified for the imputation process. Number of iterations : This is one of the two key parameters used to infer haplotypes during the phasing stage. It specifies how many iterations of the Markov sampler should be run. These iterations are used to simultaneously update the crossover map, to update the error rate map and to estimate the missing genotypes. A set value of 20 is given. Number of haplotypes : This is the other key parameter used to infer haplotypes during the phasing stage. It specifies how many haplotypes should be considered when updating each individual. A set value of 200 is given. Number of markers per chunk : This option specifies the number of markers to be included in a chromosome chunk during the phasing stage. It is recommended that hundreds (not thousands) of chunks be generated for a given GWAS panel. For example, 5000 markers/chunk can be specified for a 5M GWAS panel. Number of markers in the overlap region : It is crucial that adjacent chunks are overlapped such that phasing is done correctly. It is recommended that the overlap is at least 100kb. This is often achieved by specifying the overlap no less than one fourth of the chunk size. For example, 1500 markers/chunk can be specified with 5000 markers/chunk for a 5M GWAS panel. Reference library : Human B37.3 is currently used for the reference panel. Job number : This needs to be determined by the number of core processors on the server. A higher number would improve the overall speed of the process. The output of the imputation step will be saved in the output folder specified. Users can use the Browse button to choose output folder. In this tutorial, chromosome 20 is imputed with HAPI-UR using 8 nodes (Job number = 8) on the server. Please click Send To Queue to run imputation step. Imputation Output At the end of the imputation process, a single VCF file is generated that combines data from all the chromosome chunks. In the VCF file, chromosome, position, reference allele, alternative allele, marker ID, imputation quality (R2), minor allele frequency (MAF), genotyped or imputed (Is Genotype), and allelic dosage data are included. The VCF table will show under Table. In this table, rows correspond to variants. Columns provide aforementioned information on variants and from column 10 and onwards, subjects genotype and dose information are presented. A subject s ID is represented by Family ID -> Individual ID as provided in the original plink files. In this instance (as pointed by the red arrow), the first subject is NA18524->NA18524 with both Family ID and Individual ID being NA18524. Imputed data of the first marker for this subject is 0|0:0.000 as shown in the red rectangle in the figure below. The notation is based on output of GT:DS where GT is imputed genotype and DS is the imputed dosage data. In the \"Is Genotype\" column, \"False\" means this marker is imputed, while True means this marker is included in genotyping file and not from imputation result.","title":"Imputation"},{"location":"tutorials/GWAS/Imputation/#imputation","text":"","title":"Imputation"},{"location":"tutorials/GWAS/Imputation/#imputation-process","text":"In the imputation step, it is absolutely essential that you are using the strand-normalized and post-QC data for this step. Genotype imputation makes statistical inferences of unobserved genotypes based on reference haplotypes. Currently, haplotypes from 2504 1000 Genomes Phase 3 subjects are used as reference panel. Future implementation may include larger reference panels to allow more powerful and accurate imputation. The entire process can be divided into two stages. In the first stage, GWAS subjects are pre-phased. To achieve memory and speed efficiency, this pre-phasing step is carried out in parallel for chunks of chromosomes. After pre-phasing, imputation is conducted in parallel for each chunk of the chromosome and imputed data are subsequently combined into one VCF file. Similar to QC pipeline, imputation needs to run on Linux server. During the pre-phasing step, there are three methods to choose HAPI-UR, MaCH and Automatic For automatic method, MaCH is used for studies with less than 1000 subjects and HAPI-UR is used for studies with at least 1000 subjects. The choice of HAPI-UR for bigger studies is primarily due to computational speed reason. Pre-phasing is the most time-consuming step. It is estimated that using MaCH, 40~50 hours on 40-node cluster are needed to phase ~180 subjects based on ~4 million markers. It is highly advisable that users find out the number of nodes available on their servers/clusters to determine an optimal number of jobs (Job number) for this step. Users can also try it out by running imputation for one chromosome region (e.g. 50 mb) to estimate the number needed. This can be achieved by entering in the SNP list field as shown in the figure below. Users can specify a subset of subjects instead of the entire set of subjects available in the plink files for imputation. This allows flexibility to impute data for a subset of subjects should there be a need to exclude certain subjects from the post-QC plink files. The following options can be specified for the imputation process. Number of iterations : This is one of the two key parameters used to infer haplotypes during the phasing stage. It specifies how many iterations of the Markov sampler should be run. These iterations are used to simultaneously update the crossover map, to update the error rate map and to estimate the missing genotypes. A set value of 20 is given. Number of haplotypes : This is the other key parameter used to infer haplotypes during the phasing stage. It specifies how many haplotypes should be considered when updating each individual. A set value of 200 is given. Number of markers per chunk : This option specifies the number of markers to be included in a chromosome chunk during the phasing stage. It is recommended that hundreds (not thousands) of chunks be generated for a given GWAS panel. For example, 5000 markers/chunk can be specified for a 5M GWAS panel. Number of markers in the overlap region : It is crucial that adjacent chunks are overlapped such that phasing is done correctly. It is recommended that the overlap is at least 100kb. This is often achieved by specifying the overlap no less than one fourth of the chunk size. For example, 1500 markers/chunk can be specified with 5000 markers/chunk for a 5M GWAS panel. Reference library : Human B37.3 is currently used for the reference panel. Job number : This needs to be determined by the number of core processors on the server. A higher number would improve the overall speed of the process. The output of the imputation step will be saved in the output folder specified. Users can use the Browse button to choose output folder. In this tutorial, chromosome 20 is imputed with HAPI-UR using 8 nodes (Job number = 8) on the server. Please click Send To Queue to run imputation step.","title":"Imputation process"},{"location":"tutorials/GWAS/Imputation/#imputation-output","text":"At the end of the imputation process, a single VCF file is generated that combines data from all the chromosome chunks. In the VCF file, chromosome, position, reference allele, alternative allele, marker ID, imputation quality (R2), minor allele frequency (MAF), genotyped or imputed (Is Genotype), and allelic dosage data are included. The VCF table will show under Table. In this table, rows correspond to variants. Columns provide aforementioned information on variants and from column 10 and onwards, subjects genotype and dose information are presented. A subject s ID is represented by Family ID -> Individual ID as provided in the original plink files. In this instance (as pointed by the red arrow), the first subject is NA18524->NA18524 with both Family ID and Individual ID being NA18524. Imputed data of the first marker for this subject is 0|0:0.000 as shown in the red rectangle in the figure below. The notation is based on output of GT:DS where GT is imputed genotype and DS is the imputed dosage data. In the \"Is Genotype\" column, \"False\" means this marker is imputed, while True means this marker is included in genotyping file and not from imputation result.","title":"Imputation Output"},{"location":"tutorials/GWAS/Introduction/","text":"Introduction In this document, we will provide step-by-step tutorials on how to create a server project for server-based GWAS analysis. Starting with a plink dataset, this tutorial will teach you how to strand-normalize, filter by quality control (QC) parameters, impute for untested genotypes in samples, and perform association analysis between genotype and phenotypes of interest. ArrayServer The GWAS module needs to be run on OmicSoft Array Server, the OmicSoft enterprise solution that allows users to store, share, search, and integrate their GWAS projects and data. The same solution has been applied to microarray/SNP/CNV/NGS projects and data to easily share analyzed data with clients and colleagues. ArrayServer also hosts shared genome browsers. The following diagram demonstrates the functionality of Array Server: Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, Array Server has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of GWAS/imputed data. All the Array Studio modules available for local analysis are also accessible for server-based analysis, with similar graphic interfaces. Server Project A Server Project is a project that is created on the server, rather than on the user s client machine. This project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user s home folder, typically MyDocuments/Omicsoft/ServerProjects . A Server Project, when stored locally in the cache folder, has a different filename suffix (.ossprj) compared to a regular project (.osprj), and can only be opened when the user is connected to the server. The concept behind a Server Project is that any data that is added to a project is first stored on the server. When the user adds a new dataset (whether it is GWAS, Gene Expression, CNV, or NextGen sequencing data), the user will be prompted with the folder structure of the Array Server instead of the local file system. If a user wishes to use a file from their local file system, the user must first upload the file to the server file system or ask an Admin to map the corresponding storage. Most companies store data on network drives, so they can map these drives directly in Array Server and all users will be able to access data easily during server analysis. All data addition and extraction is done on the server side, by Array Server, instead of the user s client machine. This allows the user to use the power of the server, instead of the user s individual client machine for the importing of data. This is extremely important for some memory/CPU-intensive importing operations (such as imputation). After data QC, imputation and analysis, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc. Anytime the user saves the project, it is synchronized with the version on the server. Test Dataset The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be accessed from the following URL: link The dataset is based on The Geuvadis Project that combined transcriptomics and genomics for a subset of 465 individuals from the 1000 Genomes Project. The input phase 3 1000 Genomes Project data is in plink format link . CPNE1 gene expression data for these individuals can be found in file Phenotype.txt in the Phenotype folder and is based on the normalized gene-level expression provided by The Geuvadis mRNA sequencing ( http://www.ebi.ac.uk/arrayexpress/files/E-GEUV-1/analysis_results/ ). The expression data file also contains gender information and principal component scores, which we will discuss in detail later. Note: Omicsoft constantly updates the GWAS module in order to meet continued requests of our customers. Therefore, you may note slightly different results when you compare your results to the results in this tutorial. Please contact customer support ( support@omicsoft.com ) if you have any questions as you go through this tutorial. After this tutorial, users will be able to perform GWAS analysis to find the SNPs significantly associated with the expression level of a gene of interest (e.g. CPNE1 ).","title":"Introduction"},{"location":"tutorials/GWAS/Introduction/#introduction","text":"In this document, we will provide step-by-step tutorials on how to create a server project for server-based GWAS analysis. Starting with a plink dataset, this tutorial will teach you how to strand-normalize, filter by quality control (QC) parameters, impute for untested genotypes in samples, and perform association analysis between genotype and phenotypes of interest.","title":"Introduction"},{"location":"tutorials/GWAS/Introduction/#arrayserver","text":"The GWAS module needs to be run on OmicSoft Array Server, the OmicSoft enterprise solution that allows users to store, share, search, and integrate their GWAS projects and data. The same solution has been applied to microarray/SNP/CNV/NGS projects and data to easily share analyzed data with clients and colleagues. ArrayServer also hosts shared genome browsers. The following diagram demonstrates the functionality of Array Server: Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, Array Server has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of GWAS/imputed data. All the Array Studio modules available for local analysis are also accessible for server-based analysis, with similar graphic interfaces.","title":"ArrayServer"},{"location":"tutorials/GWAS/Introduction/#server-project","text":"A Server Project is a project that is created on the server, rather than on the user s client machine. This project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user s home folder, typically MyDocuments/Omicsoft/ServerProjects . A Server Project, when stored locally in the cache folder, has a different filename suffix (.ossprj) compared to a regular project (.osprj), and can only be opened when the user is connected to the server. The concept behind a Server Project is that any data that is added to a project is first stored on the server. When the user adds a new dataset (whether it is GWAS, Gene Expression, CNV, or NextGen sequencing data), the user will be prompted with the folder structure of the Array Server instead of the local file system. If a user wishes to use a file from their local file system, the user must first upload the file to the server file system or ask an Admin to map the corresponding storage. Most companies store data on network drives, so they can map these drives directly in Array Server and all users will be able to access data easily during server analysis. All data addition and extraction is done on the server side, by Array Server, instead of the user s client machine. This allows the user to use the power of the server, instead of the user s individual client machine for the importing of data. This is extremely important for some memory/CPU-intensive importing operations (such as imputation). After data QC, imputation and analysis, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc. Anytime the user saves the project, it is synchronized with the version on the server.","title":"Server Project"},{"location":"tutorials/GWAS/Introduction/#test-dataset","text":"The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be accessed from the following URL: link The dataset is based on The Geuvadis Project that combined transcriptomics and genomics for a subset of 465 individuals from the 1000 Genomes Project. The input phase 3 1000 Genomes Project data is in plink format link . CPNE1 gene expression data for these individuals can be found in file Phenotype.txt in the Phenotype folder and is based on the normalized gene-level expression provided by The Geuvadis mRNA sequencing ( http://www.ebi.ac.uk/arrayexpress/files/E-GEUV-1/analysis_results/ ). The expression data file also contains gender information and principal component scores, which we will discuss in detail later. Note: Omicsoft constantly updates the GWAS module in order to meet continued requests of our customers. Therefore, you may note slightly different results when you compare your results to the results in this tutorial. Please contact customer support ( support@omicsoft.com ) if you have any questions as you go through this tutorial. After this tutorial, users will be able to perform GWAS analysis to find the SNPs significantly associated with the expression level of a gene of interest (e.g. CPNE1 ).","title":"Test Dataset"},{"location":"tutorials/GWAS/Preprocessing/","text":"Preprocessing Strand normalization Once the tutorial plink files are available on the server, you can proceed to the Preprocessing step. To mirror the sequential process of the overall work flow, the GWAS module is designed to automatically include output of the previous step as the input of the subsequent step. For example, the output of the Preprocess step will be loaded as the input of the QC step by default. Subsequently, the output of the QC step will be loaded as the input for the imputation step, which will generate input for the association step. This streamlined process enables users to efficiently conduct GWAS analysis from raw input data to association analysis. To facilitate GWAS data imputation and downstream variant annotation, we recommend that users first perform the normalize strand step. This is to ensure that all the genotypes are reported on the forward strand of the reference genome. This is a crucial step to ensure the accuracy of the imputation and variant annotations. OmicSoft builds SNP panels to allow users to select a specific GWAS platform to normalize strand . If you do not see your GWAS panel listed as one of the SNP panel options, please contact OmicSoft support ( support@omicsoft.com ) and we will be able to build one for you. Please note that if there is only a very little proportion of markers (less than 2%) having inconsistent strands, flipping will NOT be automatically attempted. If there is a flipping issue, you will see a significant proportion of inconsistent SNPs. To normalize strand, go to the Analysis tab, then select GWAS | Preprocess | Normalize .BED Files . Once you click Normalize .BED Files, a new window will show up. Here, you need to add the plink Binary PED (BED) file using the Add button, then select the corresponding SNP panel, Reference library and specify an output folder path. For this tutorial, please select Human.B37.3 as the reference library, and Illumina.HumanOmni2.5-8v1 as the SNP panel. There are two options users can select: Override mapping information : Checking this option will recreate mapping positions based on SNP panel. To do a liftover, this option has to be selected. Use dbsnp information to infer mapping : If this option is checked, Array Studio will ignore any coordinate information in the source file. Array Studio will search the latest dbSNP database and recover the chromosome and position information from the \"rs\" IDs. For this tutorial, please leave both options unchecked. You will need to uncheck to override mapping information to remove default settings. Please ensure that you specify an output folder. It is good practice to name the output folder, for example 'StrandNormalize' so that it can be identified for the following QC steps. Then click Send To Queue to submit your job. After your job is submitted, it will run on the server and you will be able to monitor its progress under the Server Jobs tab. Once this job is complete, you will find a new set of plink files in the output folder previously specified. This folder can be found under the ServerFiles tab.","title":"Preprocessing"},{"location":"tutorials/GWAS/Preprocessing/#preprocessing","text":"","title":"Preprocessing"},{"location":"tutorials/GWAS/Preprocessing/#strand-normalization","text":"Once the tutorial plink files are available on the server, you can proceed to the Preprocessing step. To mirror the sequential process of the overall work flow, the GWAS module is designed to automatically include output of the previous step as the input of the subsequent step. For example, the output of the Preprocess step will be loaded as the input of the QC step by default. Subsequently, the output of the QC step will be loaded as the input for the imputation step, which will generate input for the association step. This streamlined process enables users to efficiently conduct GWAS analysis from raw input data to association analysis. To facilitate GWAS data imputation and downstream variant annotation, we recommend that users first perform the normalize strand step. This is to ensure that all the genotypes are reported on the forward strand of the reference genome. This is a crucial step to ensure the accuracy of the imputation and variant annotations. OmicSoft builds SNP panels to allow users to select a specific GWAS platform to normalize strand . If you do not see your GWAS panel listed as one of the SNP panel options, please contact OmicSoft support ( support@omicsoft.com ) and we will be able to build one for you. Please note that if there is only a very little proportion of markers (less than 2%) having inconsistent strands, flipping will NOT be automatically attempted. If there is a flipping issue, you will see a significant proportion of inconsistent SNPs. To normalize strand, go to the Analysis tab, then select GWAS | Preprocess | Normalize .BED Files . Once you click Normalize .BED Files, a new window will show up. Here, you need to add the plink Binary PED (BED) file using the Add button, then select the corresponding SNP panel, Reference library and specify an output folder path. For this tutorial, please select Human.B37.3 as the reference library, and Illumina.HumanOmni2.5-8v1 as the SNP panel. There are two options users can select: Override mapping information : Checking this option will recreate mapping positions based on SNP panel. To do a liftover, this option has to be selected. Use dbsnp information to infer mapping : If this option is checked, Array Studio will ignore any coordinate information in the source file. Array Studio will search the latest dbSNP database and recover the chromosome and position information from the \"rs\" IDs. For this tutorial, please leave both options unchecked. You will need to uncheck to override mapping information to remove default settings. Please ensure that you specify an output folder. It is good practice to name the output folder, for example 'StrandNormalize' so that it can be identified for the following QC steps. Then click Send To Queue to submit your job. After your job is submitted, it will run on the server and you will be able to monitor its progress under the Server Jobs tab. Once this job is complete, you will find a new set of plink files in the output folder previously specified. This folder can be found under the ServerFiles tab.","title":"Strand normalization"},{"location":"tutorials/GWAS/QC_of_GWAS_data/","text":"QC of GWAS data The data QC module offers a suite of standard data QC procedures to help prepare GWAS data for imputation or association analysis. The main purpose of the QC is to identify problematic subjects or markers for follow-up investigation or data exclusion. The output of the preprocessing step can be used as the input for the QC step. Go to the Analysis tab, then select GWAS | QC ; you will be prompted to add the input files for the QC pipeline, which consists of a sequential set of QC steps. The Add button allows you to add the set of plink files that have been pre-processed. If the file names are the same as the raw data, please ensure that you select the set of files that have been saved in the output folder specified in the pre-processing step. GWAS QC steps There are six QC options you can specify at the QC stage; default values are given in the above figure. A more or less stringent threshold can be specified for each QC step. Marker missing rate threshold (round 1) Two rounds of marker missing rate QCs are conducted. Default cut-off for the first round is set at 25%. Markers with missing data more than 25% will be identified and removed. This cut-off value is deliberately set at a relatively high level to flag markers with high missing rate. The main purpose of this step is to identify markers with poor quality due to high missing rate and to exclude these markers from subject-level missing rate calculation. Subject missing rate threshold (round 1) This step identified subjects with relatively high missing rate. A default value of 0.05 is given to identify and remove subjects with at least 5% missing data rate. A more stringent cut-off value can also be used. Marker missing rate threshold (round 2) In the second round of marker level missing rate QC, a default value of 0.05 is set to identify and remove markers with at least 5% missing data rate. A more stringent cut-off value can also be used. Cutoff of kinship coefficient (relatedness) The aim of this QC step is to identify cryptic related subjects which are established by testing pair-wise identity by state. Related samples are inferred based on the range of estimated kinship coefficients: >0.354, 0.354-0.177, 0.177-0.0884, and 0.0884-0.0442 that corresponds to duplicate/MZ twin, 1 st -degree, 2 nd -degree, and 3 rd -degree relationships, respectively. A default kinship value of 0.0442 is set to identify pairs of subjects with 3 rd -degree or closer relationships. By default, any subject pair with kinship value > 0.0442 will be removed. MAF threshold for the pruning step This cut-off is set for Linkage Disequilibrium (LD)-based pruning to select an independent set of common markers for Principle Component Analysis (PCA). A default value of 0.05 is given, which means the markers with minor allele frequency (MAF) more than 0.05 will be included in the pruning step. After pruning, the set of independent markers are used to conduct PCA analysis which include all the study subjects and 2504 1000Genomes subjects. Joint analysis of study subjects and 1000Genomes subjects allows inference of genetic ancestry of study subjects based on 1000Genomes subjects with known genetic ancestry information. HWE p-value cutoff Checking for Hardy-Weinberg Equilibrium (HWE) is the final step in quality control analysis of genetic markers. Under HWE assumptions, allele and genotype frequencies can be estimated from one generation to the next. In genetic association studies, HWE principles can be applied to detect genotyping errors. It is critical to conduct this QC step in a subset of subjects with similar genetic ancestry. To do this, a subject s genetic ancestry is first inferred from PCA analysis results based on study subjects and ~2K 1000 genomes subjects from the five super populations -- Africans, Ad Mixed Americans, East Asians, Europeans and South Asians. Genetic ancestry of a GWAS subject is predicted using the k-Nearest Neighbors algorithm. HWE testing is subsequently conducted in the largest subgroup of GWAS subjects. The default cut-off is set at 1e-8; a more stringent cut-off can be set. Markers not passing this threshold will be excluded from the imputation step. There is also an internal Gender QC check, but parameters are fixed, so no options are displayed in the SNP QC Pipeline window. Heterozygosity rates based on X chromosome markers are used to determine genders. A male call is made if heterozygosity rate is more than 0.8, while a female call is made if it is less than 0.2. Samples that fail the gender QC will be removed. Reference library is needed here as to make sure in the PCA analysis, the genetic positions of the study subjects match with the 1000Genomes samples. For this tutorial, please leave the options as default, specify an output folder, and click Send To Queue to submit your job. After the job is finished, please click Update Project to view the results. GWAS QC results Upon completion of GWAS data QC, QC results will be summarized as shown below. On the left side of the screen under the Solution Explorer tab, you will see a list of QC results that are organized into the following four sections. Three results are presented in the format of tables, and another one is a scatter plot which is fully interactive. Marker exclusion list The set of markers that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions. Replicate Sample Check For samples that are identified as technical replicates, a test of within family relatedness is performed to confirm that pairs of samples are identical. Samples that fail this test are output in this file and are excluded. Subject exclusion list The set of subjects that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions. Unexpected Sample Relatedness list** This table contains any subject pair with estimated kinship coefficient >0.0442. The output is generated by testing for pairwise relationship across families. N SNP (the number of SNPs that do not have missing genotypes for either individual, Z0 (the probability that IBD=0), Phi (the kinship coefficient), IBS0 (the proportion of SNPs with zero identity-by-state), Kinship (estimated kinship coefficient from the SNP data, and error (indicates a difference between the estimated and specified kinship coefficients). PCA results PCA analysis is based on a set of LD-pruned independent common markers in 1000 Genomes subjects and GWAS subjects. There are two PCA results in the view. The first one corresponds to the combined results with both post-QC study subjects and the 1000 Genomes subjects (which will be discussed in detail soon), and the second one corresponds to the post-QC study samples only. In the latter case, top 100 PC scores are shown. You can export this table by selecting one of the options in the menu bar (shown in the red rectangle) in the figure below. These results are needed in the downstream association analysis. Therefore, you should save this table as PCA_results.txt , which would later be merged with phenotype data. In this tutorial, however, a combined file ( Phenotype.txt ) is provided with the sample data, so this merge step will not be needed. PCA plot The combined PCA result with both post-QC study subjects and the 1000 Genomes subjects is shown in the form of PCA scatter plot. PCA scatter plots are generated from pairs of selected PC scores (also called eigenvectors). In the below example, PC1 (or Eigen1 on the X-axis) is plotted against PC2 (or Eigen2 on the Y-axis). Subjects from the 1000 Genomes project are represented by the square symbols and study subjects are denoted by filled circles. The five super-populations, Africans (AFR), Ad Mixed Americans (AMR), East Asians (EAS), Europeans (EUR) and South Asians (SAS), are represented by different colors as shown in the right hand View Controller . In this example, the vast majority of the study subjects are clustered with Europeans. Genetic ancestry of a study subject is further predicted using the k-Nearest Neighbors algorithm. The legends of the colors and symbols can be found on the right-hand of the screen under the View Controller tab. PCA plot is fully interactive. As shown in the example above, detailed information of the highlighted subject is shown in the table right below the PCA plot in the middle panel of the screen. You can also review genetic ancestry information of all the study samples by selecting the filled circle symbol in the View Controller. All of the study subjects will be highlighted in red color and detailed information on all the study subjects will be presented in the table format in the Details window. You can view the table in Excel, or perform other actions by selecting symbols shown on the menu bar of the table. This can be handy if you would like to export the inferred race information for further comparison to self-reported race data. In addition to QC results under GWAS_QC, there will also be a BED file containing the genetic information after QC step.","title":"QC of GWAS data"},{"location":"tutorials/GWAS/QC_of_GWAS_data/#qc-of-gwas-data","text":"The data QC module offers a suite of standard data QC procedures to help prepare GWAS data for imputation or association analysis. The main purpose of the QC is to identify problematic subjects or markers for follow-up investigation or data exclusion. The output of the preprocessing step can be used as the input for the QC step. Go to the Analysis tab, then select GWAS | QC ; you will be prompted to add the input files for the QC pipeline, which consists of a sequential set of QC steps. The Add button allows you to add the set of plink files that have been pre-processed. If the file names are the same as the raw data, please ensure that you select the set of files that have been saved in the output folder specified in the pre-processing step.","title":"QC of GWAS data"},{"location":"tutorials/GWAS/QC_of_GWAS_data/#gwas-qc-steps","text":"There are six QC options you can specify at the QC stage; default values are given in the above figure. A more or less stringent threshold can be specified for each QC step. Marker missing rate threshold (round 1) Two rounds of marker missing rate QCs are conducted. Default cut-off for the first round is set at 25%. Markers with missing data more than 25% will be identified and removed. This cut-off value is deliberately set at a relatively high level to flag markers with high missing rate. The main purpose of this step is to identify markers with poor quality due to high missing rate and to exclude these markers from subject-level missing rate calculation. Subject missing rate threshold (round 1) This step identified subjects with relatively high missing rate. A default value of 0.05 is given to identify and remove subjects with at least 5% missing data rate. A more stringent cut-off value can also be used. Marker missing rate threshold (round 2) In the second round of marker level missing rate QC, a default value of 0.05 is set to identify and remove markers with at least 5% missing data rate. A more stringent cut-off value can also be used. Cutoff of kinship coefficient (relatedness) The aim of this QC step is to identify cryptic related subjects which are established by testing pair-wise identity by state. Related samples are inferred based on the range of estimated kinship coefficients: >0.354, 0.354-0.177, 0.177-0.0884, and 0.0884-0.0442 that corresponds to duplicate/MZ twin, 1 st -degree, 2 nd -degree, and 3 rd -degree relationships, respectively. A default kinship value of 0.0442 is set to identify pairs of subjects with 3 rd -degree or closer relationships. By default, any subject pair with kinship value > 0.0442 will be removed. MAF threshold for the pruning step This cut-off is set for Linkage Disequilibrium (LD)-based pruning to select an independent set of common markers for Principle Component Analysis (PCA). A default value of 0.05 is given, which means the markers with minor allele frequency (MAF) more than 0.05 will be included in the pruning step. After pruning, the set of independent markers are used to conduct PCA analysis which include all the study subjects and 2504 1000Genomes subjects. Joint analysis of study subjects and 1000Genomes subjects allows inference of genetic ancestry of study subjects based on 1000Genomes subjects with known genetic ancestry information. HWE p-value cutoff Checking for Hardy-Weinberg Equilibrium (HWE) is the final step in quality control analysis of genetic markers. Under HWE assumptions, allele and genotype frequencies can be estimated from one generation to the next. In genetic association studies, HWE principles can be applied to detect genotyping errors. It is critical to conduct this QC step in a subset of subjects with similar genetic ancestry. To do this, a subject s genetic ancestry is first inferred from PCA analysis results based on study subjects and ~2K 1000 genomes subjects from the five super populations -- Africans, Ad Mixed Americans, East Asians, Europeans and South Asians. Genetic ancestry of a GWAS subject is predicted using the k-Nearest Neighbors algorithm. HWE testing is subsequently conducted in the largest subgroup of GWAS subjects. The default cut-off is set at 1e-8; a more stringent cut-off can be set. Markers not passing this threshold will be excluded from the imputation step. There is also an internal Gender QC check, but parameters are fixed, so no options are displayed in the SNP QC Pipeline window. Heterozygosity rates based on X chromosome markers are used to determine genders. A male call is made if heterozygosity rate is more than 0.8, while a female call is made if it is less than 0.2. Samples that fail the gender QC will be removed. Reference library is needed here as to make sure in the PCA analysis, the genetic positions of the study subjects match with the 1000Genomes samples. For this tutorial, please leave the options as default, specify an output folder, and click Send To Queue to submit your job. After the job is finished, please click Update Project to view the results.","title":"GWAS QC steps"},{"location":"tutorials/GWAS/QC_of_GWAS_data/#gwas-qc-results","text":"Upon completion of GWAS data QC, QC results will be summarized as shown below. On the left side of the screen under the Solution Explorer tab, you will see a list of QC results that are organized into the following four sections. Three results are presented in the format of tables, and another one is a scatter plot which is fully interactive. Marker exclusion list The set of markers that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions. Replicate Sample Check For samples that are identified as technical replicates, a test of within family relatedness is performed to confirm that pairs of samples are identical. Samples that fail this test are output in this file and are excluded. Subject exclusion list The set of subjects that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions. Unexpected Sample Relatedness list** This table contains any subject pair with estimated kinship coefficient >0.0442. The output is generated by testing for pairwise relationship across families. N SNP (the number of SNPs that do not have missing genotypes for either individual, Z0 (the probability that IBD=0), Phi (the kinship coefficient), IBS0 (the proportion of SNPs with zero identity-by-state), Kinship (estimated kinship coefficient from the SNP data, and error (indicates a difference between the estimated and specified kinship coefficients). PCA results PCA analysis is based on a set of LD-pruned independent common markers in 1000 Genomes subjects and GWAS subjects. There are two PCA results in the view. The first one corresponds to the combined results with both post-QC study subjects and the 1000 Genomes subjects (which will be discussed in detail soon), and the second one corresponds to the post-QC study samples only. In the latter case, top 100 PC scores are shown. You can export this table by selecting one of the options in the menu bar (shown in the red rectangle) in the figure below. These results are needed in the downstream association analysis. Therefore, you should save this table as PCA_results.txt , which would later be merged with phenotype data. In this tutorial, however, a combined file ( Phenotype.txt ) is provided with the sample data, so this merge step will not be needed. PCA plot The combined PCA result with both post-QC study subjects and the 1000 Genomes subjects is shown in the form of PCA scatter plot. PCA scatter plots are generated from pairs of selected PC scores (also called eigenvectors). In the below example, PC1 (or Eigen1 on the X-axis) is plotted against PC2 (or Eigen2 on the Y-axis). Subjects from the 1000 Genomes project are represented by the square symbols and study subjects are denoted by filled circles. The five super-populations, Africans (AFR), Ad Mixed Americans (AMR), East Asians (EAS), Europeans (EUR) and South Asians (SAS), are represented by different colors as shown in the right hand View Controller . In this example, the vast majority of the study subjects are clustered with Europeans. Genetic ancestry of a study subject is further predicted using the k-Nearest Neighbors algorithm. The legends of the colors and symbols can be found on the right-hand of the screen under the View Controller tab. PCA plot is fully interactive. As shown in the example above, detailed information of the highlighted subject is shown in the table right below the PCA plot in the middle panel of the screen. You can also review genetic ancestry information of all the study samples by selecting the filled circle symbol in the View Controller. All of the study subjects will be highlighted in red color and detailed information on all the study subjects will be presented in the table format in the Details window. You can view the table in Excel, or perform other actions by selecting symbols shown on the menu bar of the table. This can be handy if you would like to export the inferred race information for further comparison to self-reported race data. In addition to QC results under GWAS_QC, there will also be a BED file containing the genetic information after QC step.","title":"GWAS QC results"},{"location":"tutorials/GWAS/Relevant_Links/","text":"Relevant Links PLINK link MaCH link HAPIUR link All the annotation sources 1000Genomes link CADD link ClinVar link Conservation link , link , link ESP6500 link ExAC link FunctionalMutation link GRASP2 link GTExEqtl link GWAVA link Haploreg link Interpro link RegulomeDB link","title":"Relevant Links"},{"location":"tutorials/GWAS/Relevant_Links/#relevant-links","text":"PLINK link MaCH link HAPIUR link All the annotation sources 1000Genomes link CADD link ClinVar link Conservation link , link , link ESP6500 link ExAC link FunctionalMutation link GRASP2 link GTExEqtl link GWAVA link Haploreg link Interpro link RegulomeDB link","title":"Relevant Links"},{"location":"tutorials/GWAS/Save_Close_Project/","text":"Save & Close Project As one last step, users may need to save the project. This is especially important if users made changes to a table view that need to be saved on the server. Users can access all the information saved in this project in the future by selecting Open Server Project in the File menu. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) if you have any questions questions.","title":"Save/Close Project"},{"location":"tutorials/GWAS/Save_Close_Project/#save-close-project","text":"As one last step, users may need to save the project. This is especially important if users made changes to a table view that need to be saved on the server. Users can access all the information saved in this project in the future by selecting Open Server Project in the File menu. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) if you have any questions questions.","title":"Save &amp; Close Project"},{"location":"tutorials/GeneticsLand/","text":"GeneticsLand Tutorial .. toctree:: :maxdepth: 2 Introduction_to_GeneticsLand Adding_Data_to_GeneticsLand Explore_Your_Data_in_GeneticsLand Delete_your_GeneticsLand","title":"Home"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/","text":"Adding Data to GeneticsLand In this section, you will go through the basic procedures for adding data to your GeneticsLand (Sample Metadata, control access to patient information, genotypes/imputed doses, associations, and phenotypes), as well as how to export these different data to Array Studio to perform analyses such as GWAS. Add Sample MetaData to a GeneticsLand To avoid conflicting sample IDs, and to ensure access controls are in-place before restricted genetic data are added, it is considered best practice to register samples in the Sample MetaData table before adding their genetic data into the Land. From the Land tab, select Manage | Samples | Manage Sample Meta Data Take note of the number of samples (rows) currently in the table. Following this tutorial, the Land will be empty at this point so there will be 0 rows. Click the Add/Replace button: Click Load from tab delimited file and select the SampleMetaData.txt file from the tutorial dataset. Preview the metadata to ensure that you selected the proper file, then click the OK button to finish. Note the new number of samples it should be the sum of the prior number and the number of new samples being registered (0 + 870 = 870 in this case). If it is less, then one or more of the new sample IDs has conflicted with an existing sample ID, which means that the old metadata were over-written for the conflicting sample(s). If sample metadata were overwritten, the simplest solution is to map the new samples to new unique IDs. First, restore the appropriate metadata for the existing samples, as necessary (load from the metadata text files you had previously used). Then, re-register the new samples with new IDs. Use a mapping file when publishing the new samples data to the Land (next steps) to ensure they are published with the new IDs and don t collide with the existing samples and their data. Click the X in the MetaData tab to close it, and repeat with any other open tabs. Re-select the Land using the Select Land button, and the Sample Distribution view should now be populated: This view shows the number of samples by project, colored by sex, as indicated in the legend on the right. These groupings are the defaults (PrimaryGrouping and SecondaryGrouping) as configured when the Land was created. You can change the primary grouping using the Grouping button at the top. You can change the secondary grouping and make other adjustments to the chart by switching to the Task tab on the right. Note the sample attributes under the Sample tab on the left, which can be used to filter the view. All of these come from the Sample MetaData that you just loaded. The exception is the Data Availability attributes, which displays the amount of genetic data in the Land (currently none, as we haven t added any yet). Using your mouse to select a component of the chart (the males of STUDY009 here) will display the details of the relevant data points (the Sample MetaData in this case) below the chart: These chart configuration, filtering, and selecting mechanisms will generally behave the same across all views in the Land. For more detailed explanations of how to group/filter/alter Land Views, please see the OncoLand tutorial. Control Data Access in GeneticsLand If there are any restrictions on access to data for certain projects, it is best to configure this before adding the genetic data for those projects. Select Manage | Manage Project Access : You will see the default access level is Read for the standard users group (includes all users) across all GeneticsLand projects. You can adjust the access for each project at the User or User group level. Users with Read access (either individually or through a user group) will be able to see all data for samples in that project. Note, samples are mapped to a project using the ProjectName column in the Sample MetaData table, which is a key column. This is why we had to register the samples in the MetaData before configuring this access control. The Project level frequency access is a restricted access level that will hide all sample level data (like the MetaData that we just loaded, and the genotype data we will add in the next step) but expose allele frequencies and other aggregate summary statistics calculated from those hidden samples. In addition to this project level access control, there is also a higher Land level access control. To configure this, select Manage | Manage User Access You will see the default is for the standard users group to have Read/Search access (amongst others). Without this basic access level, a user s project level access becomes irrelevant, as they won t be able to access the Land (it will not be listed under the Select Land menu). Publish Array Genotypes to a GeneticsLand Loading data into a GeneticsLand is done through publishing procedures that are optimized to be multi-threaded, assuming these datasets may be very large. There are several procedures available for different data types (sequencing, non-sequencing, imputed allele doses, association results) and formats (VCF, PLINK, IMPUTE2, etc. ). Following the logical experimental workflow, we will first publish the assayed genotypes. In the tutorial dataset, these are from a genotype array in PLINK format. From the Land tab, select Tools | Publish To Land : Select the tutorial Land , set Data type to BED and Job number to 4 (or higher if your server can handle more than 4 parallel threads). For File , Browse to the downloaded Callset_2016-05-26.bed file. We won t specify a Sample File here (this is an option to allow adding Sample Meta Data while publishing, but we have already done this). Note Note: The File Browser will display Array Server locations,so you either need to upload the data to your Array Server folder, or navigate to a network drive location with the data. For the Panel , you would normally select the array that was used to generate the data, so that its annotations can be used to resolve the alleles to VCF convention. However, this tutorial dataset is synthesized and not from any particular array, so you should instead select the option. This option assumes the alleles are already resolved to VCF convention and reads the REF/ALT designations from the variant ID in the PLINK bim file (IDs are CHROM:POS:REF:ALT). Tick the box to automatically generate variant annotation . In the SampleID Mapping section, note that the sample IDs have been populated from the PLINK fam file. Specifically, they are the IIDs (second column). The data will be published using these IDs as their primary sample identifiers, which is used to join to the Sample MetaData we added above. The FIDs (first column of fam file) will be read and stored for future exports of the data to PLINK format, but otherwise won t be visible in the Land. In some cases, the SampleIDs extracted from the file are not the IDs you want used for the Land, for example, if you determined in the prior step when adding Sample MetaData that some of these IDs conflict with samples that already have data in the Land. You can load a mapping file containing two columns (column 1: Original Sample ID; column 2: Land Sample ID), either from a local file, or from the server. If you use the local Load option, the preview will display the contents of the file, NOT the effective mapping. For example, below we have only included the first two samples in the mapping file (all other samples in the PLINK dataset will be loaded using their IID). However, note the typo in the first sample (the extra a at the end). This means the Plate1008_Well63 sample will be loaded as-is without any mapping. For this tutorial, it is not necessary to specify any mapping as these IDs are sufficiently unique. Click the Send to Queue button to submit the job. After clicking Send To Queue, you will be taken to the ServerJobs tab under the Server tab to see the status of the publish job. Note, these jobs are multi-threaded (per the specified Job number ), so to avoid disk IO issues, only one publish job per server will run at a time. If another publish job is already running, you will see the status of your job as InQueue . If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if higher). The Server Job Status should be Finished , and if you scroll towards the bottom of the log, you should see a section like: Where the last line indicates the number of samples that have been published. You can also confirm by logging off the server and re-connecting. Then re-open the Land, and in the default Sample Distribution view in the Sample tab on the left, expand the Data Availability attributes to see that there are now 870 samples with ArraySnp data. Export Array Genotypes from a GeneticsLand In the next section, you will import a set of imputed dose data pre-generated from the tutorial dataset, but only using a subset of the output data. If you wished to generate the full dataset, or wanted to perform GWAS on other data in GeneticsLand, you can follow the steps in this section to export GeneticsLand data. Otherwise, you can skip ahead to the next section. We are going to export a subset of the genotypes that we just published to PLINK format, so that we can run a GWAS on these data. First, create a Sample Set containing the samples you wish to export for analysis. Return to the Sample Distribution view by opening the Land (if not already open) and clicking on the Select View button to select the Samples View , under the Overview heading. Use the Sample attributes on the left to filter to STUDY005 , then click on Create SampleSet : Select Create Sample Set From Filter and click OK . Enter STUDY005 as the Name and STUDY as the Tag , then click Upload . Now the samples in STUDY005 can be exported as one group. SampleSets are a convenient and powerful way to sub-group Land Data for analysis. To export the STUDY005 data for GWAS analysis, in the Land tab, select Tools | Export From Land : Select the tutorial Land , leave Output as Plink BED , and set Data type to Genotyped Data , which will exclude any imputed allele doses or genotypes from sequencing. Browse to a location and give a name to the Output file . For the Variants , leave the All variants option selected. The other options allow you to Browse to a file containing a list of variants, genes, or regions. For the Samples , switch to the SampleSet and then Choose the set just created ( STUDY | STUDY005 ). The Selected samples option allows you to Browse to a file containing a list of sample IDs. Untick the box to Infer RS IDs from the variant definitions (rs IDs are not needed for GWAS) but leave the box ticked for Remove fully missing variants (these will have call rate of 0 in the selected samples, so are of no value for GWAS). You can leave the Dose to genotype threshold at 0.5 and the R2 cutoff at 0. The default dose to genotype threshold will convert all dosage values to a genotype. The R2 cutoff is the imputation quality threshold. Set to 0 to export everything. Set the Job number to 4 (or 64 if your Array Server uses a cluster) and click the Send To Queue button to start the job. You will again be taken to the ServerJobs tab under the Server tab to see the status of the export job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (5 to 10 minutes). The Status should be Finished . You can also confirm that the expected number of samples were exported by navigating to the PLINK fam file and counting the lines it should be 412. Publish Imputed Allele Doses to a GeneticsLand GeneticsLand can also contain imputed dose data, such as those that would be calculated by running Array Studio GWAS functions (see the GWAS tutorial for further guidance). The tutorial dataset contains a subset of imputed dose data from the tutorial GeneticsLand data, but you could run the full genotype data from the previous section through the Array Studio GWAS pipeline for additional practice. In order for the data underlying association results to be explorable in the Land, we need to add the imputed allele doses that were analyzed to generate the results. The tutorial imputed data were generated by the minimac imputation module in Array Studio, and thus the imputed allele doses are in 3 VCF files autosomes, male chrX and female chrX (thinned to ~1 million variants for the purposes of this tutorial). From the Land tab, select Tools | Publish To Land : Select the tutorial Land , set Data type to VCF (imputed) and Job number to 4 (or higher if you have a server than can handle more than 4 parallel threads). For File , Browse to the downloaded autosome VCF file ( ThinnedAuto.vcf.gz ). In the SampleID Mapping section, note the joint FID->IIDs in the VCF file have automatically be truncated to just the IID. This ensures that the data will be added to the Land under the same ID as the array genotypes from which it was derived. Unlike when initially publishing the array genotypes, where we first added the Sample MetaData to ensure no sample ID conflicts, here we are intentionally publishing the data under the same IDs. Because they are different data types (genotypes vs imputed doses), they are both stored in the Land (one will not overwrite the other), and you will be able to visualize them separately. Click the Send to Queue button to submit the job. You will be taken to the ServerJobs tab under the Server tab to see the status of the publish job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The Status should be Finished and if you scroll towards the bottom of the log, you should see a section like: Where the last line indicates the number of samples that have been published. Note, this is less than the 412 that were exported, due to the pre-GWAS QC, which excluded some samples. You can also confirm these imputed allele doses were published by logging off the server and re-connecting. Then re-open the Land and in the default Sample Distribution view in the Sample tab on the left, expand the Data Availability attributes to see there are now 333 samples with Imputed Snp Dose data. Repeat this process with the remaining two VCF files (ThinnedFchrX.vcf.gz and ThinnedMchrX.vcf.gz). Note, even though we are publishing the same data type (imputed doses) for the same sample IDs, these operations won t overwrite any data already in the Land, because these VCF files contain entirely new variants ( i.e. those on chromosome X, which were not present in the ThinnedAuto.vcf.gz file). Publish Genetic Associations to a GeneticsLand In addition to the subject-level genetic data generated from DNA samples, GeneticsLand can also host and present genetic association results. For this step, we are assuming a genotype-phenotype association analysis has been conducted with the Association module in Array Studio, and the results are already in the appropriate GTT format; these data can be found in the tutorial dataset. From the Land tab, select Tools | Publish To Land : Select the tutorial Land , set Data type to Association Report and Job number to 4 (or higher if your server can handle more parallel threads). For File , Browse to the downloaded GTT file (fev1 study005.gtt). In the SampleID Mapping section, note the file name has been used as the Sample ID . For association results, Sample ID is the name or label for the result set. This is what will be searchable and displayed in the Land, so ensure it is sufficiently descriptive. For example, if you have analyzed the same dataset multiple times and have multiple result sets ( e.g. once with smoking status as a covariate and once without), you will need to ensure each association file has a unique name, and you will want the names to be descriptive enough to distinguish between them when you see them in the Land. You have the same options for mapping from the default file name to a new value as described above when publishing the array genotypes. For this tutorial, it is ok to leave the Sample ID as-is. Click the Send to Queue button to submit the job. You will be taken to the ServerJobs tab under the Server tab to see the status of the publish job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The Status should be Finished , and you can confirm the set was published by starting to type the name into the search bar at the top of the Land tab to see the association type record found: Add Phenotype Data to a GeneticsLand In order to aid in the interpretation of the genetic data in GeneticsLand and explore the data underlying a genetic association result, the Land will host and present sample attributes (metadata). There are currently four ways to manage phenotype or other sample measures in a GeneticsLand: Sample Meta Data (metadata categories that can be viewed for all samples in GeneticsLand) Sample Set Meta Data (metadata categories attached only for a selected subset of samples) Clinical Data (extended sample metadata for clinical variables) Manage Project Meta Data (association sets can be tied to a project and metadata organized by Project Name) Our objective here is to add the phenotype data that were used for the GWAS whose results we just published. These types of measures are typically not added to the Sample MetaData , as they can be sparse ( i.e. you may have lung function measures for a respiratory study but not for a neurology one). The Clinical Data system is likely the best location for these types of data, as it is shared by all users like Sample MetaData (pursuant to access controls), while a Sample Set s access can be managed by its creator. However, for the sake of simplicity in this tutorial, we will use the Sample Set MetaData . From the Land tab, select Manage | Samples | Manage Sample Sets : We will use the same sample set created to export the array genotypes. Select STUDY005 and then click on the edit button: Switch to the MetaData tab and select Load tab delimited file : Browse to and select the phenotypes.txt file, then click the Update button to finish. You may now close the SampleSets tab by clicking the X : And if you close the other tabs and re-open the Land to the default Sample Distribution view (allowing the Land to refresh with your SampleSet data), you will now see the phenotypes listed under the Sample Set heading: Note, we are using the term phenotype loosely, as we have also included other sample measures like smoking status, drug treatment, and consent, which are relevant to exploring and interpreting the data and results.","title":"Adding Data to GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#adding-data-to-geneticsland","text":"In this section, you will go through the basic procedures for adding data to your GeneticsLand (Sample Metadata, control access to patient information, genotypes/imputed doses, associations, and phenotypes), as well as how to export these different data to Array Studio to perform analyses such as GWAS.","title":"Adding Data to GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#add-sample-metadata-to-a-geneticsland","text":"To avoid conflicting sample IDs, and to ensure access controls are in-place before restricted genetic data are added, it is considered best practice to register samples in the Sample MetaData table before adding their genetic data into the Land. From the Land tab, select Manage | Samples | Manage Sample Meta Data Take note of the number of samples (rows) currently in the table. Following this tutorial, the Land will be empty at this point so there will be 0 rows. Click the Add/Replace button: Click Load from tab delimited file and select the SampleMetaData.txt file from the tutorial dataset. Preview the metadata to ensure that you selected the proper file, then click the OK button to finish. Note the new number of samples it should be the sum of the prior number and the number of new samples being registered (0 + 870 = 870 in this case). If it is less, then one or more of the new sample IDs has conflicted with an existing sample ID, which means that the old metadata were over-written for the conflicting sample(s). If sample metadata were overwritten, the simplest solution is to map the new samples to new unique IDs. First, restore the appropriate metadata for the existing samples, as necessary (load from the metadata text files you had previously used). Then, re-register the new samples with new IDs. Use a mapping file when publishing the new samples data to the Land (next steps) to ensure they are published with the new IDs and don t collide with the existing samples and their data. Click the X in the MetaData tab to close it, and repeat with any other open tabs. Re-select the Land using the Select Land button, and the Sample Distribution view should now be populated: This view shows the number of samples by project, colored by sex, as indicated in the legend on the right. These groupings are the defaults (PrimaryGrouping and SecondaryGrouping) as configured when the Land was created. You can change the primary grouping using the Grouping button at the top. You can change the secondary grouping and make other adjustments to the chart by switching to the Task tab on the right. Note the sample attributes under the Sample tab on the left, which can be used to filter the view. All of these come from the Sample MetaData that you just loaded. The exception is the Data Availability attributes, which displays the amount of genetic data in the Land (currently none, as we haven t added any yet). Using your mouse to select a component of the chart (the males of STUDY009 here) will display the details of the relevant data points (the Sample MetaData in this case) below the chart: These chart configuration, filtering, and selecting mechanisms will generally behave the same across all views in the Land. For more detailed explanations of how to group/filter/alter Land Views, please see the OncoLand tutorial.","title":"Add Sample MetaData to a GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#control-data-access-in-geneticsland","text":"If there are any restrictions on access to data for certain projects, it is best to configure this before adding the genetic data for those projects. Select Manage | Manage Project Access : You will see the default access level is Read for the standard users group (includes all users) across all GeneticsLand projects. You can adjust the access for each project at the User or User group level. Users with Read access (either individually or through a user group) will be able to see all data for samples in that project. Note, samples are mapped to a project using the ProjectName column in the Sample MetaData table, which is a key column. This is why we had to register the samples in the MetaData before configuring this access control. The Project level frequency access is a restricted access level that will hide all sample level data (like the MetaData that we just loaded, and the genotype data we will add in the next step) but expose allele frequencies and other aggregate summary statistics calculated from those hidden samples. In addition to this project level access control, there is also a higher Land level access control. To configure this, select Manage | Manage User Access You will see the default is for the standard users group to have Read/Search access (amongst others). Without this basic access level, a user s project level access becomes irrelevant, as they won t be able to access the Land (it will not be listed under the Select Land menu).","title":"Control Data Access in GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#publish-array-genotypes-to-a-geneticsland","text":"Loading data into a GeneticsLand is done through publishing procedures that are optimized to be multi-threaded, assuming these datasets may be very large. There are several procedures available for different data types (sequencing, non-sequencing, imputed allele doses, association results) and formats (VCF, PLINK, IMPUTE2, etc. ). Following the logical experimental workflow, we will first publish the assayed genotypes. In the tutorial dataset, these are from a genotype array in PLINK format. From the Land tab, select Tools | Publish To Land : Select the tutorial Land , set Data type to BED and Job number to 4 (or higher if your server can handle more than 4 parallel threads). For File , Browse to the downloaded Callset_2016-05-26.bed file. We won t specify a Sample File here (this is an option to allow adding Sample Meta Data while publishing, but we have already done this). Note Note: The File Browser will display Array Server locations,so you either need to upload the data to your Array Server folder, or navigate to a network drive location with the data. For the Panel , you would normally select the array that was used to generate the data, so that its annotations can be used to resolve the alleles to VCF convention. However, this tutorial dataset is synthesized and not from any particular array, so you should instead select the option. This option assumes the alleles are already resolved to VCF convention and reads the REF/ALT designations from the variant ID in the PLINK bim file (IDs are CHROM:POS:REF:ALT). Tick the box to automatically generate variant annotation . In the SampleID Mapping section, note that the sample IDs have been populated from the PLINK fam file. Specifically, they are the IIDs (second column). The data will be published using these IDs as their primary sample identifiers, which is used to join to the Sample MetaData we added above. The FIDs (first column of fam file) will be read and stored for future exports of the data to PLINK format, but otherwise won t be visible in the Land. In some cases, the SampleIDs extracted from the file are not the IDs you want used for the Land, for example, if you determined in the prior step when adding Sample MetaData that some of these IDs conflict with samples that already have data in the Land. You can load a mapping file containing two columns (column 1: Original Sample ID; column 2: Land Sample ID), either from a local file, or from the server. If you use the local Load option, the preview will display the contents of the file, NOT the effective mapping. For example, below we have only included the first two samples in the mapping file (all other samples in the PLINK dataset will be loaded using their IID). However, note the typo in the first sample (the extra a at the end). This means the Plate1008_Well63 sample will be loaded as-is without any mapping. For this tutorial, it is not necessary to specify any mapping as these IDs are sufficiently unique. Click the Send to Queue button to submit the job. After clicking Send To Queue, you will be taken to the ServerJobs tab under the Server tab to see the status of the publish job. Note, these jobs are multi-threaded (per the specified Job number ), so to avoid disk IO issues, only one publish job per server will run at a time. If another publish job is already running, you will see the status of your job as InQueue . If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if higher). The Server Job Status should be Finished , and if you scroll towards the bottom of the log, you should see a section like: Where the last line indicates the number of samples that have been published. You can also confirm by logging off the server and re-connecting. Then re-open the Land, and in the default Sample Distribution view in the Sample tab on the left, expand the Data Availability attributes to see that there are now 870 samples with ArraySnp data.","title":"Publish Array Genotypes to a GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#export-array-genotypes-from-a-geneticsland","text":"In the next section, you will import a set of imputed dose data pre-generated from the tutorial dataset, but only using a subset of the output data. If you wished to generate the full dataset, or wanted to perform GWAS on other data in GeneticsLand, you can follow the steps in this section to export GeneticsLand data. Otherwise, you can skip ahead to the next section. We are going to export a subset of the genotypes that we just published to PLINK format, so that we can run a GWAS on these data. First, create a Sample Set containing the samples you wish to export for analysis. Return to the Sample Distribution view by opening the Land (if not already open) and clicking on the Select View button to select the Samples View , under the Overview heading. Use the Sample attributes on the left to filter to STUDY005 , then click on Create SampleSet : Select Create Sample Set From Filter and click OK . Enter STUDY005 as the Name and STUDY as the Tag , then click Upload . Now the samples in STUDY005 can be exported as one group. SampleSets are a convenient and powerful way to sub-group Land Data for analysis. To export the STUDY005 data for GWAS analysis, in the Land tab, select Tools | Export From Land : Select the tutorial Land , leave Output as Plink BED , and set Data type to Genotyped Data , which will exclude any imputed allele doses or genotypes from sequencing. Browse to a location and give a name to the Output file . For the Variants , leave the All variants option selected. The other options allow you to Browse to a file containing a list of variants, genes, or regions. For the Samples , switch to the SampleSet and then Choose the set just created ( STUDY | STUDY005 ). The Selected samples option allows you to Browse to a file containing a list of sample IDs. Untick the box to Infer RS IDs from the variant definitions (rs IDs are not needed for GWAS) but leave the box ticked for Remove fully missing variants (these will have call rate of 0 in the selected samples, so are of no value for GWAS). You can leave the Dose to genotype threshold at 0.5 and the R2 cutoff at 0. The default dose to genotype threshold will convert all dosage values to a genotype. The R2 cutoff is the imputation quality threshold. Set to 0 to export everything. Set the Job number to 4 (or 64 if your Array Server uses a cluster) and click the Send To Queue button to start the job. You will again be taken to the ServerJobs tab under the Server tab to see the status of the export job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (5 to 10 minutes). The Status should be Finished . You can also confirm that the expected number of samples were exported by navigating to the PLINK fam file and counting the lines it should be 412.","title":"Export Array Genotypes from a GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#publish-imputed-allele-doses-to-a-geneticsland","text":"GeneticsLand can also contain imputed dose data, such as those that would be calculated by running Array Studio GWAS functions (see the GWAS tutorial for further guidance). The tutorial dataset contains a subset of imputed dose data from the tutorial GeneticsLand data, but you could run the full genotype data from the previous section through the Array Studio GWAS pipeline for additional practice. In order for the data underlying association results to be explorable in the Land, we need to add the imputed allele doses that were analyzed to generate the results. The tutorial imputed data were generated by the minimac imputation module in Array Studio, and thus the imputed allele doses are in 3 VCF files autosomes, male chrX and female chrX (thinned to ~1 million variants for the purposes of this tutorial). From the Land tab, select Tools | Publish To Land : Select the tutorial Land , set Data type to VCF (imputed) and Job number to 4 (or higher if you have a server than can handle more than 4 parallel threads). For File , Browse to the downloaded autosome VCF file ( ThinnedAuto.vcf.gz ). In the SampleID Mapping section, note the joint FID->IIDs in the VCF file have automatically be truncated to just the IID. This ensures that the data will be added to the Land under the same ID as the array genotypes from which it was derived. Unlike when initially publishing the array genotypes, where we first added the Sample MetaData to ensure no sample ID conflicts, here we are intentionally publishing the data under the same IDs. Because they are different data types (genotypes vs imputed doses), they are both stored in the Land (one will not overwrite the other), and you will be able to visualize them separately. Click the Send to Queue button to submit the job. You will be taken to the ServerJobs tab under the Server tab to see the status of the publish job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The Status should be Finished and if you scroll towards the bottom of the log, you should see a section like: Where the last line indicates the number of samples that have been published. Note, this is less than the 412 that were exported, due to the pre-GWAS QC, which excluded some samples. You can also confirm these imputed allele doses were published by logging off the server and re-connecting. Then re-open the Land and in the default Sample Distribution view in the Sample tab on the left, expand the Data Availability attributes to see there are now 333 samples with Imputed Snp Dose data. Repeat this process with the remaining two VCF files (ThinnedFchrX.vcf.gz and ThinnedMchrX.vcf.gz). Note, even though we are publishing the same data type (imputed doses) for the same sample IDs, these operations won t overwrite any data already in the Land, because these VCF files contain entirely new variants ( i.e. those on chromosome X, which were not present in the ThinnedAuto.vcf.gz file).","title":"Publish Imputed Allele Doses to a GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#publish-genetic-associations-to-a-geneticsland","text":"In addition to the subject-level genetic data generated from DNA samples, GeneticsLand can also host and present genetic association results. For this step, we are assuming a genotype-phenotype association analysis has been conducted with the Association module in Array Studio, and the results are already in the appropriate GTT format; these data can be found in the tutorial dataset. From the Land tab, select Tools | Publish To Land : Select the tutorial Land , set Data type to Association Report and Job number to 4 (or higher if your server can handle more parallel threads). For File , Browse to the downloaded GTT file (fev1 study005.gtt). In the SampleID Mapping section, note the file name has been used as the Sample ID . For association results, Sample ID is the name or label for the result set. This is what will be searchable and displayed in the Land, so ensure it is sufficiently descriptive. For example, if you have analyzed the same dataset multiple times and have multiple result sets ( e.g. once with smoking status as a covariate and once without), you will need to ensure each association file has a unique name, and you will want the names to be descriptive enough to distinguish between them when you see them in the Land. You have the same options for mapping from the default file name to a new value as described above when publishing the array genotypes. For this tutorial, it is ok to leave the Sample ID as-is. Click the Send to Queue button to submit the job. You will be taken to the ServerJobs tab under the Server tab to see the status of the publish job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The Status should be Finished , and you can confirm the set was published by starting to type the name into the search bar at the top of the Land tab to see the association type record found:","title":"Publish Genetic Associations to a GeneticsLand"},{"location":"tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#add-phenotype-data-to-a-geneticsland","text":"In order to aid in the interpretation of the genetic data in GeneticsLand and explore the data underlying a genetic association result, the Land will host and present sample attributes (metadata). There are currently four ways to manage phenotype or other sample measures in a GeneticsLand: Sample Meta Data (metadata categories that can be viewed for all samples in GeneticsLand) Sample Set Meta Data (metadata categories attached only for a selected subset of samples) Clinical Data (extended sample metadata for clinical variables) Manage Project Meta Data (association sets can be tied to a project and metadata organized by Project Name) Our objective here is to add the phenotype data that were used for the GWAS whose results we just published. These types of measures are typically not added to the Sample MetaData , as they can be sparse ( i.e. you may have lung function measures for a respiratory study but not for a neurology one). The Clinical Data system is likely the best location for these types of data, as it is shared by all users like Sample MetaData (pursuant to access controls), while a Sample Set s access can be managed by its creator. However, for the sake of simplicity in this tutorial, we will use the Sample Set MetaData . From the Land tab, select Manage | Samples | Manage Sample Sets : We will use the same sample set created to export the array genotypes. Select STUDY005 and then click on the edit button: Switch to the MetaData tab and select Load tab delimited file : Browse to and select the phenotypes.txt file, then click the Update button to finish. You may now close the SampleSets tab by clicking the X : And if you close the other tabs and re-open the Land to the default Sample Distribution view (allowing the Land to refresh with your SampleSet data), you will now see the phenotypes listed under the Sample Set heading: Note, we are using the term phenotype loosely, as we have also included other sample measures like smoking status, drug treatment, and consent, which are relevant to exploring and interpreting the data and results.","title":"Add Phenotype Data to a GeneticsLand"},{"location":"tutorials/GeneticsLand/Delete_your_GeneticsLand/","text":"Delete your GeneticsLand You may wish to keep the Land you have created for this tutorial for additional training and testing. The datasets that were published were relatively small and will not consume much disk space on the server. When you are done with your Land and want to delete it, from the Tools menu, select Delete Land Confirm it is your Land that is selected, leave the Delete all data types option selected and click OK . You will be prompted to confirm you want to delete the Land. If you are sure, select Yes . Congratulations! You are done with this tutorial, which represents just a piece of what OmicSoft Lands are capable of. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Delete your GeneticsLand"},{"location":"tutorials/GeneticsLand/Delete_your_GeneticsLand/#delete-your-geneticsland","text":"You may wish to keep the Land you have created for this tutorial for additional training and testing. The datasets that were published were relatively small and will not consume much disk space on the server. When you are done with your Land and want to delete it, from the Tools menu, select Delete Land Confirm it is your Land that is selected, leave the Delete all data types option selected and click OK . You will be prompted to confirm you want to delete the Land. If you are sure, select Yes . Congratulations! You are done with this tutorial, which represents just a piece of what OmicSoft Lands are capable of. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Delete your GeneticsLand"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/","text":"Explore Your Data in GeneticsLand Review Genetic Association Results in a GeneticsLand After all that setup, we are now ready to explore the data in your GeneticsLand. The tutorial dataset reflects a respiratory GWAS assessing genetic association with the FEV1 (Forced Expiratory Volume in One Second) endpoint. The primary access point for exploring the data in the Land will be the search box at the top of the Land tab. Start typing the name of the genetic association result set that we just published ( fev1 study005 ), then select the matching entry from the drop-down box: Association Annotation View When you search an association, five views are available. The Association Annotation view is the fully annotated table of all association results. The primary use case for this view is to query (filter) all results by variant attributes ( i.e. all putatively functional coding variants). Note, these annotations were generated when the association results (GTT file) were published, and thus may be slightly out of date if new annotations have been released since then. For all other views in the Land, the most current annotations will be dynamically joined. The annotation sources were defined in the configuration when the Land was created (VariantClassifiers=ClinVar_20170501, FunctionalMutation_20170501\u2026). The specific classifiers we used for this tutorial are provided by OmicSoft. OmicSoft support ( support@omicsoft.com ) can assist you with building custom classifiers if you have proprietary or licensed annotations you wish to include. You can use the variant attributes in the Search Result tab on the left to filter. Switch to the Task tab on the right and click on Specify Columns to configure which columns to display (by default, they are all displayed): If you have filtered to a smaller number of rows (<2000 rows), new buttons will appear at the top to enable sorting and searching of the table (you can also right click on a column header to sort): Once you have configured the table as you want, you can use the three buttons at the top-left to either open in a text editor, Excel, or save to a file, including an OmicSoft object file (.osobj) that can be opened in an Array Studio project ( Analysis tab) for further analysis. Alternatively, you can save the view to a file that can be re-opened later ( File | Save View ) or share it for future access by you or others ( Share | Share Land View ). All of these options for configuring, exporting, and saving the view are common across all tabular views in the Land, and similar options are available for graphical views. Region Plot View Use the Select View button to switch to the Region Plot view: This view will show a Manhattan plot of the top 10,000 most significant results by p-value. With your mouse, click and drag to select the peak over chr15. This defines the center for the region plot. Note, the genome plot will disappear as the region plot is displayed. Click the Show Overview button to re-display it (and Hide Overview to hide it again). In addition to selecting points from the genome plot, you can also go to a specific variant, gene, or region using the Select Region button: This also allows you to set the region length (500 kb is the default). Note, specifying a variant (or coordinate using the Region option) does not set that as the key variant for calculating LD. The pairwise LD is always calculated relative to the variant in the region with the lowest p-value. Back in the region plot, you can choose to display or hide the pairwise LD matrix by selecting or de-selecting pairwise LD . Also in the region plot, you can use the LD Source and LD Measurement menus to adjust those values. As the LD Sources are from 1000 Genomes, which are shallow short read data that have been statistically phased, these data are subject to switch errors, and the R2(Haplotype) may be inaccurate. Looking at the default 1000G.EUR LD Source with R2 as the LD Measurement , we see that many of the variants passing the genome wide significance threshold (PValue < 5E10 -8) appear to be in LD and thus likely represent a single causal variant. However, given the extreme significance of many of these associations (note the scale of the -Log10(PValue) Y axis), there may be additional independent signals that are less significant but still pass the genome wide PValue threshold. This Region Plot view is based on the OmicSoft Genome Browser, so you can configure display of various genomic annotation tracks. These options are available in the Task tab on the right, where you can Manage the existing tracks and Add Tracks from a variety of sources. This tab also has the option to Export the plot to an image file. There are three remaining views available under Select View . These three views are Top Hits views and the results displayed are user defined by the TopHitsN parameter. The TopHitsN parameter controls how many association results with the most significant p-values to display in these views. The default is 10,000. The Top Hits (Genome Plot) view is a variation of what we have already seen. It is the same genome plot as shown in the Region Plot view, except instead of being used to set the center of the region plot (the primary component of the Region Plot view), the genome plot itself will be the primary component. The Top Hist (QQ plot) displays the negative logarithm of the observed (x-axis) and the expected (y-axis) P value for each SNP. This plot can be used to investigate confounders and identify true associations. Both of these views are fully interactive, such that you can use your mouse to select from the views, and give you options to explore the most significant results (filter on variant attributes, select to see details, etc .) and configure the charts. The Top Hits (Table) will be the fully annotated table of those same 1,000 most significant results. The output here is similar to the original Association Annotation view, except that the most current annotations will be dynamically joined. Select this view. To see which specific annotation versions are being reported, use the Options button in the Search Result tab on the left to select Show Annotation Sources : This same classifier listing will be included as a header if you Open as Text file The first column in the Top Hits (Table) view is the Snp ID , which contains a link to the variant s views (as if you had searched for the variant from the search box at the top). Right click on the PValue column to Sort Descending (the sort is based on the -log(PValue), so larger values are more significant). Then click on the Snp ID for the first row ( rs475535 ) and continue to the next section to learn about the data and views available for this highly-significant variant. Review Variant Knowledge in GeneticsLand Having searched for rs475535, the default view that is returned is the Allele Frequency plot. Like the Sample Distribution view, this is also grouped based on the PrimaryGrouping=ProjectName defined when the Land was created, and can be adjusted using the Grouping button at the top. Note there are actually two charts here, the first ( Genotyped ) being calculated from all the non-sequencing based genotypes that are in the Land (the array genotypes we published). Scroll down to see the next chart ( Imputed ), which is calculated from all the imputed allele doses in the Land ( i.e. the ones we published from the GWAS). In addition to the frequency being represented on the X axis, the carrier count is also displayed to the right of the bar in parentheses. Another view available is Genotype Frequency , which is configured similarly to the Allele Frequency plot. The number displayed to the right of each bar is still the carrier count (sum of heterozygotes and homozygote ALT). To get the count of each of these sub-groups, click on the View Filtered Table button at the bottom left to see the counts for each chart element. There is also a special view named Case Control Allele Frequency , which is available because at least one of the columns in our phenotype file was specified as a case/control value: Switch to this view under the Select View menu and you will see that instead of being grouped by Project Name , the allele frequencies are now grouped by the case/control status for all three phenotypes that were specified as case/control: The final view under the Summary heading in the Select View menu ( SNP Annotation ) is the table of variant annotations. These will match what were reported in the Top Hits (Table) view when we were reviewing the association results. Back in the Select View menu, select the All SNPs option under the Genotypes heading. This will display a table of all genotypes in the Land (those we published). Note the Data Type column, which will indicate if the genotypes came from sequencing ( Sequenced ), non-sequencing ( Genotyped ), or imputation ( Imputed ). You can filter on this column, or there are dedicated views for each of these under the same Genotypes heading in the Select View menu. This is the first view we have encountered with individual level data; these data can be hidden, depending on the project level access controls we configured before publishing the genetic data. If a user only had the Project level frequency access , they would have seen all the summary level information in the prior views (allele and genotype frequencies and counts) but would not see the corresponding genotypes in this table. Select the last view under the Genotypes heading in the Select View menu, Covariate View : This view will plot each relevant numeric sample attribute by genotype. Note that there are three charts (one numeric column from the Sample MetaData table and two from the phenotypes we added to the Sample Set MetaData ). There are not separate charts for each genotype source (sequencing, non-sequencing, imputed). Imputed doses are converted to genotypes and plotted with all other genotypes. Scroll down to the FEV1 chart, which was the endpoint analyzed for the association results we were just reviewing. We can clearly see a relationship between FEV1 and genotype. From the Task tab on the right, under Customize , select Show Summary Information to add a PValue Note, this does not match the PValue reported in the association results we were just exploring (1.00E-325) for a number of different reasons. The two primary reasons being the statistical model used for the association analysis ( i.e. it included covariates) and the samples included in the association analysis (this view considers all samples for which there is a genotype and FEV1 measure in the Land, while the association analysis only included a subset of samples). We can filter the results using the Search Result tab on the left to try to better emulate the association analysis. For example, we only analyzed STUDY005, so we can filter to that under ProjectName (note, there is no change, as we only added these phenotype measures for STUDY005, so the samples from other projects are already missing). Next we can filter to those which remained in the analysis after consent check under Sample Set | STUDY005 | GxConsent | Disease . This filtering did cause a change so the view defaulted back to the first chart scroll down to FEV1 again and note the PValue is now closer to the one reported in the association results. Another potential source of different sample content could be the project level access controls. You can select points on the chart to display the sample details below including Sample ID. For example, select the highest FEV1 values for the AA genotype: Since this view could potentially expose sample identity, samples from any project where you only have Project level frequency access will be excluded from the view, and the PValue calculation will not take them into account. Our initial interest in this variant was piqued by it being associated with our endpoint from our association analysis. Let s look at what other endpoints it may be associated with. From the Select View menu, select GRASP2 Table under Association : This displays a table of all the records in the GRASP database (version 2) for this variant. GRASP is a collection of all published GWAS results with Pvalue < 0.05, however, as most publications only include genome wide significant results using a much more stringent PValue threshold, it should generally be considered to only contain top hits. By default, this table is sorted by PValue, so the most significant results are at the top. You can see the phenotype and link to the source paper. Here we see a potential eQTL and three likely insignificant findings. Nothing related to our lung function endpoint (not surprising given our GWAS was simulated). Next we can look at the Curated Studies (Table) view under the Select View menu under the Association heading: This is similar to the GRASP2 Table view, except the source is all the association results that have been published to the Land, and as such will be complete (no PValue thresholds applied). In our case, we have only published the results from our single GWAS, so only see that one record returned. Review Gene Knowledge in GeneticsLand If you recall from the SNP Annotation view for rs475535, this variant was in the IGDCC3 gene, so let s search that from the box at the top: The default view is All SNPs . This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association Top Hits (Table) view, the RS ID column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the Source attribute in the Search Result tab on the left: The Coding SNPs view under the same Variants heading will return the exact same columns but remove the variants (rows) that are non-coding. Under the Select View menu, note the first section of views are divided by data source ( Sequenced , Genotyped for non-sequencing assays, and Imputed ). Let s switch to the corresponding Gene Summary view for Imputed data: If we switch to the Variant Annotation tab on the left, we see how the putatively functional variants were selected, and can modify this classification to update the chart If we switch to the Genome Browser view, we can see these data summarized across the gene: We see the variants in this gene plotted along the genome colored by their classification (per the Legend on the right) where the height and dot size correspond to the allele frequency. We see two tracks, one for All (meaning all samples) and one for STUDY005 because the grouping is still the PrimaryGrouping=ProjectName we defined when creating the Land. As we currently only have imputed data from this one project published, the grouping is uninformative. Let s switch to grouping by RACE and ETHNIC using the Grouping button at the top: Now, in addition to the All track, we see five new tracks grouped by the RACE and ETHNIC values from the Sample MetaData : Note, some of the longer labels are truncated, right click on the chart and select Organize Groups to see the full listing and optionally re-sort. As a genome browser view, you can configure the tracks and add new ones using the Task tab on the right. We can also look at the allele frequency in a table view for our selected grouping (RACE+ETHNIC) using the Grouped Allele Frequency view under the Select View menu. Here we see six Allele Frequency columns. The first five on the left correspond to the grouping, which is still set as RACE and ETHNIC . The last one on the right is the overall frequency considering all samples including those to which you don t have access per the project level access controls. As long as you have Project level frequency access , the samples from that project will be included in calculating the allele frequencies reported here. However, if you switch to a view that reports individual level information like the Dose Matrix , you would not see the samples from those projects for which you only have Project level frequency access : This view is a table of the imputed ALT allele doses with samples as rows and variant as columns. The column headers take the form CHROM:POS:REF:ALT , so you know, for example, that the first column contains doses of the A allele. There is also the special Case Control Allele Frequency view, where the grouping will be based on the three case/control values that were specified in the phenotype file: We can also look at the variant annotations in a table view. In the Select View menu, under Variants , select All SNPs This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association Top Hits (Table) view, the RS ID column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the Source attribute in the Search Result tab on the left: The Coding SNPs view under the same Variants heading will return the exact same columns but remove the variants (rows) that are non-coding. The final two views in the Select View menu, GRASP2 Table and Curated Studies (Table) under the Association heading, are identical to what we saw when exploring rs475535, except they will contain the list of associations for every variant in the All SNPs view (all variants in the gene). Review Knowledge for a Region or Variant / Gene List in GeneticsLand In addition to searching for one gene, you can also search for a region (up to 1 Mb) using the form CHROM:START-END in the search box. For example, if we wanted to search 15 bases up and downstream of rs475535, we could enter 15:65632700-65632730 . You will have all the same views as when looking at the search results for the IGDCC3 gene with one additional Genes in Region view under the Variants heading which will show a list of all genes mapping to this region. You can click on the link in the Gene Name column to search that gene as if you had typed it into the search bar. You can also Search Multiple Variants or genes by clicking on the drop down arrow next to the green Search arrow at the top: Note the instructions above the entry box for formatting the list of variants. For the Search Multiple Genes option, the gene symbols you enter will be checked. For example, having intentionally entered a non-existent gene BRCA56: The genes found sum in the upper right indicates only the single OPRM1 gene was found, and the Remove invalid gene symbols button at the bottom left appears. You can also create a re-usable Gene Set , analogous to a Sample Set , in that access is controlled by the creator. From the Manage menu, select Genes | Manage Gene Sets Select the Add option to create a new Gene Set Enter STUDY005 Candidate Genes for Name and STUDY005 for Tag Switch to the MetaData tab and select Load from tab delimited file to browse to the downloaded GeneList.txt file The first column must contain the gene identifier and you can specify the type of identifier with the ID type option (we are using Gene_Symbol for this example). Note, unlike when searching for multiple genes where the symbols are validated as you enter them, any erroneous identifiers here won t be reported until you try to use the Gene Set . Any additional columns are just treated as generic user notes and not used in any way. Select OK to save the Gene Set . Now you can search for this Gene Set by name in the search box at the top. Start typing the name and select the Gene Set which is found. For these multi-variant and multi-gene searches, you will get all the same views as the IGDCC3 gene search except for the Genome Browser view. Review Phenotype Knowledge in a GeneticsLand We first started exploring the data in our Land with the endpoint from our association analysis. Now let s look at some other phenotypes. Start typing psoriasis into the search box at the top and select the result for psoriasis: As a Phenotype result (as opposed to an association result, as we selected when we searched for the endpoint from our association analysis), this indicates the results are from GRASP. The default view is a genome plot of the top 1,000 results. This is identical to the Top Hits (Genome Plot) view we saw when exploring the endpoint from our association analysis except instead of the results coming from out single analysis, they are compiled across all the literature. Therefore, we are likely to see the same variant reported multiple times. For example, if you select the peak on the p arm of chromosome 6, we see the SNV at 31252925 is reported twice: Although, scrolling right to review the annotations, we see it is a common variant with MAF > 5% in all reference populations, is intergenic, has GWAVA scores indicating it has no functional effect, and HaploReg and RegulomeDB values confirming minimal regulator impact. So even though this variant was found to be associated with psoriasis in two studies, the association is likely to be driven by a variant with more functional effects in LD with this variant. We see from the Platform description that these studies used imputation, however, from the variant counts ~2 million, we can infer that these used reference haplotypes from HapMap, which only captures a fraction of the variation in the 1000 Genomes project. So, it is possible the driving variant in LD was not imputed from HapMap. We can switch to the other view, Top Hits (Table) , to explore or export these fully annotated results using the Select View menu: Note, in the GRASP data, Psoriasis is categorized under Skin-related for the Phenotype Category . And if we return to our original psoriasis search results, scrolling down to the bottom of the list, we see other psoriasis phenotypes that are likely of interest. By searching the broader Skin-related category, we can get to all of these If we filter in the Search Result tab on the left to only the psoriasis related phenotypes and select the same peak on the p arm of chromosome 6, we see that same variant at 31252925 shows up again but for slightly different phenotypes. Although, note from the PMID that these are coming from the same study (19169254), which was also one of the studies we saw when looking at the psoriasis specific results.","title":"Explore Your Data in GeneticsLand"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#explore-your-data-in-geneticsland","text":"","title":"Explore Your Data in GeneticsLand"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-genetic-association-results-in-a-geneticsland","text":"After all that setup, we are now ready to explore the data in your GeneticsLand. The tutorial dataset reflects a respiratory GWAS assessing genetic association with the FEV1 (Forced Expiratory Volume in One Second) endpoint. The primary access point for exploring the data in the Land will be the search box at the top of the Land tab. Start typing the name of the genetic association result set that we just published ( fev1 study005 ), then select the matching entry from the drop-down box:","title":"Review Genetic Association Results in a GeneticsLand"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#association-annotation-view","text":"When you search an association, five views are available. The Association Annotation view is the fully annotated table of all association results. The primary use case for this view is to query (filter) all results by variant attributes ( i.e. all putatively functional coding variants). Note, these annotations were generated when the association results (GTT file) were published, and thus may be slightly out of date if new annotations have been released since then. For all other views in the Land, the most current annotations will be dynamically joined. The annotation sources were defined in the configuration when the Land was created (VariantClassifiers=ClinVar_20170501, FunctionalMutation_20170501\u2026). The specific classifiers we used for this tutorial are provided by OmicSoft. OmicSoft support ( support@omicsoft.com ) can assist you with building custom classifiers if you have proprietary or licensed annotations you wish to include. You can use the variant attributes in the Search Result tab on the left to filter. Switch to the Task tab on the right and click on Specify Columns to configure which columns to display (by default, they are all displayed): If you have filtered to a smaller number of rows (<2000 rows), new buttons will appear at the top to enable sorting and searching of the table (you can also right click on a column header to sort): Once you have configured the table as you want, you can use the three buttons at the top-left to either open in a text editor, Excel, or save to a file, including an OmicSoft object file (.osobj) that can be opened in an Array Studio project ( Analysis tab) for further analysis. Alternatively, you can save the view to a file that can be re-opened later ( File | Save View ) or share it for future access by you or others ( Share | Share Land View ). All of these options for configuring, exporting, and saving the view are common across all tabular views in the Land, and similar options are available for graphical views.","title":"Association Annotation View"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#region-plot-view","text":"Use the Select View button to switch to the Region Plot view: This view will show a Manhattan plot of the top 10,000 most significant results by p-value. With your mouse, click and drag to select the peak over chr15. This defines the center for the region plot. Note, the genome plot will disappear as the region plot is displayed. Click the Show Overview button to re-display it (and Hide Overview to hide it again). In addition to selecting points from the genome plot, you can also go to a specific variant, gene, or region using the Select Region button: This also allows you to set the region length (500 kb is the default). Note, specifying a variant (or coordinate using the Region option) does not set that as the key variant for calculating LD. The pairwise LD is always calculated relative to the variant in the region with the lowest p-value. Back in the region plot, you can choose to display or hide the pairwise LD matrix by selecting or de-selecting pairwise LD . Also in the region plot, you can use the LD Source and LD Measurement menus to adjust those values. As the LD Sources are from 1000 Genomes, which are shallow short read data that have been statistically phased, these data are subject to switch errors, and the R2(Haplotype) may be inaccurate. Looking at the default 1000G.EUR LD Source with R2 as the LD Measurement , we see that many of the variants passing the genome wide significance threshold (PValue < 5E10 -8) appear to be in LD and thus likely represent a single causal variant. However, given the extreme significance of many of these associations (note the scale of the -Log10(PValue) Y axis), there may be additional independent signals that are less significant but still pass the genome wide PValue threshold. This Region Plot view is based on the OmicSoft Genome Browser, so you can configure display of various genomic annotation tracks. These options are available in the Task tab on the right, where you can Manage the existing tracks and Add Tracks from a variety of sources. This tab also has the option to Export the plot to an image file. There are three remaining views available under Select View . These three views are Top Hits views and the results displayed are user defined by the TopHitsN parameter. The TopHitsN parameter controls how many association results with the most significant p-values to display in these views. The default is 10,000. The Top Hits (Genome Plot) view is a variation of what we have already seen. It is the same genome plot as shown in the Region Plot view, except instead of being used to set the center of the region plot (the primary component of the Region Plot view), the genome plot itself will be the primary component. The Top Hist (QQ plot) displays the negative logarithm of the observed (x-axis) and the expected (y-axis) P value for each SNP. This plot can be used to investigate confounders and identify true associations. Both of these views are fully interactive, such that you can use your mouse to select from the views, and give you options to explore the most significant results (filter on variant attributes, select to see details, etc .) and configure the charts. The Top Hits (Table) will be the fully annotated table of those same 1,000 most significant results. The output here is similar to the original Association Annotation view, except that the most current annotations will be dynamically joined. Select this view. To see which specific annotation versions are being reported, use the Options button in the Search Result tab on the left to select Show Annotation Sources : This same classifier listing will be included as a header if you Open as Text file The first column in the Top Hits (Table) view is the Snp ID , which contains a link to the variant s views (as if you had searched for the variant from the search box at the top). Right click on the PValue column to Sort Descending (the sort is based on the -log(PValue), so larger values are more significant). Then click on the Snp ID for the first row ( rs475535 ) and continue to the next section to learn about the data and views available for this highly-significant variant.","title":"Region Plot View"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-variant-knowledge-in-geneticsland","text":"Having searched for rs475535, the default view that is returned is the Allele Frequency plot. Like the Sample Distribution view, this is also grouped based on the PrimaryGrouping=ProjectName defined when the Land was created, and can be adjusted using the Grouping button at the top. Note there are actually two charts here, the first ( Genotyped ) being calculated from all the non-sequencing based genotypes that are in the Land (the array genotypes we published). Scroll down to see the next chart ( Imputed ), which is calculated from all the imputed allele doses in the Land ( i.e. the ones we published from the GWAS). In addition to the frequency being represented on the X axis, the carrier count is also displayed to the right of the bar in parentheses. Another view available is Genotype Frequency , which is configured similarly to the Allele Frequency plot. The number displayed to the right of each bar is still the carrier count (sum of heterozygotes and homozygote ALT). To get the count of each of these sub-groups, click on the View Filtered Table button at the bottom left to see the counts for each chart element. There is also a special view named Case Control Allele Frequency , which is available because at least one of the columns in our phenotype file was specified as a case/control value: Switch to this view under the Select View menu and you will see that instead of being grouped by Project Name , the allele frequencies are now grouped by the case/control status for all three phenotypes that were specified as case/control: The final view under the Summary heading in the Select View menu ( SNP Annotation ) is the table of variant annotations. These will match what were reported in the Top Hits (Table) view when we were reviewing the association results. Back in the Select View menu, select the All SNPs option under the Genotypes heading. This will display a table of all genotypes in the Land (those we published). Note the Data Type column, which will indicate if the genotypes came from sequencing ( Sequenced ), non-sequencing ( Genotyped ), or imputation ( Imputed ). You can filter on this column, or there are dedicated views for each of these under the same Genotypes heading in the Select View menu. This is the first view we have encountered with individual level data; these data can be hidden, depending on the project level access controls we configured before publishing the genetic data. If a user only had the Project level frequency access , they would have seen all the summary level information in the prior views (allele and genotype frequencies and counts) but would not see the corresponding genotypes in this table. Select the last view under the Genotypes heading in the Select View menu, Covariate View : This view will plot each relevant numeric sample attribute by genotype. Note that there are three charts (one numeric column from the Sample MetaData table and two from the phenotypes we added to the Sample Set MetaData ). There are not separate charts for each genotype source (sequencing, non-sequencing, imputed). Imputed doses are converted to genotypes and plotted with all other genotypes. Scroll down to the FEV1 chart, which was the endpoint analyzed for the association results we were just reviewing. We can clearly see a relationship between FEV1 and genotype. From the Task tab on the right, under Customize , select Show Summary Information to add a PValue Note, this does not match the PValue reported in the association results we were just exploring (1.00E-325) for a number of different reasons. The two primary reasons being the statistical model used for the association analysis ( i.e. it included covariates) and the samples included in the association analysis (this view considers all samples for which there is a genotype and FEV1 measure in the Land, while the association analysis only included a subset of samples). We can filter the results using the Search Result tab on the left to try to better emulate the association analysis. For example, we only analyzed STUDY005, so we can filter to that under ProjectName (note, there is no change, as we only added these phenotype measures for STUDY005, so the samples from other projects are already missing). Next we can filter to those which remained in the analysis after consent check under Sample Set | STUDY005 | GxConsent | Disease . This filtering did cause a change so the view defaulted back to the first chart scroll down to FEV1 again and note the PValue is now closer to the one reported in the association results. Another potential source of different sample content could be the project level access controls. You can select points on the chart to display the sample details below including Sample ID. For example, select the highest FEV1 values for the AA genotype: Since this view could potentially expose sample identity, samples from any project where you only have Project level frequency access will be excluded from the view, and the PValue calculation will not take them into account. Our initial interest in this variant was piqued by it being associated with our endpoint from our association analysis. Let s look at what other endpoints it may be associated with. From the Select View menu, select GRASP2 Table under Association : This displays a table of all the records in the GRASP database (version 2) for this variant. GRASP is a collection of all published GWAS results with Pvalue < 0.05, however, as most publications only include genome wide significant results using a much more stringent PValue threshold, it should generally be considered to only contain top hits. By default, this table is sorted by PValue, so the most significant results are at the top. You can see the phenotype and link to the source paper. Here we see a potential eQTL and three likely insignificant findings. Nothing related to our lung function endpoint (not surprising given our GWAS was simulated). Next we can look at the Curated Studies (Table) view under the Select View menu under the Association heading: This is similar to the GRASP2 Table view, except the source is all the association results that have been published to the Land, and as such will be complete (no PValue thresholds applied). In our case, we have only published the results from our single GWAS, so only see that one record returned.","title":"Review Variant Knowledge in GeneticsLand"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-gene-knowledge-in-geneticsland","text":"If you recall from the SNP Annotation view for rs475535, this variant was in the IGDCC3 gene, so let s search that from the box at the top: The default view is All SNPs . This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association Top Hits (Table) view, the RS ID column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the Source attribute in the Search Result tab on the left: The Coding SNPs view under the same Variants heading will return the exact same columns but remove the variants (rows) that are non-coding. Under the Select View menu, note the first section of views are divided by data source ( Sequenced , Genotyped for non-sequencing assays, and Imputed ). Let s switch to the corresponding Gene Summary view for Imputed data: If we switch to the Variant Annotation tab on the left, we see how the putatively functional variants were selected, and can modify this classification to update the chart If we switch to the Genome Browser view, we can see these data summarized across the gene: We see the variants in this gene plotted along the genome colored by their classification (per the Legend on the right) where the height and dot size correspond to the allele frequency. We see two tracks, one for All (meaning all samples) and one for STUDY005 because the grouping is still the PrimaryGrouping=ProjectName we defined when creating the Land. As we currently only have imputed data from this one project published, the grouping is uninformative. Let s switch to grouping by RACE and ETHNIC using the Grouping button at the top: Now, in addition to the All track, we see five new tracks grouped by the RACE and ETHNIC values from the Sample MetaData : Note, some of the longer labels are truncated, right click on the chart and select Organize Groups to see the full listing and optionally re-sort. As a genome browser view, you can configure the tracks and add new ones using the Task tab on the right. We can also look at the allele frequency in a table view for our selected grouping (RACE+ETHNIC) using the Grouped Allele Frequency view under the Select View menu. Here we see six Allele Frequency columns. The first five on the left correspond to the grouping, which is still set as RACE and ETHNIC . The last one on the right is the overall frequency considering all samples including those to which you don t have access per the project level access controls. As long as you have Project level frequency access , the samples from that project will be included in calculating the allele frequencies reported here. However, if you switch to a view that reports individual level information like the Dose Matrix , you would not see the samples from those projects for which you only have Project level frequency access : This view is a table of the imputed ALT allele doses with samples as rows and variant as columns. The column headers take the form CHROM:POS:REF:ALT , so you know, for example, that the first column contains doses of the A allele. There is also the special Case Control Allele Frequency view, where the grouping will be based on the three case/control values that were specified in the phenotype file: We can also look at the variant annotations in a table view. In the Select View menu, under Variants , select All SNPs This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association Top Hits (Table) view, the RS ID column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the Source attribute in the Search Result tab on the left: The Coding SNPs view under the same Variants heading will return the exact same columns but remove the variants (rows) that are non-coding. The final two views in the Select View menu, GRASP2 Table and Curated Studies (Table) under the Association heading, are identical to what we saw when exploring rs475535, except they will contain the list of associations for every variant in the All SNPs view (all variants in the gene).","title":"Review Gene Knowledge in GeneticsLand"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-knowledge-for-a-region-or-variant-gene-list-in-geneticsland","text":"In addition to searching for one gene, you can also search for a region (up to 1 Mb) using the form CHROM:START-END in the search box. For example, if we wanted to search 15 bases up and downstream of rs475535, we could enter 15:65632700-65632730 . You will have all the same views as when looking at the search results for the IGDCC3 gene with one additional Genes in Region view under the Variants heading which will show a list of all genes mapping to this region. You can click on the link in the Gene Name column to search that gene as if you had typed it into the search bar. You can also Search Multiple Variants or genes by clicking on the drop down arrow next to the green Search arrow at the top: Note the instructions above the entry box for formatting the list of variants. For the Search Multiple Genes option, the gene symbols you enter will be checked. For example, having intentionally entered a non-existent gene BRCA56: The genes found sum in the upper right indicates only the single OPRM1 gene was found, and the Remove invalid gene symbols button at the bottom left appears. You can also create a re-usable Gene Set , analogous to a Sample Set , in that access is controlled by the creator. From the Manage menu, select Genes | Manage Gene Sets Select the Add option to create a new Gene Set Enter STUDY005 Candidate Genes for Name and STUDY005 for Tag Switch to the MetaData tab and select Load from tab delimited file to browse to the downloaded GeneList.txt file The first column must contain the gene identifier and you can specify the type of identifier with the ID type option (we are using Gene_Symbol for this example). Note, unlike when searching for multiple genes where the symbols are validated as you enter them, any erroneous identifiers here won t be reported until you try to use the Gene Set . Any additional columns are just treated as generic user notes and not used in any way. Select OK to save the Gene Set . Now you can search for this Gene Set by name in the search box at the top. Start typing the name and select the Gene Set which is found. For these multi-variant and multi-gene searches, you will get all the same views as the IGDCC3 gene search except for the Genome Browser view.","title":"Review Knowledge for a Region or Variant / Gene List in GeneticsLand"},{"location":"tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-phenotype-knowledge-in-a-geneticsland","text":"We first started exploring the data in our Land with the endpoint from our association analysis. Now let s look at some other phenotypes. Start typing psoriasis into the search box at the top and select the result for psoriasis: As a Phenotype result (as opposed to an association result, as we selected when we searched for the endpoint from our association analysis), this indicates the results are from GRASP. The default view is a genome plot of the top 1,000 results. This is identical to the Top Hits (Genome Plot) view we saw when exploring the endpoint from our association analysis except instead of the results coming from out single analysis, they are compiled across all the literature. Therefore, we are likely to see the same variant reported multiple times. For example, if you select the peak on the p arm of chromosome 6, we see the SNV at 31252925 is reported twice: Although, scrolling right to review the annotations, we see it is a common variant with MAF > 5% in all reference populations, is intergenic, has GWAVA scores indicating it has no functional effect, and HaploReg and RegulomeDB values confirming minimal regulator impact. So even though this variant was found to be associated with psoriasis in two studies, the association is likely to be driven by a variant with more functional effects in LD with this variant. We see from the Platform description that these studies used imputation, however, from the variant counts ~2 million, we can infer that these used reference haplotypes from HapMap, which only captures a fraction of the variation in the 1000 Genomes project. So, it is possible the driving variant in LD was not imputed from HapMap. We can switch to the other view, Top Hits (Table) , to explore or export these fully annotated results using the Select View menu: Note, in the GRASP data, Psoriasis is categorized under Skin-related for the Phenotype Category . And if we return to our original psoriasis search results, scrolling down to the bottom of the list, we see other psoriasis phenotypes that are likely of interest. By searching the broader Skin-related category, we can get to all of these If we filter in the Search Result tab on the left to only the psoriasis related phenotypes and select the same peak on the p arm of chromosome 6, we see that same variant at 31252925 shows up again but for slightly different phenotypes. Although, note from the PMID that these are coming from the same study (19169254), which was also one of the studies we saw when looking at the psoriasis specific results.","title":"Review Phenotype Knowledge in a GeneticsLand"},{"location":"tutorials/GeneticsLand/Introduction_to_GeneticsLand/","text":"Introduction to GeneticsLand GeneticsLand is a robust solution for storage, integration, querying, and visualization of big genetic datasets up to a million samples, each with 100 million genotypes. This includes both subject-level data, such as genotypes, and summary statistics like allele frequencies and genotype-phenotype association results. In addition to the genetic data repository, GeneticsLand will dynamically join additional data at both the variant and sample level. It currently contains variant annotations from more than fifteen sources and can handle any type of sample attribute (phenotype or clinical measures, QC and tracking information, etc. ). There are numerous tabular and graphical visualizations for exploring the data in the context of a variant, gene, genomic region, or phenotype of interest. These include standard displays like allele frequency distributions, Manhattan plots, and region plots as well as advanced views like the OmicSoft Genome Browser, all of which are highly configurable. Download Demo Dataset We will be using a small simulated dataset during this tutorial. Please download from here: link to a location that is both accessible from your client machine and Array Server (if you don t know which locations are accessible to Array Server, consult with your server admin). This dataset consists of several files that you would be expected to generate during a typical GWAS experiment: Sample information (demographics, phenotypes, etc .) Assayed genotypes Imputed allele doses Genotype-phenotype association results Note, you may begin the first few steps of the tutorial while the data are downloading. Create a GeneticsLand This tutorial is intended as a training exercise, and thus you will begin by creating your own Land, so as not to affect any existing GeneticsLands that are actively being used by others with real data. Generally, it is best to maintain a single primary GeneticsLand, containing all of your institution s genetic data, to benefit from all of the cross-dataset integration features. To create a GeneticsLand, go to the Land tab and from the Tools menu, select Create Land : Enter a Land name , specify the configuration (below), and tick the box to Create genetics land to store variant level data . Then click the OK button and wait momentarily as the Land is created.:: Description=GeneticsLandTutorial ReferenceLibraryID=Human.B37.3 GeneModelID=OmicsoftGene20130723 MutationGeneModelID=Uniprot.Ensembl75 MaxGeneCount=500 PrimaryGrouping=ProjectName SecondaryGrouping=SEX SubjectIDColumn=USUBJID VariantClassifiers=ClinVar_20170501,FunctionalMutation_20170501,1000GenomesSimple_20170501, ExAC_20170501,ESP6500_20170501,RegulomeDB_20170501,HaploregV4_20170501,Conservation_20170501, GWAVA_20170501,GRASP2_20170501,GTexEqtl_20170501,GWASCatalog_20170501,UK10K_20170501, Wellderly_20170501 Note, if this is the first GeneticsLand ever created on this server, please log off the server and restart it to trigger downloading of the relevant reference files before proceeding (contact your server admin if you don t know how to restart it). Also note, we have specified ReferenceLibraryID=Human.B37.3 in the configuration above. All data we add to the Land in subsequent steps must also use this build. User Permissions in Creating a GeneticsLand If you are not a member of the Array Server Administrators group, you will not be able to create a new GeneticsLand. Please ask an Array Server Administrator to create the Land. Then, the Administrator should connect to the test GeneticsLand and using the Manage User access function, change your User permissions to allow Write/Publish (for this Land only). Permissions should also be granted for other GeneticsLand management functions, such as Refresh/Rebuild , Manage Meta Data and Manage Measurement Data . Open a GeneticsLand After the Land has been created, open it from the Land tab using the Select Land menu to find it under the GeneticsLand Collection heading. As a new Land without any samples, you will see an empty Sample Distribution view like this:","title":"Introduction"},{"location":"tutorials/GeneticsLand/Introduction_to_GeneticsLand/#introduction-to-geneticsland","text":"GeneticsLand is a robust solution for storage, integration, querying, and visualization of big genetic datasets up to a million samples, each with 100 million genotypes. This includes both subject-level data, such as genotypes, and summary statistics like allele frequencies and genotype-phenotype association results. In addition to the genetic data repository, GeneticsLand will dynamically join additional data at both the variant and sample level. It currently contains variant annotations from more than fifteen sources and can handle any type of sample attribute (phenotype or clinical measures, QC and tracking information, etc. ). There are numerous tabular and graphical visualizations for exploring the data in the context of a variant, gene, genomic region, or phenotype of interest. These include standard displays like allele frequency distributions, Manhattan plots, and region plots as well as advanced views like the OmicSoft Genome Browser, all of which are highly configurable.","title":"Introduction to GeneticsLand"},{"location":"tutorials/GeneticsLand/Introduction_to_GeneticsLand/#download-demo-dataset","text":"We will be using a small simulated dataset during this tutorial. Please download from here: link to a location that is both accessible from your client machine and Array Server (if you don t know which locations are accessible to Array Server, consult with your server admin). This dataset consists of several files that you would be expected to generate during a typical GWAS experiment: Sample information (demographics, phenotypes, etc .) Assayed genotypes Imputed allele doses Genotype-phenotype association results Note, you may begin the first few steps of the tutorial while the data are downloading.","title":"Download Demo Dataset"},{"location":"tutorials/GeneticsLand/Introduction_to_GeneticsLand/#create-a-geneticsland","text":"This tutorial is intended as a training exercise, and thus you will begin by creating your own Land, so as not to affect any existing GeneticsLands that are actively being used by others with real data. Generally, it is best to maintain a single primary GeneticsLand, containing all of your institution s genetic data, to benefit from all of the cross-dataset integration features. To create a GeneticsLand, go to the Land tab and from the Tools menu, select Create Land : Enter a Land name , specify the configuration (below), and tick the box to Create genetics land to store variant level data . Then click the OK button and wait momentarily as the Land is created.:: Description=GeneticsLandTutorial ReferenceLibraryID=Human.B37.3 GeneModelID=OmicsoftGene20130723 MutationGeneModelID=Uniprot.Ensembl75 MaxGeneCount=500 PrimaryGrouping=ProjectName SecondaryGrouping=SEX SubjectIDColumn=USUBJID VariantClassifiers=ClinVar_20170501,FunctionalMutation_20170501,1000GenomesSimple_20170501, ExAC_20170501,ESP6500_20170501,RegulomeDB_20170501,HaploregV4_20170501,Conservation_20170501, GWAVA_20170501,GRASP2_20170501,GTexEqtl_20170501,GWASCatalog_20170501,UK10K_20170501, Wellderly_20170501 Note, if this is the first GeneticsLand ever created on this server, please log off the server and restart it to trigger downloading of the relevant reference files before proceeding (contact your server admin if you don t know how to restart it). Also note, we have specified ReferenceLibraryID=Human.B37.3 in the configuration above. All data we add to the Land in subsequent steps must also use this build.","title":"Create a GeneticsLand"},{"location":"tutorials/GeneticsLand/Introduction_to_GeneticsLand/#user-permissions-in-creating-a-geneticsland","text":"If you are not a member of the Array Server Administrators group, you will not be able to create a new GeneticsLand. Please ask an Array Server Administrator to create the Land. Then, the Administrator should connect to the test GeneticsLand and using the Manage User access function, change your User permissions to allow Write/Publish (for this Land only). Permissions should also be granted for other GeneticsLand management functions, such as Refresh/Rebuild , Manage Meta Data and Manage Measurement Data .","title":"User Permissions in Creating a GeneticsLand"},{"location":"tutorials/GeneticsLand/Introduction_to_GeneticsLand/#open-a-geneticsland","text":"After the Land has been created, open it from the Land tab using the Select Land menu to find it under the GeneticsLand Collection heading. As a new Land without any samples, you will see an empty Sample Distribution view like this:","title":"Open a GeneticsLand"},{"location":"tutorials/GenomeBrowser/","text":"Omicsoft Genome Browser Tutorial .. toctree:: :maxdepth: 2 Introduction Create_Genome_Browser Adding_Tracks Browsing_Data Browsing_Data_from_Local_Analysis Others","title":"Home"},{"location":"tutorials/GenomeBrowser/Adding_Tracks/","text":"Adding Tracks A number of data types can be added as tracks including: Alignment files, e.g. BAM, SAM Files with standard format, e.g. BED, bedGraph, GTF, VCF, BigWig Tab-delimited text files containing genomic coordinate information columns (chromosome, start, end) Pre-built mapping tracks by Omicsoft, e.g. Affymetrix probes and probesets track, SNP Data sets in Analysis tab of Array Studio, e.g. NGS data sets, variable view of -omic data sets This section focuses on adding next generation sequencing data files (BAM files). A common task is to add alignment tracks, e.g. BAM files. The BAM alignment track can display a variety of information such as coverage, exon junctions, pileup, profiles, sequences, and variations. In this tutorial we will add BAM files from a server drive. First, go to Add Track | Add Track From Server File . Adding BAM Files As Single Tracks In the Specify Track Source window, select Alignment track | Sorted BAM file . Choose the two BAM files, SRR064173.subset.bam (RNA-Seq alignment) and SRR521462.subset.bam (DNA-Seq alignment). Click Open . The two new BAM tracks will appear at the bottom of the browser. The first time that tracks are added, it may take a few minutes while indexing is performed. This only occurs once. The user can zoom in and out using the mouse wheel or zoom tool at the top right of the tool bar. We can navigate to a gene region by typing a gene symbol, e.g. abl1 , in the search box (on the top-left corner, arrow). The coverage will be displayed in red in exon region and blue in intron/intergenic regions. Adding BAM Files As Combined Tracks The user can choose to merge multiple BAM files into a single track. In the Specify Track Source window, select Alignment track | multiple sorted BAM files . Choose the four fusion BAM files and click Open . A new track from four BAM files is created in Genome Browser:","title":"Adding Tracks"},{"location":"tutorials/GenomeBrowser/Adding_Tracks/#adding-tracks","text":"A number of data types can be added as tracks including: Alignment files, e.g. BAM, SAM Files with standard format, e.g. BED, bedGraph, GTF, VCF, BigWig Tab-delimited text files containing genomic coordinate information columns (chromosome, start, end) Pre-built mapping tracks by Omicsoft, e.g. Affymetrix probes and probesets track, SNP Data sets in Analysis tab of Array Studio, e.g. NGS data sets, variable view of -omic data sets This section focuses on adding next generation sequencing data files (BAM files). A common task is to add alignment tracks, e.g. BAM files. The BAM alignment track can display a variety of information such as coverage, exon junctions, pileup, profiles, sequences, and variations. In this tutorial we will add BAM files from a server drive. First, go to Add Track | Add Track From Server File .","title":"Adding Tracks"},{"location":"tutorials/GenomeBrowser/Adding_Tracks/#adding-bam-files-as-single-tracks","text":"In the Specify Track Source window, select Alignment track | Sorted BAM file . Choose the two BAM files, SRR064173.subset.bam (RNA-Seq alignment) and SRR521462.subset.bam (DNA-Seq alignment). Click Open . The two new BAM tracks will appear at the bottom of the browser. The first time that tracks are added, it may take a few minutes while indexing is performed. This only occurs once. The user can zoom in and out using the mouse wheel or zoom tool at the top right of the tool bar. We can navigate to a gene region by typing a gene symbol, e.g. abl1 , in the search box (on the top-left corner, arrow). The coverage will be displayed in red in exon region and blue in intron/intergenic regions.","title":"Adding BAM Files As Single Tracks"},{"location":"tutorials/GenomeBrowser/Adding_Tracks/#adding-bam-files-as-combined-tracks","text":"The user can choose to merge multiple BAM files into a single track. In the Specify Track Source window, select Alignment track | multiple sorted BAM files . Choose the four fusion BAM files and click Open . A new track from four BAM files is created in Genome Browser:","title":"Adding BAM Files As Combined Tracks"},{"location":"tutorials/GenomeBrowser/Browsing_Data/","text":"Browsing Data Navigation Tools There are tools at the top of the genome browser to help the user browse data in Genome Browser: Browsing Alignment Tracks Input abl1 in the gene search box and jump to the ABL1 region. Hovering the mouse pointer over the track labels (e.g. SRR521462) will bring up additional options Coverage : By default, coverage is shown in red for each track added. User can Hide Coverage if desired. Exon Junction : This track displays the number of supporting junctions spanning reads. By default, exon junctions will be displayed when the current region is <200,000bp. Click Show Exon Junction . Variation : This track will display all variations with respect to the reference. This track is useful when examining BAM files from mutation analyses in the Genome Browser. By default, Variation is only displayed when the display window is <2,000bp. If any alignment track is gray in menu, press Shift and use the left mouse button to select an area to zoom in to a region quickly. Alignment profile : Displays blue (positive strand) and green (negative strand) lines for alignment. If the alignment profile is not visible, it can be displayed by clicking the track name and selecting \"Show Alignment Profile\". The gray lines are those mapping to multiple genomic locations. By default, Alignment Profile will be visible when the display window is <20,000 bp. Note : If coverage is high, genome browser will randomly select only 50 reads to show at the same position. The maximal level to display can be specified in the track properties. Click the + button on the right hand side of the track (arrow) to show all reads. Read Sequence : Will display sequence of individual reads mapped to reference. By default, the read sequence will be displayed when the current region is < 250bp. Press Shift and use the left mouse button to select an area to zoom in to a region quickly. Click Show Read Sequences . The user should see the read sequences colored in blue and green representing the reads on the positive and negative strand, respectively. Mutated nucleotides are in red and low-quality nucleotides are shaded in grey. Additional Track Options : If an option is in gray, the user needs to zoom in further. The cutoffs to activate these options are defined in the track properties. These options can be modified by right-clicking on the track, and selecting \"Set Track Properties\": For instance, change the longest length of when to show exon junctions: Or change the length when to show the read sequence (just keep in mind the higher the number goes, the more memory required): Intron Trimming : For RNA-Seq data, most reads are in exon regions. The genome browser wastes a lot of space by displaying intron and intergenic regions. Click the intron trimming button in the toolbar to collapse introns and intergenic regions, so that only exonic regions are displayed. Browser Fusion BAM Files In this module, we will examine fusion events. When we imported four fusion BAM files, we combined them into a single track. Here, we will look at the individual fusion events that were identified in the DNA-seq file SRR064173. Right click on the BAM fusion track and split it into multiple tracks . It will show the fusion supporting reads from four sources: SRR064173.FusionSE: DNA fusion junction spanning reads SRR064173.FusionPE: DNA inter gene fusion read pairs SRR521462.FusionSE: RNA fusion junction spanning reads SRR521462.FusionPE: RNA inter transcript fusion read pairs Be sure to remove the option \"Trim intron reads\" as the BCR-ABL1 fusion event occurs within a non-coding breakpoint. To examine fusion reads, use your mouse to left-click and zoom in on the region shown above (within intron 1 of ABL1). Show Alignment Profile for SRR064173.FusionSE and you will see reads that are only part green (mapping to ABL1). To determine where the other portion of the read maps, right-click on the green portion of a read from SRR064173.FusionSE then select Show Mate In Next Pane It will show the fusion genome browser view (where both ends of the read are shown - see arrows): The user can zoom in to show the exact fusion position at genomic level in both genes: The user can practice browsing the fusion breakpoints at transcript level on SRR521462.FusionSE and SRR521462.FusionPE tracks. Hint: it is easier to browse predicted RNA-Seq fusion results using intron trimming mode. For further practice, try using this module to identify fusions between the other two genes included in the provided BAM files (XKR3-NUP214). The user can also return to a one panel mode by simply choosing the drop-down option from the navigation toolbar and selecting 1:","title":"Browsing Data"},{"location":"tutorials/GenomeBrowser/Browsing_Data/#browsing-data","text":"","title":"Browsing Data"},{"location":"tutorials/GenomeBrowser/Browsing_Data/#navigation-tools","text":"There are tools at the top of the genome browser to help the user browse data in Genome Browser:","title":"Navigation Tools"},{"location":"tutorials/GenomeBrowser/Browsing_Data/#browsing-alignment-tracks","text":"Input abl1 in the gene search box and jump to the ABL1 region. Hovering the mouse pointer over the track labels (e.g. SRR521462) will bring up additional options Coverage : By default, coverage is shown in red for each track added. User can Hide Coverage if desired. Exon Junction : This track displays the number of supporting junctions spanning reads. By default, exon junctions will be displayed when the current region is <200,000bp. Click Show Exon Junction . Variation : This track will display all variations with respect to the reference. This track is useful when examining BAM files from mutation analyses in the Genome Browser. By default, Variation is only displayed when the display window is <2,000bp. If any alignment track is gray in menu, press Shift and use the left mouse button to select an area to zoom in to a region quickly. Alignment profile : Displays blue (positive strand) and green (negative strand) lines for alignment. If the alignment profile is not visible, it can be displayed by clicking the track name and selecting \"Show Alignment Profile\". The gray lines are those mapping to multiple genomic locations. By default, Alignment Profile will be visible when the display window is <20,000 bp. Note : If coverage is high, genome browser will randomly select only 50 reads to show at the same position. The maximal level to display can be specified in the track properties. Click the + button on the right hand side of the track (arrow) to show all reads. Read Sequence : Will display sequence of individual reads mapped to reference. By default, the read sequence will be displayed when the current region is < 250bp. Press Shift and use the left mouse button to select an area to zoom in to a region quickly. Click Show Read Sequences . The user should see the read sequences colored in blue and green representing the reads on the positive and negative strand, respectively. Mutated nucleotides are in red and low-quality nucleotides are shaded in grey. Additional Track Options : If an option is in gray, the user needs to zoom in further. The cutoffs to activate these options are defined in the track properties. These options can be modified by right-clicking on the track, and selecting \"Set Track Properties\": For instance, change the longest length of when to show exon junctions: Or change the length when to show the read sequence (just keep in mind the higher the number goes, the more memory required):","title":"Browsing Alignment Tracks"},{"location":"tutorials/GenomeBrowser/Browsing_Data/#intron-trimming","text":": For RNA-Seq data, most reads are in exon regions. The genome browser wastes a lot of space by displaying intron and intergenic regions. Click the intron trimming button in the toolbar to collapse introns and intergenic regions, so that only exonic regions are displayed.","title":"Intron Trimming"},{"location":"tutorials/GenomeBrowser/Browsing_Data/#browser-fusion-bam-files","text":"In this module, we will examine fusion events. When we imported four fusion BAM files, we combined them into a single track. Here, we will look at the individual fusion events that were identified in the DNA-seq file SRR064173. Right click on the BAM fusion track and split it into multiple tracks . It will show the fusion supporting reads from four sources: SRR064173.FusionSE: DNA fusion junction spanning reads SRR064173.FusionPE: DNA inter gene fusion read pairs SRR521462.FusionSE: RNA fusion junction spanning reads SRR521462.FusionPE: RNA inter transcript fusion read pairs Be sure to remove the option \"Trim intron reads\" as the BCR-ABL1 fusion event occurs within a non-coding breakpoint. To examine fusion reads, use your mouse to left-click and zoom in on the region shown above (within intron 1 of ABL1). Show Alignment Profile for SRR064173.FusionSE and you will see reads that are only part green (mapping to ABL1). To determine where the other portion of the read maps, right-click on the green portion of a read from SRR064173.FusionSE then select Show Mate In Next Pane It will show the fusion genome browser view (where both ends of the read are shown - see arrows): The user can zoom in to show the exact fusion position at genomic level in both genes: The user can practice browsing the fusion breakpoints at transcript level on SRR521462.FusionSE and SRR521462.FusionPE tracks. Hint: it is easier to browse predicted RNA-Seq fusion results using intron trimming mode. For further practice, try using this module to identify fusions between the other two genes included in the provided BAM files (XKR3-NUP214). The user can also return to a one panel mode by simply choosing the drop-down option from the navigation toolbar and selecting 1:","title":"Browser Fusion BAM Files"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/","text":"Browsing Data from Analyses Array Studio provides convenient views of -omic and NGS data in genome browser. The Analysis tab has been fully integrated with the Browser tab in Array Studio. Open NGS Data in Genome Browser We created the TutorialRNASeq and TutorialDNASeq projects in the RNA-Seq and DNA-Seq tutorials. The user can open both projects in Analysis Tab. NGS data sets in Analysis projects can be directly loaded into a Genome Browser by going to the Browser tab and clicking Add Track | Add Track from Analysis | Alignment track: NGS data . It will ask user to select NgsData loaded in any open (Local and Server) projects. Alternatively, in the Analysis tab, user can add new genome browser on NgsData directly: Open OmicData/Table in Genome Browser By using Add Track | Add Track from Analysis , user can add Omic Data, such as CNV and MicroArray data, and table data directly to genome browser, as long as they have the chromosome, start, end annotation columns. In this module, we will load data from the CNV Tutorial analysis performed as part of the training module. In the Analysis tab at the top of the screen, click File | Open Local Project and open the CNV Tutorial. Next, try adding this data to the Genome Browser . First, try choosing the option Segment track: segment data and click \"OK\". Find your open segment table from the CNV tutorial and click OK : Choose the default options and click \"OK\" again: You will see two additional tracks appear in your Genome Browser : Log2RatioMean and CNStatus . Browse to chromosome 13 within the toolbar and you will find that the \"Beta2\" sample has a log2RatioMean of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome: Users can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding Shift and left-clicking to highlight a region. In addition to the segment tracks, one can upload additional CNV tracks. Go to Add Track | Add Track from Analysis : This time, choose the option Numeric track with multiple series: CNV data : Find your CNV analysis output and click OK . Select the data you want to visualize and click OK . Here, we choose all the data and set all other parameters to default: In this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view: As you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more: Users are encouraged to explore additional features of the genome browser with their own data. Viewing ENCODE Data in the Genome Browser Currently, nearly 20,000 ENCODE tracks are available for the OmicSoft Genome Browser for Human Genome Reference version 37.3, over 30,000 tracks for Human Genome Reference version38, and over 12,000 tracks for Mouse Genome Reference version 38. These tracks include alignment (bam), coverage (bigWig/gcf), and feature annotation (broadPeak/narrowPeak/gtf/gff3) files. To find tracks of interest, use the Filter Window on the left to subset available tracks by Data Type, Output Type, Assay Terminology Name, Organ, etc. Users can quickly add genome coverage and annotation data for thousands of ENCODE project experiments, to compare to their data in the Genome Browser. To add ENCODE data, click Add Track | Add Track from ENCODE ENCODE Filters and Data Types Because of the sheer abundance in ENCODE tracks (almost 20,000), users will need to filter tracks based on different attributes to find tracks they are specifically interested in. When you add an ENCODE track, you will see a view listing all ENCODE tracks available. On the left side of the window, you should see a number of filters: Some of the most commonly-used filter columns for assay type are described below: Data Type: The display track type: Aligned sequence data - bam BAM tracks load from the actual .bam files, so exon junction, variation, and sequence data for individual reads can be displayed. However, these data are quite large, so BAM tracks can take a long time to update. Coverage track - gcf, bigWig BigWig tracks are genome coverage data generated by ENCODE. GCF tracks use OmicSoft's custom binary coverage format, enabling extremely fast streaming of genome coverage data. OmicSoft has processed every ENCODE .bam file into a .gcf file, to dramatically improve load times for these data. BAM, GCF, and BigWig tracks are displayed as coverage files. When you only want genome coverage for a sample, GCF files will load much faster than .bam or BigWig files Peak calls - broadPeak, narrowPeak BroadPeak/NarrowPeak tracks are usually generated by peak-calling algorithms, using different settings, and usually mark high-confidence regions of increased signal (e.g. chromatin accessibility, ChIP signal, etc). Feature annotations - gff3, gtf GTF/GFF tracks display feature annotations, such as predicted promoter sites based on CAGE or RAMPAGE assays. Output Type: The measurement represented by the track Assay Terminology Name: Experimental procedure to generate data (categorized by Assay Category) Transcription - RNA-seq, CAGE, RNA-PET, RAMPAGE DNA accessibility - DNAse-seq, FAIRE-seq, MNase-seq Protein/RNA/DNA binding - ChIP-seq, RIP-seq, eCLIP, iCLIP Adding ENCODE Tracks In this module, we will select additional RNA-seq tracks from ENCODE performed on the K562 and MCF-7 cell lines used in the RNA-seq tutorial. To identify these tracks, we will use the following filters/features: File | Data Type | gcf , Experiment | Assay Title | RNA-seq , and Biosample | Term . For the Term filter, create an entry for \"K562 OR MCF-7\". In total, these filters will select RNA-seq alignment coverage from the same cell lines used in the RNA-seq tutorial: Notice in the upper right hand corner of the window that the number of files available to view reduces with the addition of each filter. For this tutorial, we will load just four of the tracks (2 files from each cell line). Find the four files at the bottom of the table - they should have a description under the column \"Biosample Description\" that reads: \"RNA Evalution (K562 or MCF-7) Long Total from Graveley. Left-click and select all four files (holding down Shift or Control to select multiple files). Click Add Tracks on the bottom of the window. One can also combine tracks by using Add Grouped Tracks while multiple files are selected. This will function similar to grouping .gcf files when adding tracks in the beginning of this tutorial. Click Close to return to the Genome Browser . You will find that the four new tracks have been added to your view. Customizing and Viewing ENCODE Tracks Once tracks have been added, the Genome Browser is fully customizable to better visualize the data. For instance, the track name is not an easy to understand identification, so the user can change this by going to Organize Tracks and clicking on the Metadata tab. As you scroll from left to right, the Assay Title and Term column headers are good indicators of what these samples are. Highlight the four new ENCODE tracks, and click Set Labels . Choose the Term and Assay Title columns to be listed and click OK twice. The new ENCODE tracks now have simpler identifiers: Now the user can examine these tracks and compare them to their own data. In this example, we have zoomed in on the 5' end of ABL1. As you can see below, there is a pileup of reads spanning the region of intron 1 where the BCR-ABL1 fusion has occured in K562, while there are no such reads in the MCF-7 cells line. Users are encouraged to explore the many ENCODE tracks available to enhance their analyses. Once the tracks of interest have been loaded and identification changed in the genome browser, use Track Properties to adjust track heights, colors, and more. For example, in the image above, notice that the track height is set to 0-100 for all four ENCODE BAM files that were added. This allows us to visualize the alignment coverage at the same scale for each of these four tracks.","title":"Browsing Data from Local Analysis"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#browsing-data-from-analyses","text":"Array Studio provides convenient views of -omic and NGS data in genome browser. The Analysis tab has been fully integrated with the Browser tab in Array Studio.","title":"Browsing Data from Analyses"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#open-ngs-data-in-genome-browser","text":"We created the TutorialRNASeq and TutorialDNASeq projects in the RNA-Seq and DNA-Seq tutorials. The user can open both projects in Analysis Tab. NGS data sets in Analysis projects can be directly loaded into a Genome Browser by going to the Browser tab and clicking Add Track | Add Track from Analysis | Alignment track: NGS data . It will ask user to select NgsData loaded in any open (Local and Server) projects. Alternatively, in the Analysis tab, user can add new genome browser on NgsData directly:","title":"Open NGS Data in Genome Browser"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#open-omicdatatable-in-genome-browser","text":"By using Add Track | Add Track from Analysis , user can add Omic Data, such as CNV and MicroArray data, and table data directly to genome browser, as long as they have the chromosome, start, end annotation columns. In this module, we will load data from the CNV Tutorial analysis performed as part of the training module. In the Analysis tab at the top of the screen, click File | Open Local Project and open the CNV Tutorial. Next, try adding this data to the Genome Browser . First, try choosing the option Segment track: segment data and click \"OK\". Find your open segment table from the CNV tutorial and click OK : Choose the default options and click \"OK\" again: You will see two additional tracks appear in your Genome Browser : Log2RatioMean and CNStatus . Browse to chromosome 13 within the toolbar and you will find that the \"Beta2\" sample has a log2RatioMean of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome: Users can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding Shift and left-clicking to highlight a region. In addition to the segment tracks, one can upload additional CNV tracks. Go to Add Track | Add Track from Analysis : This time, choose the option Numeric track with multiple series: CNV data : Find your CNV analysis output and click OK . Select the data you want to visualize and click OK . Here, we choose all the data and set all other parameters to default: In this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view: As you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more: Users are encouraged to explore additional features of the genome browser with their own data.","title":"Open OmicData/Table in Genome Browser"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#viewing-encode-data-in-the-genome-browser","text":"Currently, nearly 20,000 ENCODE tracks are available for the OmicSoft Genome Browser for Human Genome Reference version 37.3, over 30,000 tracks for Human Genome Reference version38, and over 12,000 tracks for Mouse Genome Reference version 38. These tracks include alignment (bam), coverage (bigWig/gcf), and feature annotation (broadPeak/narrowPeak/gtf/gff3) files. To find tracks of interest, use the Filter Window on the left to subset available tracks by Data Type, Output Type, Assay Terminology Name, Organ, etc. Users can quickly add genome coverage and annotation data for thousands of ENCODE project experiments, to compare to their data in the Genome Browser. To add ENCODE data, click Add Track | Add Track from ENCODE","title":"Viewing ENCODE Data in the Genome Browser"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#encode-filters-and-data-types","text":"Because of the sheer abundance in ENCODE tracks (almost 20,000), users will need to filter tracks based on different attributes to find tracks they are specifically interested in. When you add an ENCODE track, you will see a view listing all ENCODE tracks available. On the left side of the window, you should see a number of filters: Some of the most commonly-used filter columns for assay type are described below: Data Type: The display track type: Aligned sequence data - bam BAM tracks load from the actual .bam files, so exon junction, variation, and sequence data for individual reads can be displayed. However, these data are quite large, so BAM tracks can take a long time to update. Coverage track - gcf, bigWig BigWig tracks are genome coverage data generated by ENCODE. GCF tracks use OmicSoft's custom binary coverage format, enabling extremely fast streaming of genome coverage data. OmicSoft has processed every ENCODE .bam file into a .gcf file, to dramatically improve load times for these data. BAM, GCF, and BigWig tracks are displayed as coverage files. When you only want genome coverage for a sample, GCF files will load much faster than .bam or BigWig files Peak calls - broadPeak, narrowPeak BroadPeak/NarrowPeak tracks are usually generated by peak-calling algorithms, using different settings, and usually mark high-confidence regions of increased signal (e.g. chromatin accessibility, ChIP signal, etc). Feature annotations - gff3, gtf GTF/GFF tracks display feature annotations, such as predicted promoter sites based on CAGE or RAMPAGE assays. Output Type: The measurement represented by the track Assay Terminology Name: Experimental procedure to generate data (categorized by Assay Category) Transcription - RNA-seq, CAGE, RNA-PET, RAMPAGE DNA accessibility - DNAse-seq, FAIRE-seq, MNase-seq Protein/RNA/DNA binding - ChIP-seq, RIP-seq, eCLIP, iCLIP","title":"ENCODE Filters and Data Types"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#adding-encode-tracks","text":"In this module, we will select additional RNA-seq tracks from ENCODE performed on the K562 and MCF-7 cell lines used in the RNA-seq tutorial. To identify these tracks, we will use the following filters/features: File | Data Type | gcf , Experiment | Assay Title | RNA-seq , and Biosample | Term . For the Term filter, create an entry for \"K562 OR MCF-7\". In total, these filters will select RNA-seq alignment coverage from the same cell lines used in the RNA-seq tutorial: Notice in the upper right hand corner of the window that the number of files available to view reduces with the addition of each filter. For this tutorial, we will load just four of the tracks (2 files from each cell line). Find the four files at the bottom of the table - they should have a description under the column \"Biosample Description\" that reads: \"RNA Evalution (K562 or MCF-7) Long Total from Graveley. Left-click and select all four files (holding down Shift or Control to select multiple files). Click Add Tracks on the bottom of the window. One can also combine tracks by using Add Grouped Tracks while multiple files are selected. This will function similar to grouping .gcf files when adding tracks in the beginning of this tutorial. Click Close to return to the Genome Browser . You will find that the four new tracks have been added to your view.","title":"Adding ENCODE Tracks"},{"location":"tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#customizing-and-viewing-encode-tracks","text":"Once tracks have been added, the Genome Browser is fully customizable to better visualize the data. For instance, the track name is not an easy to understand identification, so the user can change this by going to Organize Tracks and clicking on the Metadata tab. As you scroll from left to right, the Assay Title and Term column headers are good indicators of what these samples are. Highlight the four new ENCODE tracks, and click Set Labels . Choose the Term and Assay Title columns to be listed and click OK twice. The new ENCODE tracks now have simpler identifiers: Now the user can examine these tracks and compare them to their own data. In this example, we have zoomed in on the 5' end of ABL1. As you can see below, there is a pileup of reads spanning the region of intron 1 where the BCR-ABL1 fusion has occured in K562, while there are no such reads in the MCF-7 cells line. Users are encouraged to explore the many ENCODE tracks available to enhance their analyses. Once the tracks of interest have been loaded and identification changed in the genome browser, use Track Properties to adjust track heights, colors, and more. For example, in the image above, notice that the track height is set to 0-100 for all four ENCODE BAM files that were added. This allows us to visualize the alignment coverage at the same scale for each of these four tracks.","title":"Customizing and Viewing ENCODE Tracks"},{"location":"tutorials/GenomeBrowser/Create_Genome_Browser/","text":"Create Genome Browser A new browser can be created by choosing the New button on the toolbar, or by going to File | New Browser . A window will appear and allow the user to specify a reference genome build and gene model track to be loaded into the new browser. If the Reference or Gene model is not listed, the user can build one using Array Studio tools ( NGS | Build Reference or Gene Model ). Select the Human.B37.3 Reference and the OmicsoftGene20130723 gene model. Clicking the Browse button allows the user to specify a location to save the Genome Browser: Note: If one intends to load a BAM alignment track, the reference in BAM headers has to match the one in the Genome Browser. The version of reference genome in the BAM file can be checked using Array Studio ( NGS | Tools | Bam Tools | Extract header and infer reference ). If the user has connected to a server, the newly created genome browser will be a server genome browser, the window for creating a genome browser will be slightly different from creating a local genome browser, and the server genome browser will use reference genome from server (if your server already has that genome reference, you won't need to download it again). For server genome browser, users can still add tracks from local files, but alignment file can't be shared (users can only share the genome browser when they are connected to the server). After creating a new browser, the default browser window for the chromosome 1 is shown.","title":"Create Genome Browser"},{"location":"tutorials/GenomeBrowser/Create_Genome_Browser/#create-genome-browser","text":"A new browser can be created by choosing the New button on the toolbar, or by going to File | New Browser . A window will appear and allow the user to specify a reference genome build and gene model track to be loaded into the new browser. If the Reference or Gene model is not listed, the user can build one using Array Studio tools ( NGS | Build Reference or Gene Model ). Select the Human.B37.3 Reference and the OmicsoftGene20130723 gene model. Clicking the Browse button allows the user to specify a location to save the Genome Browser: Note: If one intends to load a BAM alignment track, the reference in BAM headers has to match the one in the Genome Browser. The version of reference genome in the BAM file can be checked using Array Studio ( NGS | Tools | Bam Tools | Extract header and infer reference ). If the user has connected to a server, the newly created genome browser will be a server genome browser, the window for creating a genome browser will be slightly different from creating a local genome browser, and the server genome browser will use reference genome from server (if your server already has that genome reference, you won't need to download it again). For server genome browser, users can still add tracks from local files, but alignment file can't be shared (users can only share the genome browser when they are connected to the server). After creating a new browser, the default browser window for the chromosome 1 is shown.","title":"Create Genome Browser"},{"location":"tutorials/GenomeBrowser/Introduction/","text":"Introduction Genome Browser OmicSoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). The Genome Browser tab can be found in Array Studio and Array Viewer software: The OmicSoft Genome Browser can visualize NGS data in 32-bit mode on a Windows 32-bit computer with 2GB of RAM minimum, or in 64-bit mode on a Windows 64-bit computer with 8GB of RAM. 64-bit mode can run much faster than 32-bit mode, and is highly recommended when there is no Array Server connection and alignment files are not indexed. It is highly recommended that the users complete the prerequisite for this tutorial: RNA-Seq and DNA-Seq tutorial, as a way to learn the basics in sequencing data analysis. Test Dataset This Genome Browser tutorial will cover the importing and visualizing six NGS alignment files generated from RNA-Seq and DNA-Seq tutorial. Sample ID Description SRR064173.subset DNA-Seq alignment BAM SRR064173.FusionSE DNA fusion junction spanning reads detected by ArrayStudio SRR064173.FusionPE DNA inter gene fusion read pairs detected by ArrayStudio SRR521462.subset RNA-Seq alignment BAM SRR521462.FusionSE RNA fusion junction spanning reads detected by ArrayStudio SRR521462.FusionPE RNA inter transcript fusion read pairs detected by ArrayStudio To minimize the file size, we provide a subset of the alignment files containing regions of four genes: BCR, ABL1, NUP214 and XKR3: link This tutorial mainly focuses on browsing next generation sequencing data and its integration with the analytical tools of Array Studio. For more details on general functions and usage of the Genome Browser, please refer to the Genome Browser online help: link","title":"Introduction"},{"location":"tutorials/GenomeBrowser/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/GenomeBrowser/Introduction/#genome-browser","text":"OmicSoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). The Genome Browser tab can be found in Array Studio and Array Viewer software: The OmicSoft Genome Browser can visualize NGS data in 32-bit mode on a Windows 32-bit computer with 2GB of RAM minimum, or in 64-bit mode on a Windows 64-bit computer with 8GB of RAM. 64-bit mode can run much faster than 32-bit mode, and is highly recommended when there is no Array Server connection and alignment files are not indexed. It is highly recommended that the users complete the prerequisite for this tutorial: RNA-Seq and DNA-Seq tutorial, as a way to learn the basics in sequencing data analysis.","title":"Genome Browser"},{"location":"tutorials/GenomeBrowser/Introduction/#test-dataset","text":"This Genome Browser tutorial will cover the importing and visualizing six NGS alignment files generated from RNA-Seq and DNA-Seq tutorial. Sample ID Description SRR064173.subset DNA-Seq alignment BAM SRR064173.FusionSE DNA fusion junction spanning reads detected by ArrayStudio SRR064173.FusionPE DNA inter gene fusion read pairs detected by ArrayStudio SRR521462.subset RNA-Seq alignment BAM SRR521462.FusionSE RNA fusion junction spanning reads detected by ArrayStudio SRR521462.FusionPE RNA inter transcript fusion read pairs detected by ArrayStudio To minimize the file size, we provide a subset of the alignment files containing regions of four genes: BCR, ABL1, NUP214 and XKR3: link This tutorial mainly focuses on browsing next generation sequencing data and its integration with the analytical tools of Array Studio. For more details on general functions and usage of the Genome Browser, please refer to the Genome Browser online help: link","title":"Test Dataset"},{"location":"tutorials/GenomeBrowser/Others/","text":"Additional Browser Options In this chapter, we will explore additional features users can utilize to change the display on the browser, mark specific genome locations, search specific sequences, and share browser views with others. Organize Tracks Click Organize Track on top. It will allow user to add meta data for tracks. In the MetaData tab, user can import meta data for track. Click Load Meta | Import Table | Tab delimited file | OK and find the file \"Design.txt\" you downloaded with the BAM files. Click OK to load the design. The Track label can be switched to any column in the meta data. For example, select the column header \"Sample Name\" and click Set Labels : Move the column SampleName to the \"\"Listed columns\" and click OK twice: Notice the track names have now changed to reflect this transformation: Track Properties Click Track Properties on top or right click select Set Track Properties . It shows all properties that the user can specify, such as color, font, cutoffs to hide/show coverage, exon junctions, mutations and read sequences. GenomeMark GenomeMark is a bookmark-like utility in genome browser. Adding regions into GenomeMark will record genomic regions. The user can jump back to marked regions by a single click on the GenomeMark. Click favorite star icon to bookmark the current region: User can open GenomeMark and jump to marked regions: Left click on the color line to modify the GenomeMark properties. The user can also import GenomeMark regions via File | Import Custom Regions from gene lists or bed files. Sequence searching The OmicSoft GenomeBrowser also allows searching for DNA and RNA sequences. First, click the \"Show/Hide Sequence Search Toolbar\", which will add a new toolbar below the main toolbar. Enter a DNA or RNA sequence string in the \"Sequence\" search window (shortest sequence for search is 15nt), and click the green arrow to the right. The user can specify whether DNA or RNA sequence should be searched, which specifies whether genomic or transcript sequences (including inter-exonic sequences) should be searched. In addition, the user can specify whether partial or full alignments should be searched, and whether to search only the visible region. Genomic coordinates to Sequence Searches will be saved in the GenomeMark navigator, under the SequenceMatch sub-heading. Note If running ArrayStudio and logged into ArrayServer, a user will get the following message when ArrayServer has not been used to perform an aligment with the chosen Genome Reference and Gene Model used to start a Genome Browser: If this occurs, there are two solutions to this error and they are outline here: link Sharing Genome Browser If user has ArrayServer and the Genome Browser was created using server components (reference and server BAM files), the Genome Browser is sharable on the server where others can then access it (provided that they have the necessary privileges). Click Share | Share Genome Browser , specify the genome browser title and privileges. Click OK If user has Outlook opened, an email draft with a link will be created. Other users can open the Genome Browser by clicking the link or open it based on genome browser id (gb000016) in Share | Open Shared Genome Browser .","title":"Others"},{"location":"tutorials/GenomeBrowser/Others/#additional-browser-options","text":"In this chapter, we will explore additional features users can utilize to change the display on the browser, mark specific genome locations, search specific sequences, and share browser views with others.","title":"Additional Browser Options"},{"location":"tutorials/GenomeBrowser/Others/#organize-tracks","text":"Click Organize Track on top. It will allow user to add meta data for tracks. In the MetaData tab, user can import meta data for track. Click Load Meta | Import Table | Tab delimited file | OK and find the file \"Design.txt\" you downloaded with the BAM files. Click OK to load the design. The Track label can be switched to any column in the meta data. For example, select the column header \"Sample Name\" and click Set Labels : Move the column SampleName to the \"\"Listed columns\" and click OK twice: Notice the track names have now changed to reflect this transformation:","title":"Organize Tracks"},{"location":"tutorials/GenomeBrowser/Others/#track-properties","text":"Click Track Properties on top or right click select Set Track Properties . It shows all properties that the user can specify, such as color, font, cutoffs to hide/show coverage, exon junctions, mutations and read sequences.","title":"Track Properties"},{"location":"tutorials/GenomeBrowser/Others/#genomemark","text":"GenomeMark is a bookmark-like utility in genome browser. Adding regions into GenomeMark will record genomic regions. The user can jump back to marked regions by a single click on the GenomeMark. Click favorite star icon to bookmark the current region: User can open GenomeMark and jump to marked regions: Left click on the color line to modify the GenomeMark properties. The user can also import GenomeMark regions via File | Import Custom Regions from gene lists or bed files.","title":"GenomeMark"},{"location":"tutorials/GenomeBrowser/Others/#sequence-searching","text":"The OmicSoft GenomeBrowser also allows searching for DNA and RNA sequences. First, click the \"Show/Hide Sequence Search Toolbar\", which will add a new toolbar below the main toolbar. Enter a DNA or RNA sequence string in the \"Sequence\" search window (shortest sequence for search is 15nt), and click the green arrow to the right. The user can specify whether DNA or RNA sequence should be searched, which specifies whether genomic or transcript sequences (including inter-exonic sequences) should be searched. In addition, the user can specify whether partial or full alignments should be searched, and whether to search only the visible region. Genomic coordinates to Sequence Searches will be saved in the GenomeMark navigator, under the SequenceMatch sub-heading. Note If running ArrayStudio and logged into ArrayServer, a user will get the following message when ArrayServer has not been used to perform an aligment with the chosen Genome Reference and Gene Model used to start a Genome Browser: If this occurs, there are two solutions to this error and they are outline here: link","title":"Sequence searching"},{"location":"tutorials/GenomeBrowser/Others/#sharing-genome-browser","text":"If user has ArrayServer and the Genome Browser was created using server components (reference and server BAM files), the Genome Browser is sharable on the server where others can then access it (provided that they have the necessary privileges). Click Share | Share Genome Browser , specify the genome browser title and privileges. Click OK If user has Outlook opened, an email draft with a link will be created. Other users can open the Genome Browser by clicking the link or open it based on genome browser id (gb000016) in Share | Open Shared Genome Browser .","title":"Sharing Genome Browser"},{"location":"tutorials/Land Explorer/Introduction/","text":"Introduction Land Explorer OmicSoft uses ArrayLand framework to deliver large amounts of clinical and \"omic\"-data to biologists with simplistic visualization. Land Explorer is the quickest way to explore OmicSoft Land data (OncoLand, DiseaseLand, and Internal Lands). Users of Array Studio may be familiar with the content provided within the Land Explorer framework. The streamlined web interface uses our most popular visualizations to help researchers and clinicians explore OmicSoft Lands. Video introduction to Land Explorer Please see our video for a basic introduction to Land Explorer: Land Explorer is hosted on a Windows machine which connects to ArrayServer to provide access to rich visualization of Omic-data, directly in a user's web browser, meaning no extra software required. Land Explorer can by used as a companion product to OmicSoft's ArraySuite (to use with internal Lands and OmicSoft Lands), or as a standalone product hosted by QIAGEN/OmicSoft. Like ArraySuite, Land Explorer is fully customizable to meet the needs of its users. These tutorial pages demonstrate the utility of Land Explorer, including a description of the many views available, as well as the general usage and customizations of these views. Land Explorer usage Users can login to Land Explorer using their ArrayServer credentials. Please contact your ArrayServer adminstrator or support@omicsoft.com if you are having issues logging in. Once you connect to the LandExplorer, there are two options for a landing page that can be customized for each LandExplorer installation: An Optional SampleExplorer or a Land View. SampleExplorer Option This option allows users to query data across all Lands related to specific Sample Types. For example, the view below shows a distribution of all samples represented with the OncoLand, DiseaseLand, BodyMap, Cell Line and Single Cell collections, including sample counts, counts of data types and how these samples are distributed across all Lands. For more information on how the SampleExplorer are configured and used, please visit the SampleExplorer help menu. ComparisonExplorer Option This option allows users to query data across all Lands related to comparisons. For example, the view below shows a distribution of all comparisons represented within ArrayLands, and can be grouped by disease or tissue, with interactive pie charts and tree blocks that allow users to view and click through to OmicSoft-curated comparison(s) of interest. For more information on how the ComparisonExplorer are configured and used, please visit the ComparisonExplorer help menu. Land View Option If a SampleExplorer option is not defined in Land Explorer, the default view will be a Land View. In this view, the default land chosen by the administrator (TCGA by default) will appear. Users can switch to other Lands by simply clicking Select Land : The default TCGA_B37 Land Explorer view shows a histogram plot of samples grouped on the y-axis by Tumor Type, and colored on the x-axis by Sample Type. Other views are also available for users to query the sample data at a general level.","title":"Introduction"},{"location":"tutorials/Land Explorer/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/Land Explorer/Introduction/#land-explorer","text":"OmicSoft uses ArrayLand framework to deliver large amounts of clinical and \"omic\"-data to biologists with simplistic visualization. Land Explorer is the quickest way to explore OmicSoft Land data (OncoLand, DiseaseLand, and Internal Lands). Users of Array Studio may be familiar with the content provided within the Land Explorer framework. The streamlined web interface uses our most popular visualizations to help researchers and clinicians explore OmicSoft Lands.","title":"Land Explorer"},{"location":"tutorials/Land Explorer/Introduction/#video-introduction-to-land-explorer","text":"Please see our video for a basic introduction to Land Explorer: Land Explorer is hosted on a Windows machine which connects to ArrayServer to provide access to rich visualization of Omic-data, directly in a user's web browser, meaning no extra software required. Land Explorer can by used as a companion product to OmicSoft's ArraySuite (to use with internal Lands and OmicSoft Lands), or as a standalone product hosted by QIAGEN/OmicSoft. Like ArraySuite, Land Explorer is fully customizable to meet the needs of its users. These tutorial pages demonstrate the utility of Land Explorer, including a description of the many views available, as well as the general usage and customizations of these views.","title":"Video introduction to Land Explorer"},{"location":"tutorials/Land Explorer/Introduction/#land-explorer-usage","text":"Users can login to Land Explorer using their ArrayServer credentials. Please contact your ArrayServer adminstrator or support@omicsoft.com if you are having issues logging in. Once you connect to the LandExplorer, there are two options for a landing page that can be customized for each LandExplorer installation: An Optional SampleExplorer or a Land View.","title":"Land Explorer usage"},{"location":"tutorials/Land Explorer/Introduction/#sampleexplorer-option","text":"This option allows users to query data across all Lands related to specific Sample Types. For example, the view below shows a distribution of all samples represented with the OncoLand, DiseaseLand, BodyMap, Cell Line and Single Cell collections, including sample counts, counts of data types and how these samples are distributed across all Lands. For more information on how the SampleExplorer are configured and used, please visit the SampleExplorer help menu.","title":"SampleExplorer Option"},{"location":"tutorials/Land Explorer/Introduction/#comparisonexplorer-option","text":"This option allows users to query data across all Lands related to comparisons. For example, the view below shows a distribution of all comparisons represented within ArrayLands, and can be grouped by disease or tissue, with interactive pie charts and tree blocks that allow users to view and click through to OmicSoft-curated comparison(s) of interest. For more information on how the ComparisonExplorer are configured and used, please visit the ComparisonExplorer help menu.","title":"ComparisonExplorer Option"},{"location":"tutorials/Land Explorer/Introduction/#land-view-option","text":"If a SampleExplorer option is not defined in Land Explorer, the default view will be a Land View. In this view, the default land chosen by the administrator (TCGA by default) will appear. Users can switch to other Lands by simply clicking Select Land : The default TCGA_B37 Land Explorer view shows a histogram plot of samples grouped on the y-axis by Tumor Type, and colored on the x-axis by Sample Type. Other views are also available for users to query the sample data at a general level.","title":"Land View Option"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/","text":"LandExplorer Comparison Explorer OmicSoft has added an optional Comparison Explorer to the Land Explorer interface. Here users can view a distribution of all comparisons represented within ArrayLands, grouped by disease or tissue, with interactive pie charts and tree blocks that allow users to view and click through to OmicSoft-curated comparison(s) of interest. On this help page, we describe the usage of the Comparison Explorer. Users can navigate to the Comparison Explorer using the Help menu: Comparison Explorer The Comparison Explorer has been designed to allow users to quickly access comparison data of interest. Comparison metadata from multiple lands has been unified to allow users to quickly filter to comparisons of interest and pre-filter a Land to 1) access full comparison results for a comparison of interest, or browse comparison results for a single gene. Filter samples OmicSoft lands are curated to include key metadata across all Land types (such as OncoLand and DiseaseLand). In the filtering section of the Comparison Explorer, users can filter samples across all lands using comparison- and project-level metadata. If a user would like to filter comparisons on broad areas of focus, comparisons can be filtered by Tissue (i.e. TissueCategory or Tissue) as well as Disease (i.e. DiseaseCategory or DiseaseState). Projects are also curated using the broader \"Therapeutic Area\" term. On the other hand, if a user has a specific publication or public dataset they would like to search for, the ProjectName and PubMed filters will allow for searching of specific projects. Cross-Land Distribution The distribution view is a common way to visualize how many comparisons are available using the filters selected on the left-hand side of the webpage. The default visualization will be a plot that shows the number of comparisons (ranked from highest to lowest), grouped by Case.DiseaseCategory on the y-axis. To view the distribution grouped by Case.TissueCategory instead, simply click the toggle at the top of the screen. In addition, by scrolling over the bars in the plot, users can quickly identify how many comparisons belong to that category (colored by Case.Tissue when grouping by Case.TissueCategory in the image below): Comparison Pie Charts The stacked pie charts in the upper right portion of Comparison Explorer allow users to visualize more details about the comparisons filtered to. The inner circle of both pie charts represents the proportion of comparisons reprented by the Land colored. For example, the example below has been filtered by TherapeuticArea of Cardiovascular Disease and the pie charts have been updated to have to colors in the inner circle, representing MouseDisease_B38 and HumanDisease_B37. Scrolling over the circle will reveal the Land represented (the gray portion representing HumanDisease_B37): The outer portions of the pie charts represent the Comparison Category (left) and Therapeutic Area (right) represented by each land. Not surprisingly, in the example above, the majority of these are under the Therapeutic Area of Cardiovascular Disease (with some cross-listed in other areas). For this example, there are also a number of Comparison Categories, such as Treatment vs. Control, Disease vs. Normal, Responder vs. Non-responder, etc. Scrolling over each color will show how many of each are found for the corresponding land (inner circle): Land Comparison TreeBlock View A user can quickly identify which Land(s) the filtered comparisons in with this view belong to. The blocks are sized based on the overall proportion of the comparisons represented in the selected land. Interactive Views Each of the views in the Comparison Explorer are interactive and allow users to quickly visualize additional comparison details at the project level, as well as the gene level within the respective land. Browse Comparisons and Volcano Plots When users click on the bars in the Cross-Land Distribution or Comparison Pie Charts, Comparison Explorer will populate a Comparison Details table. This table can be scrolled up and down and filtered further using the controls at the top of the table: Also, by clicking on one the comparisons, users can quickly go to the Volcano plot view that will represent the differential expression of all genes in the chosen comparison: Open Land to Gene-level Comparisons view Within the tree block view, a user can click on a Land and a search window will appear. For example, in the Pie Chart example from above (pre-filtered to TherapeuticArea of Cardiovascular Disease), clicking on the MouseDisease_B38 block at the bottom a search window appears: Typing a gene name, such as tbx20, and selecting the Search button will allow a user to open up the AllComparisons view, prefiltered to the Project metadata (Therapeutic Area) using the Comparison Filters:","title":"Comparion Explorer"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#landexplorer-comparison-explorer","text":"OmicSoft has added an optional Comparison Explorer to the Land Explorer interface. Here users can view a distribution of all comparisons represented within ArrayLands, grouped by disease or tissue, with interactive pie charts and tree blocks that allow users to view and click through to OmicSoft-curated comparison(s) of interest. On this help page, we describe the usage of the Comparison Explorer. Users can navigate to the Comparison Explorer using the Help menu:","title":"LandExplorer Comparison Explorer"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#comparison-explorer","text":"The Comparison Explorer has been designed to allow users to quickly access comparison data of interest. Comparison metadata from multiple lands has been unified to allow users to quickly filter to comparisons of interest and pre-filter a Land to 1) access full comparison results for a comparison of interest, or browse comparison results for a single gene.","title":"Comparison Explorer"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#filter-samples","text":"OmicSoft lands are curated to include key metadata across all Land types (such as OncoLand and DiseaseLand). In the filtering section of the Comparison Explorer, users can filter samples across all lands using comparison- and project-level metadata. If a user would like to filter comparisons on broad areas of focus, comparisons can be filtered by Tissue (i.e. TissueCategory or Tissue) as well as Disease (i.e. DiseaseCategory or DiseaseState). Projects are also curated using the broader \"Therapeutic Area\" term. On the other hand, if a user has a specific publication or public dataset they would like to search for, the ProjectName and PubMed filters will allow for searching of specific projects.","title":"Filter samples"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#cross-land-distribution","text":"The distribution view is a common way to visualize how many comparisons are available using the filters selected on the left-hand side of the webpage. The default visualization will be a plot that shows the number of comparisons (ranked from highest to lowest), grouped by Case.DiseaseCategory on the y-axis. To view the distribution grouped by Case.TissueCategory instead, simply click the toggle at the top of the screen. In addition, by scrolling over the bars in the plot, users can quickly identify how many comparisons belong to that category (colored by Case.Tissue when grouping by Case.TissueCategory in the image below):","title":"Cross-Land Distribution"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#comparison-pie-charts","text":"The stacked pie charts in the upper right portion of Comparison Explorer allow users to visualize more details about the comparisons filtered to. The inner circle of both pie charts represents the proportion of comparisons reprented by the Land colored. For example, the example below has been filtered by TherapeuticArea of Cardiovascular Disease and the pie charts have been updated to have to colors in the inner circle, representing MouseDisease_B38 and HumanDisease_B37. Scrolling over the circle will reveal the Land represented (the gray portion representing HumanDisease_B37): The outer portions of the pie charts represent the Comparison Category (left) and Therapeutic Area (right) represented by each land. Not surprisingly, in the example above, the majority of these are under the Therapeutic Area of Cardiovascular Disease (with some cross-listed in other areas). For this example, there are also a number of Comparison Categories, such as Treatment vs. Control, Disease vs. Normal, Responder vs. Non-responder, etc. Scrolling over each color will show how many of each are found for the corresponding land (inner circle):","title":"Comparison Pie Charts"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#land-comparison-treeblock-view","text":"A user can quickly identify which Land(s) the filtered comparisons in with this view belong to. The blocks are sized based on the overall proportion of the comparisons represented in the selected land.","title":"Land Comparison TreeBlock View"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#interactive-views","text":"Each of the views in the Comparison Explorer are interactive and allow users to quickly visualize additional comparison details at the project level, as well as the gene level within the respective land.","title":"Interactive Views"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#browse-comparisons-and-volcano-plots","text":"When users click on the bars in the Cross-Land Distribution or Comparison Pie Charts, Comparison Explorer will populate a Comparison Details table. This table can be scrolled up and down and filtered further using the controls at the top of the table: Also, by clicking on one the comparisons, users can quickly go to the Volcano plot view that will represent the differential expression of all genes in the chosen comparison:","title":"Browse Comparisons and Volcano Plots"},{"location":"tutorials/Land Explorer/Explorer/ComparisonExplorer/#open-land-to-gene-level-comparisons-view","text":"Within the tree block view, a user can click on a Land and a search window will appear. For example, in the Pie Chart example from above (pre-filtered to TherapeuticArea of Cardiovascular Disease), clicking on the MouseDisease_B38 block at the bottom a search window appears: Typing a gene name, such as tbx20, and selecting the Search button will allow a user to open up the AllComparisons view, prefiltered to the Project metadata (Therapeutic Area) using the Comparison Filters:","title":"Open Land to Gene-level Comparisons view"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/","text":"LandExplorer Sample Explorer OmicSoft has added an optional SampleExplorer to the Land Explorer interface. Here users can browse data across all available lands to identify samples of interest. On this help page, we describe the usage of the SampleExplorer. Sample Explorer From the Sample Explorer, if users are interested in a specific Land, they can choose the appropriate Land from the drop-down menu at the top of the screen Select Land and click the search button. When performing a search without selecting a gene (1), users will be taken to the sample distribution view to display all samples in that land. When performing a search after selecting a gene (2), users will be taken to the Gene FPKM view to display all samples in that land. Filter samples OmicSoft lands are curated to include key metadata across all Land types (such as OncoLand and DiseaseLand). In the filtering section of the Sample Explorer, users can filter samples across all lands using these metadata, including the Land Collection (OncoLand, DiseaseLand, BodyMap, SingleCell). For a full description of the OmicSoft Lands, please visit here . Land samples can also be filtered by the species and genome used to process the data, the type of data available, and what tissues samples came from. Cross-Land Distribution The distribution view is a common way to visualize how many samples are available using the filters selected on the left-hand side of the webpage. The default visualization will be a plot that shows the number of samples (ranked from highest to lowest), grouped by tissue on the y-axis. Collection Summary This table in the upper-right corner of the Sample Explorer will display details of how many samples exist for the filtered samples, including the data types available (RNA/DNA-seq, CNV, microarray and proteomics assays) Collection TreeBlock View A user can quickly identify which Land(s) the filtered samples are in with this view. The blocks are sized based on the overall proportion of the samples are represented in the selected land. Open Land to Filtered Gene FPKM view Within the tree block view, a user can click on a Land and a search window will appear: Typing a gene name and selecting the Search button will allow a user to open up the GeneFPKM view, prefiltered using the SampleExplorer Filters: Open Land to Filtered Land view Without entering a gene, clicking the search button will take users to the sample distribution view to display samples, prefiltered using the FrontaPage Filters.","title":"Sample Explorer"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#landexplorer-sample-explorer","text":"OmicSoft has added an optional SampleExplorer to the Land Explorer interface. Here users can browse data across all available lands to identify samples of interest. On this help page, we describe the usage of the SampleExplorer.","title":"LandExplorer Sample Explorer"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#sample-explorer","text":"From the Sample Explorer, if users are interested in a specific Land, they can choose the appropriate Land from the drop-down menu at the top of the screen Select Land and click the search button. When performing a search without selecting a gene (1), users will be taken to the sample distribution view to display all samples in that land. When performing a search after selecting a gene (2), users will be taken to the Gene FPKM view to display all samples in that land.","title":"Sample Explorer"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#filter-samples","text":"OmicSoft lands are curated to include key metadata across all Land types (such as OncoLand and DiseaseLand). In the filtering section of the Sample Explorer, users can filter samples across all lands using these metadata, including the Land Collection (OncoLand, DiseaseLand, BodyMap, SingleCell). For a full description of the OmicSoft Lands, please visit here . Land samples can also be filtered by the species and genome used to process the data, the type of data available, and what tissues samples came from.","title":"Filter samples"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#cross-land-distribution","text":"The distribution view is a common way to visualize how many samples are available using the filters selected on the left-hand side of the webpage. The default visualization will be a plot that shows the number of samples (ranked from highest to lowest), grouped by tissue on the y-axis.","title":"Cross-Land Distribution"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#collection-summary","text":"This table in the upper-right corner of the Sample Explorer will display details of how many samples exist for the filtered samples, including the data types available (RNA/DNA-seq, CNV, microarray and proteomics assays)","title":"Collection Summary"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#collection-treeblock-view","text":"A user can quickly identify which Land(s) the filtered samples are in with this view. The blocks are sized based on the overall proportion of the samples are represented in the selected land.","title":"Collection TreeBlock View"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#open-land-to-filtered-gene-fpkm-view","text":"Within the tree block view, a user can click on a Land and a search window will appear: Typing a gene name and selecting the Search button will allow a user to open up the GeneFPKM view, prefiltered using the SampleExplorer Filters:","title":"Open Land to Filtered Gene FPKM view"},{"location":"tutorials/Land Explorer/Explorer/SampleExplorer/#open-land-to-filtered-land-view","text":"Without entering a gene, clicking the search button will take users to the sample distribution view to display samples, prefiltered using the FrontaPage Filters.","title":"Open Land to Filtered Land view"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/","text":"Land Explorer for IPA Explore detailed expression patterns across human tissues directly from IPA\u2019s Isoform Views. Land Explorer for IPA provides interactive plots of gene expression in 51 different human tissues from the GTEx project, for the gene level and individual splice variants. Learn more about the details underlying IPA\u2019s IsoProfiler, and visualize patterns of differential transcript utilization across profiled tissues, or profiled by any metadata. Accessing Land Explorer for IPA IPA users can examine detailed expression patterns across human tissues directly from IPA's Isoform Views. From IPA's Isoforms View for your gene of interest, click \"View GTEx human tissue expression (Land Explorer)\" to open the web portal, displaying expression information for your gene. By default, the RefSeq gene model is used in the IPA Isoform View and Land Explorer for IPA . If you switch the drop-down box to Ensembl in the IPA Isoform View , you can view transcript and gene quantification in Land Explorer for IPA using the Ensembl gene model. Land Explorer for IPA plots the expression of the splice variants of any human gene in 51 different human tissues. Gene-level expression is also available in Land Explorer (see below). You can find detailed information about navigating Land Explorer's gene and transcript level Views , and filtering data . Tips and Tricks Filtering on metadata You can use the extensive metadata for each sample in GTEx to focus only on the samples of interest to you, such as Tissue, Gender, etc. Find metadata of interest, then select only the categories you want For example, under Tissue tab , click \"Check None\" then keep only four tissues. Click Apply button to apply the newly created filters Regrouping on metadata You can re-organize all samples along the Y-axis based on any metadata. For example, you can find more detailed tissue-level information by grouping on Tissue Detail Type . Trellis on metadata Separate samples out into entirely different charts using the Trellis option. Switch between transcript-level and gene-level View By default, expression data for your gene of interest is displayed for transcripts, but you can also view gene-level expression information. Search for a new gene While you are in Land Explorer for IPA , you can search for expression of other genes of interest, simply be typing in your gene's identifier in Find Gene . Land Explorer for IPA is available at no charge for all IPA users, and does not require registration or manual sign-in, providing gene expression data from GTEx. For full access to hundreds of thousands of samples from healthy and disease tissue, please request a trial of the full OmicSoft Land Explorer: https://www.qiagenbioinformatics.com/land-explorer/ .","title":"Introduction"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#land-explorer-for-ipa","text":"Explore detailed expression patterns across human tissues directly from IPA\u2019s Isoform Views. Land Explorer for IPA provides interactive plots of gene expression in 51 different human tissues from the GTEx project, for the gene level and individual splice variants. Learn more about the details underlying IPA\u2019s IsoProfiler, and visualize patterns of differential transcript utilization across profiled tissues, or profiled by any metadata.","title":"Land Explorer for IPA"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#accessing-land-explorer-for-ipa","text":"IPA users can examine detailed expression patterns across human tissues directly from IPA's Isoform Views. From IPA's Isoforms View for your gene of interest, click \"View GTEx human tissue expression (Land Explorer)\" to open the web portal, displaying expression information for your gene. By default, the RefSeq gene model is used in the IPA Isoform View and Land Explorer for IPA . If you switch the drop-down box to Ensembl in the IPA Isoform View , you can view transcript and gene quantification in Land Explorer for IPA using the Ensembl gene model. Land Explorer for IPA plots the expression of the splice variants of any human gene in 51 different human tissues. Gene-level expression is also available in Land Explorer (see below). You can find detailed information about navigating Land Explorer's gene and transcript level Views , and filtering data .","title":"Accessing Land Explorer for IPA"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#tips-and-tricks","text":"","title":"Tips and Tricks"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#filtering-on-metadata","text":"You can use the extensive metadata for each sample in GTEx to focus only on the samples of interest to you, such as Tissue, Gender, etc. Find metadata of interest, then select only the categories you want For example, under Tissue tab , click \"Check None\" then keep only four tissues. Click Apply button to apply the newly created filters","title":"Filtering on metadata"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#regrouping-on-metadata","text":"You can re-organize all samples along the Y-axis based on any metadata. For example, you can find more detailed tissue-level information by grouping on Tissue Detail Type .","title":"Regrouping on metadata"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#trellis-on-metadata","text":"Separate samples out into entirely different charts using the Trellis option.","title":"Trellis on metadata"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#switch-between-transcript-level-and-gene-level-view","text":"By default, expression data for your gene of interest is displayed for transcripts, but you can also view gene-level expression information.","title":"Switch between transcript-level and gene-level View"},{"location":"tutorials/Land Explorer/Land Explorer for IPA/Land_Explorer_for_IPA/#search-for-a-new-gene","text":"While you are in Land Explorer for IPA , you can search for expression of other genes of interest, simply be typing in your gene's identifier in Find Gene . Land Explorer for IPA is available at no charge for all IPA users, and does not require registration or manual sign-in, providing gene expression data from GTEx. For full access to hundreds of thousands of samples from healthy and disease tissue, please request a trial of the full OmicSoft Land Explorer: https://www.qiagenbioinformatics.com/land-explorer/ .","title":"Search for a new gene"},{"location":"tutorials/Land Explorer/Land Views/Views/","text":"Omicsoft Views The Land Explorer features a number of views to visualize and interact with the data: Sample Level Views In addition to the default Samples view above, other views like Data Availability and Table View are also available for users to query the sample data at a general level. Gene Level Views When a user searches a gene or a gene set (multiple genes), there will be more views available, like DNA-Seq, Somatic Mutation Distribution, RNA-Seq, Gene FPKM, Transcript FPKM, etc. View types Visualization of the data in Lands can come in many formats. Please find the description of each specific view found in Lands under the subsections for the Land Views page. Some basic themes exist for certain views: Distribution Views Distribution views are generally histogram views. For Sample Level views, such as Sample, Comparison or Project Distribution , these views will plot the number of each available on the x-axis. Users can group these on the Y-axis using the metadata associated with that land. As a variation, quantification of mutation data can also be plotted in a Distribution view and found for both DNA-seq and RNA-seq mutation calling. An example of a distribution view is shown below for TCGA, where all samples are plotted (with numbers of x-axis showing quantity). Under the Grouping option, Tumor Type is chosen - therefore the samples are grouped on the y-axis by the TCGA-designated tumor type. Expression Views When users search for a single gene or multiple genes, various \"omic-data\" can be plotted in expression views. Among the data types supported in these views are RNA-Seq , microarray , as well as Proteomics data . Copy Number and Methylation views are also similarly displayed in Land Explorer. In all such views, each point on the plot represents a single sample, and the x-axis will represent the expression (or copy number/methylation) status for that sample. Similar to the distribution views, samples will be grouped on the y-axis as defined by the user in the \"Grouping\" option at the top of the screen, as shown below, where fgf2 expression is grouped on the Y-axis by Sample Type. For multi-gene searches, these views will often be represented as heat-map views such as below: Comparison Views Gene level comparisons are plotted as scatter or \"bubble-plots\", where the fold change of a gene in a specific comparison is plotted on the x-axis and the size of the dot represents the significance of the gene's differential expression (larger means more significant): Details Views Details views essentially will show a table, such as representing either the Samples or Comparisons available in the land, or the metadata associated with the samples that are filtered:","title":"Views"},{"location":"tutorials/Land Explorer/Land Views/Views/#omicsoft-views","text":"The Land Explorer features a number of views to visualize and interact with the data:","title":"Omicsoft Views"},{"location":"tutorials/Land Explorer/Land Views/Views/#sample-level-views","text":"In addition to the default Samples view above, other views like Data Availability and Table View are also available for users to query the sample data at a general level.","title":"Sample Level Views"},{"location":"tutorials/Land Explorer/Land Views/Views/#gene-level-views","text":"When a user searches a gene or a gene set (multiple genes), there will be more views available, like DNA-Seq, Somatic Mutation Distribution, RNA-Seq, Gene FPKM, Transcript FPKM, etc.","title":"Gene Level Views"},{"location":"tutorials/Land Explorer/Land Views/Views/#view-types","text":"Visualization of the data in Lands can come in many formats. Please find the description of each specific view found in Lands under the subsections for the Land Views page. Some basic themes exist for certain views:","title":"View types"},{"location":"tutorials/Land Explorer/Land Views/Views/#distribution-views","text":"Distribution views are generally histogram views. For Sample Level views, such as Sample, Comparison or Project Distribution , these views will plot the number of each available on the x-axis. Users can group these on the Y-axis using the metadata associated with that land. As a variation, quantification of mutation data can also be plotted in a Distribution view and found for both DNA-seq and RNA-seq mutation calling. An example of a distribution view is shown below for TCGA, where all samples are plotted (with numbers of x-axis showing quantity). Under the Grouping option, Tumor Type is chosen - therefore the samples are grouped on the y-axis by the TCGA-designated tumor type.","title":"Distribution Views"},{"location":"tutorials/Land Explorer/Land Views/Views/#expression-views","text":"When users search for a single gene or multiple genes, various \"omic-data\" can be plotted in expression views. Among the data types supported in these views are RNA-Seq , microarray , as well as Proteomics data . Copy Number and Methylation views are also similarly displayed in Land Explorer. In all such views, each point on the plot represents a single sample, and the x-axis will represent the expression (or copy number/methylation) status for that sample. Similar to the distribution views, samples will be grouped on the y-axis as defined by the user in the \"Grouping\" option at the top of the screen, as shown below, where fgf2 expression is grouped on the Y-axis by Sample Type. For multi-gene searches, these views will often be represented as heat-map views such as below:","title":"Expression Views"},{"location":"tutorials/Land Explorer/Land Views/Views/#comparison-views","text":"Gene level comparisons are plotted as scatter or \"bubble-plots\", where the fold change of a gene in a specific comparison is plotted on the x-axis and the size of the dot represents the significance of the gene's differential expression (larger means more significant):","title":"Comparison Views"},{"location":"tutorials/Land Explorer/Land Views/Views/#details-views","text":"Details views essentially will show a table, such as representing either the Samples or Comparisons available in the land, or the metadata associated with the samples that are filtered:","title":"Details Views"},{"location":"tutorials/Land Explorer/Land Views/Comparison Level Views/Volcano_Plot/","text":"The OmicSoft Land curation teams carefully curate samples in the Land using a controlled vocabulary for each project. For each project containing RNA-seq or microarray data, the curation team will generate sample groupings (often matching the ones used by the authors, as well as other meaningful ones) such as Disease vs Normal samples, or Treatment vs. Control samples. The Land Explorer allows users to browse overall comparison reports (DEseq2 for RNA-seq data and General Linear Model for microarray studies) in a volcano plot view. Within a land, users can search for an individual comparison in the search bar: As shown in the screenshot above, fold change is plotted on the x-axis (log2 fold change) and p value is plotted on the y-axis. Each dot represents an individual gene. Selecting dots in the view will populate the details table at the bottom of the view: As seen above, users can export this data to Excel, or simply browse the information to see the specific fold change and p value for the comparison result.","title":"Volcano Plot"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/","text":"Comparison views The OmicSoft Land curation teams carefully curate samples in the Land using a controlled vocabulary for each project. For each project containing RNA-seq or microarray data, the curation team will generate sample groupings (often matching the ones used by the authors, as well as other meaningful ones) such as Disease vs Normal samples, or Treatment vs. Control samples. The Land Explorer allows users to browse gene level information for these types of comparisons in a simple \"bubble plot\" view. When searching a gene, and choosing this view, the fold change of the gene will be plotted (each bubble, or dot represents a single comparison). The y-axis will group the comparisons by the primary grouping category, while the x-axis will represent the Log2 Fold change of that gene. The size of the dots will reflect the p value from the comparison (DESeq2 for RNA-seq and General Linear Model for microarray). Selecting dot(s) in this view will populate a Details table at the bottom of the view showing some key metadata from the comparison(s) The views below can be filtered to comparisons of interest. For information on customizing comparison views, please see: Comparison Filter All Comparisons This view combines all comparisons for a gene into one view. In this view, all of the different types of comparisons in the select Land will be plotted: Disease vs Normal This view shows all comparisons where samples from affected subjects (i.e. Tumors or Disease) are compared to samples from normal subjects in the same project: Treatment vs Control This view shows all comparisons where samples from affected subjects (treated with drug or other therapy) are compared to samples from untreated subjects in the same project: Responder vs NonResponder This view shows all comparisons where samples from subjects that show favorable response to a treatment are compared to samples from subjects with no response to the same treatment in the same project: Resistant vs Sensitive This view shows all comparisons where samples from subjects that show resistance to a treatment are compared to samples from subjects showing significant difference in outcome to the same treatment in the same project: Cell Type1 vs Cell Type2 This view shows all comparisons where samples of one cell type from a subject are compared to samples another cell type from these subjects in the same project: Disease1 vs Disease2 This view shows all comparisons where samples from subjects presenting one disease are compared to samples from other subjects presenting another disease in the same project: Treatment1 vs Treatment2 This view shows all comparisons where samples from subjects undergoing one treatment are compared to samples from other subjects undergoing a different treatment in the same project: Tissue1 vs Tissue2 This view shows all comparisons where samples of one tissue from a subject are compared to samples another tissue from these subjects in the same project: OtherComparisons This view shows all comparisons that do not fall under the standard categories above: Multi-gene comparisons This view is similar to the comparison bubble plots above, but will be grouped on the y-axis by each gene.","title":"Comparisons"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#comparison-views","text":"The OmicSoft Land curation teams carefully curate samples in the Land using a controlled vocabulary for each project. For each project containing RNA-seq or microarray data, the curation team will generate sample groupings (often matching the ones used by the authors, as well as other meaningful ones) such as Disease vs Normal samples, or Treatment vs. Control samples. The Land Explorer allows users to browse gene level information for these types of comparisons in a simple \"bubble plot\" view. When searching a gene, and choosing this view, the fold change of the gene will be plotted (each bubble, or dot represents a single comparison). The y-axis will group the comparisons by the primary grouping category, while the x-axis will represent the Log2 Fold change of that gene. The size of the dots will reflect the p value from the comparison (DESeq2 for RNA-seq and General Linear Model for microarray). Selecting dot(s) in this view will populate a Details table at the bottom of the view showing some key metadata from the comparison(s) The views below can be filtered to comparisons of interest. For information on customizing comparison views, please see: Comparison Filter","title":"Comparison views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#all-comparisons","text":"This view combines all comparisons for a gene into one view. In this view, all of the different types of comparisons in the select Land will be plotted:","title":"All Comparisons"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#disease-vs-normal","text":"This view shows all comparisons where samples from affected subjects (i.e. Tumors or Disease) are compared to samples from normal subjects in the same project:","title":"Disease vs Normal"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#treatment-vs-control","text":"This view shows all comparisons where samples from affected subjects (treated with drug or other therapy) are compared to samples from untreated subjects in the same project:","title":"Treatment vs Control"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#responder-vs-nonresponder","text":"This view shows all comparisons where samples from subjects that show favorable response to a treatment are compared to samples from subjects with no response to the same treatment in the same project:","title":"Responder vs NonResponder"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#resistant-vs-sensitive","text":"This view shows all comparisons where samples from subjects that show resistance to a treatment are compared to samples from subjects showing significant difference in outcome to the same treatment in the same project:","title":"Resistant vs Sensitive"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#cell-type1-vs-cell-type2","text":"This view shows all comparisons where samples of one cell type from a subject are compared to samples another cell type from these subjects in the same project:","title":"Cell Type1 vs Cell Type2"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#disease1-vs-disease2","text":"This view shows all comparisons where samples from subjects presenting one disease are compared to samples from other subjects presenting another disease in the same project:","title":"Disease1 vs Disease2"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#treatment1-vs-treatment2","text":"This view shows all comparisons where samples from subjects undergoing one treatment are compared to samples from other subjects undergoing a different treatment in the same project:","title":"Treatment1 vs Treatment2"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#tissue1-vs-tissue2","text":"This view shows all comparisons where samples of one tissue from a subject are compared to samples another tissue from these subjects in the same project:","title":"Tissue1 vs Tissue2"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#othercomparisons","text":"This view shows all comparisons that do not fall under the standard categories above:","title":"OtherComparisons"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/AllComparisons/#multi-gene-comparisons","text":"This view is similar to the comparison bubble plots above, but will be grouped on the y-axis by each gene.","title":"Multi-gene comparisons"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/CopyNumberViews/","text":"Copy Number Views Copy Number Variations (CNVs) can be identified using a variety of platforms. In TCGA lands, users can identify CNVs using two different types of CNV data, GISTIC2 and Log2Ratio-based calling from Affymetrix. CopyNumber_Gistic2.Level_4.tar.gz files (obtained from Broad ]) are used to get the GISTIC2 call values. Log2Ratio segment data are downloaded from the GDC Legacy Archive. This data is available in a matrix which for each sample and includes genomic coordinates of segments along with the log2 ratio derived from an Affymetrix SNP6 Copy Number Inference Pipeline. Gene level copy number calls from GISTIC2, together with mutation data, are available in the DNA Alteration Distribution view. Additional copy number views are summarize on this page. Copy Number For Log2Ratio-based calls, searching a gene will display a variable view similar to the expression views seen for RNA-seq and microarray data. The x-axis values in this view represent the log2 ratio. A ratio of about zero corresponds with no change in copy number. A positive ratio indicates copy number gain while a negative ratio corresponds with copy number loss. Clicking on individual samples (dots) on the plot will provide a details view that indicates the copy number status from GISTIC2 calls and Log2 ratio calls where available: Average Log2 ratio For multi-gene searches, selecting the Copy Number view will create one chart per gene. Users can scroll up and down on the page to identify CNV data for each gene. Alternatively, users can view average CNV log2 ratios (averaging the log2 ratios for all genes searched):","title":"Copy Number"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/CopyNumberViews/#copy-number-views","text":"Copy Number Variations (CNVs) can be identified using a variety of platforms. In TCGA lands, users can identify CNVs using two different types of CNV data, GISTIC2 and Log2Ratio-based calling from Affymetrix. CopyNumber_Gistic2.Level_4.tar.gz files (obtained from Broad ]) are used to get the GISTIC2 call values. Log2Ratio segment data are downloaded from the GDC Legacy Archive. This data is available in a matrix which for each sample and includes genomic coordinates of segments along with the log2 ratio derived from an Affymetrix SNP6 Copy Number Inference Pipeline. Gene level copy number calls from GISTIC2, together with mutation data, are available in the DNA Alteration Distribution view. Additional copy number views are summarize on this page.","title":"Copy Number Views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/CopyNumberViews/#copy-number","text":"For Log2Ratio-based calls, searching a gene will display a variable view similar to the expression views seen for RNA-seq and microarray data. The x-axis values in this view represent the log2 ratio. A ratio of about zero corresponds with no change in copy number. A positive ratio indicates copy number gain while a negative ratio corresponds with copy number loss. Clicking on individual samples (dots) on the plot will provide a details view that indicates the copy number status from GISTIC2 calls and Log2 ratio calls where available:","title":"Copy Number"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/CopyNumberViews/#average-log2-ratio","text":"For multi-gene searches, selecting the Copy Number view will create one chart per gene. Users can scroll up and down on the page to identify CNV data for each gene. Alternatively, users can view average CNV log2 ratios (averaging the log2 ratios for all genes searched):","title":"Average Log2 ratio"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/","text":"DNA-seq views Omicsoft Lands hold a number of mutation calls from DNA-seq data. The mutations attributed to this data can be viewed in many formats. This page describes how users can browse these data types. DNA Alteration Distribution The alteration distribution view shows all alterations (mutations and copy number) of gene(s) for the samples in the Land. searched in the current view, limited to DNAseq alterations (mutations and copy number, such as amplification or deletion events). Samples with multiple calls will be represented as such. The view will plot the percentage of samples within each group (specified in the Grouping dropdown menu) that is altered for the gene of interest. In the example below, the % of samples with such alterations are plotted for the gene BCL2. The graph will be plotted in order of magnitude of alterations (with the highest percent at the top of the graph). For BCL2, it is most affected in DLBC (Diffuse B-cell lymphoma), with roughly 10% of samples in this group showing either CNV (Amplifications, red) or DNA-seq mutations (green): Copy number calls are derived from GISTIC2 calls, and only represent samples with the status Amplification (gain of at least 2 copies) or Homozygous Deletion (loss of both copies). For DNA-seq mutation calls, the MUT category refers to non-synonymous mutations. Filters for each data type can be altered using the CNV and Mutation filters, respectively, on the left. DNA Alteration Distribution By Gene For multi-gene searches, all mutation and CNV data will be compounded for the genes in the search to identify samples with an alteration in any of the genes queried using the DNA Alteration Distribution View. If a user is interested in the per-gene distribution of samples (rather than compounded distribution), the \"DNA Alteration Distribution By Gene\" will generate one chart per gene queried. Somatic Co-Mutation Frequencies DNA Seq somatic co-mutation frequencies shows a bar plot of # genes with mutation vs frequency of mutation. For instance, for a gene set of BRAF and PTEN, a bar will be shown for samples exhibiting 0, 1, or 2 mutations. Somatic Mutation Pattern DNA Seq somatic mutation pattern view shows a bar plot showing the number of mutations matching a particular pattern for the specified gene set across a grouping (e.g. Tumor Type). Somatic Mutation Distribution Similar to the DNA Alteration Distribution View, this view displays histograms of DNA-Seq Somatic Mutation Distribution. In this view, only mutation events will be taken into consideration when calculating the percentage of affected samples in each group. As you can see in the view below, for the gene BCL2, only mutations are plotted. In the legend, a full description of the type of mutation (Indel, Deletion, Substitution) will be displayed. Somatic Mutation Distribution By Gene For multi-gene searches, all mutation data will be compounded for the genes in the search to identify samples with a mutation in any of the genes queried using the Somatic Mutation Distribution View. If a user is interested in the per-gene distribution of samples (rather than compounded distribution), the \"Somatic Mutation Distribution By Gene\" will generate one chart per gene queried. Somatic Mutation Site Distribution The Somatic Mutation Distibution View displays gene-level distribution plots of all mutations. If users are interested in viewing the distribution of distinct alleles of a gene for the same grouping, the Somatic Mutation Site Distribution is the needed view. This view shows the percentage of each allele identified as a DNA-Seq Somatic mutation, organized by Group (e.g. Tumor Type). The x-Axis shows the percent of mutant samples: Somatic Mutation Site Distribution By Gene For multi-gene searches, a Somatic Mutation Site Distribution will be plotted for each gene in the search, displaying percentages of each allele for the gene specified in the chart title.","title":"DNA-Seq"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#dna-seq-views","text":"Omicsoft Lands hold a number of mutation calls from DNA-seq data. The mutations attributed to this data can be viewed in many formats. This page describes how users can browse these data types.","title":"DNA-seq views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#dna-alteration-distribution","text":"The alteration distribution view shows all alterations (mutations and copy number) of gene(s) for the samples in the Land. searched in the current view, limited to DNAseq alterations (mutations and copy number, such as amplification or deletion events). Samples with multiple calls will be represented as such. The view will plot the percentage of samples within each group (specified in the Grouping dropdown menu) that is altered for the gene of interest. In the example below, the % of samples with such alterations are plotted for the gene BCL2. The graph will be plotted in order of magnitude of alterations (with the highest percent at the top of the graph). For BCL2, it is most affected in DLBC (Diffuse B-cell lymphoma), with roughly 10% of samples in this group showing either CNV (Amplifications, red) or DNA-seq mutations (green): Copy number calls are derived from GISTIC2 calls, and only represent samples with the status Amplification (gain of at least 2 copies) or Homozygous Deletion (loss of both copies). For DNA-seq mutation calls, the MUT category refers to non-synonymous mutations. Filters for each data type can be altered using the CNV and Mutation filters, respectively, on the left.","title":"DNA Alteration Distribution"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#dna-alteration-distribution-by-gene","text":"For multi-gene searches, all mutation and CNV data will be compounded for the genes in the search to identify samples with an alteration in any of the genes queried using the DNA Alteration Distribution View. If a user is interested in the per-gene distribution of samples (rather than compounded distribution), the \"DNA Alteration Distribution By Gene\" will generate one chart per gene queried.","title":"DNA Alteration Distribution By Gene"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#somatic-co-mutation-frequencies","text":"DNA Seq somatic co-mutation frequencies shows a bar plot of # genes with mutation vs frequency of mutation. For instance, for a gene set of BRAF and PTEN, a bar will be shown for samples exhibiting 0, 1, or 2 mutations.","title":"Somatic Co-Mutation Frequencies"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#somatic-mutation-pattern","text":"DNA Seq somatic mutation pattern view shows a bar plot showing the number of mutations matching a particular pattern for the specified gene set across a grouping (e.g. Tumor Type).","title":"Somatic Mutation Pattern"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#somatic-mutation-distribution","text":"Similar to the DNA Alteration Distribution View, this view displays histograms of DNA-Seq Somatic Mutation Distribution. In this view, only mutation events will be taken into consideration when calculating the percentage of affected samples in each group. As you can see in the view below, for the gene BCL2, only mutations are plotted. In the legend, a full description of the type of mutation (Indel, Deletion, Substitution) will be displayed.","title":"Somatic Mutation Distribution"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#somatic-mutation-distribution-by-gene","text":"For multi-gene searches, all mutation data will be compounded for the genes in the search to identify samples with a mutation in any of the genes queried using the Somatic Mutation Distribution View. If a user is interested in the per-gene distribution of samples (rather than compounded distribution), the \"Somatic Mutation Distribution By Gene\" will generate one chart per gene queried.","title":"Somatic Mutation Distribution By Gene"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#somatic-mutation-site-distribution","text":"The Somatic Mutation Distibution View displays gene-level distribution plots of all mutations. If users are interested in viewing the distribution of distinct alleles of a gene for the same grouping, the Somatic Mutation Site Distribution is the needed view. This view shows the percentage of each allele identified as a DNA-Seq Somatic mutation, organized by Group (e.g. Tumor Type). The x-Axis shows the percent of mutant samples:","title":"Somatic Mutation Site Distribution"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/DNAAlterationDistribution/#somatic-mutation-site-distribution-by-gene","text":"For multi-gene searches, a Somatic Mutation Site Distribution will be plotted for each gene in the search, displaying percentages of each allele for the gene specified in the chart title.","title":"Somatic Mutation Site Distribution By Gene"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/","text":"Microarray Views Microarray data from various platforms are supported in the Land framework, including many Affymetrix, as well as some Illumina and Agilent Microarrays. For Omicsoft Lands in the OncoLand and DiseaseLand collections, Omicsoft re-processed the raw data and normalizes the data using standardized pipelines to improve cross-project comparisons. Depending on the type of arrays used in a specific Land, when searching a gene in the Land Explorer, two Microarray Variable views will be available: Expression Ratio or Expression Intensity Probes : Heatmap (Expression Ratio) Heatmap showing Gene Expression ratio (Sample vs Universal Human Reference) for group (e.g. Tumor Type) for multiple genes. Y-axis is gene, while X-axis is grouping (e.g. Tumor Type). Expression data was generated on a two-color chip. Use the Sample Tab to further filter the data using any associated sample/subject meta data. Expression Ratio The Expression Ratio view is available in TCGA lands and plots the expression values from Agilent Expression Arrays (Agilent G4502A). When a user searches a gene and selects this view, the Expression value in the Sample compared to the Universal Human reference will be plotted on the x-axis and the samples will be grouped on the y-axis by the Grouping column (e.g. Tumor Type): Expression Intensity (Gene Level) In other Lands, such as the GEO-based HumanDisease and MouseDisease Lands, microarray data from a number of platorms is re-processed and normalized , and the probes used in the arrays are mapped to the gene models used in the Land. When a gene is searched an the Expression Intensity view is selected, users can browse the expression data that gene. Expression of a gene is averaged across all probes mapping to that gene for each sample. Expression Intensity (ProbeSet Level) In addition to summarizing expression at the gene level for microarray studies, the Expression Intensity (ProbeSet Level) allows users to browse the expression data for all probes that mapped to that gene. One chart will be generated per probe that maps to this gene: Multi-Gene Variable (Expression Ratio) When multiple genes are searched, the multi-gene variable view allows users to visualize the expression of all genes searched in a single view. Here, the genes are grouped on the y-axis, and the expression of the gene in each sample is represented by the dots on the x-axis: Multi-Gene Correlation (Expression Ratio) Shows a scatter view comparing the Expression Ratio (Sample vs Universal Human Reference) for two or more genes. For two genes, the x-axis will be the first gene, while the y-axis will be the second gene. Use Change Regression Line Settings to automatically show the correlation values. Use the Automatic grouping to automatically change the coloring of the plot. For 3 or more genes, shows a multi-chart correlation plot. Average Expression When multiple genes are searched, the average expression view allows users to visualize the average expression of the gene set (i.e. gene signature) in the filtered samples. Samples are grouped on the y-axis by the grouping category and expression is plotted on the x-axis. Heatmap Expression When multiple genes are searched, another view users can use is the Heat map view. In this view, expression of each gene will shown as a heatmap, where each row represents a sample, and the columns represent the gene. Filtering to fewer samples will aid in visualization of the unbiased clustering of the heatmap and the expression values of each gene: Expression Survival In this view, when survival data is available and attributed to samples within the land, such as within OncoLand studies (TCGA, OncoGEO, etc.), a survival view will be generated. Samples will be grouped into quartiles (Up, upper 25% (Q1) expression of gene, Down, lower 25% (Q4), Mid (all remaining samples, Q2 and Q3)) based on microarray expression values. Survival will be plotted on the Y-axis and time on the X-axis.","title":"Microarray Expression"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#microarray-views","text":"Microarray data from various platforms are supported in the Land framework, including many Affymetrix, as well as some Illumina and Agilent Microarrays. For Omicsoft Lands in the OncoLand and DiseaseLand collections, Omicsoft re-processed the raw data and normalizes the data using standardized pipelines to improve cross-project comparisons. Depending on the type of arrays used in a specific Land, when searching a gene in the Land Explorer, two Microarray Variable views will be available: Expression Ratio or Expression Intensity Probes :","title":"Microarray Views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#heatmap-expression-ratio","text":"Heatmap showing Gene Expression ratio (Sample vs Universal Human Reference) for group (e.g. Tumor Type) for multiple genes. Y-axis is gene, while X-axis is grouping (e.g. Tumor Type). Expression data was generated on a two-color chip. Use the Sample Tab to further filter the data using any associated sample/subject meta data.","title":"Heatmap (Expression Ratio)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#expression-ratio","text":"The Expression Ratio view is available in TCGA lands and plots the expression values from Agilent Expression Arrays (Agilent G4502A). When a user searches a gene and selects this view, the Expression value in the Sample compared to the Universal Human reference will be plotted on the x-axis and the samples will be grouped on the y-axis by the Grouping column (e.g. Tumor Type):","title":"Expression Ratio"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#expression-intensity-gene-level","text":"In other Lands, such as the GEO-based HumanDisease and MouseDisease Lands, microarray data from a number of platorms is re-processed and normalized , and the probes used in the arrays are mapped to the gene models used in the Land. When a gene is searched an the Expression Intensity view is selected, users can browse the expression data that gene. Expression of a gene is averaged across all probes mapping to that gene for each sample.","title":"Expression Intensity (Gene Level)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#expression-intensity-probeset-level","text":"In addition to summarizing expression at the gene level for microarray studies, the Expression Intensity (ProbeSet Level) allows users to browse the expression data for all probes that mapped to that gene. One chart will be generated per probe that maps to this gene:","title":"Expression Intensity (ProbeSet Level)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#multi-gene-variable-expression-ratio","text":"When multiple genes are searched, the multi-gene variable view allows users to visualize the expression of all genes searched in a single view. Here, the genes are grouped on the y-axis, and the expression of the gene in each sample is represented by the dots on the x-axis:","title":"Multi-Gene Variable (Expression Ratio)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#multi-gene-correlation-expression-ratio","text":"Shows a scatter view comparing the Expression Ratio (Sample vs Universal Human Reference) for two or more genes. For two genes, the x-axis will be the first gene, while the y-axis will be the second gene. Use Change Regression Line Settings to automatically show the correlation values. Use the Automatic grouping to automatically change the coloring of the plot. For 3 or more genes, shows a multi-chart correlation plot.","title":"Multi-Gene Correlation (Expression Ratio)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#average-expression","text":"When multiple genes are searched, the average expression view allows users to visualize the average expression of the gene set (i.e. gene signature) in the filtered samples. Samples are grouped on the y-axis by the grouping category and expression is plotted on the x-axis.","title":"Average Expression"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#heatmap-expression","text":"When multiple genes are searched, another view users can use is the Heat map view. In this view, expression of each gene will shown as a heatmap, where each row represents a sample, and the columns represent the gene. Filtering to fewer samples will aid in visualization of the unbiased clustering of the heatmap and the expression values of each gene:","title":"Heatmap Expression"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/ExpressionRatio/#expression-survival","text":"In this view, when survival data is available and attributed to samples within the land, such as within OncoLand studies (TCGA, OncoGEO, etc.), a survival view will be generated. Samples will be grouped into quartiles (Up, upper 25% (Q1) expression of gene, Down, lower 25% (Q4), Mid (all remaining samples, Q2 and Q3)) based on microarray expression values. Survival will be plotted on the Y-axis and time on the X-axis.","title":"Expression Survival"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/Methylation/","text":"Methylation views DNA methylation is an epigenetic mark that plays a regulatory role in multiple biological processes and diseases. In the Land Explorer, users can visualize methylation level of genes, at high resolution and in a large number of samples. Methylation Beta Value This view shows methylation beta value, one chart for each probe, for the specified gene. Each dot on the plot represents an individual sample, and the plot is organized on the y-axis by the primary grouping (e.g. tumor type). The methylation value is shown on the x-axis:","title":"Methylation"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/Methylation/#methylation-views","text":"DNA methylation is an epigenetic mark that plays a regulatory role in multiple biological processes and diseases. In the Land Explorer, users can visualize methylation level of genes, at high resolution and in a large number of samples.","title":"Methylation views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/Methylation/#methylation-beta-value","text":"This view shows methylation beta value, one chart for each probe, for the specified gene. Each dot on the plot represents an individual sample, and the plot is organized on the y-axis by the primary grouping (e.g. tumor type). The methylation value is shown on the x-axis:","title":"Methylation Beta Value"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/OmicDataIntegrationViews/","text":"Integration views Omicsoft Lands have a number of OmicData types (such as copy number variation, expression and mutation data). In addition to viewing individual data types for samples, users can easily integrate these data types in integration views in Land Explorer. For example, users may be interested in whether a gene's copy number status correlates with its expression status. Alternatively, one may be interested in how well microarray and RNA-seq expression values of a gene correlate (where available). Microarray Expression vs. RNA-seq Expression This view shows a single chart, for each gene, comparing Gene Expression Ratio (Sample vs Universal Human Reference) vs Gene Expression (Log2(RPKM + 0.1)). A value of 0.1 has been added to every RPKM value in order to log the data and account for potential values of 0. Copy Number Variation (CNV) vs. RNA-seq Expression This view shows a single chart, for each gene, comparing Gene Expression Ratio (Sample vs Universal Human Reference) vs Average Copy Number Log2 Ratio. By default, all sample types (tumor and normal) are shown, users could visualize a geneset (multiple genes), and choose grouping by Tumor Type, Sample ID, Sample Type, Disease, etc. Copy Number Variation (CNV) vs Microarray Expression Similar to the CNV vs RNA-Seq Expression view, when CNV and Microarray data is available for a gene, pairwise comparison of the two data points (y- and x-axis, respectively) can be done to see if there is a correlation between copy number and expression: CNV Expression Ratio CNV Expression Ratio view shows a single chart, for each gene, comparing Gene Expression (e.g. Sample vs Universal Human Reference) vs Average Copy Number Log2Ratio. CNV RNA-Seq Expression CNV RNA-Seq expression view shows a single chart, for each gene, comparing Gene Expression (RPKM) vs Average Copy Number Log2 Ratio.","title":"Integration"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/OmicDataIntegrationViews/#integration-views","text":"Omicsoft Lands have a number of OmicData types (such as copy number variation, expression and mutation data). In addition to viewing individual data types for samples, users can easily integrate these data types in integration views in Land Explorer. For example, users may be interested in whether a gene's copy number status correlates with its expression status. Alternatively, one may be interested in how well microarray and RNA-seq expression values of a gene correlate (where available).","title":"Integration views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/OmicDataIntegrationViews/#microarray-expression-vs-rna-seq-expression","text":"This view shows a single chart, for each gene, comparing Gene Expression Ratio (Sample vs Universal Human Reference) vs Gene Expression (Log2(RPKM + 0.1)). A value of 0.1 has been added to every RPKM value in order to log the data and account for potential values of 0.","title":"Microarray Expression vs. RNA-seq Expression"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/OmicDataIntegrationViews/#copy-number-variation-cnv-vs-rna-seq-expression","text":"This view shows a single chart, for each gene, comparing Gene Expression Ratio (Sample vs Universal Human Reference) vs Average Copy Number Log2 Ratio. By default, all sample types (tumor and normal) are shown, users could visualize a geneset (multiple genes), and choose grouping by Tumor Type, Sample ID, Sample Type, Disease, etc.","title":"Copy Number Variation (CNV) vs. RNA-seq Expression"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/OmicDataIntegrationViews/#copy-number-variation-cnv-vs-microarray-expression","text":"Similar to the CNV vs RNA-Seq Expression view, when CNV and Microarray data is available for a gene, pairwise comparison of the two data points (y- and x-axis, respectively) can be done to see if there is a correlation between copy number and expression:","title":"Copy Number Variation (CNV) vs Microarray Expression"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/OmicDataIntegrationViews/#cnv-expression-ratio","text":"CNV Expression Ratio view shows a single chart, for each gene, comparing Gene Expression (e.g. Sample vs Universal Human Reference) vs Average Copy Number Log2Ratio.","title":"CNV Expression Ratio"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/OmicDataIntegrationViews/#cnv-rna-seq-expression","text":"CNV RNA-Seq expression view shows a single chart, for each gene, comparing Gene Expression (RPKM) vs Average Copy Number Log2 Ratio.","title":"CNV RNA-Seq Expression"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/Proteomics/","text":"Proteomics views In addition to visualizing RNA-seq and microarray expression data, the Land Explorer can be used to visualize data from proteomics assays, such as Reverse Phase Proteomics Array (RPPA) and Mass Spectrometry (MS). RPPA Heatmap The RPPA Heatmap view shows reverse phase protein array ratio (sample vs universal human reference) for multiple genes. Each gene searched is identified by column, while each sample is represented as a row. RPPA data was only generated for a subset of proteins, so this view may not be available for many genes searched. RPPA_RBN Heatmap This heatmap RPPA_RBN view shows reverse phase protein array ratio (sample vs universal human reference) for group (e.g. Tumor type) for multiple genes, with replicate-based normalization for cross-tumor comparisons (RBN). Each gene searched is identified by column, while each sample is represented as a row. RPPA data was only generated for a subset of genes, so this view may not be available for many genes.","title":"Proteomics"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/Proteomics/#proteomics-views","text":"In addition to visualizing RNA-seq and microarray expression data, the Land Explorer can be used to visualize data from proteomics assays, such as Reverse Phase Proteomics Array (RPPA) and Mass Spectrometry (MS).","title":"Proteomics views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/Proteomics/#rppa-heatmap","text":"The RPPA Heatmap view shows reverse phase protein array ratio (sample vs universal human reference) for multiple genes. Each gene searched is identified by column, while each sample is represented as a row. RPPA data was only generated for a subset of proteins, so this view may not be available for many genes searched.","title":"RPPA Heatmap"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/Proteomics/#rppa_rbn-heatmap","text":"This heatmap RPPA_RBN view shows reverse phase protein array ratio (sample vs universal human reference) for group (e.g. Tumor type) for multiple genes, with replicate-based normalization for cross-tumor comparisons (RBN). Each gene searched is identified by column, while each sample is represented as a row. RPPA data was only generated for a subset of genes, so this view may not be available for many genes.","title":"RPPA_RBN Heatmap"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/","text":"RNA SEQ Fusion RNASeq Fusion (RPKM) View Note This view is available only when searching for a single gene. This view shows a series of charts of potential fusions for the specified gene or genes. X-axis represents Fusion RPKM. RPKM is defined as seed reads per kilobase of seed region and per million mapped reads. Y-axis is organized by grouping (e.g. Tumor Type). Use the Sample tab to further filter the data using any associated sample/subject meta data. Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Suggested filters would be SplicePatternClass (remove non-canonical junctions), FrameShiftClass (remove frame shift and undefined fusions) and OnExonBoundary (look for fusions where both ends of fusion are on the exon boundary). Potential real fusions are not likely to be in many normal samples. As a result, coloring has been automatically set to Sample Type. Select Fusions in the plot and choose Fusion Details to see the full table for selected fusion. RNA-Seq Paired End Fusion (Alteration Frequency) The RNA-Seq Paired End Fusion (Alteration Frequency) view shows the specified paired end fusion gene in a single chart, organized by Group (e.g. Tumor Type). X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion. RNA-Seq Paired End Fusion (GenePair Frequency) The RNA-Seq Paired End FUsion (GenePair Frequency) view shows each paired end fusion gene pair in a single chart, organized by Group (e.g. Tumor Type). X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples. Use the Grouping option to change grouping. Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion. RNA-Seq Fusion (Site Frequency) The RNA-Seq Fusion (Site Frequency) view shows each fusion in a single chart, organized by Group (e.g. Tumor Type). X-axis shows percent of samples with the fusion, while Y-axis shows the group. By using the Sample Tab, users could apply filters to samples, and click the Grouping button to change grouping option. Under the Fusion tab, users could apply filters to the shown fusion options. By default, all potential fusions for quried genes would be shown, however potential real fusions are not likely to be in many normal samples. RNA-Seq Fusion (GenePair Frequency) The RNA-Seq Fusion (GenePair Frequency) view shows each fusion gene pair in a single chart, organized by Group (e.g. Tumor Type). X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. RNA-Seq Fusion (GenePair Count) The RNA-Seq Fusion (GenePair Count) summary view shows the count of fusion samples with each fusion gene pair, colored by Group (e.g. Tumor Type). X-Axis shows count of samples with the fusion, while Y-axis shows the fusion gene pairs. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion. RNA-Seq Fusion (Alteration Frequency) The RNA-Seq fusion (Alteration Frequency) summary view shows the percentage of samples having the fusion for the gene in a single chart. X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion.","title":"RNA-Seq Fusion"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rna-seq-fusion","text":"","title":"RNA SEQ Fusion"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rnaseq-fusion-rpkm-view","text":"Note This view is available only when searching for a single gene. This view shows a series of charts of potential fusions for the specified gene or genes. X-axis represents Fusion RPKM. RPKM is defined as seed reads per kilobase of seed region and per million mapped reads. Y-axis is organized by grouping (e.g. Tumor Type). Use the Sample tab to further filter the data using any associated sample/subject meta data. Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Suggested filters would be SplicePatternClass (remove non-canonical junctions), FrameShiftClass (remove frame shift and undefined fusions) and OnExonBoundary (look for fusions where both ends of fusion are on the exon boundary). Potential real fusions are not likely to be in many normal samples. As a result, coloring has been automatically set to Sample Type. Select Fusions in the plot and choose Fusion Details to see the full table for selected fusion.","title":"RNASeq Fusion (RPKM) View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rna-seq-paired-end-fusion-alteration-frequency","text":"The RNA-Seq Paired End Fusion (Alteration Frequency) view shows the specified paired end fusion gene in a single chart, organized by Group (e.g. Tumor Type). X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion.","title":"RNA-Seq Paired End Fusion (Alteration Frequency)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rna-seq-paired-end-fusion-genepair-frequency","text":"The RNA-Seq Paired End FUsion (GenePair Frequency) view shows each paired end fusion gene pair in a single chart, organized by Group (e.g. Tumor Type). X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples. Use the Grouping option to change grouping. Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion.","title":"RNA-Seq Paired End Fusion (GenePair Frequency)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rna-seq-fusion-site-frequency","text":"The RNA-Seq Fusion (Site Frequency) view shows each fusion in a single chart, organized by Group (e.g. Tumor Type). X-axis shows percent of samples with the fusion, while Y-axis shows the group. By using the Sample Tab, users could apply filters to samples, and click the Grouping button to change grouping option. Under the Fusion tab, users could apply filters to the shown fusion options. By default, all potential fusions for quried genes would be shown, however potential real fusions are not likely to be in many normal samples.","title":"RNA-Seq Fusion (Site Frequency)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rna-seq-fusion-genepair-frequency","text":"The RNA-Seq Fusion (GenePair Frequency) view shows each fusion gene pair in a single chart, organized by Group (e.g. Tumor Type). X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown.","title":"RNA-Seq Fusion (GenePair Frequency)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rna-seq-fusion-genepair-count","text":"The RNA-Seq Fusion (GenePair Count) summary view shows the count of fusion samples with each fusion gene pair, colored by Group (e.g. Tumor Type). X-Axis shows count of samples with the fusion, while Y-axis shows the fusion gene pairs. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion.","title":"RNA-Seq Fusion (GenePair Count)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqFusion/#rna-seq-fusion-alteration-frequency","text":"The RNA-Seq fusion (Alteration Frequency) summary view shows the percentage of samples having the fusion for the gene in a single chart. X-Axis shows percent of samples with the fusion, while Y-axis shows the group. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Fusion tab to filter the shown fusions. By default, all potential fusions are shown. Potential real fusions are not likely to be in many normal samples. Select bars in the plot and choose Fusion Details to see the full table for selected fusion.","title":"RNA-Seq Fusion (Alteration Frequency)"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqSomaticMutation/","text":"RNA-Seq Mutation Views RNA-Seq Somatic Mutation Distribution Similar to the DNA Somatic Mutation Distribution View , this view displays histograms of RNA-Seq Somatic Mutation Distribution or RNA-seq Mutation Distribution. In this view, mutation events will be calculated as a percentage of affected samples in each group. As you can see in the view below, for the gene EGR1, only mutations are plotted. In the legend, a full description of the type of mutation (INDEL, Deletion, Substitution) will be displayed. The x-Axis shows the percent of mutant samples, while the samples are grouped on the X-axis by the grouping column. Only groups with any mutations available in that gene will be plotted in the view. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Mutation tab to filter for specific Amino Acid mutation (OS_AAMutation), Annotation Type (i.e non-synonymous via OS_AnnotationType) and more. For more information on filtering in Land Explorer, please see the filtering guide Select one or more bars from the plot and choose Details for Selection to find out more details on the selected samples. Note : In different Lands, RNA-seq mutation data will be presented as RNA-Seq Somatic Mutation or RNA-Seq Mutation. This reflects the difference in mutation calling. For Somatic Mutation calls, matched normal samples can be used to filter out the germline variants. For RNA-seq Mutation calls, no matched normals are available. In this case, since variation from germline is not filtered, there may be more mutations seen in this view: RNA-Seq Somatic Mutation Distribution by Gene For multi-gene searches, all RNA-Seq mutation data will be compared for the genes in the search to identify samples with a mutation in any of the genes queried using the Somatic Mutation Distribution View. If a user is interested in the per-gene distribution of samples (rather than compounded distribution), the \"Somatic Mutation Distribution By Gene\" will generate one chart per gene queried. RNA-Seq Mutation Pattern The RNA-Seq somatic mutation pattern view shows a bar plot with the number of mutations matching a particular pattern for the specified gene set across a grouping (e.g. Tumor Type/sample type). X-axis shows the number of mutations matching the pattern, while Y-axis shows the grouping. RNA-Seq Mutation Site Distribution Similar to the DNA Somatic Mutation Site Distribution View , this view for RNA-seq mutation data will plot the RNA-seq mutations for each gene queried: All alleles identified for that gene will be represented on the x-axis as a unique color in the plot. As for the gene-level distributions for RNA-seq mutations, this can be displayed for RNA-seq Somatic mutation and RNA-seq Mutation data. RNA-Seq Somatic Mutation Gene Pattern","title":"RNA-Seq Mutation"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqSomaticMutation/#rna-seq-mutation-views","text":"","title":"RNA-Seq Mutation Views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqSomaticMutation/#rna-seq-somatic-mutation-distribution","text":"Similar to the DNA Somatic Mutation Distribution View , this view displays histograms of RNA-Seq Somatic Mutation Distribution or RNA-seq Mutation Distribution. In this view, mutation events will be calculated as a percentage of affected samples in each group. As you can see in the view below, for the gene EGR1, only mutations are plotted. In the legend, a full description of the type of mutation (INDEL, Deletion, Substitution) will be displayed. The x-Axis shows the percent of mutant samples, while the samples are grouped on the X-axis by the grouping column. Only groups with any mutations available in that gene will be plotted in the view. Use the Sample Tab to change filtering options on the samples (or to change grouping). Use the Mutation tab to filter for specific Amino Acid mutation (OS_AAMutation), Annotation Type (i.e non-synonymous via OS_AnnotationType) and more. For more information on filtering in Land Explorer, please see the filtering guide Select one or more bars from the plot and choose Details for Selection to find out more details on the selected samples. Note : In different Lands, RNA-seq mutation data will be presented as RNA-Seq Somatic Mutation or RNA-Seq Mutation. This reflects the difference in mutation calling. For Somatic Mutation calls, matched normal samples can be used to filter out the germline variants. For RNA-seq Mutation calls, no matched normals are available. In this case, since variation from germline is not filtered, there may be more mutations seen in this view:","title":"RNA-Seq Somatic Mutation Distribution"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqSomaticMutation/#rna-seq-somatic-mutation-distribution-by-gene","text":"For multi-gene searches, all RNA-Seq mutation data will be compared for the genes in the search to identify samples with a mutation in any of the genes queried using the Somatic Mutation Distribution View. If a user is interested in the per-gene distribution of samples (rather than compounded distribution), the \"Somatic Mutation Distribution By Gene\" will generate one chart per gene queried.","title":"RNA-Seq Somatic Mutation Distribution by Gene"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqSomaticMutation/#rna-seq-mutation-pattern","text":"The RNA-Seq somatic mutation pattern view shows a bar plot with the number of mutations matching a particular pattern for the specified gene set across a grouping (e.g. Tumor Type/sample type). X-axis shows the number of mutations matching the pattern, while Y-axis shows the grouping.","title":"RNA-Seq Mutation Pattern"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqSomaticMutation/#rna-seq-mutation-site-distribution","text":"Similar to the DNA Somatic Mutation Site Distribution View , this view for RNA-seq mutation data will plot the RNA-seq mutations for each gene queried: All alleles identified for that gene will be represented on the x-axis as a unique color in the plot. As for the gene-level distributions for RNA-seq mutations, this can be displayed for RNA-seq Somatic mutation and RNA-seq Mutation data.","title":"RNA-Seq Mutation Site Distribution"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RNASeqSomaticMutation/#rna-seq-somatic-mutation-gene-pattern","text":"","title":"RNA-Seq Somatic Mutation Gene Pattern"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/","text":"RNA-Seq Quantification Views RNA-Seq data that has been processed into land can be visualized to determine expression of a gene across various sample types, as well as differential transcript usage, and survival data (when available). Users can search for the expression of a single gene or multiple genes. Land Explorer will generate views specific to these types of searches. Single gene RNA-seq Quantification views Summary Gene FPKM Easily search samples in Land that have a minimal up- or down-regulation for a gene of interest. For each gene, this view shows % of disease samples whose RNA-Seq expression is 2x up-regulated or 2x down-regulated, compared to normal samples in each group (e.g. Tumor Type). Samples are grouped by the primary grouping category by default. View Navigation For each group, expression for normal samples is calculated as the average of Log2(FPKM + 0.1). For each tumor (disease) sample, when the Log2(FPKM + 0.1) value is larger than normal sample average by ExpressionUpRegulationCutoff or is smaller than normal average by ExpressionDownRegulationCutoff, this tumor sample is counted as up-regulated or down-regulated. The percentage showing on X axis = ( # of tumor samples up-regulated or down-regulated) / ( # of all tumor samples in this group). Key Filters Fold change cutoff can be changed under Expression in the left panel. Gene FPKM View The Log2(FPKM + 0.1) expression of any gene can be visualized in this view. Expression is plotted on the x-axis and samples grouped on the y-axis by the chosen Grouping column in the metadata. In the below screenshot fgf2 expression is plotted on the x-axis and samples are grouped by Sample Type (Tumor or Normal). Each dot represents a single sample: Transcript FPKM View This view shows the Transcript RPKM (Reads Per Kilobase per Million mapped reads) for the specified gene, organized by group (e.g. Tumor Type). Each transcript is shown in a separate chart. When visualizing more than one gene, all transcripts (all genes) will be represented in individual plots. The X-axis shows Transcript RPKM while the Y-axis shows the group. RNA-Seq Survival View In this view, when survival data is available and attributed to samples within the land, such as within OncoLand studies (TCGA, OncoGEO, etc.), a survival view will be generated. Samples will be grouped into quartiles (Up, upper 25% (Q1) expression of gene, Down, lower 25% (Q4), Mid (all remaining samples, Q2 and Q3)). Survival will be plotted on the Y-axis and time on the X-axis. Multi-gene RNA-seq Quantification views Average FPKM View When a user searches multiple genes, the default expression view will be the average FPKM view, where the expression of all genes searched is averaged for each sample. Each dot in the plot will represent a single sample, with expression plotted on the x-axis and samples grouped on the y-axis by the designated grouping category. The Multi-gene correlation (RNA-Seq FPKM) view shows a scatter view comparing the RNA-Seq RPKM data for two or more genes. Multi-gene Correlation (RNA-Seq FPKM) View For two genes, the X-Axis will be the first gene, while the Y-axis will be the second gene. For 3 or more genes, the view will show a multi-chart correlation plot. Multi-gene Variable (FPKM) View Similar to the gene FPKM view when searching a single gene, this view will generate plot expression on the x-axis and samples grouped on the y-axis by the GeneID. This grouping can be changed to reflect gene metadata. Trellising the view by metadata may provide better visualization of the gene expression. Values plotted are Log2(FPKM + 0.1). Transcript FPKM (Multi-Transcript Chart) View The multi transciprt FPKM view shows Transcript RPKM for all transcripts for the specified gene, organized by group (e.g. Tumor Type/Sample Type/etc.) in a single chart. Each bar represents a separate group, while each transcript is organized on the Y-axis. In this view, users could choose to filter samples by a particular disease type, and then change the grouping option to Sample Type to compare Tumor vs. Normal. Multi-gene search: Heatmap FPKM View Another way to visualize the expression of multiple genes is in a heatmap view. The Heatmap FPKM view allows users to visualize the expression of all genes (columns) by all samples filtered (rows). Unbiased heirarchial clustering of genes and samples allows users to find genes or samples that may exhibit similar gene signatures.","title":"RNA-Seq Quantification"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#rna-seq-quantification-views","text":"RNA-Seq data that has been processed into land can be visualized to determine expression of a gene across various sample types, as well as differential transcript usage, and survival data (when available). Users can search for the expression of a single gene or multiple genes. Land Explorer will generate views specific to these types of searches.","title":"RNA-Seq Quantification Views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#single-gene-rna-seq-quantification-views","text":"","title":"Single gene RNA-seq Quantification views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#summary-gene-fpkm","text":"Easily search samples in Land that have a minimal up- or down-regulation for a gene of interest. For each gene, this view shows % of disease samples whose RNA-Seq expression is 2x up-regulated or 2x down-regulated, compared to normal samples in each group (e.g. Tumor Type). Samples are grouped by the primary grouping category by default.","title":"Summary Gene FPKM"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#view-navigation","text":"For each group, expression for normal samples is calculated as the average of Log2(FPKM + 0.1). For each tumor (disease) sample, when the Log2(FPKM + 0.1) value is larger than normal sample average by ExpressionUpRegulationCutoff or is smaller than normal average by ExpressionDownRegulationCutoff, this tumor sample is counted as up-regulated or down-regulated. The percentage showing on X axis = ( # of tumor samples up-regulated or down-regulated) / ( # of all tumor samples in this group).","title":"View Navigation"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#key-filters","text":"Fold change cutoff can be changed under Expression in the left panel.","title":"Key Filters"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#gene-fpkm-view","text":"The Log2(FPKM + 0.1) expression of any gene can be visualized in this view. Expression is plotted on the x-axis and samples grouped on the y-axis by the chosen Grouping column in the metadata. In the below screenshot fgf2 expression is plotted on the x-axis and samples are grouped by Sample Type (Tumor or Normal). Each dot represents a single sample:","title":"Gene FPKM View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#transcript-fpkm-view","text":"This view shows the Transcript RPKM (Reads Per Kilobase per Million mapped reads) for the specified gene, organized by group (e.g. Tumor Type). Each transcript is shown in a separate chart. When visualizing more than one gene, all transcripts (all genes) will be represented in individual plots. The X-axis shows Transcript RPKM while the Y-axis shows the group.","title":"Transcript FPKM View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#rna-seq-survival-view","text":"In this view, when survival data is available and attributed to samples within the land, such as within OncoLand studies (TCGA, OncoGEO, etc.), a survival view will be generated. Samples will be grouped into quartiles (Up, upper 25% (Q1) expression of gene, Down, lower 25% (Q4), Mid (all remaining samples, Q2 and Q3)). Survival will be plotted on the Y-axis and time on the X-axis.","title":"RNA-Seq Survival View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#multi-gene-rna-seq-quantification-views","text":"","title":"Multi-gene RNA-seq Quantification views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#average-fpkm-view","text":"When a user searches multiple genes, the default expression view will be the average FPKM view, where the expression of all genes searched is averaged for each sample. Each dot in the plot will represent a single sample, with expression plotted on the x-axis and samples grouped on the y-axis by the designated grouping category. The Multi-gene correlation (RNA-Seq FPKM) view shows a scatter view comparing the RNA-Seq RPKM data for two or more genes.","title":"Average FPKM View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#multi-gene-correlation-rna-seq-fpkm-view","text":"For two genes, the X-Axis will be the first gene, while the Y-axis will be the second gene. For 3 or more genes, the view will show a multi-chart correlation plot.","title":"Multi-gene Correlation (RNA-Seq FPKM) View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#multi-gene-variable-fpkm-view","text":"Similar to the gene FPKM view when searching a single gene, this view will generate plot expression on the x-axis and samples grouped on the y-axis by the GeneID. This grouping can be changed to reflect gene metadata. Trellising the view by metadata may provide better visualization of the gene expression. Values plotted are Log2(FPKM + 0.1).","title":"Multi-gene Variable (FPKM) View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#transcript-fpkm-multi-transcript-chart-view","text":"The multi transciprt FPKM view shows Transcript RPKM for all transcripts for the specified gene, organized by group (e.g. Tumor Type/Sample Type/etc.) in a single chart. Each bar represents a separate group, while each transcript is organized on the Y-axis. In this view, users could choose to filter samples by a particular disease type, and then change the grouping option to Sample Type to compare Tumor vs. Normal.","title":"Transcript FPKM (Multi-Transcript Chart) View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/RnaSeqQuantification/#multi-gene-search-heatmap-fpkm-view","text":"Another way to visualize the expression of multiple genes is in a heatmap view. The Heatmap FPKM view allows users to visualize the expression of all genes (columns) by all samples filtered (rows). Unbiased heirarchial clustering of genes and samples allows users to find genes or samples that may exhibit similar gene signatures.","title":"Multi-gene search: Heatmap FPKM View"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/miRNA_views/","text":"miRNA views Users can use the search bar at the top of the screen to identify data associated with microRNAs (miRNAs) within the land. For single miRNA searches, miRNA reads are displayed in a variable view, while searching for multiple miRNAs will display a heatmap view of miRNA expression. In both cases, miRNA expression values are normalized by miRNA per million read counts. Single miRNA searches Searching for a single miRNA, such as MIR-126 in the search bar, the default view will be a variable view representing each sample in the plot as miRNA per million reads (on the x-axis). Samples will be grouped on the y-axis by the primary grouping (Disease Category by default in DiseaseLands): Multiple miRNA searches Searching for multiple miRNAs, such as MIR-126, MIR-101, LET-7 in the search bar, the default view be the same as above will be a variable view representing each sample in the plot as miRNA per million reads (on the x-axis). Simply scroll up and down to see expression of each miRNA. Another view that can be used for visualizing the expression of multiple miRNAs is the Heatmap view. In the example below, filtering to a smaller number of samples (Disease Category: Metabolic disease) will help visualize how these three miRNAs are expressed within these samples:","title":"miRNA-Seq"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/miRNA_views/#mirna-views","text":"Users can use the search bar at the top of the screen to identify data associated with microRNAs (miRNAs) within the land. For single miRNA searches, miRNA reads are displayed in a variable view, while searching for multiple miRNAs will display a heatmap view of miRNA expression. In both cases, miRNA expression values are normalized by miRNA per million read counts.","title":"miRNA views"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/miRNA_views/#single-mirna-searches","text":"Searching for a single miRNA, such as MIR-126 in the search bar, the default view will be a variable view representing each sample in the plot as miRNA per million reads (on the x-axis). Samples will be grouped on the y-axis by the primary grouping (Disease Category by default in DiseaseLands):","title":"Single miRNA searches"},{"location":"tutorials/Land Explorer/Land Views/Gene Level Views/miRNA_views/#multiple-mirna-searches","text":"Searching for multiple miRNAs, such as MIR-126, MIR-101, LET-7 in the search bar, the default view be the same as above will be a variable view representing each sample in the plot as miRNA per million reads (on the x-axis). Simply scroll up and down to see expression of each miRNA. Another view that can be used for visualizing the expression of multiple miRNAs is the Heatmap view. In the example below, filtering to a smaller number of samples (Disease Category: Metabolic disease) will help visualize how these three miRNAs are expressed within these samples:","title":"Multiple miRNA searches"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Comparison_Availability/","text":"Comparison Availability This view shows all pre-computed comparisons present in the Land. In TCGA land, this will typically be all Tumor vs Normal (where available) comparisons. In 2018, the Omicsoft OncoLand team has added a number of comparisons to reflect the mutation status of genes represented in the QIA-seq Cancer Panels . In DiseaseLands and OncoGEO, this can refer to multiple comparison types (i.e. Disease vs. Normal, Treatment vs. Control, Response vs no response, pre-treatment vs post-treatment). In this view, users can quickly query the different comparisons available within the Land, based on the category shown on the x-axis.","title":"Comparison Availability"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Comparison_Availability/#comparison-availability","text":"This view shows all pre-computed comparisons present in the Land. In TCGA land, this will typically be all Tumor vs Normal (where available) comparisons. In 2018, the Omicsoft OncoLand team has added a number of comparisons to reflect the mutation status of genes represented in the QIA-seq Cancer Panels . In DiseaseLands and OncoGEO, this can refer to multiple comparison types (i.e. Disease vs. Normal, Treatment vs. Control, Response vs no response, pre-treatment vs post-treatment). In this view, users can quickly query the different comparisons available within the Land, based on the category shown on the x-axis.","title":"Comparison Availability"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Comparisons/","text":"Comparison views This view shows all pre-computed comparisons present in the Land. In TCGA land, this will typically be all Tumor vs Normal (where available) comparisons. In DiseaseLands and OncoGEO, this can refer to multiple comparison types (i.e. Disease vs. Normal, Treatment vs. Control, Response vs no response, pre-treatment vs post-treatment). In this view, users can quickly query the different comparisons available within the Land, based on the category shown on the x-axis. General Options This view, like all views in Land Explorer, is highly customizable. Users can filter to samples of interest using columns from the ProjectName and Case vs. Control options. These columns can also be used to determine the primary grouping (what will be plotted on the Y-axis). For example, to see what skin cancer samples are available in TCGA, users can filter to the specific tumor types (ACC, BRCA, CODA, and ESCA, etc), and use Case.TissueCategory to group the samples: Chart Options The bars in the distribution views are interactive. Users can simply click on a bar of interest to get a table view of the metadata: This table can easily be exported to excel with the click of a button (located at the top of the table). Users can also simplify the table by removing columns from the view using the \"Select Columns\" button. For additional customizations of the views in Land Explorer, please see our documentation here","title":"Comparisons"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Comparisons/#comparison-views","text":"This view shows all pre-computed comparisons present in the Land. In TCGA land, this will typically be all Tumor vs Normal (where available) comparisons. In DiseaseLands and OncoGEO, this can refer to multiple comparison types (i.e. Disease vs. Normal, Treatment vs. Control, Response vs no response, pre-treatment vs post-treatment). In this view, users can quickly query the different comparisons available within the Land, based on the category shown on the x-axis.","title":"Comparison views"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Comparisons/#general-options","text":"This view, like all views in Land Explorer, is highly customizable. Users can filter to samples of interest using columns from the ProjectName and Case vs. Control options. These columns can also be used to determine the primary grouping (what will be plotted on the Y-axis). For example, to see what skin cancer samples are available in TCGA, users can filter to the specific tumor types (ACC, BRCA, CODA, and ESCA, etc), and use Case.TissueCategory to group the samples:","title":"General Options"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Comparisons/#chart-options","text":"The bars in the distribution views are interactive. Users can simply click on a bar of interest to get a table view of the metadata: This table can easily be exported to excel with the click of a button (located at the top of the table). Users can also simplify the table by removing columns from the view using the \"Select Columns\" button. For additional customizations of the views in Land Explorer, please see our documentation here","title":"Chart Options"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Data_Availability/","text":"Data Availability This view shows all sample information and \"Omic\"data available in the current Land. In TCGA land, this will typically show a table of all data available where each row represents one Tumor Type (ACC, BLCA, COAD, etc.), and each column shows -OmicData (CNV, DNA, MS, miRNA, etc.). In DiseaseLands and OncoGEO, each row of the table would represent Disease Category (i.e. allergy, arthritis, autoimmune disease, benign neoplasm, etc.), each column would show -Omic data (i.e. Expression, Methylation, miRNA, RNA-seq, etc.). In this view, users can quickly check the sample category and the -Omic data available within the Land, based on the category shown on the rows and cols.","title":"Data Availability"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Data_Availability/#data-availability","text":"This view shows all sample information and \"Omic\"data available in the current Land. In TCGA land, this will typically show a table of all data available where each row represents one Tumor Type (ACC, BLCA, COAD, etc.), and each column shows -OmicData (CNV, DNA, MS, miRNA, etc.). In DiseaseLands and OncoGEO, each row of the table would represent Disease Category (i.e. allergy, arthritis, autoimmune disease, benign neoplasm, etc.), each column would show -Omic data (i.e. Expression, Methylation, miRNA, RNA-seq, etc.). In this view, users can quickly check the sample category and the -Omic data available within the Land, based on the category shown on the rows and cols.","title":"Data Availability"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Sample_Details/","text":"Sample Details View This view shows all sample information and -Omic data available in the current Land. In TCGA land for example, this view will typically show a table of all data available where each row represents one Sample, and each column shows metadata (Tumor Type, Sample Type, Disease, Disease State, etc.). In this view, users can quickly check the sample category and the meta data available within the Land, and export this to Excel with a click of a button:","title":"Sample Details"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Sample_Details/#sample-details-view","text":"This view shows all sample information and -Omic data available in the current Land. In TCGA land for example, this view will typically show a table of all data available where each row represents one Sample, and each column shows metadata (Tumor Type, Sample Type, Disease, Disease State, etc.). In this view, users can quickly check the sample category and the meta data available within the Land, and export this to Excel with a click of a button:","title":"Sample Details View"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Samples/","text":"Distribution views Omicsoft curators manually curate all projects that are found within the Land, using a controlled vocabulary at the sample, comparison and project level. Users of Land Explorer can use Distribution views to quickly visualize and filter data using the defined metadata. These pages will describe three basic distribution views for browsing Land Data. Sample Distribution The sample distribution view is the default view of all Lands. The view is a stacked bar graph plotting all samples within the Land, grouping the samples on the y-axis by the primary grouping column and coloring the samples on the x-axis using the secondary grouping column. In TCGA land, this will correspond to Tumor type on the Y-axis and Sample type on the X-axis: General Options This view, like all views in Array Suite, is highly customizable. Users can filter to samples of interest using columns from the MetaData and Clinical Data. These columns can also be used to determine the primary grouping (what will be plotted on the Y-axis). For example, to see what skin cancer samples are available in TCGA, users can filter to a specific tumor type (SKCM), and use Sample Type to group the samples: Chart Options The bars in the distribution views are interactive. Users can simply click on a bar of interest to get a table view of the metadata: This table can easily be exported to excel with the click of a button (located at the top of the table). Users can also simplify the table by removing columns from the view using the \"Select Columns\" button. For additional customizations of the views in Land Explorer, please see our documentation here Comparison Distribution This view shows all pre-computed comparisons present in the Land. In TCGA land, this will typically be all Tumor vs Normal (where available) comparisons. In 2018, the Omicsoft OncoLand team has added a number of comparisons to reflect the mutation status of genes represented in the QIA-seq Cancer Panels . In DiseaseLands and OncoGEO, this can refer to multiple comparison types (i.e. Disease vs. Normal, Treatment vs. Control, Response vs no response, pre-treatment vs post-treatment). In this view, users can quickly query the different comparisons available within the Land, based on the category shown on the x-axis. Project Distribution In lands that comprise of many projects, such as OncoGEO, HumanDisease and MouseDisease, another useful view to identify specific projects is the project distribution view. In this view, all projects are plotted on the x-axis and categorized on the y-axis by the Therapeutic area, or general disease focus.","title":"Distribution Views"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Samples/#distribution-views","text":"Omicsoft curators manually curate all projects that are found within the Land, using a controlled vocabulary at the sample, comparison and project level. Users of Land Explorer can use Distribution views to quickly visualize and filter data using the defined metadata. These pages will describe three basic distribution views for browsing Land Data.","title":"Distribution views"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Samples/#sample-distribution","text":"The sample distribution view is the default view of all Lands. The view is a stacked bar graph plotting all samples within the Land, grouping the samples on the y-axis by the primary grouping column and coloring the samples on the x-axis using the secondary grouping column. In TCGA land, this will correspond to Tumor type on the Y-axis and Sample type on the X-axis:","title":"Sample Distribution"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Samples/#general-options","text":"This view, like all views in Array Suite, is highly customizable. Users can filter to samples of interest using columns from the MetaData and Clinical Data. These columns can also be used to determine the primary grouping (what will be plotted on the Y-axis). For example, to see what skin cancer samples are available in TCGA, users can filter to a specific tumor type (SKCM), and use Sample Type to group the samples:","title":"General Options"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Samples/#chart-options","text":"The bars in the distribution views are interactive. Users can simply click on a bar of interest to get a table view of the metadata: This table can easily be exported to excel with the click of a button (located at the top of the table). Users can also simplify the table by removing columns from the view using the \"Select Columns\" button. For additional customizations of the views in Land Explorer, please see our documentation here","title":"Chart Options"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Samples/#comparison-distribution","text":"This view shows all pre-computed comparisons present in the Land. In TCGA land, this will typically be all Tumor vs Normal (where available) comparisons. In 2018, the Omicsoft OncoLand team has added a number of comparisons to reflect the mutation status of genes represented in the QIA-seq Cancer Panels . In DiseaseLands and OncoGEO, this can refer to multiple comparison types (i.e. Disease vs. Normal, Treatment vs. Control, Response vs no response, pre-treatment vs post-treatment). In this view, users can quickly query the different comparisons available within the Land, based on the category shown on the x-axis.","title":"Comparison Distribution"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Samples/#project-distribution","text":"In lands that comprise of many projects, such as OncoGEO, HumanDisease and MouseDisease, another useful view to identify specific projects is the project distribution view. In this view, all projects are plotted on the x-axis and categorized on the y-axis by the Therapeutic area, or general disease focus.","title":"Project Distribution"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Survival_Data/","text":"Survival Data View This view shows plot of percent survival across time (Kaplan-meier Survival Curve) using a specified grouping (e.g. Tumor Type or Disease). The y-axis will represent the percentage of subjects alive, while the x-axis represents time (in days).","title":"Survival Data"},{"location":"tutorials/Land Explorer/Land Views/Sample Level Views/Survival_Data/#survival-data-view","text":"This view shows plot of percent survival across time (Kaplan-meier Survival Curve) using a specified grouping (e.g. Tumor Type or Disease). The y-axis will represent the percentage of subjects alive, while the x-axis represents time (in days).","title":"Survival Data View"},{"location":"tutorials/Land Explorer/Using Land Explorer/Customizations/","text":"Customizing Available Land Views Users of Array Studio are familiar with many of the available Land Views that can be used to visualize data. The Land Explorer is fully customizable to provide many of the rich visualizations of Array Studio, or simplified with a minimal number of key views. The customizations can be performed by specific users within Land Explorer, or by the administrator of Land Explorer for all users. User-defined Land Explorer views By default, for each type of view (i.e. Sample, Gene, Comparison), a small group of views will initially be available. Users can add or remove individual views, by clicking on the settings icon next to the available view drop-down menu. Administrator-defined Land Explorer Views During installation of Land Explorer, administrator can define available views for all users. These views can be defined in the LandExplorer.cfg file. Please contact Omicsoft Support ( support@omicsoft.com ) for assistance in customizing this setting.","title":"Customizations"},{"location":"tutorials/Land Explorer/Using Land Explorer/Customizations/#customizing-available-land-views","text":"Users of Array Studio are familiar with many of the available Land Views that can be used to visualize data. The Land Explorer is fully customizable to provide many of the rich visualizations of Array Studio, or simplified with a minimal number of key views. The customizations can be performed by specific users within Land Explorer, or by the administrator of Land Explorer for all users.","title":"Customizing Available Land Views"},{"location":"tutorials/Land Explorer/Using Land Explorer/Customizations/#user-defined-land-explorer-views","text":"By default, for each type of view (i.e. Sample, Gene, Comparison), a small group of views will initially be available. Users can add or remove individual views, by clicking on the settings icon next to the available view drop-down menu.","title":"User-defined Land Explorer views"},{"location":"tutorials/Land Explorer/Using Land Explorer/Customizations/#administrator-defined-land-explorer-views","text":"During installation of Land Explorer, administrator can define available views for all users. These views can be defined in the LandExplorer.cfg file. Please contact Omicsoft Support ( support@omicsoft.com ) for assistance in customizing this setting.","title":"Administrator-defined Land Explorer Views"},{"location":"tutorials/Land Explorer/Using Land Explorer/GenerateViewLink/","text":"Generate View Link Share View with others Once a user creates an interesting visualization that they would like to share with colleagues, there are a couple of options to share this data. The user can simply export the view using the buttons on the upper right of the screen: Alternatively, by clicking on Menu \u2192 Generate View Link: A user can create a hyperlink that can be shared to other users with access to the LandExplorer. The link will be copied and pasted to the clipboard and can be shared instantly. This a particularly useful option to provide someone that may want to further customize the visualization, but without having to filter down to the samples of interest. Customized View Generation The link created through the option described above (Generate View Link) also can function as a way for users to generate a landing page that is pre-filtered to the samples, view and grouping they would like to use. For example, the partial link below contains information related to Land, Gene, View, Grouping and Filters: MainPage? landName =HumanDisease_B37& geneID =il6%2C& viewID =RnaSeq_Transcript.GeneVariable& grouping =DiseaseState& trellis =No+Trellis& filters =Sample%7CDiseaseCategory%7Carthritis%0D%0Anormal+control The resulting view will reflect all the customizations performed by the previous user: If this user (or another user) wants to recreate this view, but for say another gene, the link can be modified to change the geneID in the link above. Alternatively, you can simply search the alternate gene name in the view that appears when you use the previous link.","title":"Generate View Link"},{"location":"tutorials/Land Explorer/Using Land Explorer/GenerateViewLink/#generate-view-link","text":"","title":"Generate View Link"},{"location":"tutorials/Land Explorer/Using Land Explorer/GenerateViewLink/#share-view-with-others","text":"Once a user creates an interesting visualization that they would like to share with colleagues, there are a couple of options to share this data. The user can simply export the view using the buttons on the upper right of the screen: Alternatively, by clicking on Menu \u2192 Generate View Link: A user can create a hyperlink that can be shared to other users with access to the LandExplorer. The link will be copied and pasted to the clipboard and can be shared instantly. This a particularly useful option to provide someone that may want to further customize the visualization, but without having to filter down to the samples of interest.","title":"Share View with others"},{"location":"tutorials/Land Explorer/Using Land Explorer/GenerateViewLink/#customized-view-generation","text":"The link created through the option described above (Generate View Link) also can function as a way for users to generate a landing page that is pre-filtered to the samples, view and grouping they would like to use. For example, the partial link below contains information related to Land, Gene, View, Grouping and Filters: MainPage? landName =HumanDisease_B37& geneID =il6%2C& viewID =RnaSeq_Transcript.GeneVariable& grouping =DiseaseState& trellis =No+Trellis& filters =Sample%7CDiseaseCategory%7Carthritis%0D%0Anormal+control The resulting view will reflect all the customizations performed by the previous user: If this user (or another user) wants to recreate this view, but for say another gene, the link can be modified to change the geneID in the link above. Alternatively, you can simply search the alternate gene name in the view that appears when you use the previous link.","title":"Customized View Generation"},{"location":"tutorials/Land Explorer/Using Land Explorer/LandExplorerInterface/","text":"Land Explorer: Usage and Customizations The Land Explorer gives users the freedom to browse Omicsoft Lands through their web browser. Users can easily customize their views by filtering to data of interest, adjusting the chart settings and even controlling the data that is visualized. These pages describe some of basic approaches to maximize the utility of the Land Explorer to fit your needs, including: Select the views that are most important to you. Apply filters using a diverse array of metadata curated by Omicsoft scientists Create custom metadata based on various types of \"Omic\"-data. Search for data related to gene(s) of interest. Simply share data with other collaborators or colleagues. ...and more!","title":"Land Explorer Interface"},{"location":"tutorials/Land Explorer/Using Land Explorer/LandExplorerInterface/#land-explorer-usage-and-customizations","text":"The Land Explorer gives users the freedom to browse Omicsoft Lands through their web browser. Users can easily customize their views by filtering to data of interest, adjusting the chart settings and even controlling the data that is visualized. These pages describe some of basic approaches to maximize the utility of the Land Explorer to fit your needs, including: Select the views that are most important to you. Apply filters using a diverse array of metadata curated by Omicsoft scientists Create custom metadata based on various types of \"Omic\"-data. Search for data related to gene(s) of interest. Simply share data with other collaborators or colleagues. ...and more!","title":"Land Explorer: Usage and Customizations"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/","text":"View Controller View Controller in Land Explorer The \"View Controller\" is an extremely important feature for the customization of views in the Land Explorer. Here, users can control the appearance of the view, such as color and size. In addition, users can determine the metadata used to group samples on the y-axis or choose to trellis a view by key metadata: Chart Setting In the Chart Setting tab, there are 4 options, Pane, Series, Axis, and Legend. Pane Settings Users could edit the Title, set the Width, Height, Font color and size in the Pane option setting window. Series Settings The Color, shape, border, and opacity of each labeled group could be defined under Series Settings . Axis Settings In the Axis Settings window, each X/Y label can be customized, as well as the scale of each axis. Legend Settings The color and position of the figure legend could be defined in the Legend Settings window. Grouping Any of the available metadata in the Land can be used to group the samples in the view. For example, in CCLE_B37, there are several options for grouping, SampleID, SubjectID, Primary Site, Histology, Gender, Land Sample Type, Land Tissue, and Tumor Or Normal. Trellis Users may want to trellis a view in order to better visualize the distribution of samples with a certain grouping. For example, in TCGA, if a user groups the samples by Gender to see how many samples from each gender are present, it will be unclear as to which tumors these represent: Simply adding a trellis for Tumor Type, now 33 charts (representing the 33 tumor types represented in TCGA) will be displayed, with a breakdown of gender for each:","title":"View Controller"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#view-controller","text":"","title":"View Controller"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#view-controller-in-land-explorer","text":"The \"View Controller\" is an extremely important feature for the customization of views in the Land Explorer. Here, users can control the appearance of the view, such as color and size. In addition, users can determine the metadata used to group samples on the y-axis or choose to trellis a view by key metadata:","title":"View Controller in Land Explorer"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#chart-setting","text":"In the Chart Setting tab, there are 4 options, Pane, Series, Axis, and Legend.","title":"Chart Setting"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#pane-settings","text":"Users could edit the Title, set the Width, Height, Font color and size in the Pane option setting window.","title":"Pane Settings"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#series-settings","text":"The Color, shape, border, and opacity of each labeled group could be defined under Series Settings .","title":"Series Settings"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#axis-settings","text":"In the Axis Settings window, each X/Y label can be customized, as well as the scale of each axis.","title":"Axis Settings"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#legend-settings","text":"The color and position of the figure legend could be defined in the Legend Settings window.","title":"Legend Settings"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#grouping","text":"Any of the available metadata in the Land can be used to group the samples in the view. For example, in CCLE_B37, there are several options for grouping, SampleID, SubjectID, Primary Site, Histology, Gender, Land Sample Type, Land Tissue, and Tumor Or Normal.","title":"Grouping"},{"location":"tutorials/Land Explorer/Using Land Explorer/View_controller/#trellis","text":"Users may want to trellis a view in order to better visualize the distribution of samples with a certain grouping. For example, in TCGA, if a user groups the samples by Gender to see how many samples from each gender are present, it will be unclear as to which tumors these represent: Simply adding a trellis for Tumor Type, now 33 charts (representing the 33 tumor types represented in TCGA) will be displayed, with a breakdown of gender for each:","title":"Trellis"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/CNV/","text":"Copy Number Variation Filters For views that contain data from Copy number calls , these views can be filtered to the variations of interest. The CNV tab will appear in these views for filtering: The filters can be applied to: Segment Length Cutoff For CNV Log2 ratio data, users can filter data based on the segment size that is represented by the data: By default, no filtering is done, but users can filter based on the values shown, or define their own cutoff by typing in the value in the box and clicking the check-mark.","title":"CNV Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/CNV/#copy-number-variation-filters","text":"For views that contain data from Copy number calls , these views can be filtered to the variations of interest. The CNV tab will appear in these views for filtering: The filters can be applied to:","title":"Copy Number Variation Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/CNV/#segment-length-cutoff","text":"For CNV Log2 ratio data, users can filter data based on the segment size that is represented by the data: By default, no filtering is done, but users can filter based on the values shown, or define their own cutoff by typing in the value in the box and clicking the check-mark.","title":"Segment Length Cutoff"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Comparison_filters/","text":"Comparison Filters All Samples, Comparisons, and Projects within OmicSoft Land's are associated with extensive metadata, which can be used to filter Land data to find the samples users are interested in. This page describes some filters that can be used to pare down to comparisons of interest. The most common comparison filters are shown here: Users can add additional filters from the comparison metadata using the Add Filter button: Fold Change Cutoff Users can filter to comparisons in which a gene is differentially regulated by typing in fold changes, or using predefined filters: PValue Cutoff Find where a gene's differentially expression is below a certain p value threshold ComparisonCategory Define the type of contrast that was performed (e.g. Disease vs. Normal or Treatment vs. Control) Case.DiseaseCategory Find comparisons where the test subject had a specified disease: Case.Treatment Find comparisons when the subject had a specified treatment:","title":"Comparison Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Comparison_filters/#comparison-filters","text":"All Samples, Comparisons, and Projects within OmicSoft Land's are associated with extensive metadata, which can be used to filter Land data to find the samples users are interested in. This page describes some filters that can be used to pare down to comparisons of interest. The most common comparison filters are shown here: Users can add additional filters from the comparison metadata using the Add Filter button:","title":"Comparison Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Comparison_filters/#fold-change-cutoff","text":"Users can filter to comparisons in which a gene is differentially regulated by typing in fold changes, or using predefined filters:","title":"Fold Change Cutoff"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Comparison_filters/#pvalue-cutoff","text":"Find where a gene's differentially expression is below a certain p value threshold","title":"PValue Cutoff"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Comparison_filters/#comparisoncategory","text":"Define the type of contrast that was performed (e.g. Disease vs. Normal or Treatment vs. Control)","title":"ComparisonCategory"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Comparison_filters/#casediseasecategory","text":"Find comparisons where the test subject had a specified disease:","title":"Case.DiseaseCategory"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Comparison_filters/#casetreatment","text":"Find comparisons when the subject had a specified treatment:","title":"Case.Treatment"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/","text":"Filtering in Land Explorer All Samples, Comparisons, and Projects within Omicsoft Lands are associated with extensive metadata, which can be used to filter Land data to find the samples users are interested in. Filter Types There are three main types of filters users could apply to Land metadata: 1) String, 2) Checkbox and 3) Numeric. String Filters String filters could be on various metadata columns, such as Sample IDs, and Subject IDs, as shown above after applying \"HCC\" as the filter, only sample IDs started with \"HCC\" will show up in the scatter plot. After selecting all the data dots in the scatter plot, detail information about these samples could be found in the data table. Check Box Filters Check Box options are available for Primary Site, Histology, Gender, Land Sample Type, Land Tissue, and Tumor Or Normal categories. As shown in the demo screenshot, after checking 5 primary sites, the samples with corresponding primary sites are shown in the scatter plot. Numeric Filters Metadata with numeric characteristics (such as Age, Survival Days, Fold-change) can be filtered using exact numbers to filter, or a range of numbers. Clicking on the 3 dots for these filters will bring up a menu with preconfigured ranges: Alternatively, users can simply type in a range. For example, in the option above, a user may be interested in comparisons where a gene has an absolute fold change greater than 2. In this case, simply type in \"<-2 or >2\". As shown in the screenshot above, this will create a new filter that will automatically be selected. Available Filters For simplicity, the Land Explorer will display 10-15 (at most) of the most commonly used metadata for users to choose from. However, all metadata for the data available in the land is available, and users can simply add the metadata category of interest using the \"Add Filter\" option at the top of the filtering menu: Legend Filtering In addition to using the metadata to filter the view on the left-hand side of the screen, users can also interact with the legend to filter samples of interest: Simply double-click on an item in the legend, and only that item will appear in the view: Single-clicking on \"hidden\" items will restore them in the view: This feature may be useful to a user who may want to visualize where a particular sample type is represented in a view where a lot of samples are plotted. Additional filters Users can also add Custom Queries to use gene level information to filter for samples of interest. Custom Queries will be available as filters in addition to the standard metadata. For more information on Custom Queries, please see Custom Queries","title":"Filtering"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#filtering-in-land-explorer","text":"All Samples, Comparisons, and Projects within Omicsoft Lands are associated with extensive metadata, which can be used to filter Land data to find the samples users are interested in.","title":"Filtering in Land Explorer"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#filter-types","text":"There are three main types of filters users could apply to Land metadata: 1) String, 2) Checkbox and 3) Numeric.","title":"Filter Types"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#string-filters","text":"String filters could be on various metadata columns, such as Sample IDs, and Subject IDs, as shown above after applying \"HCC\" as the filter, only sample IDs started with \"HCC\" will show up in the scatter plot. After selecting all the data dots in the scatter plot, detail information about these samples could be found in the data table.","title":"String Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#check-box-filters","text":"Check Box options are available for Primary Site, Histology, Gender, Land Sample Type, Land Tissue, and Tumor Or Normal categories. As shown in the demo screenshot, after checking 5 primary sites, the samples with corresponding primary sites are shown in the scatter plot.","title":"Check Box Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#numeric-filters","text":"Metadata with numeric characteristics (such as Age, Survival Days, Fold-change) can be filtered using exact numbers to filter, or a range of numbers. Clicking on the 3 dots for these filters will bring up a menu with preconfigured ranges: Alternatively, users can simply type in a range. For example, in the option above, a user may be interested in comparisons where a gene has an absolute fold change greater than 2. In this case, simply type in \"<-2 or >2\". As shown in the screenshot above, this will create a new filter that will automatically be selected.","title":"Numeric Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#available-filters","text":"For simplicity, the Land Explorer will display 10-15 (at most) of the most commonly used metadata for users to choose from. However, all metadata for the data available in the land is available, and users can simply add the metadata category of interest using the \"Add Filter\" option at the top of the filtering menu:","title":"Available Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#legend-filtering","text":"In addition to using the metadata to filter the view on the left-hand side of the screen, users can also interact with the legend to filter samples of interest: Simply double-click on an item in the legend, and only that item will appear in the view: Single-clicking on \"hidden\" items will restore them in the view: This feature may be useful to a user who may want to visualize where a particular sample type is represented in a view where a lot of samples are plotted.","title":"Legend Filtering"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Filters/#additional-filters","text":"Users can also add Custom Queries to use gene level information to filter for samples of interest. Custom Queries will be available as filters in addition to the standard metadata. For more information on Custom Queries, please see Custom Queries","title":"Additional filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Gene/","text":"Gene and Pathway Level Filters When viewing Volcano Plots displaying the differential expression results from a comparison, users may be interested in where gene(s) of interest lie within this comparison. The Gene and Pathway filters can be used to selective plot these genes in the view. Gene Filtering To select a gene of interest from a volcano plot, users can select the Gene filter tab, and choose the Gene identifier (i.e. GeneID, Entrez, or description). Typing in the gene name will filter the gene list to match your search. Simply click OK, and the view will be filtered to your gene(s) of interest: Pathway filtering Similar to filtering for a gene, users can filter to gene sets in the Pathway tab:","title":"Gene Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Gene/#gene-and-pathway-level-filters","text":"When viewing Volcano Plots displaying the differential expression results from a comparison, users may be interested in where gene(s) of interest lie within this comparison. The Gene and Pathway filters can be used to selective plot these genes in the view.","title":"Gene and Pathway Level Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Gene/#gene-filtering","text":"To select a gene of interest from a volcano plot, users can select the Gene filter tab, and choose the Gene identifier (i.e. GeneID, Entrez, or description). Typing in the gene name will filter the gene list to match your search. Simply click OK, and the view will be filtered to your gene(s) of interest:","title":"Gene Filtering"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Gene/#pathway-filtering","text":"Similar to filtering for a gene, users can filter to gene sets in the Pathway tab:","title":"Pathway filtering"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Mutation/","text":"Mutation Filters For views that contain data from DNA-seq and RNA-seq , these views can be filtered to variants of interest. The Mutation tab will appear in these views for filtering: The filters can be applied to: Location By default, only non-synonymous coding mutations are applied in the Land. Users can filter to intronic and 3'UTR variant calls: Consequence By default, only non-synonymous coding mutations are applied in the Land. Users can filter synonymous mutations, or perhaps more stringent filters using this Mutation metadata: RS_ID RS_ID (when available) can be used to filter to specific mutations: AAMutation (Amino Acid Mutation) All variants in a searched genes are represented in the mutation views. Users can filter to specific variants using this filter: Classifiers A number of classifiers can be used to filter for variants that are not highly abundant in variant databases. For example, in the case below, users can filter to mutations in a gene with less than fifty percent frequency in 1000 genomes:","title":"Mutation Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Mutation/#mutation-filters","text":"For views that contain data from DNA-seq and RNA-seq , these views can be filtered to variants of interest. The Mutation tab will appear in these views for filtering: The filters can be applied to:","title":"Mutation Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Mutation/#location","text":"By default, only non-synonymous coding mutations are applied in the Land. Users can filter to intronic and 3'UTR variant calls:","title":"Location"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Mutation/#consequence","text":"By default, only non-synonymous coding mutations are applied in the Land. Users can filter synonymous mutations, or perhaps more stringent filters using this Mutation metadata:","title":"Consequence"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Mutation/#rs_id","text":"RS_ID (when available) can be used to filter to specific mutations:","title":"RS_ID"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Mutation/#aamutation-amino-acid-mutation","text":"All variants in a searched genes are represented in the mutation views. Users can filter to specific variants using this filter:","title":"AAMutation (Amino Acid Mutation)"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Mutation/#classifiers","text":"A number of classifiers can be used to filter for variants that are not highly abundant in variant databases. For example, in the case below, users can filter to mutations in a gene with less than fifty percent frequency in 1000 genomes:","title":"Classifiers"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Pathway/","text":"--needs updating","title":"Pathway"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Project_filters/","text":"Project Filters There are a number of views in which users can apply filtering at the Project level using metadata attributed to the samples. The Land Explorer will display 10-15 (at most) of the most commonly used metadata for users to filter their samples. Additional filters can be added by the user to dig deeper into the data Add Filters This page will describe some of the key metadata that exists in the Land commonly used for filtering Projects. ProjectName Easily filter to a project by entering the GSE or EMTAB accession number attributed to the project: Disease Users can easily identify projects by disease focus using the checkbox filter: Therapeutic Area For more general disease focus, the Therapeutic Area can used to identify a broader focus of studies:","title":"Project Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Project_filters/#project-filters","text":"There are a number of views in which users can apply filtering at the Project level using metadata attributed to the samples. The Land Explorer will display 10-15 (at most) of the most commonly used metadata for users to filter their samples. Additional filters can be added by the user to dig deeper into the data Add Filters This page will describe some of the key metadata that exists in the Land commonly used for filtering Projects.","title":"Project Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Project_filters/#projectname","text":"Easily filter to a project by entering the GSE or EMTAB accession number attributed to the project:","title":"ProjectName"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Project_filters/#disease","text":"Users can easily identify projects by disease focus using the checkbox filter:","title":"Disease"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Project_filters/#therapeutic-area","text":"For more general disease focus, the Therapeutic Area can used to identify a broader focus of studies:","title":"Therapeutic Area"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/","text":"Filtering Samples using the Metadata There are a number of views in which users can apply filtering at the Sample level using metadata attributed to the samples. The Land Explorer will display 10-15 (at most) of the most commonly used metadata for users to filter their samples. Additional filters can be added by the user to dig deeper into the data Add Filters This page will describe some of the key metadata that exists in the Land commonly used for filtering samples. Sample ID Subject ID (Subject Treatment) Tumor Type Within the OncoLand Collection, and specifically within TCGA, tumor abbreviations are used to group the samples in the Land by default. Sample Type Disease Category Disease State Land Sample Type Land Tissue Primary Site Race Tissue Category Tissue Tumor Or Normal","title":"Sample Filters"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#filtering-samples-using-the-metadata","text":"There are a number of views in which users can apply filtering at the Sample level using metadata attributed to the samples. The Land Explorer will display 10-15 (at most) of the most commonly used metadata for users to filter their samples. Additional filters can be added by the user to dig deeper into the data Add Filters This page will describe some of the key metadata that exists in the Land commonly used for filtering samples.","title":"Filtering Samples using the Metadata"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#sample-id","text":"","title":"Sample ID"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#subject-id-subject-treatment","text":"","title":"Subject ID (Subject Treatment)"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#tumor-type","text":"Within the OncoLand Collection, and specifically within TCGA, tumor abbreviations are used to group the samples in the Land by default.","title":"Tumor Type"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#sample-type","text":"","title":"Sample Type"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#disease-category","text":"","title":"Disease Category"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#disease-state","text":"","title":"Disease State"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#land-sample-type","text":"","title":"Land Sample Type"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#land-tissue","text":"","title":"Land Tissue"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#primary-site","text":"","title":"Primary Site"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#race","text":"","title":"Race"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#tissue-category","text":"","title":"Tissue Category"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#tissue","text":"","title":"Tissue"},{"location":"tutorials/Land Explorer/Using Land Explorer/Filters/Sample_Filters/#tumor-or-normal","text":"","title":"Tumor Or Normal"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/","text":"Custom Query Omicsoft Land users can add Custom Query in Land to group samples based on gene-level metadata obtained from \"Omic\"-data types such as mutation status, copy number status and expression. The customized query can be used to further filter and/or group samples in the view. A number of custom queries can be generated, including: CNV call Within many of the Lands in the OncoLand collection, such as TCGA, GISTIC2 calls for copy number status have been provided. Users can identify samples with alterations in copy number status as shown below: In this example, all copy number gains (2 or more extra copies) or loss (2 missing copies) will be identified, with all remaining samples showing \"No Change\": As shown above, removing the No Change samples will filter to only samples with CNV calls. For the gene PTEN, there are 60+ samples each for prostate and breast cancer with variations in copy number. To determine if these are mainly deletions or amplifications, the custom query can by used to group the samples as well. Filtering to BRCA and PRAD tumors, and grouping the samples by the query, it is clear that the majority of these samples have deletions affecting pten: CNV Log2 Ratio Similar to the GISTIC2 calls, users can browse the log2 ratio derived from an Affymetrix SNP6 Copy Number Inference Pipeline: As shown in the screenshot above, users can simply obtain log2 ratios for a gene across all samples, or group genes as with CNV call by specific criteria: DNA Somatic mutation Users can query a gene's mutation status within the samples of the Land. Simply type in the gene name and click OK to return a custom query metadata for WT vs MUT assigned to all samples in the land. Alternatively, one can generate a more detailed mutation status returning all variants for that gene and assigning to the samples (by clicking the \"Return AAMutation classification\"). Users interested in samples with a specific allele can search it as shown below for BRAF.V600E: The variant consequence dropdown will allow users to customize the type of mutations queried. By default, only non-synonymous mutations are selected. RNA-Seq Expression A user can also attach metadata to samples based on the expression status of a gene of interest. Simply type in the gene name in the window at the top of the screen. Three options for output are available: Compare Identify samples that have an up- or down-regulation of the gene compared to the average expression of the gene across all samples or within a group (i.e. Tumor Type). Categorize Separate samples into quartiles based on the gene's expression, again pooling all samples in a group or a project. In this case, the samples in the upper quartile (Q4), will be designated as \"Up\", while the samples in the lower quartile (Q1) will designated \"Down\". All remaining quartiles (Q2 and Q3) will be pooled together and represented as \"No Change\". As a variation of this approach, users can define the breakpoints at which to define the samples. Simply choose the option to \"Categorize numeric values\" - As shown in the example below, you could designate breakpoints to separate the low and high expression level samples (based on the top and bottom 10%): With this latter option, users can perform the query across all samples, or use filter samples only (checking the option for \"Apply to visible samples only\"). By default, the categorization will happen across all samples - however, users can choose to define these breakpoints within specific groupings (i.e. Tumor Type or Disease Category, defined by Grouping column). Return Expression Values For this option, users can simply append the sample metadata with the expression value of the gene that is queried. This can be used as a numeric filter to identify samples with a minimal (or maximal level of expression for this gene).","title":"Custom Query"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#custom-query","text":"Omicsoft Land users can add Custom Query in Land to group samples based on gene-level metadata obtained from \"Omic\"-data types such as mutation status, copy number status and expression. The customized query can be used to further filter and/or group samples in the view. A number of custom queries can be generated, including:","title":"Custom Query"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#cnv-call","text":"Within many of the Lands in the OncoLand collection, such as TCGA, GISTIC2 calls for copy number status have been provided. Users can identify samples with alterations in copy number status as shown below: In this example, all copy number gains (2 or more extra copies) or loss (2 missing copies) will be identified, with all remaining samples showing \"No Change\": As shown above, removing the No Change samples will filter to only samples with CNV calls. For the gene PTEN, there are 60+ samples each for prostate and breast cancer with variations in copy number. To determine if these are mainly deletions or amplifications, the custom query can by used to group the samples as well. Filtering to BRCA and PRAD tumors, and grouping the samples by the query, it is clear that the majority of these samples have deletions affecting pten:","title":"CNV call"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#cnv-log2-ratio","text":"Similar to the GISTIC2 calls, users can browse the log2 ratio derived from an Affymetrix SNP6 Copy Number Inference Pipeline: As shown in the screenshot above, users can simply obtain log2 ratios for a gene across all samples, or group genes as with CNV call by specific criteria:","title":"CNV Log2 Ratio"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#dna-somatic-mutation","text":"Users can query a gene's mutation status within the samples of the Land. Simply type in the gene name and click OK to return a custom query metadata for WT vs MUT assigned to all samples in the land. Alternatively, one can generate a more detailed mutation status returning all variants for that gene and assigning to the samples (by clicking the \"Return AAMutation classification\"). Users interested in samples with a specific allele can search it as shown below for BRAF.V600E: The variant consequence dropdown will allow users to customize the type of mutations queried. By default, only non-synonymous mutations are selected.","title":"DNA Somatic mutation"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#rna-seq-expression","text":"A user can also attach metadata to samples based on the expression status of a gene of interest. Simply type in the gene name in the window at the top of the screen. Three options for output are available:","title":"RNA-Seq Expression"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#compare","text":"Identify samples that have an up- or down-regulation of the gene compared to the average expression of the gene across all samples or within a group (i.e. Tumor Type).","title":"Compare"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#categorize","text":"Separate samples into quartiles based on the gene's expression, again pooling all samples in a group or a project. In this case, the samples in the upper quartile (Q4), will be designated as \"Up\", while the samples in the lower quartile (Q1) will designated \"Down\". All remaining quartiles (Q2 and Q3) will be pooled together and represented as \"No Change\". As a variation of this approach, users can define the breakpoints at which to define the samples. Simply choose the option to \"Categorize numeric values\" - As shown in the example below, you could designate breakpoints to separate the low and high expression level samples (based on the top and bottom 10%): With this latter option, users can perform the query across all samples, or use filter samples only (checking the option for \"Apply to visible samples only\"). By default, the categorization will happen across all samples - however, users can choose to define these breakpoints within specific groupings (i.e. Tumor Type or Disease Category, defined by Grouping column).","title":"Categorize"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Custom_Query/#return-expression-values","text":"For this option, users can simply append the sample metadata with the expression value of the gene that is queried. This can be used as a numeric filter to identify samples with a minimal (or maximal level of expression for this gene).","title":"Return Expression Values"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Searching_Genes/","text":"Search Bar The Search Bar at the top of the Land Explorer page can search a number of things within the Land: The search bar is interactive and dynamic. Entering the first 2-3 characters in a search will automatically populate results in the search bar: Within the search bar, users can search: Gene The most common search item in the search bar is a gene search. Typing in the gene name, users can find entries that match the gene of interest and click. Afterward, the Search button will change font color to red. Clicking on the Search button will take users to the default gene-level view (usually Gene FPKM ): Multiple Genes Users can search additional genes in the search bar (with options becoming available for each additional search as well): Comparison Another search users can perform to quickly identify a comparison of interest, is to search for a specific GSE accession number. In the example below, searching GSE1563 populates the search bar drop-down with 10 comparisons that were performed for this study within HumanDisease_B37: Clicking on any of these comparsions will take you to a Volcano Plot view:","title":"Search Bar"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Searching_Genes/#search-bar","text":"The Search Bar at the top of the Land Explorer page can search a number of things within the Land: The search bar is interactive and dynamic. Entering the first 2-3 characters in a search will automatically populate results in the search bar: Within the search bar, users can search:","title":"Search Bar"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Searching_Genes/#gene","text":"The most common search item in the search bar is a gene search. Typing in the gene name, users can find entries that match the gene of interest and click. Afterward, the Search button will change font color to red. Clicking on the Search button will take users to the default gene-level view (usually Gene FPKM ):","title":"Gene"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Searching_Genes/#multiple-genes","text":"Users can search additional genes in the search bar (with options becoming available for each additional search as well):","title":"Multiple Genes"},{"location":"tutorials/Land Explorer/Using Land Explorer/Queries/Searching_Genes/#comparison","text":"Another search users can perform to quickly identify a comparison of interest, is to search for a specific GSE accession number. In the example below, searching GSE1563 populates the search bar drop-down with 10 comparisons that were performed for this study within HumanDisease_B37: Clicking on any of these comparsions will take you to a Volcano Plot view:","title":"Comparison"},{"location":"tutorials/Microarray/","text":"Microarray Tutorial .. toctree:: :maxdepth: 2 Installing_Array_Studio Importing_a_Dataset Data_Visualization_and_Quality_Control Differential_Expression Data_Exploration Audit_trail References","title":"Home"},{"location":"tutorials/Microarray/Audit_trail/","text":"Audit trail Array Studio tracks all analysis steps done in a project, using its Audit Trail feature. This is important for many company s data integrity needs, and can also be used by the individual users to see what types of changes and procedures were made to the project and to rerun the exact analysis ran previously. To see the audit trail for the MicroArray tutorial project, go to File Menu | Audit Trail to open the Audit Trail window. The Audit Trail can be accessed using the File | Audit Trail option. Open the Audit Trail window now. The Audit Trail window contains two tabs: List and All Scripts . The List tab shows a step-by-step list of everything that was performed. Clicking on an individual step shows the OmicScript for that step at the bottom. The OmicScript specifies input data and options that Array Studio needs to run the module. The List can be exported using the Export List button or the Save All scripts button. Notice that for each step, an optional Description can be entered to describe what was done at that step and other comments. Selecting an item in the List will provide the details for the script and also activate the Run Script button at the bottom of the window to allow the user to quickly rerun any script in the Audit Trail. Switch to the All Scripts tab to view all the scripts of actions and changes made to your Project . It can also be exported at any time. Notice that in the Script below that first a new project was created, followed by importation of Affymetrix CEL files and MAS report generation, etc. Click Save button to save the current project. Close the Array Studio software by clicking on the red button on top right of the window or go to File Menu | Close . Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) for sales-related questions.","title":"Audit trail"},{"location":"tutorials/Microarray/Audit_trail/#audit-trail","text":"Array Studio tracks all analysis steps done in a project, using its Audit Trail feature. This is important for many company s data integrity needs, and can also be used by the individual users to see what types of changes and procedures were made to the project and to rerun the exact analysis ran previously. To see the audit trail for the MicroArray tutorial project, go to File Menu | Audit Trail to open the Audit Trail window. The Audit Trail can be accessed using the File | Audit Trail option. Open the Audit Trail window now. The Audit Trail window contains two tabs: List and All Scripts . The List tab shows a step-by-step list of everything that was performed. Clicking on an individual step shows the OmicScript for that step at the bottom. The OmicScript specifies input data and options that Array Studio needs to run the module. The List can be exported using the Export List button or the Save All scripts button. Notice that for each step, an optional Description can be entered to describe what was done at that step and other comments. Selecting an item in the List will provide the details for the script and also activate the Run Script button at the bottom of the window to allow the user to quickly rerun any script in the Audit Trail. Switch to the All Scripts tab to view all the scripts of actions and changes made to your Project . It can also be exported at any time. Notice that in the Script below that first a new project was created, followed by importation of Affymetrix CEL files and MAS report generation, etc. Click Save button to save the current project. Close the Array Studio software by clicking on the red button on top right of the window or go to File Menu | Close . Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) for sales-related questions.","title":"Audit trail"},{"location":"tutorials/Microarray/Data_Exploration/","text":"Data Exploration Array Studio has the ability to perform further analysis on a list or lists of genes. It has the ability to upload pathways and lists to Ingenuity Pathway Analysis (IPA), as well as to check gene ontologies and find out if any significant ontology exists. IPA requires the user to have an account so that it is not covered in this tutorial. Hierarchical clustering Hierarchical clustering can provide an overview of the data, and can easily be performed in Array Studio. Go to the OmicData | Pattern menu. The OmicData | Pattern menu contains a number of different pattern detection techniques that can be used in Array Studio. This includes Find Neighbors, Correlate Covariate, Hierarchical Clustering, NMF Clustering, Cluster Variables, Cluster Observations , and Gene Shaving . Cluster Variable and Cluster Observations include PAM, CAST, K-means, and SOM for clustering algorithms. Array Studio can handle (with a regular computer) Hierarchical Clustering up to 30,000 variables in a few minutes. In comparison, the popular gene clustering program from Eisen, Gene Cluster, can only cluster up to 9,999 variables. For the purposes of this tutorial, we will cluster the already created List, 18 -> DBP vs control.Sig296 , as an example. In the Microarray Workflow , select Hierarchical Clustering , or go to the OmicData | Pattern | Hierarchical Clustering to open Hierarchical Clustering . Once the Hierarchical Clustering window opens, ensure that MicroArrayData is selected under Input/Output | Data . Next, ensure that the 18 -> DBP vs. Control.Sig 296 is selected so that only probesets in this list are used for clustering ( Customized Variables ). Ensure that MicroArray Data.Observation23(23) is selected under Customized Observations , excluding the outlier filtered out by PCA. Under Options , ensure that Compute Observation tree and Compute variable tree are both selected. Array Studio gives the option of only clustering the observations, variables, or both. Both the observation tree and the variable tree contain options for Link and Distance for the clustering. Link includes options of Ward , Single , Complete , Average , Mcquitty , Median , and Centroid . Distance includes options of Euclidean , Maximum , Manhattan , Canberra , Binary , Pearson (uncentered correlation), and Correlation . Link Options Distance Options Generate classic dendrogram view will generate the dendrogram view in the old Array Studio 1.0 format. Uncheck this box as the new improved dendrogram viewer is preferred by most users. Note for correlation distance, there is no need to normalize the data. Click Submit to begin clustering. This process should take approximately 3 seconds. A new view will be generated in the Solution Explorer , called Dendrogram . There are two visible windows in this View . The left window contains the dendrogram, while the right window contains a zoomed-in view of the dendrogram. If the entire cluster is not visible in the left window, there are two options. First, the window size can be adjusted by dragging in between the left window and the right window. More conveniently, the pixel size can be automatically adjusted using the toolbar at the top of the left window Use either the pixel size dropdown box (x*y) or clicking the Fit Dendrogram to Window button. The button provides other options for viewing the dendrogram Click the Fit Dendrogram to Window button now. Resize the left window and click the button again if the data looks too small or distorted. When finished, the left window should look similar to below. The left window view (heatmap thumbnail with dendrogram) is linked to the right window view. Clicking on a branch of the dendrogram will bring those specific rows and observations up in the right window. Branches on both the Y-axis and X-axis can be clicked on, individually and together. Click on a small branch in the left window (Y-axis). Note that the branch, when selected, turns to blue color. Now notice the right hand window. The right hand window contains a HeatmapTableView of the rows (probesets) selected in the left hand dendrogram view. Initially, all the columns will not be visible in the view . If necessary, shrink the column widths so that all columns are visible by grabbing between two columns on the header row and shrinking the column. It may also help to hide the left hand window by clicking the Hide Thumbnail button on the toolbar. Notice that scrolling to the right shows the annotation for each probeset. To change the annotation columns displayed, click the Specify Annotation Columns button in View Controller | Task | Data . Next, use the Change ColorBars under View Controller | Task | Customize | Change ColorBars to open up a window for selecting columns for color bars. Choose time , then treatment to create color bars on that heatmap. Click OK to continue. Notice that the ColorBars appear over the heatmap to label different Time and Treatment groups. To view the legend, switch the View Controller to the Legend tab. Notice that Time and Treatment are separated on the legend for each viewing. Click on with border or without border to switch the status of copied legend (whether to have border). Click on Copy Legend to copy the legend. Note: Right-clicking on anything in the Legend colors will allow the user to change colors for the chart or the color bars. Sometimes the user might want to find a particular probeset or gene in the dendrogram, in order to see other genes clustered around it. To do this, first re-expand the left window thumbnail view using the Show Thumbnail button. Expand the left-window so that it splits about half the screen with the right-hand heatmap window. If necessary, click the Fit Dendrogram to Window button in order to see the entire dendrogram. Using the Select button on the main toolbar, type the gene name Star and change the dropdown box to the Gene Symbol selection, and then press Enter. This ensures that Array Studio will select Star in the column Gene Symbol . Click select by clicking on the binoculars button . Notice that in the left-hand dendrogram thumbnail view, two lines have been selected towards the middle of the dendrogram (indicated by the blue selection lines) In the right-hand heatmap view, only the probesets containing Star in Gene Symbol are now shown. To see those genes found around Star in the Dendrogram, click on a branch of the dendrogram near the blue selection line. On the right panel, scroll until the Star probeset is found, and notice the genes that are similar in pattern to Star . In particular, it appears that the genes Scarb1, Cyp17a1, and Stc2 cluster around Star , as well as others. As the last step in hierarchical clustering, the user can choose to change the coloring scheme of the heatmaps. This is accomplished by clicking Change Color Properties in the View Controller | Task tab. Click on the Middle value color and change it to white. Close the Color Properties dialog and notice the heatmaps are instantly updated. Pattern Matching (Find Neighbors) Array Studio includes a number of pattern detection modules and we will discuss one of them, Find Neighbors , which allows the user to find neighbors for a variable or an observation based on correlations. By default, the currently selected variable or observation (if multiple variables or observations are selected, the first one) will be used as the input for this module, and the user can easily change that input. The Find Neighbors module can be run by clicking on the Find Neighbors in the Microarray Workflow | Pattern recognition , or by going to the OmicData Menu | Pattern | Find Neighbors . Now click Find neighbors to open this module. This opens the Find Neighbors dialog window: Under the Input/Output section, the user has an option for Project and Data (Choose Tutorial MicroArray and MicroArray Data now). Ensure that all variables are selected under the Variables section. The user can choose to Find Neighbors using the data in a specific list of samples. Choose the List MicroArray Data.Observation23 to only run the Find Neighbors module on the 23 chips in the List (with outlier 22A removed). Leave the Output name blank and allow Array Studio to assign the default name. For the Options section, type 1368321_at into the Find neighbors for text box. This is the probeset for Egr1 , and had this probeset been selected in the view prior to opening this window, Array Studio would have selected it by default. Instead, the top probeset on the selected list was the default option. Ensure that Variable is selected (this module can work on observations as well). Correlation method contains options for Pearson , Spearman , and Kendall correlations. Ensure that Pearson is selected. Correlation direction allows the closest neighbors to be found for Positive, Negative, or both directions. Positive is the default option. Array Studio includes the option to either search for a fixed number of neighbors or by a p value cutoff of the correlations. For this practice, ensure that Fixed neighbor number is selected and type 20 into the box. If specified a cutoff for With P-value <, correlation test pvalues will be used to search the neighbors. Array Studio allows the user to either output a HeatmapView for the Find Neighbors or a ProfileView , which can be specified in Output view . Ensure that HeatmapView is selected now. Click Submit to continue. In the Solution Explorer , a new Omic data named 1368321_at.Neighbors is created under the Pattern folder. Two new views are created ( Neighbors a HeatmapView and Table a TableView ). A HeatmapView entitled Neighbors is shown by default in the view window . If the window does not appear as below (no rows shown), ensure that no filters are set in the View Controller | Variables tab by clicking the Clear All Filters button in View Controller . While interesting, the above view is not all that useful without color bars to indicate the classification of each chip. This can be accomplished using the Change X-Axis ColorBars item in View Controller | Task | Customize tab. Click Change X-Axis ColorBars now to open the Choose Columns window. Move treatment and time to the right-hand Listed columns section to create color bars for each column. Click OK to continue. The heatmap is updated to include the color bars. In order to get a better idea of the pattern, we need to order the heatmap columns in a reasonable way. Click Sort Heatmap columns in View Controller | Task | Data . First sort by time then sort by treatment . Now the heatmap columns are sorted appropriately as can be seen from the color bars. Choose the Legend tab in the View Controller to view the legend for the chart. The chart can be opened in PowerPoint at any time using the Open Current View in PowerPoint or Open All Charts in PowerPoint button. Besides just showing the Probeset ID , the chart can also show additional columns of annotation. Click Change Y-Axis Labels in View Controller | Task | Customize now to open the Choose Columns window . Move Gene Symbol to the Listed columns section and click OK to continue. The chart is updated, now showing the Gene Symbol instead of Probeset ID . Gene ontology analysis Array Studio provides an internal gene ontology analysis. The gene ontology analysis takes lists of probesets and, using online Gene Ontology annotation, reports back the number of probesets found in each of the classes with the given ontology. This can be used, for example, to figure out if a particular class within ontology is over-represented in a particular treatment. Gene Ontology analysis can be found in the OmicData Menu | Annotation | Gene Ontology . This opens the Gene Ontology Classification Window . The Gene Ontology Classification window contains a number of options. First, select the Project and Data to be used for classification (choose Tutorial MicroArray and MicroArray Data ). Next, choose Lists for classification . In this case, we are interested in comparing the four estimates ( 1 ->DBP vs control , 3 -> DBP vs control , 6-> DBP vs control , 18 -> DBP vs control ). Choose these lists now and click OK . Choose GO term columns : because the user may choose to import customized annotation, the possibility exists that the user may wish to specify the columns that contain gene ontology terms. By default, Array Studio imports 3 columns of annotation with gene ontology terms. Array Studio automatically recognizes that Gene Ontology Biological Process , Gene Ontology Cellular Component , and Gene Ontology Molecular Function all contain GO terms. Ensure that all 3 columns are selected. Set the level of classification using the Classification level (0-6) box. The higher the level (6 being the highest), the more specific the GO classification. For instance, Level 0 is the least specific, and will have general categories of Biological Process , Cellular Component , and Molecular Function . On the other hand, level 6 will be extremely specific, for instance: cyclooxygenase pathway and GTP cyclohydrolase activity. For this exercise, leave the Classification level set to 3. This is the default setting, and may prove to be the most interesting for most practices. Biological process , molecular function , and cellular component checkboxes are provided if the user wishes to only specify a specific type of gene ontology. Many times customized annotations will include all three types in one column of annotation, and thus these checkboxes are provided for such cases. Leave all three checkboxes selected for this tutorial. Gene ontology is constantly being updated. This box Update frequency (days) sets the frequency that Array Studio should check for new ontology information. By default, this is set to 30 days. When run, if Array Studio has downloaded new annotation in the past 30 days, it will skip the download step and immediately begin classifying the lists. If users check the Calculate p-values (assumes variable independence) , the software will calculate a p-value for each GO category. This is based on Fisher s Exact Test, and it assumes variable independence. Check this box now. The Choose Universal List dropdown box is active only when Calculate p-values is selected. It can be used to choose the Universal List used for a Fisher's Exact Test. For instance, the user may choose to use the entire chip (all) for calculating of p-values, or only look at a list of probesets of interests. The Multiplicity dropdown box is active only when Calculate p-values is selected. It can be used to set the multiplicity adjustment for the Fisher s Exact Test, and contains the standard multiplicity adjustment types found elsewhere in Array Studio. Click Submit to continue. If the gene ontology has not been updated or it has been more than 30 days old (true for all first-time users of Array Studio), the gene ontology will be updated first, and then the module will run. When finished, a new Table , titled MicroArrayData.GeneOntologyReport is created in the Solution Explorer under the Ontology tab, and the Table view is opened in the center Data View window. Note Note: Due to the constantly updating nature of the Gene Ontology database, the number of rows in the example shown below and the number of rows when the user runs the tutorial may differ. This is expected. The Table contains 10 columns. The first column contains the category (the gene ontology), the second column contains the GOTerm, with the other columns containing the number of probesets, in each list or universal list [all], belonging to each category and the corresponding Fisher Exact test p-values. As in all views in Array Studio, details can be provided on demand and are fully interactive. Clicking on a particular cell, for instance, in 3 -> DBP vs control , actin filament-based process, will provide inference report details about the probesets contained in that category in the Details Window . Details for multiple cells can be obtained by holding \"Shift\" or \"Ctrl\" buttons and selecting multiple cells.","title":"Data Exploration"},{"location":"tutorials/Microarray/Data_Exploration/#data-exploration","text":"Array Studio has the ability to perform further analysis on a list or lists of genes. It has the ability to upload pathways and lists to Ingenuity Pathway Analysis (IPA), as well as to check gene ontologies and find out if any significant ontology exists. IPA requires the user to have an account so that it is not covered in this tutorial.","title":"Data Exploration"},{"location":"tutorials/Microarray/Data_Exploration/#hierarchical-clustering","text":"Hierarchical clustering can provide an overview of the data, and can easily be performed in Array Studio. Go to the OmicData | Pattern menu. The OmicData | Pattern menu contains a number of different pattern detection techniques that can be used in Array Studio. This includes Find Neighbors, Correlate Covariate, Hierarchical Clustering, NMF Clustering, Cluster Variables, Cluster Observations , and Gene Shaving . Cluster Variable and Cluster Observations include PAM, CAST, K-means, and SOM for clustering algorithms. Array Studio can handle (with a regular computer) Hierarchical Clustering up to 30,000 variables in a few minutes. In comparison, the popular gene clustering program from Eisen, Gene Cluster, can only cluster up to 9,999 variables. For the purposes of this tutorial, we will cluster the already created List, 18 -> DBP vs control.Sig296 , as an example. In the Microarray Workflow , select Hierarchical Clustering , or go to the OmicData | Pattern | Hierarchical Clustering to open Hierarchical Clustering . Once the Hierarchical Clustering window opens, ensure that MicroArrayData is selected under Input/Output | Data . Next, ensure that the 18 -> DBP vs. Control.Sig 296 is selected so that only probesets in this list are used for clustering ( Customized Variables ). Ensure that MicroArray Data.Observation23(23) is selected under Customized Observations , excluding the outlier filtered out by PCA. Under Options , ensure that Compute Observation tree and Compute variable tree are both selected. Array Studio gives the option of only clustering the observations, variables, or both. Both the observation tree and the variable tree contain options for Link and Distance for the clustering. Link includes options of Ward , Single , Complete , Average , Mcquitty , Median , and Centroid . Distance includes options of Euclidean , Maximum , Manhattan , Canberra , Binary , Pearson (uncentered correlation), and Correlation . Link Options Distance Options Generate classic dendrogram view will generate the dendrogram view in the old Array Studio 1.0 format. Uncheck this box as the new improved dendrogram viewer is preferred by most users. Note for correlation distance, there is no need to normalize the data. Click Submit to begin clustering. This process should take approximately 3 seconds. A new view will be generated in the Solution Explorer , called Dendrogram . There are two visible windows in this View . The left window contains the dendrogram, while the right window contains a zoomed-in view of the dendrogram. If the entire cluster is not visible in the left window, there are two options. First, the window size can be adjusted by dragging in between the left window and the right window. More conveniently, the pixel size can be automatically adjusted using the toolbar at the top of the left window Use either the pixel size dropdown box (x*y) or clicking the Fit Dendrogram to Window button. The button provides other options for viewing the dendrogram Click the Fit Dendrogram to Window button now. Resize the left window and click the button again if the data looks too small or distorted. When finished, the left window should look similar to below. The left window view (heatmap thumbnail with dendrogram) is linked to the right window view. Clicking on a branch of the dendrogram will bring those specific rows and observations up in the right window. Branches on both the Y-axis and X-axis can be clicked on, individually and together. Click on a small branch in the left window (Y-axis). Note that the branch, when selected, turns to blue color. Now notice the right hand window. The right hand window contains a HeatmapTableView of the rows (probesets) selected in the left hand dendrogram view. Initially, all the columns will not be visible in the view . If necessary, shrink the column widths so that all columns are visible by grabbing between two columns on the header row and shrinking the column. It may also help to hide the left hand window by clicking the Hide Thumbnail button on the toolbar. Notice that scrolling to the right shows the annotation for each probeset. To change the annotation columns displayed, click the Specify Annotation Columns button in View Controller | Task | Data . Next, use the Change ColorBars under View Controller | Task | Customize | Change ColorBars to open up a window for selecting columns for color bars. Choose time , then treatment to create color bars on that heatmap. Click OK to continue. Notice that the ColorBars appear over the heatmap to label different Time and Treatment groups. To view the legend, switch the View Controller to the Legend tab. Notice that Time and Treatment are separated on the legend for each viewing. Click on with border or without border to switch the status of copied legend (whether to have border). Click on Copy Legend to copy the legend. Note: Right-clicking on anything in the Legend colors will allow the user to change colors for the chart or the color bars. Sometimes the user might want to find a particular probeset or gene in the dendrogram, in order to see other genes clustered around it. To do this, first re-expand the left window thumbnail view using the Show Thumbnail button. Expand the left-window so that it splits about half the screen with the right-hand heatmap window. If necessary, click the Fit Dendrogram to Window button in order to see the entire dendrogram. Using the Select button on the main toolbar, type the gene name Star and change the dropdown box to the Gene Symbol selection, and then press Enter. This ensures that Array Studio will select Star in the column Gene Symbol . Click select by clicking on the binoculars button . Notice that in the left-hand dendrogram thumbnail view, two lines have been selected towards the middle of the dendrogram (indicated by the blue selection lines) In the right-hand heatmap view, only the probesets containing Star in Gene Symbol are now shown. To see those genes found around Star in the Dendrogram, click on a branch of the dendrogram near the blue selection line. On the right panel, scroll until the Star probeset is found, and notice the genes that are similar in pattern to Star . In particular, it appears that the genes Scarb1, Cyp17a1, and Stc2 cluster around Star , as well as others. As the last step in hierarchical clustering, the user can choose to change the coloring scheme of the heatmaps. This is accomplished by clicking Change Color Properties in the View Controller | Task tab. Click on the Middle value color and change it to white. Close the Color Properties dialog and notice the heatmaps are instantly updated.","title":"Hierarchical clustering"},{"location":"tutorials/Microarray/Data_Exploration/#pattern-matching-find-neighbors","text":"Array Studio includes a number of pattern detection modules and we will discuss one of them, Find Neighbors , which allows the user to find neighbors for a variable or an observation based on correlations. By default, the currently selected variable or observation (if multiple variables or observations are selected, the first one) will be used as the input for this module, and the user can easily change that input. The Find Neighbors module can be run by clicking on the Find Neighbors in the Microarray Workflow | Pattern recognition , or by going to the OmicData Menu | Pattern | Find Neighbors . Now click Find neighbors to open this module. This opens the Find Neighbors dialog window: Under the Input/Output section, the user has an option for Project and Data (Choose Tutorial MicroArray and MicroArray Data now). Ensure that all variables are selected under the Variables section. The user can choose to Find Neighbors using the data in a specific list of samples. Choose the List MicroArray Data.Observation23 to only run the Find Neighbors module on the 23 chips in the List (with outlier 22A removed). Leave the Output name blank and allow Array Studio to assign the default name. For the Options section, type 1368321_at into the Find neighbors for text box. This is the probeset for Egr1 , and had this probeset been selected in the view prior to opening this window, Array Studio would have selected it by default. Instead, the top probeset on the selected list was the default option. Ensure that Variable is selected (this module can work on observations as well). Correlation method contains options for Pearson , Spearman , and Kendall correlations. Ensure that Pearson is selected. Correlation direction allows the closest neighbors to be found for Positive, Negative, or both directions. Positive is the default option. Array Studio includes the option to either search for a fixed number of neighbors or by a p value cutoff of the correlations. For this practice, ensure that Fixed neighbor number is selected and type 20 into the box. If specified a cutoff for With P-value <, correlation test pvalues will be used to search the neighbors. Array Studio allows the user to either output a HeatmapView for the Find Neighbors or a ProfileView , which can be specified in Output view . Ensure that HeatmapView is selected now. Click Submit to continue. In the Solution Explorer , a new Omic data named 1368321_at.Neighbors is created under the Pattern folder. Two new views are created ( Neighbors a HeatmapView and Table a TableView ). A HeatmapView entitled Neighbors is shown by default in the view window . If the window does not appear as below (no rows shown), ensure that no filters are set in the View Controller | Variables tab by clicking the Clear All Filters button in View Controller . While interesting, the above view is not all that useful without color bars to indicate the classification of each chip. This can be accomplished using the Change X-Axis ColorBars item in View Controller | Task | Customize tab. Click Change X-Axis ColorBars now to open the Choose Columns window. Move treatment and time to the right-hand Listed columns section to create color bars for each column. Click OK to continue. The heatmap is updated to include the color bars. In order to get a better idea of the pattern, we need to order the heatmap columns in a reasonable way. Click Sort Heatmap columns in View Controller | Task | Data . First sort by time then sort by treatment . Now the heatmap columns are sorted appropriately as can be seen from the color bars. Choose the Legend tab in the View Controller to view the legend for the chart. The chart can be opened in PowerPoint at any time using the Open Current View in PowerPoint or Open All Charts in PowerPoint button. Besides just showing the Probeset ID , the chart can also show additional columns of annotation. Click Change Y-Axis Labels in View Controller | Task | Customize now to open the Choose Columns window . Move Gene Symbol to the Listed columns section and click OK to continue. The chart is updated, now showing the Gene Symbol instead of Probeset ID .","title":"Pattern Matching (Find Neighbors)"},{"location":"tutorials/Microarray/Data_Exploration/#gene-ontology-analysis","text":"Array Studio provides an internal gene ontology analysis. The gene ontology analysis takes lists of probesets and, using online Gene Ontology annotation, reports back the number of probesets found in each of the classes with the given ontology. This can be used, for example, to figure out if a particular class within ontology is over-represented in a particular treatment. Gene Ontology analysis can be found in the OmicData Menu | Annotation | Gene Ontology . This opens the Gene Ontology Classification Window . The Gene Ontology Classification window contains a number of options. First, select the Project and Data to be used for classification (choose Tutorial MicroArray and MicroArray Data ). Next, choose Lists for classification . In this case, we are interested in comparing the four estimates ( 1 ->DBP vs control , 3 -> DBP vs control , 6-> DBP vs control , 18 -> DBP vs control ). Choose these lists now and click OK . Choose GO term columns : because the user may choose to import customized annotation, the possibility exists that the user may wish to specify the columns that contain gene ontology terms. By default, Array Studio imports 3 columns of annotation with gene ontology terms. Array Studio automatically recognizes that Gene Ontology Biological Process , Gene Ontology Cellular Component , and Gene Ontology Molecular Function all contain GO terms. Ensure that all 3 columns are selected. Set the level of classification using the Classification level (0-6) box. The higher the level (6 being the highest), the more specific the GO classification. For instance, Level 0 is the least specific, and will have general categories of Biological Process , Cellular Component , and Molecular Function . On the other hand, level 6 will be extremely specific, for instance: cyclooxygenase pathway and GTP cyclohydrolase activity. For this exercise, leave the Classification level set to 3. This is the default setting, and may prove to be the most interesting for most practices. Biological process , molecular function , and cellular component checkboxes are provided if the user wishes to only specify a specific type of gene ontology. Many times customized annotations will include all three types in one column of annotation, and thus these checkboxes are provided for such cases. Leave all three checkboxes selected for this tutorial. Gene ontology is constantly being updated. This box Update frequency (days) sets the frequency that Array Studio should check for new ontology information. By default, this is set to 30 days. When run, if Array Studio has downloaded new annotation in the past 30 days, it will skip the download step and immediately begin classifying the lists. If users check the Calculate p-values (assumes variable independence) , the software will calculate a p-value for each GO category. This is based on Fisher s Exact Test, and it assumes variable independence. Check this box now. The Choose Universal List dropdown box is active only when Calculate p-values is selected. It can be used to choose the Universal List used for a Fisher's Exact Test. For instance, the user may choose to use the entire chip (all) for calculating of p-values, or only look at a list of probesets of interests. The Multiplicity dropdown box is active only when Calculate p-values is selected. It can be used to set the multiplicity adjustment for the Fisher s Exact Test, and contains the standard multiplicity adjustment types found elsewhere in Array Studio. Click Submit to continue. If the gene ontology has not been updated or it has been more than 30 days old (true for all first-time users of Array Studio), the gene ontology will be updated first, and then the module will run. When finished, a new Table , titled MicroArrayData.GeneOntologyReport is created in the Solution Explorer under the Ontology tab, and the Table view is opened in the center Data View window. Note Note: Due to the constantly updating nature of the Gene Ontology database, the number of rows in the example shown below and the number of rows when the user runs the tutorial may differ. This is expected. The Table contains 10 columns. The first column contains the category (the gene ontology), the second column contains the GOTerm, with the other columns containing the number of probesets, in each list or universal list [all], belonging to each category and the corresponding Fisher Exact test p-values. As in all views in Array Studio, details can be provided on demand and are fully interactive. Clicking on a particular cell, for instance, in 3 -> DBP vs control , actin filament-based process, will provide inference report details about the probesets contained in that category in the Details Window . Details for multiple cells can be obtained by holding \"Shift\" or \"Ctrl\" buttons and selecting multiple cells.","title":"Gene ontology analysis"},{"location":"tutorials/Microarray/Data_Visualization_and_Quality_Control/","text":"Data Visualization and Quality Control Array Studio contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter. The VariableView Once a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular gene or genes. This can be accomplished in a number of different ways in Array Studio , but the most unique way is VariableView . The VariableView allows the user to visualize one chart for each variable in the dataset. So, for this dataset, there will be 15,923 charts available for visualization. However, this view can be used to visualize millions of variables. To add a VariableView , go to the Solution Explorer . For the MicroArrayData dataset, right-click on MicroArrayData and select Add View from the dropdown box. Alternatively, click Add View from the toolbar. This opens the Add View window, which lists all the different types of views available for a Data object. Choose VariableView from the Choose View Type box. Notice that a preview of the view is shown in the Preview box. Click OK to add the view. After adding it, a new view will appear in the main view window. In addition, this new view will appear in the Solution Explorer , as shown below. Scroll through all 15,923 charts in the VariableView to see that Array Studio can easily handle the visualization for all the variables in the dataset. On the X-Axis, each of the 24 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed). Each point on the chart represents the intensity value of that chip for that variable (probeset). However, the power of the VariableView lies in its ability to be customized. By itself, the view picture below is somewhat non-informative. Unless the user knows what group each chip belongs to, and what gene each probeset represents, further customization is required. The Task tab in the View Controller of the VariableView (pictured below), will be used to customize this view. The first step in customizing the view is to start from the top of the Task tab and work downwards, completing the customization. In the Data section of the Task tab of the View Controller , click Specify Title Columns now. This opens the Specify Title Columns window: This window allows the user to specify which columns from the attached Annotation table should be used to identify each chart. Scroll through the Available columns to find Gene Title and Gene Symbol . Move these two columns to the Listed columns box, so that Probe Set ID, Gene Title, and Gene Symbol are all listed. Click OK to continue. Notice that the charts have been updated to reflect the additional title information, from the Gene Title and Gene Symbol columns ( if there is no associated gene for a probe set, the fields show up as \"-,-\"). For the purposes of this tutorial, go to the Variable tab of the View Controller , and once again filter Gene Symbol , using ^EGR1$ as the filter, as shown below. Note: All of the customizations performed on this view will apply to all variables, however we will concentrate on visualizing EGR1 for demonstration purposes. Notice that the view is now updated to reflect the filter, and only shows one chart. The number of charts currently visible is shown directly above the view. Now go back to the Task tab of the View Controller . The next step is to Specify Profile Column . This allows the user to group the data points by a particular column of the Design Table . Remember, the Design Table contained columns for Time, Treatment , and Group . So, theoretically, it might be good to specify profile column as Group . However, looking ahead one step, notice that there is another option, called Specify Split Column . This allows the user to split their grouping twice, and is what will occur in this case. Clicking Specify Profile Column opens the Choose Profile Column window. Choose time and click OK . The chart is updated so that each time is shown on the X-Axis. However, notice that the X-Axis does not look quite right. Time , in this case, should be a category, rather than a numeric value. Array Studio has parsed the time column as a numeric value, whereas the intended use was that of a Factor . This can be changed by editing the column type for the time column in the Design Table . To do this, first open the TableView for the Design Table by expanding the Design node of the Microarray dataset, and double-clicking on the Table for the Design . The main view window is updated to show the Design Table Right click on the time column, and choose Column Properties (this can also be accessed by going to the Table Menu | Columns | Column Properties . In this window, properties can be set for each column in the Design Table . Click on the time column, and then change the Column Type from Integer to Factor , as shown below. Close the window when finished. Switch back to the VariableView by clicking the tab in the main view window or by double-clicking on it in the Solution Explorer . Notice that the view is automatically updated, and that the X-Axis now uses a category scale, so that the 4 time points in the experiment are laid out in order along the X-Axis. Now click Specify Split Column from the Task tab of the View Controller . This opens the Choose Split Column window. The purpose of the Split Column is to further split the data, so that each Profile Column is split by the Split Column . Thus, for this tutorial, each time point will be split into the two levels of treatment (DBP and Control). Click OK to return to the chart. The VariableView is updated to reflect the splitting of the data. Notice that for each time point, there are now two colors (green and blue). To find out what the colors represent, go to View Controller . Note that the blue color represents the control group, the green color represents the DBP treatment group. The user can always open the charts in PowerPoint by clicking the Open in PowerPoint button in the main view window, above the chart. The number of charts that can be opened is determined by the maximum number of slides allowed in a single PowerPoint file. Click the Open in PowerPoint button now, and then select Open Current View in PowerPoint . This will open the view, along with the legend, in PowerPoint. Note: if the user already has a PowerPoint presentation open, Array Studio will prompt the user as to whether it should create a new presentation, or append the chart to an older presentation. The color of the legend (or shapes, fill properties, etc..) can be changed in the View Controller by right clicking on items. The Task tab of the View Controller can be used to further customize the VariableView . Select the Task tab, and click the Specify Transformation option to open the List window. This window will specify the type of transformation that is performed on the values shown in the chart. By default, no transformation is performed on the values. However, because the values are Log2 transformed, the user may wish to see the un-logged values. Select Exp2 to un-log the data. Click OK to return to the VariableView . Notice the scale is now an unlogged (linear) scale. There are a number of further customizations that can be done to the chart, so Omicsoft encourages the user to try some of the customizations on their own. But first, click the Change Profile Gallery button, in the Customize section of the Task tab of the View Controller to open the Change Profile Gallery window. The Change Gallery window allows the user to specify the type of gallery shown for the VariableView . By default, the view we have been looking at so far is Scatter . Other available options include Line, Scatter, LineScatter, Bar, BoxPlot, DotPlot, RBoxPlot , and ColorBar . Choose Bar now and click OK to return to the VariableView . The chart is updated to show a mean summarization, via a bar graph, of each group, as shown below. The user may be interested to know that the type of summarization can be changed by selecting Specify Mean Summarization in the Data section of the Task tab of the View Controller . Error bars can be shown for each bar on the chart, by selecting Show Error Bars from the Customize section in the Task tab of the View Controller . Select this now, and notice that the chart is updated to reflect the error bars. The type of error bar summarization can also be changed by selecting Specify Error Summarization in the Data section of the Task tab in the View Controller . The bar graph can be further customized using the customizations in the Task tab of the View Controller . For example, to better visualize the error bars, select View Controller | Task | Properties | Change Fill Properties and adjust the opacity: Array Studio also includes the ability to generate on-the-fly p-values for every variable in the VariableView . This can be accomplished by choosing Show Summary Information from the Customize section in the Task tab of the View Controller . Click this now, and see that the chart now shows multiple on-the-fly p-values. Because the user has specified both a Profile Column and a Split Column , Array Studio runs a two-way ANOVA on each variable, and generates p-values for each factor (time, treatment), as well as the interaction between the two treatments. It is clear from the p-values generated for this chart that this variable has significantly changing data for all three tests (time, treatment, and time*treatment). While this on-the-fly generation of p-values should not be used as a substitute for a full analysis, it can be used to get a quick read on whether or not a particular gene of interest is significantly changing in an experiment. Before continuing, make sure to Clear all filters in the Variable tab of the View Controller . The Pairwise ScatterView After the initial visualization of the data, the user may be interested in looking at some quality control parameters. (The previous generated views can be used later on, after more detailed analyses, in order to look at differentially expressed genes) The PairwiseScatterView provides a way for the user to easily visualize replicates. To add a PairwiseScatterView , go to the Solution Explorer , and right-click on the Microarray dataset. Click Add View and select PairwiseScatterView from the list of views. Once added, the main view window should look similar to the following screenshot. Note: If plots are blank, clear any applied filters from the View Controller. In this screenshot, 3 chips are shown by default (in the example below 01A, 02A and 03A). This view provides a way for the user to look at both a ScatterView of the chips against each other, as well as an MA Plot for each chip against each other. The MA Plots are contained in the upper-right of the PairwiseScatterView , and the regular ScatterViews are contained in the lower-left of the PairwiseScatterView . An r value (Pearson correlation) for each chip-to-chip comparison is shown on each chart. Go to the Observation tab of the View Controller . Expand the group column, and choose dbp.t18 . The chart is updated to only show the 3 chips belonging to the dbp.t18 group. Notice that, unlike the first group we visualized, the correlation of chip 22A to the other chips in its group is not as good. This is the first indication that this group may be a technical outlier. Finally, remove or reset the checkBox filter so that the analysis workflow can continue. Principal component analysis of RMA signals After looking at the correlation of biological replicates, the next step in quality control could be principal component analysis. Principal component analysis can be used to detect outliers in a dataset, to detect outliers among treatment groups, and to get a general idea of the distribution for the data. To run a principal component analysis on a MicroArray dataset, go to the Microarray Workflow , and select Principal component analysis from the Quality control section of the Workflow window. Alternatively, go to the OmicData Menu | QC | Principal Component Analysis to open the Principal Component Analysis window. The Principal Component Analysis window, like most analysis windows in Array Studio , contains an Input/Output section. In this section, the user picks the Project and Data on which to run the analysis, as well as the Variables and Observations on which to run the analysis. This allows the user to specify if analyses should be run on all, selected, visible, or particular Customized Lists of Variables or Observations . Ensure that the correct project ( TutorialMicroArray in this example) is selected under the Input/Output | Project drop-down box and MicroArrayData is selected under Data drop-down box. Ensure that All variables is selected for Variables . Ensure that All observations is selected for Observations . Leave Output Name blank, as by default the outputted plots will be called Microarray.PcaScores . Under options, change the Group to 'group' to indicate the biological group information. Array Studio can generate 2D(3D) PCA plots if Component number is set to 2(3). Setting the Component number to 4 or more will generate a pairwise scatterview plot of the PCA. For this example, we will generate a 3D plot by setting this value to 3. Ensure that Scale variables , Output scores , and Calculate Hotelling T2 are selected, with an Alpha level of 0.05. Click Submit . Remember that all the details about this module, including input, output and parameter explanations can be retrieved by clicking the Help button. A dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 seconds. When complete, a new view will be created, as well as a new Table object in the QC folder of the Solution Explorer with associated views. The Table section of the Solution Explorer will need to be expanded, as well as the automatically generated QC folder and the new table. This is an example of a type of Table data, as opposed to the Omic data that we have been working with before. Table data has a flat two-way structure (rows and columns), while Omic data contains multiple levels (Data, Design, and Annotation). Switch to the view MicroArray.PcaScores|PcaScores to look at the score plot. First, notice that on the X and Y axis, the variance of each component is explained (equivalent of R 2 value). Component 1 (x-axis) explains 36.43 % of the variance in the data. Component 2 represents 11.77% of the variance in the data. And Component 3 represents an additional 8.41%. Users can use the Trackball button to rotate the 3D plot. At first glance, it is clear that there is one outlier in the chart. Click on the Change Symbol Properties in the task tab. Change the Labels section to All , then the By drop-down box to chip . Then close the dialog box. The labels reveal that chip 22A is the outlier sample. Check the View Controller to see the legend for the chart. This Legend will also be included if the user chooses to open the view of this chart in PowerPoint or Excel. Again, remember that right-clicking on an item in the Legend allows the user to \"Change Color\". Array Studio supports a unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, use the Select button to select sample 22A (either click directly on the data point, or left-click and drag, or right-click and use the Lasso to drag around the sample). When selected, the point will turn red. In the View Controller , select the Task tab. Then, under the Update tab, select the Exclude Selection button. This triggers the principal component analysis to re-run, with newly generated PCAScores in the Solution Explorer . The newly generated PcaScores plot is shown below. Important: Array Studio has also added a new List , called MicroArrayData.Observation23. This is a list of the remaining 23 chips (after the outlier, 22A, has been removed). This List can be used for all further downstream analysis, to automatically exclude chip 22A. Expand the List section in Solution Explorer now to see the newly generated list.","title":"Data Visualization and Quality Control"},{"location":"tutorials/Microarray/Data_Visualization_and_Quality_Control/#data-visualization-and-quality-control","text":"Array Studio contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter.","title":"Data Visualization and Quality Control"},{"location":"tutorials/Microarray/Data_Visualization_and_Quality_Control/#the-variableview","text":"Once a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular gene or genes. This can be accomplished in a number of different ways in Array Studio , but the most unique way is VariableView . The VariableView allows the user to visualize one chart for each variable in the dataset. So, for this dataset, there will be 15,923 charts available for visualization. However, this view can be used to visualize millions of variables. To add a VariableView , go to the Solution Explorer . For the MicroArrayData dataset, right-click on MicroArrayData and select Add View from the dropdown box. Alternatively, click Add View from the toolbar. This opens the Add View window, which lists all the different types of views available for a Data object. Choose VariableView from the Choose View Type box. Notice that a preview of the view is shown in the Preview box. Click OK to add the view. After adding it, a new view will appear in the main view window. In addition, this new view will appear in the Solution Explorer , as shown below. Scroll through all 15,923 charts in the VariableView to see that Array Studio can easily handle the visualization for all the variables in the dataset. On the X-Axis, each of the 24 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed). Each point on the chart represents the intensity value of that chip for that variable (probeset). However, the power of the VariableView lies in its ability to be customized. By itself, the view picture below is somewhat non-informative. Unless the user knows what group each chip belongs to, and what gene each probeset represents, further customization is required. The Task tab in the View Controller of the VariableView (pictured below), will be used to customize this view. The first step in customizing the view is to start from the top of the Task tab and work downwards, completing the customization. In the Data section of the Task tab of the View Controller , click Specify Title Columns now. This opens the Specify Title Columns window: This window allows the user to specify which columns from the attached Annotation table should be used to identify each chart. Scroll through the Available columns to find Gene Title and Gene Symbol . Move these two columns to the Listed columns box, so that Probe Set ID, Gene Title, and Gene Symbol are all listed. Click OK to continue. Notice that the charts have been updated to reflect the additional title information, from the Gene Title and Gene Symbol columns ( if there is no associated gene for a probe set, the fields show up as \"-,-\"). For the purposes of this tutorial, go to the Variable tab of the View Controller , and once again filter Gene Symbol , using ^EGR1$ as the filter, as shown below. Note: All of the customizations performed on this view will apply to all variables, however we will concentrate on visualizing EGR1 for demonstration purposes. Notice that the view is now updated to reflect the filter, and only shows one chart. The number of charts currently visible is shown directly above the view. Now go back to the Task tab of the View Controller . The next step is to Specify Profile Column . This allows the user to group the data points by a particular column of the Design Table . Remember, the Design Table contained columns for Time, Treatment , and Group . So, theoretically, it might be good to specify profile column as Group . However, looking ahead one step, notice that there is another option, called Specify Split Column . This allows the user to split their grouping twice, and is what will occur in this case. Clicking Specify Profile Column opens the Choose Profile Column window. Choose time and click OK . The chart is updated so that each time is shown on the X-Axis. However, notice that the X-Axis does not look quite right. Time , in this case, should be a category, rather than a numeric value. Array Studio has parsed the time column as a numeric value, whereas the intended use was that of a Factor . This can be changed by editing the column type for the time column in the Design Table . To do this, first open the TableView for the Design Table by expanding the Design node of the Microarray dataset, and double-clicking on the Table for the Design . The main view window is updated to show the Design Table Right click on the time column, and choose Column Properties (this can also be accessed by going to the Table Menu | Columns | Column Properties . In this window, properties can be set for each column in the Design Table . Click on the time column, and then change the Column Type from Integer to Factor , as shown below. Close the window when finished. Switch back to the VariableView by clicking the tab in the main view window or by double-clicking on it in the Solution Explorer . Notice that the view is automatically updated, and that the X-Axis now uses a category scale, so that the 4 time points in the experiment are laid out in order along the X-Axis. Now click Specify Split Column from the Task tab of the View Controller . This opens the Choose Split Column window. The purpose of the Split Column is to further split the data, so that each Profile Column is split by the Split Column . Thus, for this tutorial, each time point will be split into the two levels of treatment (DBP and Control). Click OK to return to the chart. The VariableView is updated to reflect the splitting of the data. Notice that for each time point, there are now two colors (green and blue). To find out what the colors represent, go to View Controller . Note that the blue color represents the control group, the green color represents the DBP treatment group. The user can always open the charts in PowerPoint by clicking the Open in PowerPoint button in the main view window, above the chart. The number of charts that can be opened is determined by the maximum number of slides allowed in a single PowerPoint file. Click the Open in PowerPoint button now, and then select Open Current View in PowerPoint . This will open the view, along with the legend, in PowerPoint. Note: if the user already has a PowerPoint presentation open, Array Studio will prompt the user as to whether it should create a new presentation, or append the chart to an older presentation. The color of the legend (or shapes, fill properties, etc..) can be changed in the View Controller by right clicking on items. The Task tab of the View Controller can be used to further customize the VariableView . Select the Task tab, and click the Specify Transformation option to open the List window. This window will specify the type of transformation that is performed on the values shown in the chart. By default, no transformation is performed on the values. However, because the values are Log2 transformed, the user may wish to see the un-logged values. Select Exp2 to un-log the data. Click OK to return to the VariableView . Notice the scale is now an unlogged (linear) scale. There are a number of further customizations that can be done to the chart, so Omicsoft encourages the user to try some of the customizations on their own. But first, click the Change Profile Gallery button, in the Customize section of the Task tab of the View Controller to open the Change Profile Gallery window. The Change Gallery window allows the user to specify the type of gallery shown for the VariableView . By default, the view we have been looking at so far is Scatter . Other available options include Line, Scatter, LineScatter, Bar, BoxPlot, DotPlot, RBoxPlot , and ColorBar . Choose Bar now and click OK to return to the VariableView . The chart is updated to show a mean summarization, via a bar graph, of each group, as shown below. The user may be interested to know that the type of summarization can be changed by selecting Specify Mean Summarization in the Data section of the Task tab of the View Controller . Error bars can be shown for each bar on the chart, by selecting Show Error Bars from the Customize section in the Task tab of the View Controller . Select this now, and notice that the chart is updated to reflect the error bars. The type of error bar summarization can also be changed by selecting Specify Error Summarization in the Data section of the Task tab in the View Controller . The bar graph can be further customized using the customizations in the Task tab of the View Controller . For example, to better visualize the error bars, select View Controller | Task | Properties | Change Fill Properties and adjust the opacity: Array Studio also includes the ability to generate on-the-fly p-values for every variable in the VariableView . This can be accomplished by choosing Show Summary Information from the Customize section in the Task tab of the View Controller . Click this now, and see that the chart now shows multiple on-the-fly p-values. Because the user has specified both a Profile Column and a Split Column , Array Studio runs a two-way ANOVA on each variable, and generates p-values for each factor (time, treatment), as well as the interaction between the two treatments. It is clear from the p-values generated for this chart that this variable has significantly changing data for all three tests (time, treatment, and time*treatment). While this on-the-fly generation of p-values should not be used as a substitute for a full analysis, it can be used to get a quick read on whether or not a particular gene of interest is significantly changing in an experiment. Before continuing, make sure to Clear all filters in the Variable tab of the View Controller .","title":"The VariableView"},{"location":"tutorials/Microarray/Data_Visualization_and_Quality_Control/#the-pairwise-scatterview","text":"After the initial visualization of the data, the user may be interested in looking at some quality control parameters. (The previous generated views can be used later on, after more detailed analyses, in order to look at differentially expressed genes) The PairwiseScatterView provides a way for the user to easily visualize replicates. To add a PairwiseScatterView , go to the Solution Explorer , and right-click on the Microarray dataset. Click Add View and select PairwiseScatterView from the list of views. Once added, the main view window should look similar to the following screenshot. Note: If plots are blank, clear any applied filters from the View Controller. In this screenshot, 3 chips are shown by default (in the example below 01A, 02A and 03A). This view provides a way for the user to look at both a ScatterView of the chips against each other, as well as an MA Plot for each chip against each other. The MA Plots are contained in the upper-right of the PairwiseScatterView , and the regular ScatterViews are contained in the lower-left of the PairwiseScatterView . An r value (Pearson correlation) for each chip-to-chip comparison is shown on each chart. Go to the Observation tab of the View Controller . Expand the group column, and choose dbp.t18 . The chart is updated to only show the 3 chips belonging to the dbp.t18 group. Notice that, unlike the first group we visualized, the correlation of chip 22A to the other chips in its group is not as good. This is the first indication that this group may be a technical outlier. Finally, remove or reset the checkBox filter so that the analysis workflow can continue.","title":"The Pairwise ScatterView"},{"location":"tutorials/Microarray/Data_Visualization_and_Quality_Control/#principal-component-analysis-of-rma-signals","text":"After looking at the correlation of biological replicates, the next step in quality control could be principal component analysis. Principal component analysis can be used to detect outliers in a dataset, to detect outliers among treatment groups, and to get a general idea of the distribution for the data. To run a principal component analysis on a MicroArray dataset, go to the Microarray Workflow , and select Principal component analysis from the Quality control section of the Workflow window. Alternatively, go to the OmicData Menu | QC | Principal Component Analysis to open the Principal Component Analysis window. The Principal Component Analysis window, like most analysis windows in Array Studio , contains an Input/Output section. In this section, the user picks the Project and Data on which to run the analysis, as well as the Variables and Observations on which to run the analysis. This allows the user to specify if analyses should be run on all, selected, visible, or particular Customized Lists of Variables or Observations . Ensure that the correct project ( TutorialMicroArray in this example) is selected under the Input/Output | Project drop-down box and MicroArrayData is selected under Data drop-down box. Ensure that All variables is selected for Variables . Ensure that All observations is selected for Observations . Leave Output Name blank, as by default the outputted plots will be called Microarray.PcaScores . Under options, change the Group to 'group' to indicate the biological group information. Array Studio can generate 2D(3D) PCA plots if Component number is set to 2(3). Setting the Component number to 4 or more will generate a pairwise scatterview plot of the PCA. For this example, we will generate a 3D plot by setting this value to 3. Ensure that Scale variables , Output scores , and Calculate Hotelling T2 are selected, with an Alpha level of 0.05. Click Submit . Remember that all the details about this module, including input, output and parameter explanations can be retrieved by clicking the Help button. A dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 seconds. When complete, a new view will be created, as well as a new Table object in the QC folder of the Solution Explorer with associated views. The Table section of the Solution Explorer will need to be expanded, as well as the automatically generated QC folder and the new table. This is an example of a type of Table data, as opposed to the Omic data that we have been working with before. Table data has a flat two-way structure (rows and columns), while Omic data contains multiple levels (Data, Design, and Annotation). Switch to the view MicroArray.PcaScores|PcaScores to look at the score plot. First, notice that on the X and Y axis, the variance of each component is explained (equivalent of R 2 value). Component 1 (x-axis) explains 36.43 % of the variance in the data. Component 2 represents 11.77% of the variance in the data. And Component 3 represents an additional 8.41%. Users can use the Trackball button to rotate the 3D plot. At first glance, it is clear that there is one outlier in the chart. Click on the Change Symbol Properties in the task tab. Change the Labels section to All , then the By drop-down box to chip . Then close the dialog box. The labels reveal that chip 22A is the outlier sample. Check the View Controller to see the legend for the chart. This Legend will also be included if the user chooses to open the view of this chart in PowerPoint or Excel. Again, remember that right-clicking on an item in the Legend allows the user to \"Change Color\". Array Studio supports a unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, use the Select button to select sample 22A (either click directly on the data point, or left-click and drag, or right-click and use the Lasso to drag around the sample). When selected, the point will turn red. In the View Controller , select the Task tab. Then, under the Update tab, select the Exclude Selection button. This triggers the principal component analysis to re-run, with newly generated PCAScores in the Solution Explorer . The newly generated PcaScores plot is shown below. Important: Array Studio has also added a new List , called MicroArrayData.Observation23. This is a list of the remaining 23 chips (after the outlier, 22A, has been removed). This List can be used for all further downstream analysis, to automatically exclude chip 22A. Expand the List section in Solution Explorer now to see the newly generated list.","title":"Principal component analysis of RMA signals"},{"location":"tutorials/Microarray/Differential_Expression/","text":"Differential Expression Array Studio contains a number of different modules for performing univariate analysis/differential expression, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others. Two-Way ANOVA Two-Way ANOVA can be used to research the effects of multiple factors on expression data. The design of the experiment in this tutorial is set-up so that the user will perform a Two-Way ANOVA . For this tutorial, we are interested in generating contrasts for each time point, in comparing the DBP (treatment) group to the control group. The first factor in the ANOVA is time while the second factor is treatment . Thus, we should be able to generate four contrasts, and associating fold changes, p-values, estimates, etc. While the General Linear Model could easily be used instead (and provide more customization of the results), it is a much more straightforward process for the novice user to use the Two-way ANOVA module. To run the Differential Expression-Two Way ANOVA module, go to the Statistical Inference section of the workflow, and select Two-Way ANOVA . Alternatively, the same module can be selected by going to the OmicData Menu | Inference | Standard Tests | Two-way ANOVA . This opens the Two-way Analysis of Variance window: As with other analysis windows, the user must first set the Project and Data on which to run the analysis, in the Input/Output section. Make sure TutorialMicroArray is chosen as the project and MicroArrayData is chosen as the input data. For Variables , ensure that All Variables is selected. For Observations , choose Customized observations , then click the Select button to choose the list MicroArrayData.Observation23 . This ensures that the statistical tests are only run on the 23 observations that passed the PCA quality control. Array Studio will attempt to automatically populate the Factor 1 and Factor 2 dropdown boxes, using the first two Factor type columns in the design table. For this tutorial, this should correctly populate Factor 1 as time and Factor 2 as treatment . For generating the comparisons, the For each box is used. The factor chosen for Factor 1 will automatically be populated into the For each box, and cannot be changed, unless the user changes the Factor 1 column. To figure out what comparisons will be generated, read the For each , Compare to boxes together. So, For each: time\u00b8 Compare to : control will generate a contrast comparing DBP to control at each time point. Ensure that the Compare to dropdown box is set to control . The option to Include interaction term should be enabled, however if users wish to run a two-way ANOVA without the interaction, this is available here as well. Comparison specifies the multiple comparison procedure. Options include Control , Dunnett and Tukey . By - Allows the user to select an additional categorical variable to subset the data set before running ANOVA. Multiplicity adjustments for the comparisons can be set as well, with the default adjustment being FDR_BH (options include None , FDR_BH , FDR_BY , Bonferonni , Sidak , StepDownBonferroni , StepDownSidak , StepUp , QValue , QValue41 ). The multiplicity adjustment will calculate an Adjusted p-value column in the result report. FC Transformation specifies how the Fold Change is calculated based on estimate. Fold change is defined as the unlogged estimate. By default, it is Exp2: sign(estimate)*2^abs(estimate). User also has the options of Exp, Exp10 and Ratio. The Alpha level , or p-value cutoff, is used in the automatic generation of Lists for each contrast. If a multiplicity adjustment is set to anything other than None , these lists will be generated for probesets that have an adjusted p-value less than this value (by default 0.05). Report F-Test Pvalues will report the p-values for the F-tests (i.e. one p-value each for time, treatment, and treatment*time). Leave this box unchecked as we are more interested in specific estimates. Generate LSMean data will generate a new Data object, where each observation is the LSMean of the interaction of Factor 1 and Factor 2 group (i.e. in this case, the LSMean data would have 8 observations, one for each time treatment* group). For this tutorial, leave this box unchecked. If Generate LSMean data is checked, Append LSMeans to the inference report becomes available. This will append the LSMeans data , for each interaction group, to the inference report. This can be used to see the adjusted mean intensity levels of each group for any potential differentially expressed probesets (i.e. some users prefer to ignore lower-expressing probesets, and this provides the user with a way to filter by these values). Generate estimate data will generate a Data object containing one observation per contrast. So, in the case of this tutorial, the new Estimate data would contain four observations, one for each of the four comparisons being generated. For the purposes of this tutorial, leave this box unchecked. Split the significant list by change direction will split each generated significant list (based on the alpha level value) by direction of change. For users familiar with SAS Code, clicking the Show SAS Code button will generate the equivalent SAS code in a text file (the SAS code can only be used to run one probeset at a time). To run the differential expression, click the Submit button. The VolcanoPlotView and Inference Report After running the Two-way ANOVA (the computing time should be 1-3 seconds), a Table is generated under the Inference folder of the Solution Explorer, MicroArray Data.Tests (expand the Inference folder to see this). This table contains the information generated by the Two-way ANOVA . As can be observed in the Solution Explorer , this table contains 15923 rows (for the 15923 probesets) and 51 columns (35 from the original Annotation and 16 new columns). Also notice that a number of new Lists have been automatically generated by the Two-way ANOVA . These Lists can be used for purposes of filtering, and also in the next section, for generating a Venn Diagram . These lists were generated using an adjusted p-value cutoff of 0.05 (this was set in the previous dialog menu). If the user preferred to automatically generate lists using raw p-value, then no multiplicity adjustment test should have been specified. By default, a VolcanoPlotView will be generated for the Inference Table . It should be the view visible in the main view window. If not, double-click on it in the Solution Explorer or switch to the view in the main Data View window. After opening the view VolcanoPlot , notice that four volcano plots have been created in this view, one for each comparison generated by the Two-Way ANOVA window. To change all graphs to the same scale, click Use Uniform Scale icon on the toolbar (as shown below). The graph should be updated instantly. Looking in the toolbar , the user should recognize many of the icons from previous views. Open Current view as picture : will open current visible view in the default picture viewer Open Current view in Excel: will open current visible view in Microsoft Excel Open All Charts in Excel: will open all opened views in Microsoft Excel Open Current view in Excel (Editable) : will open current visible view in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above) Open All Charts in Excel (Editable) : will open all opened views in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above) Open Current view in PowerPoint : will open current visible view in Microsoft PowerPoint Open All Charts in PowerPoint : will open all opened views in Microsoft PowerPoint Open Current view in PowerPoint (Editable) : will open current visible viewin Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above) Open All Charts in PowerPoint (Editable) : will open current visible view in Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above) Copy Current View : will copy current view to the clipboard Save Current View : will save the current visible view as an image file (default is pdf but other formats include png, emf, gif, jpg, tif, bmp) Print Current View : will print the current view Print All Charts : will print charts that are currently opened Select : allow the user to lasso multiple selections Zoom in : will zoom in the table using lasso Full Screen : will open the view in full screen mode Refresh Chart and Undo all Zooms/Pans : Returns view to the original format Specify Layout (rows columns) : To specify layout by rows and columns. For instance, if the user was only interested in seeing one column per view in order to see a particular view in greater detail, this would be set to 3 1 (3 rows*1 column). Each column represents a view. Use Uniform Scale : when selected, will use the same scale (x and y-axis) for all graphs. The VolcanoPlotView shows the * Log10* P-value on the y-axis and the Estimate ( Estimate is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the most positive or negative genes can be found at the extremes of the x-axis. Similar to all views in Array Studio, the VolcanoPlotView is fully interactive. Selecting a particular point or points on the plot brings up the details of that probeset (based on its annotation) in the Details window at the bottom of the screen. The View Controller | Task under VolcanoPlotView mode gives the user options to Change Chart Properties (which includes renaming the title of the chart as well as the x and y-axis titles, and many other options), Change Symbol Properties , and Change To Quality-First Mode . The VolcanoPlot will often default to what is known as a \"Speed-First Mode\", where it is updated quickly when any changes are applied to the view (i.e. layout, specify columns). This mode is particularly useful when dealing with large numbers of variables. Users can toggle between this mode and Quality-First mode by clicking the option in the View Controller : Switch to Quality-First mode now and select Change Symbol Properties . To enlarge the data points in the volcano plot and allow for better visualization, users can slide the button in Size. Users can also add labels to all data points, or only those selected. In this example, choose selected and use the drop-down menu to label by Probe Set ID: Now, move the mouse around the volcano plot named 1 DBP vs. Control . Notice that a red square encompasses each individual point on the graph. This can be used to select an individual probeset from the graph, and retrieve information in the Details Window . Now, click on the data point that is in the upper most right corner of this plot. The point should now turn red, as it has been selected and labeled. Make sure that the Details Window is visible down below. If it has been closed, go to View | Show Details Window . If necessary, drag the border between the main Data View Window and the Details Window to expand the size of the Details Window . After selecting the upper right-hand data point, check the Details Window . Notice that the Details Window now contains the information of Estimates , Fold Changes , Raw P-values , and Adjusted P-values for each comparison. Scroll right in the Details Window to see the rest of the annotation columns. Because the test report is a type of Table , it also allows the user to use the View Controller | Column and Row tabs to filter the data by any column or row (includes the Two-Way ANOVA generated columns, as well as the gene annotation columns). Click the Options icon in the Row tab This allows the user to group the filters by either mode (i.e. p-value, fold-change, estimate, etc.) or contrast (time point 1 DBP vs. control, time point 2 DBP vs. control, etc.). Try grouping the p-values by mode now, and notice the effect on the filters. Notice that the Estimates for each comparison are now grouped together, as are the FoldChange, RawPValue, and AdjustedPValue columns. This is especially helpful for organizing filters in studies where a large number of contrasts have been generated. Also, note that the filter can be set to Match All Column or Match Any Columns . By default, the filter uses Match All Columns , ensuring that all filters will be matched when set. However, choosing Match Any Columns will allow the user to get results matching any of the filters. The Table View for the inference report is also automatically generated by the Two-way ANOVA , as a TableView named Report . Open this view now by double clicking in the Solution Explorer . A TableView is now shown in the main view window, containing the columns generated by the Two-way ANOVA , as well as the annotation columns. For this particular dataset, there are 15923 rows of probesets, with 51 columns of annotation . Notice that this includes annotation columns for Estimate columns, Fold Change columns, Raw p-value columns, and Adjusted p-value columns for each comparison made by the Two-way ANOVA . Click Specify Columns in the View Controller | Task tab. A Choose Columns window allows the user to specify the columns for view in the table. This can be useful, as the user may want to create different Table Views for the report, each containing different information. Columns can be removed, added, or the order of the columns can be changed. Click OK to return to the TableView of the report. The View Controller | Row tab can be used, just as in the VolcanoPlotView, to filter the data. Expand the RawPValue filter section, then expand 1 DBP vs. Control.RawPValue filter and enter <.05 to filter all probesets to only include those that have a RawPValue of less than 0.05 for 1 DBP vs. Control . Do the same for the filter of 3 DBP vs. Control.RawPValue filter, 6 DBP vs. control.RawPValue and 18 DBP vs. Control.RawPValue , filter. This will show only those genes with p-values less than 0.05 in four comparisons. Look at the top right of the table view to see the number of rows remaining after filtering (or just look at the top of the View Controller ). In this case, 24 probesets have p-values less than 0.05 at all 4 time points. Go to the Add Item drop-down button in the tool strip. Choose Add List From Visible rows to add a new List containing only those rows visible from the filter. The Choose List Source window opens. This allows the user to create a list using any of the different columns in the Table . The name of the list can be set as well as the organized folder location for the list. Here we use Probe Set ID to generate the list, notice that each line has a unique Probe set ID so the list would not contain any repeated probe set IDs. However, if you choose other IDs such as Gene Name to build the list, it may have repeated IDs since mulitple rows may share the same gene name. In this case, users can check the Make a unique list so that the repeat IDs would only show up once in the list. Choose Probe Set ID , name the list Significant at All Timepoints , and click OK to continue. Notice that a new list has been created. The Venn diagram view Array Studio also has the ability to easily create a Venn Diagram . The Venn Diagram could utilize the Lists , either created by the user or by Array Studio and the Two Way ANOVA (or other statistical inference module), to segment the data points. To add a Venn Diagram View , first go to the Solution Explorer and the -Omic Data section. Right click on MicroarrayData and select Add View from the menu. Select VennDiagramView from the list of choices. Notice that the Preview window automatically creates a simple Venn Diagram , using only the first List in the Lists tab of the Solution Explorer . This will be changed in the following steps. Click OK to add the View . Notice that a new view, called Venn Diagram , is now visible in the Solution Explorer Window , as well as in the main view window. Now the Venn Diagram view only contains one list. The user can add more lists by using the Specify Data Source option in the Task tab of the View Controller . However, it is much easier to do this using drag-and-drop. Note: Array Studio can handle up to six lists. However, only 4 lists can be shown in one chart at a time. So, if the user enters more than 4 lists, Array Studio will create every combination of those lists, and one chart for each combination will be shown in the View . To drag-and-drop to the Venn Diagram view, go to the List in Solution Explorer , and choose the lists of all four time points (use shift or control-click to choose multiple lists at the same time). Now, drag these lists into the main view window, which is then updated to include the four lists in the Diagram . Like every other view in Array Studio, the Venn Diagram view is also fully interactive. Click on the number 29 in the intersection of the 3 lists. First, note that parentheses now appears after the number 29 so that it looks like 29(29). This indicates that the user has selected the 29 genes found in that intersection. Look at the Details Window and notice that 29 probesets are now listed in the Details Window . Similar to every other view, the Venn Diagram view can be exported to other programs using the toolbar. The General Linear Model If users have a complicated design table (such as some large clinical experiment) involving many factors, they can use General linear model function to build some complicated statistical model. Users can find the function of General linear model here: Or through windows here: Two-Way ANOVA is a specific case of General model, here we can get the same results using General linear model: Just like in Two Way ANOVA, users can specify the observations by list to do the analysis based the 23 observations. After that, users can specify the model by selecting the time and treatment and clicking Add . The interaction term \"time:treatment\" is made by selecting both classes and clicking the Cross button as shown below. Notice that array studio would automatically treat numeric variables such as time as continuous factor, so users have to check the Class box to convert time as categorical factor. After clicking OK , users can specify the Test. Here we choose the option Specify Test : Here we want to compare control to case for each time point, so users can specify the test by first checking the option For each and selecting time from the drop-down menu. Under the Compare to drop-down menu, select control . Once these options are entered, click the Add button and the four comparisons will be populated as below: After clicking OK , and Submit , users will get the same results with 2-way ANOVA. Summarize Inference Report Sometimes, a user wishes to count the number of variables, or probesets, corresponding to a set of criteria for each comparison in an analysis. For instance, the user might want to see how many variables have a p-value <0.05/Fold change >2, p-value<0.05/Fold change >3, p-value<0.05/Fold change>4, p-value<0.05/Fold change<-2, p-value<0.05/Fold change <-3, and p-value<0.05/Fold change <-4 for each of the four comparisons. This can be done manually by creating filters for each of these different criteria and counting the number of genes fitting that criteria. Alternatively, and the faster approach, the user can use the Summarize Inference Report module, by switching from Solution Explorer to Workflow and clicking on Summarize inference report , or by going to the OmicData Menu | Inference | Summarize Inference Report . This opens the Summarize Inference Report window. In this window, the user needs to first set the Project and Inference test object, on which to run the module. Choose TutorialMicroArray and MicroArrayData.Tests . Ensure that All rows is selected for Rows , and that all 4 estimates are selected for Estimates . Under Options , the user just needs to add the conditions of interest. For example, in order to add a condition whereby the Raw Pvalue<0.05 and the Fold change>2, ensure that both of these boxes are checked, and that the Fold change > box contains 2 while the < box is empty. Click the Add button to add this to the Conditions section. Double-click the name of the condition to rename it (FC>2). Repeat this process until conditions have been added, whereby all have Raw Pvalue<0.05, but with FC>2, FC>3, FC>4, FC<-2, FC<-3, and FC<-4. There should be a total of 6 conditions in the Conditions box. The module will generate (interactive) counts of variables that meet these conditions for each of the 4 estimates/contrasts selected. Optionally, the user can select the Generate lists based on conditions checkbox (under the Advanced tab) to automatically generate one List for each condition/estimate. For this tutorial, leave this unchecked, as it will generate 19 Lists . Click Submit to run the module. A new Table will be generated in the Solution Explorer , called MicroArray Data.Tests.SummaryReport , as well as a TableView . The generated TableView , as shown below, contains the count, for each estimate, of the 6 different criteria. This TableView is fully interactive, as selecting one or multiple cells shows the associated variables in the Details Window . In addition, Array Studio automatically updates the Details Window to only show the results of the particular tests for the selected estimate(s). In other words, if the user selects a summary count for certain condition(s) for 1 DBP vs. Control, only 1 DBP vs. Control columns (and annotation) will be shown in the Details Window . This is done so that the user can easily export the results for that particular comparison.","title":"Differential Expression"},{"location":"tutorials/Microarray/Differential_Expression/#differential-expression","text":"Array Studio contains a number of different modules for performing univariate analysis/differential expression, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others.","title":"Differential Expression"},{"location":"tutorials/Microarray/Differential_Expression/#two-way-anova","text":"Two-Way ANOVA can be used to research the effects of multiple factors on expression data. The design of the experiment in this tutorial is set-up so that the user will perform a Two-Way ANOVA . For this tutorial, we are interested in generating contrasts for each time point, in comparing the DBP (treatment) group to the control group. The first factor in the ANOVA is time while the second factor is treatment . Thus, we should be able to generate four contrasts, and associating fold changes, p-values, estimates, etc. While the General Linear Model could easily be used instead (and provide more customization of the results), it is a much more straightforward process for the novice user to use the Two-way ANOVA module. To run the Differential Expression-Two Way ANOVA module, go to the Statistical Inference section of the workflow, and select Two-Way ANOVA . Alternatively, the same module can be selected by going to the OmicData Menu | Inference | Standard Tests | Two-way ANOVA . This opens the Two-way Analysis of Variance window: As with other analysis windows, the user must first set the Project and Data on which to run the analysis, in the Input/Output section. Make sure TutorialMicroArray is chosen as the project and MicroArrayData is chosen as the input data. For Variables , ensure that All Variables is selected. For Observations , choose Customized observations , then click the Select button to choose the list MicroArrayData.Observation23 . This ensures that the statistical tests are only run on the 23 observations that passed the PCA quality control. Array Studio will attempt to automatically populate the Factor 1 and Factor 2 dropdown boxes, using the first two Factor type columns in the design table. For this tutorial, this should correctly populate Factor 1 as time and Factor 2 as treatment . For generating the comparisons, the For each box is used. The factor chosen for Factor 1 will automatically be populated into the For each box, and cannot be changed, unless the user changes the Factor 1 column. To figure out what comparisons will be generated, read the For each , Compare to boxes together. So, For each: time\u00b8 Compare to : control will generate a contrast comparing DBP to control at each time point. Ensure that the Compare to dropdown box is set to control . The option to Include interaction term should be enabled, however if users wish to run a two-way ANOVA without the interaction, this is available here as well. Comparison specifies the multiple comparison procedure. Options include Control , Dunnett and Tukey . By - Allows the user to select an additional categorical variable to subset the data set before running ANOVA. Multiplicity adjustments for the comparisons can be set as well, with the default adjustment being FDR_BH (options include None , FDR_BH , FDR_BY , Bonferonni , Sidak , StepDownBonferroni , StepDownSidak , StepUp , QValue , QValue41 ). The multiplicity adjustment will calculate an Adjusted p-value column in the result report. FC Transformation specifies how the Fold Change is calculated based on estimate. Fold change is defined as the unlogged estimate. By default, it is Exp2: sign(estimate)*2^abs(estimate). User also has the options of Exp, Exp10 and Ratio. The Alpha level , or p-value cutoff, is used in the automatic generation of Lists for each contrast. If a multiplicity adjustment is set to anything other than None , these lists will be generated for probesets that have an adjusted p-value less than this value (by default 0.05). Report F-Test Pvalues will report the p-values for the F-tests (i.e. one p-value each for time, treatment, and treatment*time). Leave this box unchecked as we are more interested in specific estimates. Generate LSMean data will generate a new Data object, where each observation is the LSMean of the interaction of Factor 1 and Factor 2 group (i.e. in this case, the LSMean data would have 8 observations, one for each time treatment* group). For this tutorial, leave this box unchecked. If Generate LSMean data is checked, Append LSMeans to the inference report becomes available. This will append the LSMeans data , for each interaction group, to the inference report. This can be used to see the adjusted mean intensity levels of each group for any potential differentially expressed probesets (i.e. some users prefer to ignore lower-expressing probesets, and this provides the user with a way to filter by these values). Generate estimate data will generate a Data object containing one observation per contrast. So, in the case of this tutorial, the new Estimate data would contain four observations, one for each of the four comparisons being generated. For the purposes of this tutorial, leave this box unchecked. Split the significant list by change direction will split each generated significant list (based on the alpha level value) by direction of change. For users familiar with SAS Code, clicking the Show SAS Code button will generate the equivalent SAS code in a text file (the SAS code can only be used to run one probeset at a time). To run the differential expression, click the Submit button.","title":"Two-Way ANOVA"},{"location":"tutorials/Microarray/Differential_Expression/#the-volcanoplotview-and-inference-report","text":"After running the Two-way ANOVA (the computing time should be 1-3 seconds), a Table is generated under the Inference folder of the Solution Explorer, MicroArray Data.Tests (expand the Inference folder to see this). This table contains the information generated by the Two-way ANOVA . As can be observed in the Solution Explorer , this table contains 15923 rows (for the 15923 probesets) and 51 columns (35 from the original Annotation and 16 new columns). Also notice that a number of new Lists have been automatically generated by the Two-way ANOVA . These Lists can be used for purposes of filtering, and also in the next section, for generating a Venn Diagram . These lists were generated using an adjusted p-value cutoff of 0.05 (this was set in the previous dialog menu). If the user preferred to automatically generate lists using raw p-value, then no multiplicity adjustment test should have been specified. By default, a VolcanoPlotView will be generated for the Inference Table . It should be the view visible in the main view window. If not, double-click on it in the Solution Explorer or switch to the view in the main Data View window. After opening the view VolcanoPlot , notice that four volcano plots have been created in this view, one for each comparison generated by the Two-Way ANOVA window. To change all graphs to the same scale, click Use Uniform Scale icon on the toolbar (as shown below). The graph should be updated instantly. Looking in the toolbar , the user should recognize many of the icons from previous views. Open Current view as picture : will open current visible view in the default picture viewer Open Current view in Excel: will open current visible view in Microsoft Excel Open All Charts in Excel: will open all opened views in Microsoft Excel Open Current view in Excel (Editable) : will open current visible view in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above) Open All Charts in Excel (Editable) : will open all opened views in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above) Open Current view in PowerPoint : will open current visible view in Microsoft PowerPoint Open All Charts in PowerPoint : will open all opened views in Microsoft PowerPoint Open Current view in PowerPoint (Editable) : will open current visible viewin Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above) Open All Charts in PowerPoint (Editable) : will open current visible view in Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above) Copy Current View : will copy current view to the clipboard Save Current View : will save the current visible view as an image file (default is pdf but other formats include png, emf, gif, jpg, tif, bmp) Print Current View : will print the current view Print All Charts : will print charts that are currently opened Select : allow the user to lasso multiple selections Zoom in : will zoom in the table using lasso Full Screen : will open the view in full screen mode Refresh Chart and Undo all Zooms/Pans : Returns view to the original format Specify Layout (rows columns) : To specify layout by rows and columns. For instance, if the user was only interested in seeing one column per view in order to see a particular view in greater detail, this would be set to 3 1 (3 rows*1 column). Each column represents a view. Use Uniform Scale : when selected, will use the same scale (x and y-axis) for all graphs. The VolcanoPlotView shows the * Log10* P-value on the y-axis and the Estimate ( Estimate is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the most positive or negative genes can be found at the extremes of the x-axis. Similar to all views in Array Studio, the VolcanoPlotView is fully interactive. Selecting a particular point or points on the plot brings up the details of that probeset (based on its annotation) in the Details window at the bottom of the screen. The View Controller | Task under VolcanoPlotView mode gives the user options to Change Chart Properties (which includes renaming the title of the chart as well as the x and y-axis titles, and many other options), Change Symbol Properties , and Change To Quality-First Mode . The VolcanoPlot will often default to what is known as a \"Speed-First Mode\", where it is updated quickly when any changes are applied to the view (i.e. layout, specify columns). This mode is particularly useful when dealing with large numbers of variables. Users can toggle between this mode and Quality-First mode by clicking the option in the View Controller : Switch to Quality-First mode now and select Change Symbol Properties . To enlarge the data points in the volcano plot and allow for better visualization, users can slide the button in Size. Users can also add labels to all data points, or only those selected. In this example, choose selected and use the drop-down menu to label by Probe Set ID: Now, move the mouse around the volcano plot named 1 DBP vs. Control . Notice that a red square encompasses each individual point on the graph. This can be used to select an individual probeset from the graph, and retrieve information in the Details Window . Now, click on the data point that is in the upper most right corner of this plot. The point should now turn red, as it has been selected and labeled. Make sure that the Details Window is visible down below. If it has been closed, go to View | Show Details Window . If necessary, drag the border between the main Data View Window and the Details Window to expand the size of the Details Window . After selecting the upper right-hand data point, check the Details Window . Notice that the Details Window now contains the information of Estimates , Fold Changes , Raw P-values , and Adjusted P-values for each comparison. Scroll right in the Details Window to see the rest of the annotation columns. Because the test report is a type of Table , it also allows the user to use the View Controller | Column and Row tabs to filter the data by any column or row (includes the Two-Way ANOVA generated columns, as well as the gene annotation columns). Click the Options icon in the Row tab This allows the user to group the filters by either mode (i.e. p-value, fold-change, estimate, etc.) or contrast (time point 1 DBP vs. control, time point 2 DBP vs. control, etc.). Try grouping the p-values by mode now, and notice the effect on the filters. Notice that the Estimates for each comparison are now grouped together, as are the FoldChange, RawPValue, and AdjustedPValue columns. This is especially helpful for organizing filters in studies where a large number of contrasts have been generated. Also, note that the filter can be set to Match All Column or Match Any Columns . By default, the filter uses Match All Columns , ensuring that all filters will be matched when set. However, choosing Match Any Columns will allow the user to get results matching any of the filters. The Table View for the inference report is also automatically generated by the Two-way ANOVA , as a TableView named Report . Open this view now by double clicking in the Solution Explorer . A TableView is now shown in the main view window, containing the columns generated by the Two-way ANOVA , as well as the annotation columns. For this particular dataset, there are 15923 rows of probesets, with 51 columns of annotation . Notice that this includes annotation columns for Estimate columns, Fold Change columns, Raw p-value columns, and Adjusted p-value columns for each comparison made by the Two-way ANOVA . Click Specify Columns in the View Controller | Task tab. A Choose Columns window allows the user to specify the columns for view in the table. This can be useful, as the user may want to create different Table Views for the report, each containing different information. Columns can be removed, added, or the order of the columns can be changed. Click OK to return to the TableView of the report. The View Controller | Row tab can be used, just as in the VolcanoPlotView, to filter the data. Expand the RawPValue filter section, then expand 1 DBP vs. Control.RawPValue filter and enter <.05 to filter all probesets to only include those that have a RawPValue of less than 0.05 for 1 DBP vs. Control . Do the same for the filter of 3 DBP vs. Control.RawPValue filter, 6 DBP vs. control.RawPValue and 18 DBP vs. Control.RawPValue , filter. This will show only those genes with p-values less than 0.05 in four comparisons. Look at the top right of the table view to see the number of rows remaining after filtering (or just look at the top of the View Controller ). In this case, 24 probesets have p-values less than 0.05 at all 4 time points. Go to the Add Item drop-down button in the tool strip. Choose Add List From Visible rows to add a new List containing only those rows visible from the filter. The Choose List Source window opens. This allows the user to create a list using any of the different columns in the Table . The name of the list can be set as well as the organized folder location for the list. Here we use Probe Set ID to generate the list, notice that each line has a unique Probe set ID so the list would not contain any repeated probe set IDs. However, if you choose other IDs such as Gene Name to build the list, it may have repeated IDs since mulitple rows may share the same gene name. In this case, users can check the Make a unique list so that the repeat IDs would only show up once in the list. Choose Probe Set ID , name the list Significant at All Timepoints , and click OK to continue. Notice that a new list has been created.","title":"The VolcanoPlotView and Inference Report"},{"location":"tutorials/Microarray/Differential_Expression/#the-venn-diagram-view","text":"Array Studio also has the ability to easily create a Venn Diagram . The Venn Diagram could utilize the Lists , either created by the user or by Array Studio and the Two Way ANOVA (or other statistical inference module), to segment the data points. To add a Venn Diagram View , first go to the Solution Explorer and the -Omic Data section. Right click on MicroarrayData and select Add View from the menu. Select VennDiagramView from the list of choices. Notice that the Preview window automatically creates a simple Venn Diagram , using only the first List in the Lists tab of the Solution Explorer . This will be changed in the following steps. Click OK to add the View . Notice that a new view, called Venn Diagram , is now visible in the Solution Explorer Window , as well as in the main view window. Now the Venn Diagram view only contains one list. The user can add more lists by using the Specify Data Source option in the Task tab of the View Controller . However, it is much easier to do this using drag-and-drop. Note: Array Studio can handle up to six lists. However, only 4 lists can be shown in one chart at a time. So, if the user enters more than 4 lists, Array Studio will create every combination of those lists, and one chart for each combination will be shown in the View . To drag-and-drop to the Venn Diagram view, go to the List in Solution Explorer , and choose the lists of all four time points (use shift or control-click to choose multiple lists at the same time). Now, drag these lists into the main view window, which is then updated to include the four lists in the Diagram . Like every other view in Array Studio, the Venn Diagram view is also fully interactive. Click on the number 29 in the intersection of the 3 lists. First, note that parentheses now appears after the number 29 so that it looks like 29(29). This indicates that the user has selected the 29 genes found in that intersection. Look at the Details Window and notice that 29 probesets are now listed in the Details Window . Similar to every other view, the Venn Diagram view can be exported to other programs using the toolbar.","title":"The Venn diagram view"},{"location":"tutorials/Microarray/Differential_Expression/#the-general-linear-model","text":"If users have a complicated design table (such as some large clinical experiment) involving many factors, they can use General linear model function to build some complicated statistical model. Users can find the function of General linear model here: Or through windows here: Two-Way ANOVA is a specific case of General model, here we can get the same results using General linear model: Just like in Two Way ANOVA, users can specify the observations by list to do the analysis based the 23 observations. After that, users can specify the model by selecting the time and treatment and clicking Add . The interaction term \"time:treatment\" is made by selecting both classes and clicking the Cross button as shown below. Notice that array studio would automatically treat numeric variables such as time as continuous factor, so users have to check the Class box to convert time as categorical factor. After clicking OK , users can specify the Test. Here we choose the option Specify Test : Here we want to compare control to case for each time point, so users can specify the test by first checking the option For each and selecting time from the drop-down menu. Under the Compare to drop-down menu, select control . Once these options are entered, click the Add button and the four comparisons will be populated as below: After clicking OK , and Submit , users will get the same results with 2-way ANOVA.","title":"The General Linear Model"},{"location":"tutorials/Microarray/Differential_Expression/#summarize-inference-report","text":"Sometimes, a user wishes to count the number of variables, or probesets, corresponding to a set of criteria for each comparison in an analysis. For instance, the user might want to see how many variables have a p-value <0.05/Fold change >2, p-value<0.05/Fold change >3, p-value<0.05/Fold change>4, p-value<0.05/Fold change<-2, p-value<0.05/Fold change <-3, and p-value<0.05/Fold change <-4 for each of the four comparisons. This can be done manually by creating filters for each of these different criteria and counting the number of genes fitting that criteria. Alternatively, and the faster approach, the user can use the Summarize Inference Report module, by switching from Solution Explorer to Workflow and clicking on Summarize inference report , or by going to the OmicData Menu | Inference | Summarize Inference Report . This opens the Summarize Inference Report window. In this window, the user needs to first set the Project and Inference test object, on which to run the module. Choose TutorialMicroArray and MicroArrayData.Tests . Ensure that All rows is selected for Rows , and that all 4 estimates are selected for Estimates . Under Options , the user just needs to add the conditions of interest. For example, in order to add a condition whereby the Raw Pvalue<0.05 and the Fold change>2, ensure that both of these boxes are checked, and that the Fold change > box contains 2 while the < box is empty. Click the Add button to add this to the Conditions section. Double-click the name of the condition to rename it (FC>2). Repeat this process until conditions have been added, whereby all have Raw Pvalue<0.05, but with FC>2, FC>3, FC>4, FC<-2, FC<-3, and FC<-4. There should be a total of 6 conditions in the Conditions box. The module will generate (interactive) counts of variables that meet these conditions for each of the 4 estimates/contrasts selected. Optionally, the user can select the Generate lists based on conditions checkbox (under the Advanced tab) to automatically generate one List for each condition/estimate. For this tutorial, leave this unchecked, as it will generate 19 Lists . Click Submit to run the module. A new Table will be generated in the Solution Explorer , called MicroArray Data.Tests.SummaryReport , as well as a TableView . The generated TableView , as shown below, contains the count, for each estimate, of the 6 different criteria. This TableView is fully interactive, as selecting one or multiple cells shows the associated variables in the Details Window . In addition, Array Studio automatically updates the Details Window to only show the results of the particular tests for the selected estimate(s). In other words, if the user selects a summary count for certain condition(s) for 1 DBP vs. Control, only 1 DBP vs. Control columns (and annotation) will be shown in the Details Window . This is done so that the user can easily export the results for that particular comparison.","title":"Summarize Inference Report"},{"location":"tutorials/Microarray/Importing_a_Dataset/","text":"Importing a Dataset Downloading the DBPTS dataset For this tutorial, the following materials will be required: 24 .CEL files from the DBPTS Time Series dataset (Platform: Affymetrix RAE230A), as well as the included dbpts.design file, derived from the sample information for this dataset. The DBPTS dataset is available at: link After downloading the single .zip file, unzip the file to a folder to be used for this tutorial. The DBP Time Series data set contains information for 15923 probesets in a 2 by 4 factorial experiment. There are treatment (DBP) and control groups, measured at four different times (1 hr, 3 hr, 6 hr, and 18 hr). The experiment measures the intensity of gene expression level of 15923 probesets, with three replicates for each combination of treatment and time. This is NOT a repeated measure experiment, as different samples were used for different time points. The primary interest of this experiment is to find probesets that are differentially expressed under two conditions (treatment and control) at the 4 different time points. The dbpts.design file contains the design information for the study, including columns for chip, time, treatment, and group. A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed Chip for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the .CEL file extensions. Additional columns usually include treatment, time, etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it can be edited later on. The Workflow Window/ The Solution Explorer When Array Studio is first installed, it will be similar to below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. Notice at the top there will be four tabs: Analysis, Server, Land and Browser. This tutorial will focus on Analysis. The Workflow Window should be visible on the left side of the screen. If the Workflow Window is not visible, go to the View Menu | Show Workflow or click on Workflow at the bottom left. The Workflow Window should appear similar to the screenshot below. Tips: One can always go back to windows in the original setting by selecting the Menu View | Reset Windows . The Workflow Window provides users, especially new users, with a guide to running different types of analysis. Clicking the Workflow dropdown box shows all available workflows (Microarray, Single Channel Expression, Two Channel Expression, Exon Array, RT-PCR, Genotype, CNV, DNA-Seq, RNA-Seq, and miRNA-Seq: Make sure that Microarray is selected now. Notice that the Microarray Workflow is separated into different categories, including Getting started , Manage data , Preprocess , Quality control , Statistical inference , and Pattern recognition . While it is possible to access all of these functions via the menu commands in Array Studio , the Workflows are designed to make it easier for new users to work through their data. The first section of the Microarray Workflow is the Getting Started section. In this section, it is suggested that the user either create a new project or open a previously created project. To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window: Array Studio allows the user to create two different project types. A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects). Since this project is a microarray project, choose Create a simple project now. Then, click the Browse button to select a location and enter the name for the project. Once this is complete, click OK to continue. Besides the Workflow Window on the left hand side of the screen, Array Studio also contains the Solution Explorer . The Solution Explorer is used to organize each project, and within each project, dataset, results table, etc., that is generated while analyzing and visualizing a project. Another way to create a new project is by this icon in the Analysis tab: Note that users can choose to create different projects: Local project as mentioned above and server project. A server project is a distributed project saved on server. Once the user is connected to server, the option of creating a new server project will become available. When users want to create a server project, some basic metadata need to be provided: The interface of creating of a new local project is different from creating a new server project, but the rest of the steps, such as data import and data analysis, share the same interface. The \"local\" or \"server\" project types tell Array Studio where to run the analysis. If it is a local project, Array Studio runs the analysis on the local machine; if it is a server project, Array Studio would run the analysis on the server. Server projects are recommended when dealing with larger datasets, as server-based analyses allow the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The analyses in this tutorial are performed as a local project, but these can also be followed as a server project if the user is connected to ArrayServer. To switch to the Solution Explorer , choose the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, switch to it by going to the View Menu | Show Solution Explorer . The Solution Explorer will be empty, containing slots for List, Cluster, Text and Attachment . You can right-click on List, Cluster, Text and Attachment for additional options for each. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (in the case of microarray data, this would be probesets), or Observations (in the case of microarray data, this would be chips or samples). Right Clicking on List brings up this menu: Adding Microarray Data/Chip Normalization At this point, we are ready to add microarray data to the Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the Workflow Window , by selecting the Workflow tab at the bottom of the Solution Explorer . Alternatively, go to View Menu | Show Workflow to show the Workflow Window . Next, choose Add Expression Data , from the Manage Data section of the workflow. Alternatively, data can be added by going to the File Menu | Add Data |Add Omic Data | Add Expression Data or by clicking the Add Data button on the tool strip, and choosing Add Omic Data | Add Expression Data . A dialog box will open asking the user to specify the expression data source. Many different sources of data are available to choose from in Array Studio and can be seen in the dialog window below. For this tutorial, the 24 Affymetrix .CEL files downloaded earlier will be used. Select Affymetrix .CEL files (3 IVT, or Gene Arrays) and click OK . The Extract Affymetrix CEL file window appears: Click the Add button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click Open to continue. Check that there are 24 .CEL files listed for extraction by looking in the upper left corner of the dialog box. Under Options , the user will be shown the Array type of the CEL files that are being imported. The user has the option to select an alternative CDF (Affymetrix Library) file. The user can also select from the following Options: The choice of analysis methods include: RMA, GCRMA2, MAS5 and OMICSOFT (see reference for details). For experiments performed at different times, the Scale RMA/GCRMA signals can be used to scale all chips to a particular Target intensity . For MAS5 extractions, as well as when the Scale RMA/GCRMA signals box is checked, a number can be entered into the Target intensity box. A log-2 transformation can be performed on the signal matrix data upon extraction. If the user unchecks the Perform log-2 transformation on the signal matrix box, a log-2 transformation can still be performed at a later stage. If checked, the Import Sample Information from ARR files option will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files if they were generated by Affymetrix's Expression Console . The Generate MAS5 QC Report checkbox (available after adding CEL files), allows the user to automatically generate a MAS5 Report, without going through the separate menu option ( Tools |Affymetrix | Generate Affymetrix MAS5 QC Report ), however it offers fewer options than the regular menu item. The Select controls button allows the user to select the control genes for calculating 3 /5 ratios in the report (i.e. GAPDH, beta-actin, etc.). The Generate detection flag with p-value < checkbox allows the user to automatically generate a detection flag value based on a cutoff value specified (default of <0.05). Selecting this option will generate a table with values of 0 (meaning not present with a p-value <0.05) or 1 (present with a p-value <0.05). The resulting \"FlagTable\" view is hidden, but can be added by right click on MicroArrayData | Add View | FlagTableView . The detection flag table can be used in MicroArray | Preprocess | Filter By Flags . Selecting Report intensity + detection p-values will automatically generate an \"IntensityReport\" data object with an associated \"Intensity_Detection\" view and table. A CEL Report (Probe level) can also be generated, if Generate CEL Report box is checked. This can be done with the separate menu option Tools | Affymetrix |Generate Affymetrix CEL report . Optionally, a model based QC report can be generated as well. This is discussed further in the online help. Finally, the user can generate CHP files while extraction takes place, using the Write CHP files checkbox. Click on the Help button on the bottom left of the window to open the wiki page for Extract Affymetrix CEL Files . The wiki page describes the function input and output of this module, and explains all the options and parameters used in this module. Every analysis module in Array Studio has this Help button to link to the corresponding wiki page. When complete, the window should look similar to the following screenshot. Click Submit to start the RMA intensity signal matrix extraction. Data extraction will begin and take approximately 30 seconds. When complete, Array Studio will prompt the user to attach a design table. Click Yes now to attach the design table that was packaged with the CEL files. If No was selected instead, the design table can always be attached by right clicking on the design node for the project in the Solution Explorer and choosing Import to attach/reattach the design. The Specify Table Source window will open. As dbpts.design.txt is a tab-delimited text file, choose Tab delimited file and click OK to continue. Choose dbpts.design and click Open to continue the attachment process. Specify the location of the Design table file. Once the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to Append to the existing covariate table (if one exists) and to Use the name order in the new covariate table . Leave these options as default. Selecting \"OK\" will then proceed with the data parsing and creation of the Design table. The TableView At this point, the screen should look similar to below. On the left, the Solution Explorer will show an Annotation (automatically downloaded according to chip type) and Design Table (just imported) along with the Microarray Data type in Table format. Also, in the Table Data type, there will be a Mas5Report (under QC) and IntensityReport as chosen in the output of the previous command. In the center of the screen, a table view called Table should be visible. Scroll through the dataset to see how quickly Array Studio is able to scroll. Array Studio is able to easily handle millions of rows and columns in the TableView . Now switch back to the Solution Explorer . In Array Studio, the Solution Explorer will contain two types of data (-Omic data and Table data). These are organized separately in the Solution Explorer for each project. Open the Omic data node now, followed by the MicroArrayData node. In the main view window, click on the button on the right top corner to close the current view, MicroarrayData|Table. Then double-click in the Solution Explorer | Tutorial | -Omic Data |MicroArrayData | Table to reopen the TableView . Moving the mouse over any of the icons in the toolbar will give a short description of the button. Open as Text : will open current visible table in the default text editor (e.g. Notepad) Open in Excel : will open current visible table in Microsoft Excel Save as Text/object : will open dialog box to save current visible table as Text, Excel or Omicsoft object Sort Table : will sort the view, opening the Sort window. The Sort window allows the user to sort by up to four different columns, in either ascending or descending order. Note that the sorting mentioned above only applies to the current view, and not the actual data. So if the current Table View is closed, it would need to be sorted again. For more advanced features including sorting of the actual data instead of the view, use the menu, Omic Data | Manipulation | Sort Variables . Filter : Filter table by different rows Copy Table to Clipboard : will copy current visible table to clipboard. Additional Tools : contains a popup menu for additional tools: Find/Replace : find or replace cells in the table (this is not allowed with Omic data but can be used with regular table data. Match Selected Cells : select one or multiple cells in the table. Then click Match Selected Cells to find all of the other cells in the table that match the selected cells. Next Selected Row : finds the next row in the table from that of the currently selected row. Previous Selected Row : finds the previous row in the table from that of the previously selected row. Go to Row : allows the user to input either the row name or the row index (starting from 1) and Array Studio will automatically scroll to the row in the table. Zoom out : will zoom out the table. Specify Zoom Factor : click to specific zoom factor Zoom in : will zoom in the table. Fit window to full screen Details Window/Web Details The TableView , and all other views in Array Studio , are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the Details Window . In the TableView , click the column header cell for 02A. The green color here shows that this field has been selected. To remove the selection, click the toolbar \"Clear\" If the Details Window is not shown at the bottom of the screen, go to View Menu | Show Details Window now to show it. Once visible, the Details Window should update with information about the selected observation, 02A. The user can also click on the header cell for any variable. Do this now, and notice that the Details Window updates with the automatically downloaded gene annotation for that particular probeset. Besides the Details Window , Array Studio also contains Web Details On-Demand . Web Details allow the user to connect to online websites for further information about a particular variable or probeset. In the Details Window , right-click on the row header cell that was previously selected. This should bring up a list of different Web Details that are available. Depending on the probeset picked, this list could be longer or shorter than that shown below. Scroll to a probeID that does not begin with AFFX, right click and choose the UCSC link. This should open a new window in Internet Explorer . The MAS5 Report and Intensity Report Under the Table | QC folder of the Solution Explorer , there is a MAS5 report telling us the RawQ, ScaleFactor, Background, BackgroundStdDev, PresentPercentage and AverageSignal of each chip. The IntensityReport under Table folder of the Solution Explorer gives a visualization of detection pvalue against probe set intensity. The View Controller The View Controller is an extremely important feature for the visualizations in Array Studio. Its purpose is to allow the user to customize the views on the screen. If you do not see View Controller , go to the menu View | Show View Controller . The view controller should now be visible on the right side of the screen. Click the pin button so that it is facing downwards. This ensures that the View Controller remains in constant view. If the pin is facing to the left, the View Controller (and any other window i.e. Solution Explorer, Details Window, etc. ) will auto hide itself when it loses the mouse focus. When the user rolls the mouse pointer over the hidden view, it will reappear. Keep the View Controller with the pin facing downwards so that the View Controller is visible at all times. As can be seen from the picture above, the View Controller contains three tabs. The Task tab contains all the settings for modifying the properties of the current view. For the TableView , this includes Show Row Numbers , Specify Columns , Reset Columns , Generate Data From View and Export With Customized Column Headers . Click Specify Columns to specify which columns of the dataset are visible. Move columns to the left or right using the left and right arrows, and organize the order that the columns appear by using the up and down arrows. Click OK to return to View Controller | Task . Click on the Observation tab. For the TableView , the Observation tab contains the name of every column in the attached Design Table by default. The toolbar icons for the Variable and Observation views are defined as follows: Collapse All : will collapse all the filters to return the user to the view above. Expand All : will expand all the filters. Reset All Filters : will reset all filters to the default states (no filter). Clear All Filters : will clear all filters, including removing any added filters. Show/Hide Columns : will bring up a dialog box to determine which columns, and in what order, will be displayed in the Filter tab. Add List Filter : will add a list filter to the currently selected column in the Filter tab. At this point in the tutorial, the user does not yet have a List so this will be discussed in more detail later. Options - allows the user to group the filters. This is useful when looking at filters for an Inference Report , but has no real use for the Observation tab of a data object. In addition, the user can set Match All Columns (default) or Match Any Columns for the filters (this is the equivalent of AND or OR for multiple filters). The \"+\" icon will expand the entire filter group. The \"-\" icon will collapse the filter group. At this point, click the Expand All button to expand all column filters. There are four different types of filters visible in this view. The first type is referred as a String Filter . Clicking there allows the user to type in a filter for the column. For instance, typing in 2A under chip column will filter the chip column for any row that contains 2A . When a filter is selected, it is highlighted by the radio checkbox next to it. In addition, the filter informs the user how many variables or observations passed filtering. . Taking a look at the TableView in the center of the screen, it is clear that the only observations remaining visible are those containing 2A . The second type of filter visible with this table can be seen with the treatment and group columns. This is referred to as the Radio filter in which the filters are automatically created, each with its own button. Array Studio defaults to the Radio filter when there are a limited number of choices (if that does not appear to be the case, the column type will need to be set to Factor ; the user can change any columns to a factor column by choosing Table | Columns | Column Properties Next, right click on the factor in the View Controller and select Radio Filter ). The Radio filter is not available on columns with larger numbers of options than limit. First, remove the previous filter by switching it from 02A to (no filter) . Next, the data can be filtered with the Radio filter by clicking on the desired filter. Select control from the options under the treatment filter. Again, take a look at the TableView and select the column headers to see that the only samples in the table are in control group. A third type of filter is the Checkbox filter. If this type of filter is not shown, it can easily be added by changing the filter type. Simply right-click on the name of the column filter and choose the \"CheckBox\" option as shown below: Clicking CheckBox will then allow the user to check off each option available for filtering. In the example below, only those rows that contain a group control.t3 or DBP.t3 will be visible in the TableView . There is a fourth type of filter: numeric filter , which is available only for numeric columns. This type of filter will be discussed later in the inference report view. At this point, clear all filters by clicking the Clear All button. Click on the Variable tab in the View Controller . Notice that Array Studio automatically adds potential filters for every column of chip annotation. The buttons on the View Controller | Variable are exactly the same as that found in the View Controller | Observation . Expand the Gene Symbol filter, and type ^Egr1$ , or \"Egr1\" (with quote) to find all Variables that match exactly Egr1 (the ^ and $ symbols are used in the same way as regular expression). Supported filter syntax in Array Studio: Syntax Description >N Greater than N <N Less than N =N Equal to N >=N Greater than or equal to N <=N Less than or equal to N a&b Matching a and b a Matching a a a AND b a and b a b a OR b Matching a or b ^abc Starts with abc abc$ Ends with abc abc Matches exactly abc ^abc$ Matches exactly abc NOT Includes everything not in the filter To keep only empty strings ~ To keep only non-empty strings Notice that this then filters the dataset. 1 row is found that exactly matches Egr1 for Gene Symbol . Again, dimensions of the filtered table can be found by looking at the top right of the center table view Notice that when a filter is applied to a parameter, it changes to a red color in the View Controller . This can be used to quickly track what filters are in place on a heavily filtered dataset. Remove the filter by either clicking the Clear All button or right-clicking on the Gene Symbol Filter ^Egr1$ and clicking Remove Filter . Click on Save button from the toolbar to save the current project. Congratulations! The dataset from DBPTS is successfully loaded into Array Studio and is ready for downstream visualization and analysis.","title":"Importing a Dataset"},{"location":"tutorials/Microarray/Importing_a_Dataset/#importing-a-dataset","text":"","title":"Importing a Dataset"},{"location":"tutorials/Microarray/Importing_a_Dataset/#downloading-the-dbpts-dataset","text":"For this tutorial, the following materials will be required: 24 .CEL files from the DBPTS Time Series dataset (Platform: Affymetrix RAE230A), as well as the included dbpts.design file, derived from the sample information for this dataset. The DBPTS dataset is available at: link After downloading the single .zip file, unzip the file to a folder to be used for this tutorial. The DBP Time Series data set contains information for 15923 probesets in a 2 by 4 factorial experiment. There are treatment (DBP) and control groups, measured at four different times (1 hr, 3 hr, 6 hr, and 18 hr). The experiment measures the intensity of gene expression level of 15923 probesets, with three replicates for each combination of treatment and time. This is NOT a repeated measure experiment, as different samples were used for different time points. The primary interest of this experiment is to find probesets that are differentially expressed under two conditions (treatment and control) at the 4 different time points. The dbpts.design file contains the design information for the study, including columns for chip, time, treatment, and group. A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed Chip for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the .CEL file extensions. Additional columns usually include treatment, time, etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it can be edited later on.","title":"Downloading the DBPTS dataset"},{"location":"tutorials/Microarray/Importing_a_Dataset/#the-workflow-window-the-solution-explorer","text":"When Array Studio is first installed, it will be similar to below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. Notice at the top there will be four tabs: Analysis, Server, Land and Browser. This tutorial will focus on Analysis. The Workflow Window should be visible on the left side of the screen. If the Workflow Window is not visible, go to the View Menu | Show Workflow or click on Workflow at the bottom left. The Workflow Window should appear similar to the screenshot below. Tips: One can always go back to windows in the original setting by selecting the Menu View | Reset Windows . The Workflow Window provides users, especially new users, with a guide to running different types of analysis. Clicking the Workflow dropdown box shows all available workflows (Microarray, Single Channel Expression, Two Channel Expression, Exon Array, RT-PCR, Genotype, CNV, DNA-Seq, RNA-Seq, and miRNA-Seq: Make sure that Microarray is selected now. Notice that the Microarray Workflow is separated into different categories, including Getting started , Manage data , Preprocess , Quality control , Statistical inference , and Pattern recognition . While it is possible to access all of these functions via the menu commands in Array Studio , the Workflows are designed to make it easier for new users to work through their data. The first section of the Microarray Workflow is the Getting Started section. In this section, it is suggested that the user either create a new project or open a previously created project. To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window: Array Studio allows the user to create two different project types. A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects). Since this project is a microarray project, choose Create a simple project now. Then, click the Browse button to select a location and enter the name for the project. Once this is complete, click OK to continue. Besides the Workflow Window on the left hand side of the screen, Array Studio also contains the Solution Explorer . The Solution Explorer is used to organize each project, and within each project, dataset, results table, etc., that is generated while analyzing and visualizing a project. Another way to create a new project is by this icon in the Analysis tab: Note that users can choose to create different projects: Local project as mentioned above and server project. A server project is a distributed project saved on server. Once the user is connected to server, the option of creating a new server project will become available. When users want to create a server project, some basic metadata need to be provided: The interface of creating of a new local project is different from creating a new server project, but the rest of the steps, such as data import and data analysis, share the same interface. The \"local\" or \"server\" project types tell Array Studio where to run the analysis. If it is a local project, Array Studio runs the analysis on the local machine; if it is a server project, Array Studio would run the analysis on the server. Server projects are recommended when dealing with larger datasets, as server-based analyses allow the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The analyses in this tutorial are performed as a local project, but these can also be followed as a server project if the user is connected to ArrayServer. To switch to the Solution Explorer , choose the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, switch to it by going to the View Menu | Show Solution Explorer . The Solution Explorer will be empty, containing slots for List, Cluster, Text and Attachment . You can right-click on List, Cluster, Text and Attachment for additional options for each. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (in the case of microarray data, this would be probesets), or Observations (in the case of microarray data, this would be chips or samples). Right Clicking on List brings up this menu:","title":"The Workflow Window/ The Solution Explorer"},{"location":"tutorials/Microarray/Importing_a_Dataset/#adding-microarray-datachip-normalization","text":"At this point, we are ready to add microarray data to the Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the Workflow Window , by selecting the Workflow tab at the bottom of the Solution Explorer . Alternatively, go to View Menu | Show Workflow to show the Workflow Window . Next, choose Add Expression Data , from the Manage Data section of the workflow. Alternatively, data can be added by going to the File Menu | Add Data |Add Omic Data | Add Expression Data or by clicking the Add Data button on the tool strip, and choosing Add Omic Data | Add Expression Data . A dialog box will open asking the user to specify the expression data source. Many different sources of data are available to choose from in Array Studio and can be seen in the dialog window below. For this tutorial, the 24 Affymetrix .CEL files downloaded earlier will be used. Select Affymetrix .CEL files (3 IVT, or Gene Arrays) and click OK . The Extract Affymetrix CEL file window appears: Click the Add button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click Open to continue. Check that there are 24 .CEL files listed for extraction by looking in the upper left corner of the dialog box. Under Options , the user will be shown the Array type of the CEL files that are being imported. The user has the option to select an alternative CDF (Affymetrix Library) file. The user can also select from the following Options: The choice of analysis methods include: RMA, GCRMA2, MAS5 and OMICSOFT (see reference for details). For experiments performed at different times, the Scale RMA/GCRMA signals can be used to scale all chips to a particular Target intensity . For MAS5 extractions, as well as when the Scale RMA/GCRMA signals box is checked, a number can be entered into the Target intensity box. A log-2 transformation can be performed on the signal matrix data upon extraction. If the user unchecks the Perform log-2 transformation on the signal matrix box, a log-2 transformation can still be performed at a later stage. If checked, the Import Sample Information from ARR files option will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files if they were generated by Affymetrix's Expression Console . The Generate MAS5 QC Report checkbox (available after adding CEL files), allows the user to automatically generate a MAS5 Report, without going through the separate menu option ( Tools |Affymetrix | Generate Affymetrix MAS5 QC Report ), however it offers fewer options than the regular menu item. The Select controls button allows the user to select the control genes for calculating 3 /5 ratios in the report (i.e. GAPDH, beta-actin, etc.). The Generate detection flag with p-value < checkbox allows the user to automatically generate a detection flag value based on a cutoff value specified (default of <0.05). Selecting this option will generate a table with values of 0 (meaning not present with a p-value <0.05) or 1 (present with a p-value <0.05). The resulting \"FlagTable\" view is hidden, but can be added by right click on MicroArrayData | Add View | FlagTableView . The detection flag table can be used in MicroArray | Preprocess | Filter By Flags . Selecting Report intensity + detection p-values will automatically generate an \"IntensityReport\" data object with an associated \"Intensity_Detection\" view and table. A CEL Report (Probe level) can also be generated, if Generate CEL Report box is checked. This can be done with the separate menu option Tools | Affymetrix |Generate Affymetrix CEL report . Optionally, a model based QC report can be generated as well. This is discussed further in the online help. Finally, the user can generate CHP files while extraction takes place, using the Write CHP files checkbox. Click on the Help button on the bottom left of the window to open the wiki page for Extract Affymetrix CEL Files . The wiki page describes the function input and output of this module, and explains all the options and parameters used in this module. Every analysis module in Array Studio has this Help button to link to the corresponding wiki page. When complete, the window should look similar to the following screenshot. Click Submit to start the RMA intensity signal matrix extraction. Data extraction will begin and take approximately 30 seconds. When complete, Array Studio will prompt the user to attach a design table. Click Yes now to attach the design table that was packaged with the CEL files. If No was selected instead, the design table can always be attached by right clicking on the design node for the project in the Solution Explorer and choosing Import to attach/reattach the design. The Specify Table Source window will open. As dbpts.design.txt is a tab-delimited text file, choose Tab delimited file and click OK to continue. Choose dbpts.design and click Open to continue the attachment process. Specify the location of the Design table file. Once the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to Append to the existing covariate table (if one exists) and to Use the name order in the new covariate table . Leave these options as default. Selecting \"OK\" will then proceed with the data parsing and creation of the Design table.","title":"Adding Microarray Data/Chip Normalization"},{"location":"tutorials/Microarray/Importing_a_Dataset/#the-tableview","text":"At this point, the screen should look similar to below. On the left, the Solution Explorer will show an Annotation (automatically downloaded according to chip type) and Design Table (just imported) along with the Microarray Data type in Table format. Also, in the Table Data type, there will be a Mas5Report (under QC) and IntensityReport as chosen in the output of the previous command. In the center of the screen, a table view called Table should be visible. Scroll through the dataset to see how quickly Array Studio is able to scroll. Array Studio is able to easily handle millions of rows and columns in the TableView . Now switch back to the Solution Explorer . In Array Studio, the Solution Explorer will contain two types of data (-Omic data and Table data). These are organized separately in the Solution Explorer for each project. Open the Omic data node now, followed by the MicroArrayData node. In the main view window, click on the button on the right top corner to close the current view, MicroarrayData|Table. Then double-click in the Solution Explorer | Tutorial | -Omic Data |MicroArrayData | Table to reopen the TableView . Moving the mouse over any of the icons in the toolbar will give a short description of the button. Open as Text : will open current visible table in the default text editor (e.g. Notepad) Open in Excel : will open current visible table in Microsoft Excel Save as Text/object : will open dialog box to save current visible table as Text, Excel or Omicsoft object Sort Table : will sort the view, opening the Sort window. The Sort window allows the user to sort by up to four different columns, in either ascending or descending order. Note that the sorting mentioned above only applies to the current view, and not the actual data. So if the current Table View is closed, it would need to be sorted again. For more advanced features including sorting of the actual data instead of the view, use the menu, Omic Data | Manipulation | Sort Variables . Filter : Filter table by different rows Copy Table to Clipboard : will copy current visible table to clipboard. Additional Tools : contains a popup menu for additional tools: Find/Replace : find or replace cells in the table (this is not allowed with Omic data but can be used with regular table data. Match Selected Cells : select one or multiple cells in the table. Then click Match Selected Cells to find all of the other cells in the table that match the selected cells. Next Selected Row : finds the next row in the table from that of the currently selected row. Previous Selected Row : finds the previous row in the table from that of the previously selected row. Go to Row : allows the user to input either the row name or the row index (starting from 1) and Array Studio will automatically scroll to the row in the table. Zoom out : will zoom out the table. Specify Zoom Factor : click to specific zoom factor Zoom in : will zoom in the table. Fit window to full screen","title":"The TableView"},{"location":"tutorials/Microarray/Importing_a_Dataset/#details-windowweb-details","text":"The TableView , and all other views in Array Studio , are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the Details Window . In the TableView , click the column header cell for 02A. The green color here shows that this field has been selected. To remove the selection, click the toolbar \"Clear\" If the Details Window is not shown at the bottom of the screen, go to View Menu | Show Details Window now to show it. Once visible, the Details Window should update with information about the selected observation, 02A. The user can also click on the header cell for any variable. Do this now, and notice that the Details Window updates with the automatically downloaded gene annotation for that particular probeset. Besides the Details Window , Array Studio also contains Web Details On-Demand . Web Details allow the user to connect to online websites for further information about a particular variable or probeset. In the Details Window , right-click on the row header cell that was previously selected. This should bring up a list of different Web Details that are available. Depending on the probeset picked, this list could be longer or shorter than that shown below. Scroll to a probeID that does not begin with AFFX, right click and choose the UCSC link. This should open a new window in Internet Explorer .","title":"Details Window/Web Details"},{"location":"tutorials/Microarray/Importing_a_Dataset/#the-mas5-report-and-intensity-report","text":"Under the Table | QC folder of the Solution Explorer , there is a MAS5 report telling us the RawQ, ScaleFactor, Background, BackgroundStdDev, PresentPercentage and AverageSignal of each chip. The IntensityReport under Table folder of the Solution Explorer gives a visualization of detection pvalue against probe set intensity.","title":"The MAS5 Report and Intensity Report"},{"location":"tutorials/Microarray/Importing_a_Dataset/#the-view-controller","text":"The View Controller is an extremely important feature for the visualizations in Array Studio. Its purpose is to allow the user to customize the views on the screen. If you do not see View Controller , go to the menu View | Show View Controller . The view controller should now be visible on the right side of the screen. Click the pin button so that it is facing downwards. This ensures that the View Controller remains in constant view. If the pin is facing to the left, the View Controller (and any other window i.e. Solution Explorer, Details Window, etc. ) will auto hide itself when it loses the mouse focus. When the user rolls the mouse pointer over the hidden view, it will reappear. Keep the View Controller with the pin facing downwards so that the View Controller is visible at all times. As can be seen from the picture above, the View Controller contains three tabs. The Task tab contains all the settings for modifying the properties of the current view. For the TableView , this includes Show Row Numbers , Specify Columns , Reset Columns , Generate Data From View and Export With Customized Column Headers . Click Specify Columns to specify which columns of the dataset are visible. Move columns to the left or right using the left and right arrows, and organize the order that the columns appear by using the up and down arrows. Click OK to return to View Controller | Task . Click on the Observation tab. For the TableView , the Observation tab contains the name of every column in the attached Design Table by default. The toolbar icons for the Variable and Observation views are defined as follows: Collapse All : will collapse all the filters to return the user to the view above. Expand All : will expand all the filters. Reset All Filters : will reset all filters to the default states (no filter). Clear All Filters : will clear all filters, including removing any added filters. Show/Hide Columns : will bring up a dialog box to determine which columns, and in what order, will be displayed in the Filter tab. Add List Filter : will add a list filter to the currently selected column in the Filter tab. At this point in the tutorial, the user does not yet have a List so this will be discussed in more detail later. Options - allows the user to group the filters. This is useful when looking at filters for an Inference Report , but has no real use for the Observation tab of a data object. In addition, the user can set Match All Columns (default) or Match Any Columns for the filters (this is the equivalent of AND or OR for multiple filters). The \"+\" icon will expand the entire filter group. The \"-\" icon will collapse the filter group. At this point, click the Expand All button to expand all column filters. There are four different types of filters visible in this view. The first type is referred as a String Filter . Clicking there allows the user to type in a filter for the column. For instance, typing in 2A under chip column will filter the chip column for any row that contains 2A . When a filter is selected, it is highlighted by the radio checkbox next to it. In addition, the filter informs the user how many variables or observations passed filtering. . Taking a look at the TableView in the center of the screen, it is clear that the only observations remaining visible are those containing 2A . The second type of filter visible with this table can be seen with the treatment and group columns. This is referred to as the Radio filter in which the filters are automatically created, each with its own button. Array Studio defaults to the Radio filter when there are a limited number of choices (if that does not appear to be the case, the column type will need to be set to Factor ; the user can change any columns to a factor column by choosing Table | Columns | Column Properties Next, right click on the factor in the View Controller and select Radio Filter ). The Radio filter is not available on columns with larger numbers of options than limit. First, remove the previous filter by switching it from 02A to (no filter) . Next, the data can be filtered with the Radio filter by clicking on the desired filter. Select control from the options under the treatment filter. Again, take a look at the TableView and select the column headers to see that the only samples in the table are in control group. A third type of filter is the Checkbox filter. If this type of filter is not shown, it can easily be added by changing the filter type. Simply right-click on the name of the column filter and choose the \"CheckBox\" option as shown below: Clicking CheckBox will then allow the user to check off each option available for filtering. In the example below, only those rows that contain a group control.t3 or DBP.t3 will be visible in the TableView . There is a fourth type of filter: numeric filter , which is available only for numeric columns. This type of filter will be discussed later in the inference report view. At this point, clear all filters by clicking the Clear All button. Click on the Variable tab in the View Controller . Notice that Array Studio automatically adds potential filters for every column of chip annotation. The buttons on the View Controller | Variable are exactly the same as that found in the View Controller | Observation . Expand the Gene Symbol filter, and type ^Egr1$ , or \"Egr1\" (with quote) to find all Variables that match exactly Egr1 (the ^ and $ symbols are used in the same way as regular expression). Supported filter syntax in Array Studio: Syntax Description >N Greater than N <N Less than N =N Equal to N >=N Greater than or equal to N <=N Less than or equal to N a&b Matching a and b a Matching a a a AND b a and b a b a OR b Matching a or b ^abc Starts with abc abc$ Ends with abc abc Matches exactly abc ^abc$ Matches exactly abc NOT Includes everything not in the filter To keep only empty strings ~ To keep only non-empty strings Notice that this then filters the dataset. 1 row is found that exactly matches Egr1 for Gene Symbol . Again, dimensions of the filtered table can be found by looking at the top right of the center table view Notice that when a filter is applied to a parameter, it changes to a red color in the View Controller . This can be used to quickly track what filters are in place on a heavily filtered dataset. Remove the filter by either clicking the Clear All button or right-clicking on the Gene Symbol Filter ^Egr1$ and clicking Remove Filter . Click on Save button from the toolbar to save the current project. Congratulations! The dataset from DBPTS is successfully loaded into Array Studio and is ready for downstream visualization and analysis.","title":"The View Controller"},{"location":"tutorials/Microarray/Installing_Array_Studio/","text":"Installing Array Studio Introduction update Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer , which organizes each project into two main sections ( -Omic data and Table data ), as well as different folders: QC, Inference, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and the Web Details On-Demand . This chapter will cover installation of Array Studio. The next chapter will cover downloading of the data and chip normalization. In the process, the user will become familiar with some of the features of the Workflow Window and Solution Explorer , as well as getting acquainted with the TableView in Array Studio . Prerequisites and installation of Array Studio While Array Studio does not have any specific requirements for memory or processor speed, the following are suggested for successfully finishing this tutorial: 2.0GHz 32-bit (x86) or 64-bit (x64) processor 512MB of RAM (1GB recommended) 2GB of RAM for ExonArray, SNP/Genotyping, and CNV analysis 2GB hard drive (4GB recommended) 800*600 display resolution (1024*768 recommended) To install Array Studio, (in Internet Explorer) proceed to link Click Install to install Array Studio Launcher . Note: The version number listed here is for Array Studio Launcher, not the Array Studio program. Array Studio Launcher is a tool to download Array Studio online. If you have not previously installed the .NET Framework Version 3.5 on your machine, the website will prompt you to do so. The next time you would like to access Array Studio, you can double click the Array Studio Launcher icon file that was automatically created on your desktop (and in the start menu). Alternatively, you can go to the same website (you can easily bookmark the page) and click the Install button again. If the Array Studio has been updated since your last use, the software will automatically update itself before launching. In other words, you will be able to immediately access the software. Note : Bioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The latest version is updated frequently. If the installation of the .NET Framework 3.5 is required, a dialog box will appear with a security warning after installing .NET Framework. Click Run again to proceed and the application will install. Next time you use Array Studio, you can easily launch the program by just clicking the Run button. Microarray Data and other Data types In Bioinformatics research, there are many different data sources such as microarray, sequence data, CNV data, etc. In Array Studio, we divide genetic data into two groups: One is called -Omic data, which is basically a data matrix with annotation for both columns (sample information) and rows (gene/probe set/transcript information), and NGS data, which contains reads data. Microarray data is a standard example of -Omic data. We have provided additional tutorials to analyze the multiple types of data that users may obtain, but in this tutorial we will focus on microarray data. Microarray data can be further categorized into many sub-classes according to the chip or platform. It is also important to know that many methods mentioned in this tutorial can also be applied to other -Omic data, such as RNAseq quantification data. For example, when users load RNAseq data as NGS data, Array Studio provides modules to compute gene/transcription quantification, which is also stored as -Omic data. It shares the same views as microarray data, and users can apply many methods mentioned in this tutorial to such -Omic data. Therefore, we recommend all users begin with this microarray tutorial to understand the basics of how to analyze -Omic data in Array Studio before exploring other tutorials.","title":"Installing Array Studio"},{"location":"tutorials/Microarray/Installing_Array_Studio/#installing-array-studio","text":"","title":"Installing Array Studio"},{"location":"tutorials/Microarray/Installing_Array_Studio/#introduction-update","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its Solution Explorer , which organizes each project into two main sections ( -Omic data and Table data ), as well as different folders: QC, Inference, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and the Web Details On-Demand . This chapter will cover installation of Array Studio. The next chapter will cover downloading of the data and chip normalization. In the process, the user will become familiar with some of the features of the Workflow Window and Solution Explorer , as well as getting acquainted with the TableView in Array Studio .","title":"Introduction update"},{"location":"tutorials/Microarray/Installing_Array_Studio/#prerequisites-and-installation-of-array-studio","text":"While Array Studio does not have any specific requirements for memory or processor speed, the following are suggested for successfully finishing this tutorial: 2.0GHz 32-bit (x86) or 64-bit (x64) processor 512MB of RAM (1GB recommended) 2GB of RAM for ExonArray, SNP/Genotyping, and CNV analysis 2GB hard drive (4GB recommended) 800*600 display resolution (1024*768 recommended) To install Array Studio, (in Internet Explorer) proceed to link Click Install to install Array Studio Launcher . Note: The version number listed here is for Array Studio Launcher, not the Array Studio program. Array Studio Launcher is a tool to download Array Studio online. If you have not previously installed the .NET Framework Version 3.5 on your machine, the website will prompt you to do so. The next time you would like to access Array Studio, you can double click the Array Studio Launcher icon file that was automatically created on your desktop (and in the start menu). Alternatively, you can go to the same website (you can easily bookmark the page) and click the Install button again. If the Array Studio has been updated since your last use, the software will automatically update itself before launching. In other words, you will be able to immediately access the software. Note : Bioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The latest version is updated frequently. If the installation of the .NET Framework 3.5 is required, a dialog box will appear with a security warning after installing .NET Framework. Click Run again to proceed and the application will install. Next time you use Array Studio, you can easily launch the program by just clicking the Run button.","title":"Prerequisites and installation of Array Studio"},{"location":"tutorials/Microarray/Installing_Array_Studio/#microarray-data-and-other-data-types","text":"In Bioinformatics research, there are many different data sources such as microarray, sequence data, CNV data, etc. In Array Studio, we divide genetic data into two groups: One is called -Omic data, which is basically a data matrix with annotation for both columns (sample information) and rows (gene/probe set/transcript information), and NGS data, which contains reads data. Microarray data is a standard example of -Omic data. We have provided additional tutorials to analyze the multiple types of data that users may obtain, but in this tutorial we will focus on microarray data. Microarray data can be further categorized into many sub-classes according to the chip or platform. It is also important to know that many methods mentioned in this tutorial can also be applied to other -Omic data, such as RNAseq quantification data. For example, when users load RNAseq data as NGS data, Array Studio provides modules to compute gene/transcription quantification, which is also stored as -Omic data. It shares the same views as microarray data, and users can apply many methods mentioned in this tutorial to such -Omic data. Therefore, we recommend all users begin with this microarray tutorial to understand the basics of how to analyze -Omic data in Array Studio before exploring other tutorials.","title":"Microarray Data and other Data types"},{"location":"tutorials/Microarray/References/","text":"References MAS5 Hubbell, E. et al. (2002) Robust estimation for expression analysis. Bioinformatics, 18, 1585-1592 link RMA Irizarry, R. A. et al., (2003) Exploration, normalization, and summaries of high density oligonucleotide array probe level data. Biostatistics, 4, 249-264 link GCRMA A Model-Based Background Adjustment for Oligonucleotide Expression Arrays Zhijin Wu , Rafael A. Irizarry , Robert Gentleman , Francisco Martinez-Murillo , Forrest Spencer Journal of the American Statistical Association, 2004 vol 99 page 909 link GCRMA 2 GCRMA2 is newer implementation of GCRMA which fixes a bug in original GCRMA implementation that introduces artifacts that can lead to the overestimation of pair wise correlation link Moderated t-test (Limma Package in R) The moderated t-test is used to rank genes in order of evidence for differential expression. They use an empirical Bayes method to shrink the probe-wise sample variances towards a common value and to augment the degrees of freedom for the individual variances (Smyth, 2004). The empirical Bayes moderated t-statistics test each individual contrast equal to zero. For each probe (row), the moderated F-statistic tests whether all the contrasts are zero. The F-statistic is an overall test computed from the set of t-statistics for that probe. This is exactly analogous to the relationship between t-tests and F-statistics in conventional anova, except that the residual mean squares and residual degrees of freedom have been moderated between probes. link","title":"References"},{"location":"tutorials/Microarray/References/#references","text":"","title":"References"},{"location":"tutorials/Microarray/References/#mas5","text":"Hubbell, E. et al. (2002) Robust estimation for expression analysis. Bioinformatics, 18, 1585-1592 link","title":"MAS5"},{"location":"tutorials/Microarray/References/#rma","text":"Irizarry, R. A. et al., (2003) Exploration, normalization, and summaries of high density oligonucleotide array probe level data. Biostatistics, 4, 249-264 link","title":"RMA"},{"location":"tutorials/Microarray/References/#gcrma","text":"A Model-Based Background Adjustment for Oligonucleotide Expression Arrays Zhijin Wu , Rafael A. Irizarry , Robert Gentleman , Francisco Martinez-Murillo , Forrest Spencer Journal of the American Statistical Association, 2004 vol 99 page 909 link","title":"GCRMA"},{"location":"tutorials/Microarray/References/#gcrma-2","text":"GCRMA2 is newer implementation of GCRMA which fixes a bug in original GCRMA implementation that introduces artifacts that can lead to the overestimation of pair wise correlation link","title":"GCRMA 2"},{"location":"tutorials/Microarray/References/#moderated-t-test-limma-package-in-r","text":"The moderated t-test is used to rank genes in order of evidence for differential expression. They use an empirical Bayes method to shrink the probe-wise sample variances towards a common value and to augment the degrees of freedom for the individual variances (Smyth, 2004). The empirical Bayes moderated t-statistics test each individual contrast equal to zero. For each probe (row), the moderated F-statistic tests whether all the contrasts are zero. The F-statistic is an overall test computed from the set of t-statistics for that probe. This is exactly analogous to the relationship between t-tests and F-statistics in conventional anova, except that the residual mean squares and residual degrees of freedom have been moderated between probes. link","title":"Moderated t-test (Limma Package in R)"},{"location":"tutorials/OncoLand/Advanced_Analytics/","text":"Advanced Analytics Sample Set Like Gene Set, user can also create a sample set, a collection of Samples. Sample sets can contain additional sample meta data, which are supplementary to the meta data shipped with Land. Unlike meta data and clinical data, which are normally controlled by administrators, sample sets can be created and managed by all users. Users can share the sample sets they created with other users and can also subscribe/unsubscribe sample sets. User can create a sample set based on imported sample design table, selection in land or query analytics. Create A Sample Set by Importing To create sample set, go to Land | Manage | Samples | Manage Sample Set : Same as gene set, sample sets are organized by tags, user can add a new sample set by clicking Add and the following window will show up: In the MetaData tab, user can upload sample set from file, local analysis or an omicsoft data object (.osobj) file: Create A Sample Set by selection User can create sample set directly by selection/filter using the following four options in Sample Set : Create sample set will only create a set of samples selected (marked as red in views) or visible after filter: Group sample set will include all samples but mark them as Yes/No as meta data: In the Info tab, user will name sampleset (such as NUSAP1 upregulated samples ), tag the sampleset (such as PRAD, NUSAP1 ) and set Readers and Editors access. Create A Sample Set by Land Analytics ArrayLand also provides a list of powerful analytic functions to query the whole land database and create sample set, based on mutation, copy number status: Taking generating Generate Site Mutation Status Sample Set as one example, it will open a query window: Site mutation query allows user to input mutation ID (in the format of chr.position.alteration ) or mutation amino acid change, such as BRAF.V600E . In the example above, we query four types of mutations together, including IDH1.R132* (IDH1 mutations change 132th amino acid position from R to anything). Once click Send to Queue , the analytic job will send to ArrayServer job queue: Once job finishes, the sample set, Test BRAF IDH RNASeq Mutation SampleSet , will show in Land | Manage | Samples | Manage Sample Sets . Mutation status, MUT or WT, is marked for each mutation site in the sample set. User can modify the permission, sample set tags by clicking Edit/Update after a sample set is created. Once a sample set is created, users can subscribe the sample set. Once a sample set is subscribed, a check mark will appear in front of the sample set name. Once you subscribe to a sample set, you will see it in all future land queries, as a filter column in Sample tab under \"Sample Set\", and also a profile column to trellis and split samples in the visualization. Below is the IDH1 expression boxplot, categorized by Tumor Type (filter to SKCM only), Sample Type and BRAF mutation status: Custom Query Custom query provides another approach to query genes/features quickly. Custom queries are created by dynamic land database query. Custom queries can be combined and they can be viewed by OmicPrint. But unlike sample sets, custom queries cannot be shared, nor can they be used to limit samples used in Analytics . Add Omic Data Query To add a custom query, click the icon besides Select View and choose from the list: We provide custom queries of a gene on expression, CNV, mutation, fusion and RPPA. The following example shows how to query the expression level of ERG and TMPRSS2 in RNA-Seq dataset, separated by ',': We can also query the TMPRSS2->ERG fusion in RNA-Seq dataset: Three query results are immediately available to do customizations for the current view. In the view above for ERG Gene FPKM , we filter Tumor Type to PRAD, specify multiple profile columns to Tumor Type and Fusion Status And Change Symbol Properties to color by ERG expression status: The color legend is shown on the Legend tab, where you can change color for each category: Numeric data (Like Expression Ratio, RPPA, FPKM etc) can also be categorized by user-defined breakpoints. Say we want the samples with FPKM less than 10% as \"Low\", larger than 90% as \"High\" and Others as \"Middle\", the breakpoints can be set as this Then the custom query will show as The categorization is based on the overall samples. If users want the categorization based on each group, then check Discretization for each group . The custom query can also be performed using summarized numeric data in multiple genes by checking Summarize multiple genes by and choosing a summarization method. Add Measurement Data Query In addition to Omic Data Query, measurement data query can also be added if measurement data has been imported. Detailed information about measurement data will be described in the next chapter. Combine Multiple Queries After creating multiple Custom Queries in Land Sample tab, users can use AND/OR logic to combine multiple custom queries. From the left panel, users can select multiple levels in different queries to combine. The default logic is OR . If users want to use AND logic to combine queries, please check Match all option. Other Users can also add SampleSet query (for the sample sets, regardless of whether they are subscribed or not) and MetaData query. Sample Sets can also be created from custom queries: Moreover, ArrayLand provides an overview of all custom query results as an OmicPrint view: OmicPrint view is a tree, categorized by tumor type, then gene names and queries. The same sample is aligned vertically. It will show the sample ID when users mouse over the block. Sample blocks are colored by alteration types, such as mutation (MUT), amplified, deleted, etc. From the view above, we can see clear the correlation between ERG up-regulation and presence of TMPRSS2->ERG fusion. Report Top Gene List In Land analytics, we also provide tools to scan all or a subset of samples for top mutated, amplified or deleted genes, top fusion and top transcripts: Below is one example of scanning COAD samples for top mutated genes (only select important mutation types shown in at least 10% of samples). The COAD sample set can be created by \"Create Sample Set From Selection\", described in the sample set chapter. By clicking Send to Queue , the job will run on ArrayServer. Depending on the number of samples in the chosen sample set (or maybe all samples), it may take more than 30 min to traverse all genes in all samples to generate the report. Generated top-gene reports are stored in Land | Analytics | Open Result Set :","title":"Advanced Analytics"},{"location":"tutorials/OncoLand/Advanced_Analytics/#advanced-analytics","text":"","title":"Advanced Analytics"},{"location":"tutorials/OncoLand/Advanced_Analytics/#sample-set","text":"Like Gene Set, user can also create a sample set, a collection of Samples. Sample sets can contain additional sample meta data, which are supplementary to the meta data shipped with Land. Unlike meta data and clinical data, which are normally controlled by administrators, sample sets can be created and managed by all users. Users can share the sample sets they created with other users and can also subscribe/unsubscribe sample sets. User can create a sample set based on imported sample design table, selection in land or query analytics.","title":"Sample Set"},{"location":"tutorials/OncoLand/Advanced_Analytics/#create-a-sample-set-by-importing","text":"To create sample set, go to Land | Manage | Samples | Manage Sample Set : Same as gene set, sample sets are organized by tags, user can add a new sample set by clicking Add and the following window will show up: In the MetaData tab, user can upload sample set from file, local analysis or an omicsoft data object (.osobj) file:","title":"Create A Sample Set by Importing"},{"location":"tutorials/OncoLand/Advanced_Analytics/#create-a-sample-set-by-selection","text":"User can create sample set directly by selection/filter using the following four options in Sample Set : Create sample set will only create a set of samples selected (marked as red in views) or visible after filter: Group sample set will include all samples but mark them as Yes/No as meta data: In the Info tab, user will name sampleset (such as NUSAP1 upregulated samples ), tag the sampleset (such as PRAD, NUSAP1 ) and set Readers and Editors access.","title":"Create A Sample Set by selection"},{"location":"tutorials/OncoLand/Advanced_Analytics/#create-a-sample-set-by-land-analytics","text":"ArrayLand also provides a list of powerful analytic functions to query the whole land database and create sample set, based on mutation, copy number status: Taking generating Generate Site Mutation Status Sample Set as one example, it will open a query window: Site mutation query allows user to input mutation ID (in the format of chr.position.alteration ) or mutation amino acid change, such as BRAF.V600E . In the example above, we query four types of mutations together, including IDH1.R132* (IDH1 mutations change 132th amino acid position from R to anything). Once click Send to Queue , the analytic job will send to ArrayServer job queue: Once job finishes, the sample set, Test BRAF IDH RNASeq Mutation SampleSet , will show in Land | Manage | Samples | Manage Sample Sets . Mutation status, MUT or WT, is marked for each mutation site in the sample set. User can modify the permission, sample set tags by clicking Edit/Update after a sample set is created. Once a sample set is created, users can subscribe the sample set. Once a sample set is subscribed, a check mark will appear in front of the sample set name. Once you subscribe to a sample set, you will see it in all future land queries, as a filter column in Sample tab under \"Sample Set\", and also a profile column to trellis and split samples in the visualization. Below is the IDH1 expression boxplot, categorized by Tumor Type (filter to SKCM only), Sample Type and BRAF mutation status:","title":"Create A Sample Set by Land Analytics"},{"location":"tutorials/OncoLand/Advanced_Analytics/#custom-query","text":"Custom query provides another approach to query genes/features quickly. Custom queries are created by dynamic land database query. Custom queries can be combined and they can be viewed by OmicPrint. But unlike sample sets, custom queries cannot be shared, nor can they be used to limit samples used in Analytics .","title":"Custom Query"},{"location":"tutorials/OncoLand/Advanced_Analytics/#add-omic-data-query","text":"To add a custom query, click the icon besides Select View and choose from the list: We provide custom queries of a gene on expression, CNV, mutation, fusion and RPPA. The following example shows how to query the expression level of ERG and TMPRSS2 in RNA-Seq dataset, separated by ',': We can also query the TMPRSS2->ERG fusion in RNA-Seq dataset: Three query results are immediately available to do customizations for the current view. In the view above for ERG Gene FPKM , we filter Tumor Type to PRAD, specify multiple profile columns to Tumor Type and Fusion Status And Change Symbol Properties to color by ERG expression status: The color legend is shown on the Legend tab, where you can change color for each category: Numeric data (Like Expression Ratio, RPPA, FPKM etc) can also be categorized by user-defined breakpoints. Say we want the samples with FPKM less than 10% as \"Low\", larger than 90% as \"High\" and Others as \"Middle\", the breakpoints can be set as this Then the custom query will show as The categorization is based on the overall samples. If users want the categorization based on each group, then check Discretization for each group . The custom query can also be performed using summarized numeric data in multiple genes by checking Summarize multiple genes by and choosing a summarization method.","title":"Add Omic Data Query"},{"location":"tutorials/OncoLand/Advanced_Analytics/#add-measurement-data-query","text":"In addition to Omic Data Query, measurement data query can also be added if measurement data has been imported. Detailed information about measurement data will be described in the next chapter.","title":"Add Measurement Data Query"},{"location":"tutorials/OncoLand/Advanced_Analytics/#combine-multiple-queries","text":"After creating multiple Custom Queries in Land Sample tab, users can use AND/OR logic to combine multiple custom queries. From the left panel, users can select multiple levels in different queries to combine. The default logic is OR . If users want to use AND logic to combine queries, please check Match all option.","title":"Combine Multiple Queries"},{"location":"tutorials/OncoLand/Advanced_Analytics/#other","text":"Users can also add SampleSet query (for the sample sets, regardless of whether they are subscribed or not) and MetaData query. Sample Sets can also be created from custom queries: Moreover, ArrayLand provides an overview of all custom query results as an OmicPrint view: OmicPrint view is a tree, categorized by tumor type, then gene names and queries. The same sample is aligned vertically. It will show the sample ID when users mouse over the block. Sample blocks are colored by alteration types, such as mutation (MUT), amplified, deleted, etc. From the view above, we can see clear the correlation between ERG up-regulation and presence of TMPRSS2->ERG fusion.","title":"Other"},{"location":"tutorials/OncoLand/Advanced_Analytics/#report-top-gene-list","text":"In Land analytics, we also provide tools to scan all or a subset of samples for top mutated, amplified or deleted genes, top fusion and top transcripts: Below is one example of scanning COAD samples for top mutated genes (only select important mutation types shown in at least 10% of samples). The COAD sample set can be created by \"Create Sample Set From Selection\", described in the sample set chapter. By clicking Send to Queue , the job will run on ArrayServer. Depending on the number of samples in the chosen sample set (or maybe all samples), it may take more than 30 min to traverse all genes in all samples to generate the report. Generated top-gene reports are stored in Land | Analytics | Open Result Set :","title":"Report Top Gene List"},{"location":"tutorials/OncoLand/Introduction/","text":"Introduction OncoLand OmicSoft uses ArrayLand framework to deliver large data service results. OncoLand is an important part of ArrayLand specifically focused on oncology data. Land files are built up based on OmicSoft File System (OFS), which stores genomics data in database files and different layers of indexes for gene/markers and samples. It is a revolutionary google-like storage for vector data. The goal of OncoLand is to provide fast data access in both sample and gene directions. Once users configured Land data on ArrayServer internally, all ArrayStudio/ArrayLand users can search all types of genomics profiles of a single gene or a set of genes instantly with rich visualizations. This tutorial is mainly based on TCGA Land and CCLE Land. Please refer to the OncoLand Whitepaper, available through the Help menu item, for descriptions of all available lands within OncoLand. TCGALand The Cancer Genome Atlas (TCGA) is a project, begun in 2006, to collect cancer samples and generate genomic profiling dataset for bioinformatics and biomedical researchers. There are a number of different techniques/platforms used to generate genomics datasets, including expression microarray, copy number variation profiling, SNP genotyping, methylation profiling, microRNA sequencing, transcriptome and exon sequencing. Once you connect to the server, you can find the TCGA land data by clicking Select Land : The default view is Samples view showing the number of samples in each tumor type. Other views are also available for users to query the sample data at a general level: One useful view is Clinical Significance - Group Association . It is a dynamic view showing the association of all clinical variables with the selected grouping (sample variable). Survival Data view is a plot of percent survival across time (Kaplan-Meier Survival Curve) using a specific grouping (e.g. Tumor Type) CCLELand The Cancer Cell Line Encylopedia (CCLE) project is an effort to conduct a detailed genetic and pharmacologic characterization of a large panel of human cancer cell lines. The CCLE provides public access to genomic data, analysis and visualization of DNA copy number, mRNA expression, mutation data and more, for about 1000 cell lines.","title":"Introduction"},{"location":"tutorials/OncoLand/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/OncoLand/Introduction/#oncoland","text":"OmicSoft uses ArrayLand framework to deliver large data service results. OncoLand is an important part of ArrayLand specifically focused on oncology data. Land files are built up based on OmicSoft File System (OFS), which stores genomics data in database files and different layers of indexes for gene/markers and samples. It is a revolutionary google-like storage for vector data. The goal of OncoLand is to provide fast data access in both sample and gene directions. Once users configured Land data on ArrayServer internally, all ArrayStudio/ArrayLand users can search all types of genomics profiles of a single gene or a set of genes instantly with rich visualizations. This tutorial is mainly based on TCGA Land and CCLE Land. Please refer to the OncoLand Whitepaper, available through the Help menu item, for descriptions of all available lands within OncoLand.","title":"OncoLand"},{"location":"tutorials/OncoLand/Introduction/#tcgaland","text":"The Cancer Genome Atlas (TCGA) is a project, begun in 2006, to collect cancer samples and generate genomic profiling dataset for bioinformatics and biomedical researchers. There are a number of different techniques/platforms used to generate genomics datasets, including expression microarray, copy number variation profiling, SNP genotyping, methylation profiling, microRNA sequencing, transcriptome and exon sequencing. Once you connect to the server, you can find the TCGA land data by clicking Select Land : The default view is Samples view showing the number of samples in each tumor type. Other views are also available for users to query the sample data at a general level: One useful view is Clinical Significance - Group Association . It is a dynamic view showing the association of all clinical variables with the selected grouping (sample variable). Survival Data view is a plot of percent survival across time (Kaplan-Meier Survival Curve) using a specific grouping (e.g. Tumor Type)","title":"TCGALand"},{"location":"tutorials/OncoLand/Introduction/#ccleland","text":"The Cancer Cell Line Encylopedia (CCLE) project is an effort to conduct a detailed genetic and pharmacologic characterization of a large panel of human cancer cell lines. The CCLE provides public access to genomic data, analysis and visualization of DNA copy number, mRNA expression, mutation data and more, for about 1000 cell lines.","title":"CCLELand"},{"location":"tutorials/OncoLand/Land_Tools/","text":"Land Tools ArrayLand provides other Tools to download a slice of Land to ArrayStudio local analysis: Download Sample Data To Local Analysis The Download Sample Data To Local Analysis function allows users to query the Land database with a list of genes or a list of samples and download them as OmicData/Table to Local Analysis project. Users must first open or create a project in ArrayStudio Analysis: Then open the Download Sample Data To Local Analysis window in the Land tab. There are two options. Users can download selected genes across all samples, and can also download selected samples across all genes. Specify the target ArrayStudio project to store downloaded Land data, a collection of samples (sampleSet) or get all samples. Choose the land data type to download, each one will be an OmicData/Table in ArrayStudio project. Note: Original data is the original values stored in Land, such as RNA-Seq FRKM at transcript level and microarray data at probeset level. Gene level data are values summarized at gene level. Matrix data is to organize output as feature by Samples in \"MicroArray\" format if possible. By default, only PrimaryGrouping and SecondaryGrouping columns are attached as design in each generated OmicData. Check Full meta data box will be download all sample meta data as a table in the project. Downloaded data are shown as project contents: User can do more advanced data analysis and visualizations on downloaded data objects use ArrayStudio functions. Download Sample Data To Text Files User can also download land data to text files through Land | Download | Download Sample Data To Text Files :","title":"Land Tools"},{"location":"tutorials/OncoLand/Land_Tools/#land-tools","text":"ArrayLand provides other Tools to download a slice of Land to ArrayStudio local analysis:","title":"Land Tools"},{"location":"tutorials/OncoLand/Land_Tools/#download-sample-data-to-local-analysis","text":"The Download Sample Data To Local Analysis function allows users to query the Land database with a list of genes or a list of samples and download them as OmicData/Table to Local Analysis project. Users must first open or create a project in ArrayStudio Analysis: Then open the Download Sample Data To Local Analysis window in the Land tab. There are two options. Users can download selected genes across all samples, and can also download selected samples across all genes. Specify the target ArrayStudio project to store downloaded Land data, a collection of samples (sampleSet) or get all samples. Choose the land data type to download, each one will be an OmicData/Table in ArrayStudio project. Note: Original data is the original values stored in Land, such as RNA-Seq FRKM at transcript level and microarray data at probeset level. Gene level data are values summarized at gene level. Matrix data is to organize output as feature by Samples in \"MicroArray\" format if possible. By default, only PrimaryGrouping and SecondaryGrouping columns are attached as design in each generated OmicData. Check Full meta data box will be download all sample meta data as a table in the project. Downloaded data are shown as project contents: User can do more advanced data analysis and visualizations on downloaded data objects use ArrayStudio functions.","title":"Download Sample Data To Local Analysis"},{"location":"tutorials/OncoLand/Land_Tools/#download-sample-data-to-text-files","text":"User can also download land data to text files through Land | Download | Download Sample Data To Text Files :","title":"Download Sample Data To Text Files"},{"location":"tutorials/OncoLand/Measurement_Data/","text":"Measurement Data Measurement data is orthogonal data associated with Land Omics Data, such as compound/drug screening and RNAi data. User can add measurement data to create views and query the land omics data. Import Measurement Data In this tutorial, we are using a cell line land data as one example since it has drug screening data. User can add measurement data in Manage | Measurement | Add Measurement Data : The measurement data source file should have columns for Sample ID matching Land samples, measurement label column containing compound/screening names, and one or more measurement columns. Example of IC50 table below: User can browse the measurement data using Manage | Measurement | Manage Measurement Data : User can also add measurement meta data in Manage | Measurement | Add Measurement Meta Data These meta data will be attached to each compound when browsing them in Manage Measurement Data window. Search/Visualize Measurement Data Once measurement data is imported, the measurement labels (such as compound names) are searchable in the search box: There are boxplot and heatmap views for this compound: Measurement Data Query Measurement data can also be used to query Land Omic Data in custom query in any Sample tab: User can categorize the measurement data into categories, such as sensitive and resistant, using numeric break points or directly labeling. Here we categorize the drug IC50 values for Nutlin-3a by: <3: sensitive Between 3 and 6: middle 6 Resistant The custom query results can be used as a filter and profile column in views for Omics data.","title":"Measurement Data"},{"location":"tutorials/OncoLand/Measurement_Data/#measurement-data","text":"Measurement data is orthogonal data associated with Land Omics Data, such as compound/drug screening and RNAi data. User can add measurement data to create views and query the land omics data.","title":"Measurement Data"},{"location":"tutorials/OncoLand/Measurement_Data/#import-measurement-data","text":"In this tutorial, we are using a cell line land data as one example since it has drug screening data. User can add measurement data in Manage | Measurement | Add Measurement Data : The measurement data source file should have columns for Sample ID matching Land samples, measurement label column containing compound/screening names, and one or more measurement columns. Example of IC50 table below: User can browse the measurement data using Manage | Measurement | Manage Measurement Data : User can also add measurement meta data in Manage | Measurement | Add Measurement Meta Data These meta data will be attached to each compound when browsing them in Manage Measurement Data window.","title":"Import Measurement Data"},{"location":"tutorials/OncoLand/Measurement_Data/#searchvisualize-measurement-data","text":"Once measurement data is imported, the measurement labels (such as compound names) are searchable in the search box: There are boxplot and heatmap views for this compound:","title":"Search/Visualize Measurement Data"},{"location":"tutorials/OncoLand/Measurement_Data/#measurement-data-query","text":"Measurement data can also be used to query Land Omic Data in custom query in any Sample tab: User can categorize the measurement data into categories, such as sensitive and resistant, using numeric break points or directly labeling. Here we categorize the drug IC50 values for Nutlin-3a by: <3: sensitive Between 3 and 6: middle 6 Resistant The custom query results can be used as a filter and profile column in views for Omics data.","title":"Measurement Data Query"},{"location":"tutorials/OncoLand/Search_Basics/","text":"Search Basics Search a single gene Open TCGALand, then type a gene name, such as nusap1 , in the search box. Notice that the auto fill box will assist you to complete the full gene name. Click the green arrow then select \"Search\", or press \"Enter\" to search gene NUSAP1 in TCGA land. A figure showing DNA Alteration Distribution for gene NUSAP1 is returned. This shows the number of different Alteration types, organized by primary group type (in TCGA , the primary group type is Tumor Type.) On the left panel, Sample , Mutation and CNV tabs are used to filter samples depending on different filter criteria. Under Mutation , clicking \"View Filtered Table\" will show detailed mutation information matching with the selected filter criteria. On the right panel, Legend tab shows legend by color. The color can be changed by right-clicking each level. Task tab can be used to change data shown in the view, change profile columns, specify data summarization method, change chart properties, etc. The data used in the view can be exported to txt or excel files. OncoLand provides bunches of data views which can be accessed in Select View . Data are organized into sections based on platform types as well as an Integration section. In each customized view, there will be a tooltip, describing the view when moused over: By clicking a different view, the default setting is to replace the current view with the newly selected view. If users prefer to keep all views, there is an option: DNA-Seq Somatic Mutation is based on MAF (Mutation Annotation Format) files downloaded from TCGA. By definition, somatic is present in tumor but not control. Somatic Mutation Distribution view shows the percentage of mutant samples in each grouping (e.g. Tumor Type). Somatic mutations can be visualized in built-in ArrayLand genome browser. Visualizations will be automatically refreshed in response to the filters on mutation features and sample meta data. RNA-Seq Quantification RNA-Seq gene and transcript FPKM Gene FPKM Charts return visualizations based on FPKM (Fragments Per Kilobase of transcript per Million mapped fragments). All FPKM data calculated at the transcript level, using an EM algorithm based on RSEM link . Data are further normalized for each sample by firstly adding 0.1 to FPKM and then taking log 2. This makes FPKM values comparable across all samples in the Land. Data are summarized at the gene level, by taking the sum of all transcript FPKM values. Visualization is further configurable in the task tab, including chart/symbol properties (shape, color and size). Summary (gene FPKM) view shows percentage of tumor samples whose RNA-Seq log2(FPKM+0.1) expression is 2x up-regulated or 2x down-regulated, compared to normal samples in each group (e.g. Tumor Type). The default fold change cutoff 2x can be changed under Expression tab in the left panel. RNA-Seq Exon Details RNA-Seq details on exon and exon junction level are visualized in the built-in genome browser. It can help the user answer questions such as \u201c Are there FGF12 transcript expression differences between PRAD tumor samples? Search FGF12 and open RNA-Seq Quantification| Genome Browser (Exon Details) . In Sample tab, filter to PRAD: User can change the grouping to Sample Type (In this case, Normal, Primary Tumor, Metastatic) since we have filtered to show one tumor type (PRAD) only: The coverage is at exon level and colored by grouping (Sample Type), as illustrated in Legend . The genome browser transcripts are painted as stack bars representing the relative expression ratios between two sample types. From this view, normal tissue clearly expresses the first transcript; while tumor tissue expresses the second transcript, with more obvious expression of the second transcript in metastatic tumor tissue. RNA-Seq Fusion Gene fusion events in tumor samples can be identified using Omicsoft\u2019s FusionMap link algorithm. There are two main algorithms: Read spanning algorithm - using a cutting-edge technique, a read must map partially to one gene and partially to the second gene. At least 1 read must be fusion-spanning for it to be returned in ArrayLand views; Discordant pair algorithm \u2013 if one read is mapped to one gene, and another read is mapped to a second gene, this is considered a potential fusion. Here is the Fusion (RPKM) view by searching gene erg in the search box: For the TCGA land version in this tutorial, to be sensitive, we report all fusions with at least one junction-spanning read support. But by default, we apply some filters to show the more interesting fusions. We provide varied options to filter false positives? in the Fusion tab, such as Canonical splice junctions (GT-AG, GC-AG and AT-AC) are considered to be more likely than other splice junction patterns. In-frame fusions are more likely to be real than frame shift fusions. On Exon Boundary indicates whether one or both breakpoints are on an exon boundary (more likely for real fusions). In Control means in normal samples. By default it is checked and any fusions shown in normal samples are filtered out. You can relax this option if you want to explore more. Loading of fusion results might be slow in this version since there are too many fusion candidates with relaxed (require only one junction spanning read) parameters. For more details about fusion detection and filters on fusion features, please read the following wiki page: link In the fusion views at fusion junction level ( Fusion Site Frequency ), user can get more fusion details by clicking the link on the upper right: Fusion data of this particular form will be added to the Analysis solution tab: User gets the expression pattern views of gene A, gene B and fusion gene A->B, such as the variable view: RNA-Seq Mutation Views in this section are based on results using Omicsoft\u2019s mutation detection algorithm, summarized by frequency of the mutation. TCGA Land only stores mutations with at least 10 total hits, 5 mutation hits, and mutation read frequency >0.20. There are summary views as well as a built-in ArrayLand genome browser view: RNA-Seq Somatic Mutation If there are both tumor and normal RNA-Seq samples for a patient, Omicsoft\u2019s Summarize Matched Pair Variation method is used to call mutations as somatic. For more details, please read the following wiki article: link Same as RNA-Seq Mutation, there are summary views as well as built-in ArrayLand genome browser view. RNA-Seq (Survival View) Survival View is a quick way to check if a gene's expression status affects the survival of individuals. For example, when searching for the gene tgif1 and filtering for LGG tumor types and primary tumors, we see that high levels of tgif1 appear to correlate with poor survival. (Try removing these filters and looking at all tumor types - you will notice that there is no longer a nice separation of these groups): Expression Expression Ratio is from Agilent data, comparing Tumor or normal sample to universal human reference. Summary (Expression Ratio) view shows a plot of percentage of tumor samples showing 2x up-regulation and 2x down-regulation, organized by group (e.g. Tumor Type). The default fold change cutoff 2x can be changed to other fold of cutoff under Expression tab. Protein Protein data, reverse phase protein array (RPPA), is only available for a subset of genes (like BRAF). Normalized RPPA (RPPA_RBN) is the Replicates Based Normalized RPPA. For more information about RPPA technology, please read the following webpage in MD Anderson Cancer Center: link Copy Number Copy number data is based on Affymetrix SNP 6.0 data, in Log2 Ratio values. In built-in ArrayLand genome browser, copy number data is shown as segments. Genome browser tracks can be filtered by sample or CNV features. Samples in tumor group are sortable by log2Ratio values. Methylation Methylation data is from the Illumina Methylation 450 platform, summarized at the probe level. Future improvements may summarize at promoter regions or transcript regions. Integration Integration section includes integrative visualization of expression correlation of CNV-expression, expression in array VS RNA-Seq. Here is an example: copy number VS expression (from RNA-Seq) for MET Integration (Scan All Genes) Integration section includes integrative visualization of a selected gene's RNA-seq expression, somatic expression, cnv etc in comparison with all other genes' RNA-seq expression, RPPA etc. For example, below shows RNA-Seq expression of other genes vs copy number of BRAF. By default, the gene with the highest correlation will show in the plot. The left window shows the correlation coefficients for all other genes. By clicking one of them, the plot will dynamically change to the selected gene. More details can be seen by clicking \"View Correlation Table\". Action When samples are selected on a plot or summary tables, detailed sample meta data for selected samples will be displayed in a window below. After clicking the small '+' symbol on the left side of the detail window, multiple options for Selection Details will appear. For example, clicking Copy Number Details will return copy number details. The user can also select one or more samples in an RNA-Seq related charts, such as Gene FPKM , then click Browse Selected Samples | Open RNA-Seq BAS Files for selection . BAS (BAM summary) files contains coverage at base pair resolution, exon junction and mutation information. On average, it is 64x smaller than BAM file and does not contain sequence information. Click OK after selecting the grouping. It will open a genome browser in the Browser tab: User can further remove the grouping and split the genome browser track to samples from the option in right click menu. For more information about genome browser, please read Genome Browser Tutorial . Select any samples in RNA-Seq Fusion| Fusion (RPKM) , and click Browse Selected Samples |Open Fusion BAS Files for selection . It will open genome browser views for fusion alignments based on fusion junction spanning reads and inter-transcript fusion reads: If user gets TCGA approval with level 1 data access, they can further link their BAM files in ArrayLand. Two more options will show in the Selection by specifying EnableBam=TRUE in land configuration: Search Two or More Genes User can search two or more genes by typing geneA,geneB,geneC (separated by commas) in the search box: Or input the gene list in Search Multiple Genes Searching for multiple genes enables different views compared to single gene search. There are new charts, such as Co-Mutation Frequency views: Multi-Gene Correlation views in Expression, CNV, and RNA-Seq Quantification sections. The regression line mode can be changed under Task tab. The example below shows RNA-Seq FPKM correlation between ERG and TMPRSS2 for TGCT tumor samples. Heatmap Views in Expression, CNV, RNA-Seq Quantification, DNA-Seq and RNA-Seq Mutation sections: Fusion (Genepair Frequency) Charts will only show fusions between these multiple genes. Browse Selected Samples | Open fusion BAM/BAS Files for selected samples will remain but Browse Selected Samples |Open BAM/BAS Files for select samples will not be allowed since there are multiple gene regions. Fusion Genome Browser will show the fusion information between the searched genes. Fusion Negative Exon Coverage shows the exon coverage for samples without fusion. Fusion Positive Exon Coverage shows the exon coverage for samples with fusion. The genome browser clearly shows the first few exons of ERG have less coverage in fusion positive samples in comparison with those in fusion negative samples, due to fusion with TMPRSS2. Each circle represents each fusion ID. By clicking one circle, the corresponding fusion in the other gene panel will also be highlighted. Fusion details will show in the detail window. Gene Set In ArrayLand, each user can create a set of genes they are interested in, such as a set of genes in one pathway. To create a gene set, go to Land | Manage | Genes | Manage Gene Sets . User can add a new Gene Set by clicking Add User can specify the GeneSet name, tags, and read/editor permissions. In the MetaData, user can load a list of genes from a file or ArrayStudio analysis with certain meta data: Created Gene Sets are organized in the Land by tags The whole set of genes is searchable in Land by typing the gene set name in the search box: All multiple-gene views will be based on the whole set of genes, such as the expression (FPKM) heatmap:","title":"Basic Search"},{"location":"tutorials/OncoLand/Search_Basics/#search-basics","text":"","title":"Search Basics"},{"location":"tutorials/OncoLand/Search_Basics/#search-a-single-gene","text":"Open TCGALand, then type a gene name, such as nusap1 , in the search box. Notice that the auto fill box will assist you to complete the full gene name. Click the green arrow then select \"Search\", or press \"Enter\" to search gene NUSAP1 in TCGA land. A figure showing DNA Alteration Distribution for gene NUSAP1 is returned. This shows the number of different Alteration types, organized by primary group type (in TCGA , the primary group type is Tumor Type.) On the left panel, Sample , Mutation and CNV tabs are used to filter samples depending on different filter criteria. Under Mutation , clicking \"View Filtered Table\" will show detailed mutation information matching with the selected filter criteria. On the right panel, Legend tab shows legend by color. The color can be changed by right-clicking each level. Task tab can be used to change data shown in the view, change profile columns, specify data summarization method, change chart properties, etc. The data used in the view can be exported to txt or excel files. OncoLand provides bunches of data views which can be accessed in Select View . Data are organized into sections based on platform types as well as an Integration section. In each customized view, there will be a tooltip, describing the view when moused over: By clicking a different view, the default setting is to replace the current view with the newly selected view. If users prefer to keep all views, there is an option:","title":"Search a single gene"},{"location":"tutorials/OncoLand/Search_Basics/#dna-seq","text":"Somatic Mutation is based on MAF (Mutation Annotation Format) files downloaded from TCGA. By definition, somatic is present in tumor but not control. Somatic Mutation Distribution view shows the percentage of mutant samples in each grouping (e.g. Tumor Type). Somatic mutations can be visualized in built-in ArrayLand genome browser. Visualizations will be automatically refreshed in response to the filters on mutation features and sample meta data.","title":"DNA-Seq"},{"location":"tutorials/OncoLand/Search_Basics/#rna-seq-quantification","text":"","title":"RNA-Seq Quantification"},{"location":"tutorials/OncoLand/Search_Basics/#rna-seq-gene-and-transcript-fpkm","text":"Gene FPKM Charts return visualizations based on FPKM (Fragments Per Kilobase of transcript per Million mapped fragments). All FPKM data calculated at the transcript level, using an EM algorithm based on RSEM link . Data are further normalized for each sample by firstly adding 0.1 to FPKM and then taking log 2. This makes FPKM values comparable across all samples in the Land. Data are summarized at the gene level, by taking the sum of all transcript FPKM values. Visualization is further configurable in the task tab, including chart/symbol properties (shape, color and size). Summary (gene FPKM) view shows percentage of tumor samples whose RNA-Seq log2(FPKM+0.1) expression is 2x up-regulated or 2x down-regulated, compared to normal samples in each group (e.g. Tumor Type). The default fold change cutoff 2x can be changed under Expression tab in the left panel.","title":"RNA-Seq gene and transcript FPKM"},{"location":"tutorials/OncoLand/Search_Basics/#rna-seq-exon-details","text":"RNA-Seq details on exon and exon junction level are visualized in the built-in genome browser. It can help the user answer questions such as \u201c Are there FGF12 transcript expression differences between PRAD tumor samples? Search FGF12 and open RNA-Seq Quantification| Genome Browser (Exon Details) . In Sample tab, filter to PRAD: User can change the grouping to Sample Type (In this case, Normal, Primary Tumor, Metastatic) since we have filtered to show one tumor type (PRAD) only: The coverage is at exon level and colored by grouping (Sample Type), as illustrated in Legend . The genome browser transcripts are painted as stack bars representing the relative expression ratios between two sample types. From this view, normal tissue clearly expresses the first transcript; while tumor tissue expresses the second transcript, with more obvious expression of the second transcript in metastatic tumor tissue.","title":"RNA-Seq Exon Details"},{"location":"tutorials/OncoLand/Search_Basics/#rna-seq-fusion","text":"Gene fusion events in tumor samples can be identified using Omicsoft\u2019s FusionMap link algorithm. There are two main algorithms: Read spanning algorithm - using a cutting-edge technique, a read must map partially to one gene and partially to the second gene. At least 1 read must be fusion-spanning for it to be returned in ArrayLand views; Discordant pair algorithm \u2013 if one read is mapped to one gene, and another read is mapped to a second gene, this is considered a potential fusion. Here is the Fusion (RPKM) view by searching gene erg in the search box: For the TCGA land version in this tutorial, to be sensitive, we report all fusions with at least one junction-spanning read support. But by default, we apply some filters to show the more interesting fusions. We provide varied options to filter false positives? in the Fusion tab, such as Canonical splice junctions (GT-AG, GC-AG and AT-AC) are considered to be more likely than other splice junction patterns. In-frame fusions are more likely to be real than frame shift fusions. On Exon Boundary indicates whether one or both breakpoints are on an exon boundary (more likely for real fusions). In Control means in normal samples. By default it is checked and any fusions shown in normal samples are filtered out. You can relax this option if you want to explore more. Loading of fusion results might be slow in this version since there are too many fusion candidates with relaxed (require only one junction spanning read) parameters. For more details about fusion detection and filters on fusion features, please read the following wiki page: link In the fusion views at fusion junction level ( Fusion Site Frequency ), user can get more fusion details by clicking the link on the upper right: Fusion data of this particular form will be added to the Analysis solution tab: User gets the expression pattern views of gene A, gene B and fusion gene A->B, such as the variable view:","title":"RNA-Seq Fusion"},{"location":"tutorials/OncoLand/Search_Basics/#rna-seq-mutation","text":"Views in this section are based on results using Omicsoft\u2019s mutation detection algorithm, summarized by frequency of the mutation. TCGA Land only stores mutations with at least 10 total hits, 5 mutation hits, and mutation read frequency >0.20. There are summary views as well as a built-in ArrayLand genome browser view:","title":"RNA-Seq Mutation"},{"location":"tutorials/OncoLand/Search_Basics/#rna-seq-somatic-mutation","text":"If there are both tumor and normal RNA-Seq samples for a patient, Omicsoft\u2019s Summarize Matched Pair Variation method is used to call mutations as somatic. For more details, please read the following wiki article: link Same as RNA-Seq Mutation, there are summary views as well as built-in ArrayLand genome browser view.","title":"RNA-Seq Somatic Mutation"},{"location":"tutorials/OncoLand/Search_Basics/#rna-seq-survival-view","text":"Survival View is a quick way to check if a gene's expression status affects the survival of individuals. For example, when searching for the gene tgif1 and filtering for LGG tumor types and primary tumors, we see that high levels of tgif1 appear to correlate with poor survival. (Try removing these filters and looking at all tumor types - you will notice that there is no longer a nice separation of these groups):","title":"RNA-Seq (Survival View)"},{"location":"tutorials/OncoLand/Search_Basics/#expression","text":"Expression Ratio is from Agilent data, comparing Tumor or normal sample to universal human reference. Summary (Expression Ratio) view shows a plot of percentage of tumor samples showing 2x up-regulation and 2x down-regulation, organized by group (e.g. Tumor Type). The default fold change cutoff 2x can be changed to other fold of cutoff under Expression tab.","title":"Expression"},{"location":"tutorials/OncoLand/Search_Basics/#protein","text":"Protein data, reverse phase protein array (RPPA), is only available for a subset of genes (like BRAF). Normalized RPPA (RPPA_RBN) is the Replicates Based Normalized RPPA. For more information about RPPA technology, please read the following webpage in MD Anderson Cancer Center: link","title":"Protein"},{"location":"tutorials/OncoLand/Search_Basics/#copy-number","text":"Copy number data is based on Affymetrix SNP 6.0 data, in Log2 Ratio values. In built-in ArrayLand genome browser, copy number data is shown as segments. Genome browser tracks can be filtered by sample or CNV features. Samples in tumor group are sortable by log2Ratio values.","title":"Copy Number"},{"location":"tutorials/OncoLand/Search_Basics/#methylation","text":"Methylation data is from the Illumina Methylation 450 platform, summarized at the probe level. Future improvements may summarize at promoter regions or transcript regions.","title":"Methylation"},{"location":"tutorials/OncoLand/Search_Basics/#integration","text":"Integration section includes integrative visualization of expression correlation of CNV-expression, expression in array VS RNA-Seq. Here is an example: copy number VS expression (from RNA-Seq) for MET","title":"Integration"},{"location":"tutorials/OncoLand/Search_Basics/#integration-scan-all-genes","text":"Integration section includes integrative visualization of a selected gene's RNA-seq expression, somatic expression, cnv etc in comparison with all other genes' RNA-seq expression, RPPA etc. For example, below shows RNA-Seq expression of other genes vs copy number of BRAF. By default, the gene with the highest correlation will show in the plot. The left window shows the correlation coefficients for all other genes. By clicking one of them, the plot will dynamically change to the selected gene. More details can be seen by clicking \"View Correlation Table\".","title":"Integration (Scan All Genes)"},{"location":"tutorials/OncoLand/Search_Basics/#action","text":"When samples are selected on a plot or summary tables, detailed sample meta data for selected samples will be displayed in a window below. After clicking the small '+' symbol on the left side of the detail window, multiple options for Selection Details will appear. For example, clicking Copy Number Details will return copy number details. The user can also select one or more samples in an RNA-Seq related charts, such as Gene FPKM , then click Browse Selected Samples | Open RNA-Seq BAS Files for selection . BAS (BAM summary) files contains coverage at base pair resolution, exon junction and mutation information. On average, it is 64x smaller than BAM file and does not contain sequence information. Click OK after selecting the grouping. It will open a genome browser in the Browser tab: User can further remove the grouping and split the genome browser track to samples from the option in right click menu. For more information about genome browser, please read Genome Browser Tutorial . Select any samples in RNA-Seq Fusion| Fusion (RPKM) , and click Browse Selected Samples |Open Fusion BAS Files for selection . It will open genome browser views for fusion alignments based on fusion junction spanning reads and inter-transcript fusion reads: If user gets TCGA approval with level 1 data access, they can further link their BAM files in ArrayLand. Two more options will show in the Selection by specifying EnableBam=TRUE in land configuration:","title":"Action"},{"location":"tutorials/OncoLand/Search_Basics/#search-two-or-more-genes","text":"User can search two or more genes by typing geneA,geneB,geneC (separated by commas) in the search box: Or input the gene list in Search Multiple Genes Searching for multiple genes enables different views compared to single gene search. There are new charts, such as Co-Mutation Frequency views: Multi-Gene Correlation views in Expression, CNV, and RNA-Seq Quantification sections. The regression line mode can be changed under Task tab. The example below shows RNA-Seq FPKM correlation between ERG and TMPRSS2 for TGCT tumor samples. Heatmap Views in Expression, CNV, RNA-Seq Quantification, DNA-Seq and RNA-Seq Mutation sections: Fusion (Genepair Frequency) Charts will only show fusions between these multiple genes. Browse Selected Samples | Open fusion BAM/BAS Files for selected samples will remain but Browse Selected Samples |Open BAM/BAS Files for select samples will not be allowed since there are multiple gene regions. Fusion Genome Browser will show the fusion information between the searched genes. Fusion Negative Exon Coverage shows the exon coverage for samples without fusion. Fusion Positive Exon Coverage shows the exon coverage for samples with fusion. The genome browser clearly shows the first few exons of ERG have less coverage in fusion positive samples in comparison with those in fusion negative samples, due to fusion with TMPRSS2. Each circle represents each fusion ID. By clicking one circle, the corresponding fusion in the other gene panel will also be highlighted. Fusion details will show in the detail window.","title":"Search Two or More Genes"},{"location":"tutorials/OncoLand/Search_Basics/#gene-set","text":"In ArrayLand, each user can create a set of genes they are interested in, such as a set of genes in one pathway. To create a gene set, go to Land | Manage | Genes | Manage Gene Sets . User can add a new Gene Set by clicking Add User can specify the GeneSet name, tags, and read/editor permissions. In the MetaData, user can load a list of genes from a file or ArrayStudio analysis with certain meta data: Created Gene Sets are organized in the Land by tags The whole set of genes is searchable in Land by typing the gene set name in the search box: All multiple-gene views will be based on the whole set of genes, such as the expression (FPKM) heatmap:","title":"Gene Set"},{"location":"tutorials/OncoLand/Virtual_Land/","text":"Virtual Land Virtual Land is a virtual link between multiple Array Lands. By creating a virtual land, users can search and compare across multiple lands. Create Virtual Land To create a virtual land, go to Tools | Create Virtual Land . Please note that the default server setting only allows administrators to be able to create virtual land. Select multiple lands and enter a virtual land name: The created virtual land will be listed in the land collection (right panel): Cross Land Search Open a virtual land and search for one or multiple genes. The search includes data and samples from all Array Lands in this virtual land. There is a column \"Source Land\" automatically added to the virtual land when it is created. Data will be able to compare between different Array Lands by Specify Multiple Profile Columns and add SourceLand in. This tutorial represents just a piece of what ArraySuite is capable of. Feel free to try different options to get a feel for what the software can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ).","title":"Virtual Land"},{"location":"tutorials/OncoLand/Virtual_Land/#virtual-land","text":"Virtual Land is a virtual link between multiple Array Lands. By creating a virtual land, users can search and compare across multiple lands.","title":"Virtual Land"},{"location":"tutorials/OncoLand/Virtual_Land/#create-virtual-land","text":"To create a virtual land, go to Tools | Create Virtual Land . Please note that the default server setting only allows administrators to be able to create virtual land. Select multiple lands and enter a virtual land name: The created virtual land will be listed in the land collection (right panel):","title":"Create Virtual Land"},{"location":"tutorials/OncoLand/Virtual_Land/#cross-land-search","text":"Open a virtual land and search for one or multiple genes. The search includes data and samples from all Array Lands in this virtual land. There is a column \"Source Land\" automatically added to the virtual land when it is created. Data will be able to compare between different Array Lands by Specify Multiple Profile Columns and add SourceLand in. This tutorial represents just a piece of what ArraySuite is capable of. Feel free to try different options to get a feel for what the software can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ).","title":"Cross Land Search"},{"location":"tutorials/Oscript/","text":"OmicScript Tutorial .. toctree:: :maxdepth: 2 Introduction RunOscript PipelineScript","title":"Home"},{"location":"tutorials/Oscript/Introduction/","text":"Introduction Array Studio provides an integrated OmicSoft Project Environment for analyzing, visualizing and organizing high dimensional data. Its well-designed graphic user interface is convenient for complicated bioinformatics data processing. Besides running analysis within graphic user interface, advanced Array Studio users can also run analysis with OmicScript (Oscript). By building Oscript pipelines, user can run batch jobs automatically. Array Studio allows users to build two kinds of scripts: OmicScript (Oscript) and Pipeline Server Script (Pscript). Oscript is normally created, used and managed by individual advanced users to process their own data. Users may run oscripts either in a local machine or a server. Pscript is normally created by an administor of Array Server, and used by users as pipeline tools to work on large scale data processing on a server (as a standalone server or in cluster). The users may submit samples to the pscript pipelines via Array Server's sample registration system, and monitor the job status in Array Studio GUI. This tutorial will introduce both Oscript and Pscript in individual sections. It is highly recommended that the user complete the prerequisite for this tutorial: the RNA-Seq Tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, data structure, and different modules within the software.","title":"Introduction"},{"location":"tutorials/Oscript/Introduction/#introduction","text":"Array Studio provides an integrated OmicSoft Project Environment for analyzing, visualizing and organizing high dimensional data. Its well-designed graphic user interface is convenient for complicated bioinformatics data processing. Besides running analysis within graphic user interface, advanced Array Studio users can also run analysis with OmicScript (Oscript). By building Oscript pipelines, user can run batch jobs automatically. Array Studio allows users to build two kinds of scripts: OmicScript (Oscript) and Pipeline Server Script (Pscript). Oscript is normally created, used and managed by individual advanced users to process their own data. Users may run oscripts either in a local machine or a server. Pscript is normally created by an administor of Array Server, and used by users as pipeline tools to work on large scale data processing on a server (as a standalone server or in cluster). The users may submit samples to the pscript pipelines via Array Server's sample registration system, and monitor the job status in Array Studio GUI. This tutorial will introduce both Oscript and Pscript in individual sections. It is highly recommended that the user complete the prerequisite for this tutorial: the RNA-Seq Tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, data structure, and different modules within the software.","title":"Introduction"},{"location":"tutorials/Oscript/PipelineScript/","text":"Pipeline Script A pipeline script (Pscript) is created and managed by ArrayServer administrators. Once a pscript is installed in Array Server, it becomes a pipeline tool. Users can submit large amount of samples to the pipelines to process the samples and analyze data. The input and output for the pipeline can also be pre-configured and exposed to GUI. A Pscript includes three blocks: Info , Input and Script . Info block allows the administrator to specify a label for the script, a description of the script, as well as a category (separated by \\ for multiple levels) for the pscript, as in the example below: &lt;Info&gt; Label=Illumina RNA-Seq Alignment Description=Import Illumina reads with B37/R62 Category=NGS\\RNA-Seq\\Illumina Input block allows the user to specify variables (also defined as Parameters) that will be used by the script. Variables are named by using the @VariableName@ pattern. These variables can be substituted at appropriate places within the script. Each variable should follow this pattern: @VariableName@=DefaultOption ~@VariableName@=Variable description ~@VariableName@Levels=Level1, Level ~@VariableName@ExclusiveLevels=True Script block contains the Ocript procs that perform data analysis in the pipeline. User may refer to Oscript that was introduced in the previous chapter in this tutorial. Below is an example of a pscript (RnaSeq Alignment Pscript Pipeline) that align RnaSeq reads and save the output bam files to a specified folder: & lt ; Info & gt ; Label = RnaSeq Alignment Pscript Pipeline Description = Align RnaSeq reads and export Bam to a folder Category = NGS \\ RNA - Seq \\ Illumina & lt ; Input & gt ; @ JobNumber @ = 4 ~ @ JobNumber @ = Number of threads to run for each of the steps . ~ @ JobNumber @ Levels = 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ~ @ JobNumber @ ExclusiveLevels = True @ ThreadNumber @ = 4 ~ @ ThreadNumber @ = Number of threads to run for each of the steps . ~ @ ThreadNumer @ Levels = 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ~ @ ThreadNumber @ ExclusiveLevels = True @ ProjectFolder @ = ~ @ ProjectFolder @ Type = FilePath ~ @ ProjectFolder @ = Output folder for ALV and BAM files ~ @ ProjectFolder @ Type = FilePath & lt ; Script & gt ; Begin OpenProject ; ServerProject @ ProjectName @; End ; Begin MapRnaSeqReadsToGenome / Namespace = NgsLib / RunOnServer = True ; Files \"@FileNames@\" ; Reference Human . B38 ; GeneModel Ensembl . R82 ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / PairedEnd = True / FileFormat = FASTQ / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = False / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / WriteReadsInSeparateFiles = True / OutputFolder = \"@ProjectFolder@/@ProjectName@/BAM\" / GenerateSamFiles = False / ParallelJobNumber = @ JobNumber @ / ThreadNumber = @ ThreadNumber @ / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / MatePair = False / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = Gzip / Gzip = True / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False / KeepFullRead = False / Replace = False / Platform = ILLUMINA / CompressBam = False ; Output RNASeqAlignment ; End ; Begin SaveProject ; End ; Begin CloseProject ; Project @ ProjectName @; End ; The Pscript may be saved as RnaSeqAlignmentPipeline.pscript, and installed in Array Server in Manage | Manage Scripts as shown in the next section. Manage Pscript in Array Server ArrayServer administrators can manage (add, edit and remove) PScripts in Array Server. The pscript management is in Manage | Manage Scripts : Administrators may install new pscript as a pipeline in Array Server by clicking on Add | Download script from Omicsoft | Load From File , and select the .pscript file (for example RnaSeqAlignmentPipeline.pscript). Administrators may install pre-configured pscript pipelines prepared by Omicsoft by clicking on Add | Download script from Omicsoft . Choose one script, for example IlluminaDNASeqBAMFullPipeline , and click OK to show the details of the script, including description, required input, oscript for each analysis module. Click on OK to install this script on Array Server. Submit Samples To Pscript Pipeline to Run Jobs on Array Server Users may submit samples to Pscript pipeline to perform large scale data analysis on array server. The most typical way for users run samples in a pipeline is to upload a sample registration file (file extension .osreg) to the user's Instruction folder in Array Server. Array Server automatically scans the Instruction folder, picks up any sample registration files (osreg files) in the folder, and submits the samples in the osreg file to the pscript pipeline that is specified in the osreg file. The pscript pipeline will process samples in Array Server. Here is an osreg file example that provides input sample and parameters for the RnaSeq Alignment Pscript Pipeline shown in the begining of this chapter: [Samples] SampleID FilePath SampleName SRR521462 FASTQ1=/path1/test1.fastq|FASTQ2=/path1/test1.fastq Sample1 [SampleSet] ID=Alignment_test Title=Alignment_test Reader=standard users Editor=standard users ExperimentSource=Test ExperimentTitle=Test Experiment1 ExperimentDescription=Test Pscript for a customer ExperimentDesignDate=07/24/2017 PrincipalInvestigator=Test Project=test 1 [Pipeline] Project.Readers=standard users Project.ID=AlignmentTest UserID=omicsoft ScriptID=RnaSeqAlignmentPipeline.pscript Project.Editors=omicsoft Parameters.JobNumber=2 Parameters.ThreadNumber=4 Parameters.ProjectFolder=/Users/omicsoft/20170724_pscript_user_v1 Users may refer to the Sample Registration Chapter in Sample Management tutorial for more details on the osreg file. Users may also submit samples to pscript pipeline by browsing server samples and right click on any SampleSet to Run Server Pipeline . Users may then choose one of the installed scripts to process their samples. Customize Pscript and Expose it to Array Studio GUI Server administrators have the capability to make a Pscript available in the Analysis tab of Array Studio. This option would allow users to automate analyses without registering the samples on the server, similar to our built-in analysis pipelines under the Add Data | Add NGS Data menu option. To expose a Pscript to GUI, the Pscript author needs to include the following in section. &lt;Input&gt; ExternalScriptInputType=Files ExternalScriptMenuText=Customized Function Name ExternalScriptMenuStructure=NGS\\RNA-Seq\\Alignment ExternalScriptFileFilter=FASTQ files|*.fastq|.gz|*.gz Example of the full script allowing GUI input: & lt ; Info & gt ; Label = RNA - Seq Custom Pipeline ( with save after each step ) Description = Raw data QC , Align to B37 .3 with RefGene , Post Alignment QC with Ensembl Category = NGS \\ RNA - Seq \\ Illumina & lt ; Input & gt ; ExternalScriptInputType = Files ExternalScriptMenuText = RNA - Seq Custom Pipeline ExternalScriptMenuStructure = NGS \\ RNA - Seq \\ Pipeline ExternalScriptFileFilter = FASTQ files |* . fastq | . gz |* . gz @ PairedSamples @ = True ~ @ PairedSamples @ = Data is paired . Options are True or False ( True by default ) ~ @ PairedSamples @ Levels = True , False ~ @ PairedSamples @ ExclusiveLevels = True @ ThreadNumberPerJob @ = 4 ~ @ ThreadNumberPerJob @ = Number of threads to run for each of the steps . ~ @ ThreadNumerPerJob @ Levels = 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ~ @ ThreadNumberPerJob @ ExclusiveLevels = False @ ParallelJobNumber @ = 8 ~ @ ParallelJobNumber @ = Number of parallel jobs to run for each of the steps @ PreviewMode @ = True ~ @ PreviewMode @ = Set to true to run raw data QC in preview mode ~ @ PreviewMode @ Levels = True , False ~ @ PreviewMode @ ExclusiveLevels = True @ Gzip @ = Gzip ~ @ Gzip @ = Set to Gzip if input files are gzipped or None ~ @ Gzip @ Levels = Gzip , None ~ @ Gzip @ ExclusiveLevels = True @ OutputFolderName @ = ~ @ OutputFolderName @ Type = FilePath ~ @ OutputFolderName @ = Output folder for results and BAM files & lt ; Script & gt ; //Raw data QC section Begin NgsQCWizard / Namespace = NgsLib ; Files \"@FileNames@\" ; Options / FileFormat = AUTO / QualityEncoding = Automatic / CompressionMethod = @ Gzip @ / PreviewMode = @ PreviewMode @ / ParallelJobNumber = @ ParallelJobNumber @ / BasicStatistics = True / BaseDistribution = True / QualityBoxPlot = True / KMerAnalysis = True / SequenceDuplication = True / IgnoreFF = True / OutputFolder = \"@OutputFolderName@\" ; Output ; End ; Begin SaveProject ; End ; //Mapping Section Begin MapRnaSeqReadsToGenome / Namespace = NgsLib ; Files \"@FileNames@\" ; Reference Human . B37 .3 ; GeneModel RefGene ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / ParallelJobNumber = @ ParallelJobNumber @ / PairedEnd = @ PairedSamples @ / FileFormat = AUTO / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = False / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / WriteReadsInSeparateFiles = True / OutputFolder = \"@OutputFolderName@\" / GenerateSamFiles = False / ThreadNumberPerJob = @ ThreadNumberPerJob @ / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = @ Gzip @ / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False ; Output ; End ; Begin SaveProject ; End ; After installing the PScript on Array Server, any Array Server user can open a server project and open this PScript in Scripts (click on Update Scripts first). RNA-Seq Custom Pipeline PScript example with full script. Users can simply input their files and parameters and perform their analyses using the customized PScript.","title":"Pipeline Script"},{"location":"tutorials/Oscript/PipelineScript/#pipeline-script","text":"A pipeline script (Pscript) is created and managed by ArrayServer administrators. Once a pscript is installed in Array Server, it becomes a pipeline tool. Users can submit large amount of samples to the pipelines to process the samples and analyze data. The input and output for the pipeline can also be pre-configured and exposed to GUI. A Pscript includes three blocks: Info , Input and Script . Info block allows the administrator to specify a label for the script, a description of the script, as well as a category (separated by \\ for multiple levels) for the pscript, as in the example below: &lt;Info&gt; Label=Illumina RNA-Seq Alignment Description=Import Illumina reads with B37/R62 Category=NGS\\RNA-Seq\\Illumina Input block allows the user to specify variables (also defined as Parameters) that will be used by the script. Variables are named by using the @VariableName@ pattern. These variables can be substituted at appropriate places within the script. Each variable should follow this pattern: @VariableName@=DefaultOption ~@VariableName@=Variable description ~@VariableName@Levels=Level1, Level ~@VariableName@ExclusiveLevels=True Script block contains the Ocript procs that perform data analysis in the pipeline. User may refer to Oscript that was introduced in the previous chapter in this tutorial. Below is an example of a pscript (RnaSeq Alignment Pscript Pipeline) that align RnaSeq reads and save the output bam files to a specified folder: & lt ; Info & gt ; Label = RnaSeq Alignment Pscript Pipeline Description = Align RnaSeq reads and export Bam to a folder Category = NGS \\ RNA - Seq \\ Illumina & lt ; Input & gt ; @ JobNumber @ = 4 ~ @ JobNumber @ = Number of threads to run for each of the steps . ~ @ JobNumber @ Levels = 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ~ @ JobNumber @ ExclusiveLevels = True @ ThreadNumber @ = 4 ~ @ ThreadNumber @ = Number of threads to run for each of the steps . ~ @ ThreadNumer @ Levels = 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ~ @ ThreadNumber @ ExclusiveLevels = True @ ProjectFolder @ = ~ @ ProjectFolder @ Type = FilePath ~ @ ProjectFolder @ = Output folder for ALV and BAM files ~ @ ProjectFolder @ Type = FilePath & lt ; Script & gt ; Begin OpenProject ; ServerProject @ ProjectName @; End ; Begin MapRnaSeqReadsToGenome / Namespace = NgsLib / RunOnServer = True ; Files \"@FileNames@\" ; Reference Human . B38 ; GeneModel Ensembl . R82 ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / PairedEnd = True / FileFormat = FASTQ / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = False / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / WriteReadsInSeparateFiles = True / OutputFolder = \"@ProjectFolder@/@ProjectName@/BAM\" / GenerateSamFiles = False / ParallelJobNumber = @ JobNumber @ / ThreadNumber = @ ThreadNumber @ / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / MatePair = False / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = Gzip / Gzip = True / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False / KeepFullRead = False / Replace = False / Platform = ILLUMINA / CompressBam = False ; Output RNASeqAlignment ; End ; Begin SaveProject ; End ; Begin CloseProject ; Project @ ProjectName @; End ; The Pscript may be saved as RnaSeqAlignmentPipeline.pscript, and installed in Array Server in Manage | Manage Scripts as shown in the next section.","title":"Pipeline Script"},{"location":"tutorials/Oscript/PipelineScript/#manage-pscript-in-array-server","text":"ArrayServer administrators can manage (add, edit and remove) PScripts in Array Server. The pscript management is in Manage | Manage Scripts : Administrators may install new pscript as a pipeline in Array Server by clicking on Add | Download script from Omicsoft | Load From File , and select the .pscript file (for example RnaSeqAlignmentPipeline.pscript). Administrators may install pre-configured pscript pipelines prepared by Omicsoft by clicking on Add | Download script from Omicsoft . Choose one script, for example IlluminaDNASeqBAMFullPipeline , and click OK to show the details of the script, including description, required input, oscript for each analysis module. Click on OK to install this script on Array Server.","title":"Manage Pscript in Array Server"},{"location":"tutorials/Oscript/PipelineScript/#submit-samples-to-pscript-pipeline-to-run-jobs-on-array-server","text":"Users may submit samples to Pscript pipeline to perform large scale data analysis on array server. The most typical way for users run samples in a pipeline is to upload a sample registration file (file extension .osreg) to the user's Instruction folder in Array Server. Array Server automatically scans the Instruction folder, picks up any sample registration files (osreg files) in the folder, and submits the samples in the osreg file to the pscript pipeline that is specified in the osreg file. The pscript pipeline will process samples in Array Server. Here is an osreg file example that provides input sample and parameters for the RnaSeq Alignment Pscript Pipeline shown in the begining of this chapter: [Samples] SampleID FilePath SampleName SRR521462 FASTQ1=/path1/test1.fastq|FASTQ2=/path1/test1.fastq Sample1 [SampleSet] ID=Alignment_test Title=Alignment_test Reader=standard users Editor=standard users ExperimentSource=Test ExperimentTitle=Test Experiment1 ExperimentDescription=Test Pscript for a customer ExperimentDesignDate=07/24/2017 PrincipalInvestigator=Test Project=test 1 [Pipeline] Project.Readers=standard users Project.ID=AlignmentTest UserID=omicsoft ScriptID=RnaSeqAlignmentPipeline.pscript Project.Editors=omicsoft Parameters.JobNumber=2 Parameters.ThreadNumber=4 Parameters.ProjectFolder=/Users/omicsoft/20170724_pscript_user_v1 Users may refer to the Sample Registration Chapter in Sample Management tutorial for more details on the osreg file. Users may also submit samples to pscript pipeline by browsing server samples and right click on any SampleSet to Run Server Pipeline . Users may then choose one of the installed scripts to process their samples.","title":"Submit Samples To Pscript Pipeline to Run Jobs on Array Server"},{"location":"tutorials/Oscript/PipelineScript/#customize-pscript-and-expose-it-to-array-studio-gui","text":"Server administrators have the capability to make a Pscript available in the Analysis tab of Array Studio. This option would allow users to automate analyses without registering the samples on the server, similar to our built-in analysis pipelines under the Add Data | Add NGS Data menu option. To expose a Pscript to GUI, the Pscript author needs to include the following in section. &lt;Input&gt; ExternalScriptInputType=Files ExternalScriptMenuText=Customized Function Name ExternalScriptMenuStructure=NGS\\RNA-Seq\\Alignment ExternalScriptFileFilter=FASTQ files|*.fastq|.gz|*.gz Example of the full script allowing GUI input: & lt ; Info & gt ; Label = RNA - Seq Custom Pipeline ( with save after each step ) Description = Raw data QC , Align to B37 .3 with RefGene , Post Alignment QC with Ensembl Category = NGS \\ RNA - Seq \\ Illumina & lt ; Input & gt ; ExternalScriptInputType = Files ExternalScriptMenuText = RNA - Seq Custom Pipeline ExternalScriptMenuStructure = NGS \\ RNA - Seq \\ Pipeline ExternalScriptFileFilter = FASTQ files |* . fastq | . gz |* . gz @ PairedSamples @ = True ~ @ PairedSamples @ = Data is paired . Options are True or False ( True by default ) ~ @ PairedSamples @ Levels = True , False ~ @ PairedSamples @ ExclusiveLevels = True @ ThreadNumberPerJob @ = 4 ~ @ ThreadNumberPerJob @ = Number of threads to run for each of the steps . ~ @ ThreadNumerPerJob @ Levels = 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 ~ @ ThreadNumberPerJob @ ExclusiveLevels = False @ ParallelJobNumber @ = 8 ~ @ ParallelJobNumber @ = Number of parallel jobs to run for each of the steps @ PreviewMode @ = True ~ @ PreviewMode @ = Set to true to run raw data QC in preview mode ~ @ PreviewMode @ Levels = True , False ~ @ PreviewMode @ ExclusiveLevels = True @ Gzip @ = Gzip ~ @ Gzip @ = Set to Gzip if input files are gzipped or None ~ @ Gzip @ Levels = Gzip , None ~ @ Gzip @ ExclusiveLevels = True @ OutputFolderName @ = ~ @ OutputFolderName @ Type = FilePath ~ @ OutputFolderName @ = Output folder for results and BAM files & lt ; Script & gt ; //Raw data QC section Begin NgsQCWizard / Namespace = NgsLib ; Files \"@FileNames@\" ; Options / FileFormat = AUTO / QualityEncoding = Automatic / CompressionMethod = @ Gzip @ / PreviewMode = @ PreviewMode @ / ParallelJobNumber = @ ParallelJobNumber @ / BasicStatistics = True / BaseDistribution = True / QualityBoxPlot = True / KMerAnalysis = True / SequenceDuplication = True / IgnoreFF = True / OutputFolder = \"@OutputFolderName@\" ; Output ; End ; Begin SaveProject ; End ; //Mapping Section Begin MapRnaSeqReadsToGenome / Namespace = NgsLib ; Files \"@FileNames@\" ; Reference Human . B37 .3 ; GeneModel RefGene ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / ParallelJobNumber = @ ParallelJobNumber @ / PairedEnd = @ PairedSamples @ / FileFormat = AUTO / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = False / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / WriteReadsInSeparateFiles = True / OutputFolder = \"@OutputFolderName@\" / GenerateSamFiles = False / ThreadNumberPerJob = @ ThreadNumberPerJob @ / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = @ Gzip @ / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False ; Output ; End ; Begin SaveProject ; End ; After installing the PScript on Array Server, any Array Server user can open a server project and open this PScript in Scripts (click on Update Scripts first). RNA-Seq Custom Pipeline PScript example with full script. Users can simply input their files and parameters and perform their analyses using the customized PScript.","title":"Customize Pscript and Expose it to Array Studio GUI"},{"location":"tutorials/Oscript/RunOscript/","text":"Run Oscript OSCRIPT Oscript file (file extension .oscript) contains a list of omicsoft procs that can be sequentially excecuted to process user's data in a local or server project. A proc is a script corresponding to a data process operation in Array Studio GUI. A proc starts with keyword BEGIN and the name of the proc, and end with keyword END and semicolon ;. Users may obtain a template of the procs by following the Export Oscript from GUI section. A Oscript may include procs for macro definition, initiation of project, analysis modules, saving and closing project. The figure below provides a simplified example showing the structure of an Oscript. As shown in the example, a local Omicsoft project is created and saved as an OSPRJ file (see line 9-12 in the figure below). The OSPRJ file records all analysis steps and results (or links to large result files such as BAM files) as the analysis modules are performed. NGS projects are specified as distributed projects, which save different analysis results in separate files. Undistributed projects save all results in a single file. Input for analysis modules can be either raw sequence files (specified by Files ) or intermediate data objects (specified by Project and Data ). One advantage of working in the OSPRJ environment is that all data objects generated in preceding modules can be passed onto downstream modules smoothly by calling the data object name. For example, the output data object in AnalysisModuleA is defined as ResultA , which can be directly used by AnalysisModuleB as input (see line 13-26 in the figure below). Whenever new analysis results need to be saved in the OSPRJ file, SaveProject is called, which usually happens before closing a project (see line 27-30 in the figure below). Details of options used in each module can be found in our online collection of Oscript templates. Macro proc are used for parameters that are frequently called in the Oscript, including project-specific parameters (project name, project folder and input files) and parameters shared across modules (thread number, paired-end or single-end layout, reference genome and gene model). Macros are defined as @ParameterName@ Value (see line 1-8 in the figure below). A full example OScript can be found at link Oscripts may be launched from Array Studio or from a linux or windows Oshell command line. Export Oscript Procs from GUI Each analysis module in the GUI corresponds to a unique proc section in human-readable Oscript, for instance MapRnaSeqReadsToGenome for RNA-Seq alignment and NgsQCWizard for raw NGS data quality control. The OScript proc can be obtained by clicking on Show Script button after setting all parameters in GUI. In RNA-Seq alignment module, for example, after setting all parameters, user can click Show Script to get MapRnaSeqReadsToGenome OScript proc. The user can modify input, analysis parameters and output directly in the OScript for other jobs. A text file will open with the full OScript: Begin MapRnaSeqReadsToGenome / Namespace = NgsLib ; Files \"D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_1.fastq.gz D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_2.fastq.gz D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_1.fastq.gz D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_2.fastq.gz\" ; Reference Human . B37 . 3 ; GeneModel OmicsoftGene20130723 ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / ParallelJobNumber = 4 / PairedEnd = True / FileFormat = AUTO / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = True / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / OutputFolder = \"D:\\Tutorial\\RNASeq\" / ThreadNumber = 2 / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / MatePair = False / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = Gzip / Gzip = True / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False / KeepFullRead = False / Replace = False / Platform = ILLUMINA / CompressBam = False ; Output ; End ; Run Oscript from Array Studio Tools | Run Script Users can submit an oscript via Array Studio GUI Tools | Run Script . It is typically used to work on local projects and less frequently in server projects. For large-scale server projects, we recommend to use pscript that has an optimized workflow for sample registration, job submission and job monitoring (see next chapter for more details). Once an oscript is saved with extension .oscript, users may click on Tools | Run Script to open the window to submit the .oscript file. Run Script may submit jobs to a local machine for a local project, and a server (and HPC cluster) for a server project, depending on the procs used in the oscript. If an oscript does not contain a connectServer proc, the oscript submitted via Tools | Run Script will run in the local machine where Array Studio resides. One example is the oscript in the figure at the begining of this chapter. Another example is shown below to create an local project, map DnaSeq reads, save and close the project: Begin Macro ; @ ThreadNum @ 6 ; @ ProjectName @ \"testProject\" ; @ ProjectFolder @ \"/local/data/support/test\" ; @ FileNames @ \"/workspace/ws03/IData/TestDataSets/HumanDNASeqPaired/test_1.fastq.gz / workspace / ws03 / IData / TestDataSets / HumanDNASeqPaired / test_2 . fastq . gz \"; @ CompressionMethod @ None ; @ Gzip @ False ; @ PairedEnd @ True ; @ ReferenceName @ Human . B37 .3 ; End ; Begin NewProject ; File \"@ProjectFolder@/@ProjectName@.osprj\" ; Options / Distributed = True ; End ; Begin MapDnaSeqReads / Namespace = NgsLib ; Files \"@FileNames@\" ; Reference @ ReferenceName @; Trimming / Mode = Composite / LeftTrimming = 0 / RightTrimming = 0 / ReadTrimQuality = 2 / ReadTrimSize = 65536 ; AdapterStripping 3 ' End / AdapterSequence = CTGTCTCTTATA / ExcludeUnmatched = False ; Options / PairedEnd = @ PairedEnd @ / FileFormat = FASTQ / AutoPenalty = True / FixedPenalty = 2 / IndelPenalty = 2 / DetectIndels = False / Greedy = False / IndexMode = 14 Mer / ExcludeNonUniqueMapping = True / ReportCutoff = 2 / WriteReadsInSeparateFiles = True / OutputFolder = \"@ProjectFolder@/BAMOutput\" / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 1000 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / GenerateSamFiles = False / ThreadNumber = @ ThreadNum @ / ExpectedInsertSize = 300 / InsertSizeStandardDeviation = 40 / QualityEncoding = Automatic / CompressionMethod = @ CompressionMethod @ / Gzip = @ Gzip @ / ExcludeUnmappedInBam = True / KeepFullRead = False / MapRead = True / MapReverseComplement = True / Version = 4 / ParallelJobNumber = 1 / BamSubFolder = / Platform = ILLUMINA / Replace = False / LocalAlignment = True ; Output Alignment ; End ; Begin SaveProject ; Project @ ProjectName @; File \"@ProjectFolder@/@ProjectName@.osprj\" ; End ; Begin CloseProject ; Project @ ProjectName @; End ; To run jobs on a server and cluster via Tools | Run Script , a connectServer proc is required to connect to an array server. The procs that are intended to run on server are also required to be compatible to server jobs. Please refer to the proc documentation for server job compatability. In some cases, a statement /RunOnServer=True is required in a proc in order for the proc to be excecuted on the server. Here is an example of an oscript that was submitted via Tools | Run Script to work on a server project. The script defined some parameters in a Macro proc, connected to an array server, created a new project in the server, performed RnaSeq alignment in a cluster, saved and closed the project in the server. Begin Macro ; @ ThreadNum @ 6 ; @ ProjectName @ \"AlignmentProject10\" ; @ ProjectFolder @ \"/local_data/TestDataSets/tem/tem_20170720\" ; @ FileNames @ \" / local_data / TestDataSets / SRR521462_1 . fastq / local_data / TestDataSets / SRR521462_2 . fastq \"; @ JobNumber @ 4 ; @ ThreadNumber @ 4 ; @ DesignFile @ \"/local_data/TestDataSets/tem/tem_20170720/design3.txt\" ; End ; Begin ConnectServer ; Server \"tcp://192.168.3.226:9065\" / User = xxx / Password = xxxxx ; End ; Begin NewProject ; ServerProject \"@ProjectName@\" ; Options / Distributed = True ; End ; Begin MapRnaSeqReadsToGenome / Namespace = NgsLib / RunOnServer = True ; Files \"@FileNames@\" ; Reference Human . B38 ; GeneModel Ensembl . R82 ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / PairedEnd = True / FileFormat = FASTQ / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = False / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / WriteReadsInSeparateFiles = Tru / OutputFolder = \"@ProjectFolder@/@ProjectName@/BAM\" / GenerateSamFiles = False / ParallelJobNumber = @ JobNumber @ / ThreadNumber = @ ThreadNumber @ / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / MatePair = False / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = Gzip / Gzip = True / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False / KeepFullRead = False / Replace = False / Platform = ILLUMINA / CompressBam = False ; Output RNASeqAlignment ; End ; Begin SaveProject ; Project @ ProjectName @; Options / Distributed = True ; End ; Begin CloseProject ; Project @ ProjectName @; End ; Run Oscript from Array Studio Tools | Run Script (Send To Queue) If a user has logged into Array Server from Array Studio, the user may click on Run Script (Send To Queue) to submit an oscript to work on a server project and run jobs in HPC cluster. Users may monitor the job status in Server | Manage Server Jobs . Please note that the connectServer proc is not required in the oscript in this case since the user has logged into Array Server. Please also note that the Macro proc can not currently be used for constructing paths if the oscript is submitted via Tools | Run Script (Send To Queue) . Below is an example oscript that can be submit via Run Script (Send To Queue) to run on a server: Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True; Files \" /local_data/TestDataSets/SRR521462_1.fastq /local_data/TestDataSets/SRR521462_2.fastq\"; Reference Human.B38; GeneModel Ensembl.R82; Trimming /Mode=TrimByQuality /ReadTrimQuality=2; Options /PairedEnd=True /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /Greedy=false /IndelPenalty=2 /DetectIndels=False /MaxMiddleInsertionSize=10 /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10 /MinDistalEndSize=3 /ExcludeNonUniqueMapping=False /ReportCutoff=10 /WriteReadsInSeparateFiles=True /OutputFolder=\"/local_data/TestDataSets/tem/tem_20170720/AlignmentProject/BAM\" /GenerateSamFiles=False /ParallelJobNumber=4 /ThreadNumber=6 /InsertSizeStandardDeviation=40 /ExpectedInsertSize=300 /MatePair=False /InsertOnSameStrand=False /InsertOnDifferentStrand=True /QualityEncoding=Automatic /CompressionMethod=Gzip /Gzip=True /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False /KeepFullRead=False /Replace=False /Platform=ILLUMINA /CompressBam=False; Output RNASeqAlignment; End; Begin SaveProject; Project AlignmentProject; Options /Distributed=True; End; Run Oscript from Windows or Linux Oshell Commandline Users may also run an oscript from a single windows or linux command line (oshell commandline) by using Omicsoft's oshell.exe function in Omicsoft Oshell environment. The Oshell Environment is another Omicsoft package that is independent from Array Server and Array Studio. Users may need to obtain a license from Omicsoft to install the package. Please contact support@omicsoft.com for more information. By running with OShell command line, users do not need to interact with the GUI. The Oshell Environment can work on a local project as a commandline version of Array Studio GUI, and also can interact with an Array Server to work on a server project. The requirements of the oscripts for Oshell commandline is the same as the oscript for Tools | Run Script (Send To Queue) . Specifically, Marco proc allows for path construction. The oscript will be ran in a server (and cluster) if it has connectServer proc and server job compatible procs, and would run in the local machine if otherwise. In fact, the example oscripts in Run Oscript from Array Studio Tools | Run Script can be directly launched from the oshell commandline. Users may save the file as test.oscript and run using command line: If OShell is installed on Windows (one line command): C : \\ Oshell \\ oshell . exe --runscript C : \\ Users \\ user \\ Documents \\ Omicsoft C : \\ tmp \\ test . oscript C : \\ Users \\ user \\ Documents \\ OmicsoftTmpDirectory & gt ; C : \\ tmp \\ testrun . log If Oshell is installed on Linux and can be run using mono (one line command): /opt/mono-2.10.9/bin/mono /home/user/Oshell/oshell.exe --runscript /home/user/OmicsoftHome /tmp/test.oscript /home/user/OmicsoftTmp /opt/mono-2.10.9/bin/mono &gt; /tmp/testrun.log Wrapping External Tools into Oscript Omicsoft has implemented external script (EScript) integration to build pipelines/workflows using public bioinformatics tools. Since most third-party tools are Linux-only, users should run Escript in Oshell or ArrayServer on a Linux machine. Escript can wrap and run public bioinformatics tools, such as BWA, Bowtie, Tophat, and Cufflink, in OmicSoft Project Environment. The results from public tools can be imported as a table in Array Studio seamlessly. Escript runs can be submitted to the job queue in ArrayServer and run in Grid Engine if the server has been configured. Escript jobs are monitored and tracked in ArrayServer. Here is a local (as opposed to server) Escript using a simple example wrapping Bowtie. The script assumes that: Bowtie is installed and can be found in PATH ebwt indexes are located in /idx Example Script: Begin RunEScript; Files \"/home/user/Test/_Raw/SRR243575.s.1.fastq /home/user/Test/_Raw/SRR243575.s.2.fastq\"; EScriptName Bowtie; Command mkdir \"/tmp/testRun\"; Command bowtie \"/idx/hg19\" -1 \"%Path1%\" -2 \"%Path2%\" -p 8 -a -m 1 -v 2 -t -S \"/tmp/test.sam\"; Options /ParallelJobNumber=1 /ThreadNumberPerJob=8 /Mode=Paired /ErrorOnStdErr=False; End; Begin AddMappedDnaSeqReads /Namespace=NgsLib; Files \"/tmp/test.sam\"; Reference Human.hg19; Options /FileFormat=SAM /ThreadNumber=4 /NoCopy=True; Output BAMFile; End;","title":"Run Oscript"},{"location":"tutorials/Oscript/RunOscript/#run-oscript","text":"","title":"Run Oscript"},{"location":"tutorials/Oscript/RunOscript/#oscript","text":"Oscript file (file extension .oscript) contains a list of omicsoft procs that can be sequentially excecuted to process user's data in a local or server project. A proc is a script corresponding to a data process operation in Array Studio GUI. A proc starts with keyword BEGIN and the name of the proc, and end with keyword END and semicolon ;. Users may obtain a template of the procs by following the Export Oscript from GUI section. A Oscript may include procs for macro definition, initiation of project, analysis modules, saving and closing project. The figure below provides a simplified example showing the structure of an Oscript. As shown in the example, a local Omicsoft project is created and saved as an OSPRJ file (see line 9-12 in the figure below). The OSPRJ file records all analysis steps and results (or links to large result files such as BAM files) as the analysis modules are performed. NGS projects are specified as distributed projects, which save different analysis results in separate files. Undistributed projects save all results in a single file. Input for analysis modules can be either raw sequence files (specified by Files ) or intermediate data objects (specified by Project and Data ). One advantage of working in the OSPRJ environment is that all data objects generated in preceding modules can be passed onto downstream modules smoothly by calling the data object name. For example, the output data object in AnalysisModuleA is defined as ResultA , which can be directly used by AnalysisModuleB as input (see line 13-26 in the figure below). Whenever new analysis results need to be saved in the OSPRJ file, SaveProject is called, which usually happens before closing a project (see line 27-30 in the figure below). Details of options used in each module can be found in our online collection of Oscript templates. Macro proc are used for parameters that are frequently called in the Oscript, including project-specific parameters (project name, project folder and input files) and parameters shared across modules (thread number, paired-end or single-end layout, reference genome and gene model). Macros are defined as @ParameterName@ Value (see line 1-8 in the figure below). A full example OScript can be found at link Oscripts may be launched from Array Studio or from a linux or windows Oshell command line.","title":"OSCRIPT"},{"location":"tutorials/Oscript/RunOscript/#export-oscript-procs-from-gui","text":"Each analysis module in the GUI corresponds to a unique proc section in human-readable Oscript, for instance MapRnaSeqReadsToGenome for RNA-Seq alignment and NgsQCWizard for raw NGS data quality control. The OScript proc can be obtained by clicking on Show Script button after setting all parameters in GUI. In RNA-Seq alignment module, for example, after setting all parameters, user can click Show Script to get MapRnaSeqReadsToGenome OScript proc. The user can modify input, analysis parameters and output directly in the OScript for other jobs. A text file will open with the full OScript: Begin MapRnaSeqReadsToGenome / Namespace = NgsLib ; Files \"D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_1.fastq.gz D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_2.fastq.gz D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_1.fastq.gz D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_2.fastq.gz\" ; Reference Human . B37 . 3 ; GeneModel OmicsoftGene20130723 ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / ParallelJobNumber = 4 / PairedEnd = True / FileFormat = AUTO / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = True / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / OutputFolder = \"D:\\Tutorial\\RNASeq\" / ThreadNumber = 2 / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / MatePair = False / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = Gzip / Gzip = True / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False / KeepFullRead = False / Replace = False / Platform = ILLUMINA / CompressBam = False ; Output ; End ;","title":"Export Oscript Procs from GUI"},{"location":"tutorials/Oscript/RunOscript/#run-oscript-from-array-studio-tools-run-script","text":"Users can submit an oscript via Array Studio GUI Tools | Run Script . It is typically used to work on local projects and less frequently in server projects. For large-scale server projects, we recommend to use pscript that has an optimized workflow for sample registration, job submission and job monitoring (see next chapter for more details). Once an oscript is saved with extension .oscript, users may click on Tools | Run Script to open the window to submit the .oscript file. Run Script may submit jobs to a local machine for a local project, and a server (and HPC cluster) for a server project, depending on the procs used in the oscript. If an oscript does not contain a connectServer proc, the oscript submitted via Tools | Run Script will run in the local machine where Array Studio resides. One example is the oscript in the figure at the begining of this chapter. Another example is shown below to create an local project, map DnaSeq reads, save and close the project: Begin Macro ; @ ThreadNum @ 6 ; @ ProjectName @ \"testProject\" ; @ ProjectFolder @ \"/local/data/support/test\" ; @ FileNames @ \"/workspace/ws03/IData/TestDataSets/HumanDNASeqPaired/test_1.fastq.gz / workspace / ws03 / IData / TestDataSets / HumanDNASeqPaired / test_2 . fastq . gz \"; @ CompressionMethod @ None ; @ Gzip @ False ; @ PairedEnd @ True ; @ ReferenceName @ Human . B37 .3 ; End ; Begin NewProject ; File \"@ProjectFolder@/@ProjectName@.osprj\" ; Options / Distributed = True ; End ; Begin MapDnaSeqReads / Namespace = NgsLib ; Files \"@FileNames@\" ; Reference @ ReferenceName @; Trimming / Mode = Composite / LeftTrimming = 0 / RightTrimming = 0 / ReadTrimQuality = 2 / ReadTrimSize = 65536 ; AdapterStripping 3 ' End / AdapterSequence = CTGTCTCTTATA / ExcludeUnmatched = False ; Options / PairedEnd = @ PairedEnd @ / FileFormat = FASTQ / AutoPenalty = True / FixedPenalty = 2 / IndelPenalty = 2 / DetectIndels = False / Greedy = False / IndexMode = 14 Mer / ExcludeNonUniqueMapping = True / ReportCutoff = 2 / WriteReadsInSeparateFiles = True / OutputFolder = \"@ProjectFolder@/BAMOutput\" / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 1000 / MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / GenerateSamFiles = False / ThreadNumber = @ ThreadNum @ / ExpectedInsertSize = 300 / InsertSizeStandardDeviation = 40 / QualityEncoding = Automatic / CompressionMethod = @ CompressionMethod @ / Gzip = @ Gzip @ / ExcludeUnmappedInBam = True / KeepFullRead = False / MapRead = True / MapReverseComplement = True / Version = 4 / ParallelJobNumber = 1 / BamSubFolder = / Platform = ILLUMINA / Replace = False / LocalAlignment = True ; Output Alignment ; End ; Begin SaveProject ; Project @ ProjectName @; File \"@ProjectFolder@/@ProjectName@.osprj\" ; End ; Begin CloseProject ; Project @ ProjectName @; End ; To run jobs on a server and cluster via Tools | Run Script , a connectServer proc is required to connect to an array server. The procs that are intended to run on server are also required to be compatible to server jobs. Please refer to the proc documentation for server job compatability. In some cases, a statement /RunOnServer=True is required in a proc in order for the proc to be excecuted on the server. Here is an example of an oscript that was submitted via Tools | Run Script to work on a server project. The script defined some parameters in a Macro proc, connected to an array server, created a new project in the server, performed RnaSeq alignment in a cluster, saved and closed the project in the server. Begin Macro ; @ ThreadNum @ 6 ; @ ProjectName @ \"AlignmentProject10\" ; @ ProjectFolder @ \"/local_data/TestDataSets/tem/tem_20170720\" ; @ FileNames @ \" / local_data / TestDataSets / SRR521462_1 . fastq / local_data / TestDataSets / SRR521462_2 . fastq \"; @ JobNumber @ 4 ; @ ThreadNumber @ 4 ; @ DesignFile @ \"/local_data/TestDataSets/tem/tem_20170720/design3.txt\" ; End ; Begin ConnectServer ; Server \"tcp://192.168.3.226:9065\" / User = xxx / Password = xxxxx ; End ; Begin NewProject ; ServerProject \"@ProjectName@\" ; Options / Distributed = True ; End ; Begin MapRnaSeqReadsToGenome / Namespace = NgsLib / RunOnServer = True ; Files \"@FileNames@\" ; Reference Human . B38 ; GeneModel Ensembl . R82 ; Trimming / Mode = TrimByQuality / ReadTrimQuality = 2 ; Options / PairedEnd = True / FileFormat = FASTQ / AutoPenalty = True / FixedPenalty = 2 / Greedy = false / IndelPenalty = 2 / DetectIndels = False / MaxMiddleInsertionSize = 10 / MaxMiddleDeletionSize = 10 MaxEndInsertionSize = 10 / MaxEndDeletionSize = 10 / MinDistalEndSize = 3 / ExcludeNonUniqueMapping = False / ReportCutoff = 10 / WriteReadsInSeparateFiles = Tru / OutputFolder = \"@ProjectFolder@/@ProjectName@/BAM\" / GenerateSamFiles = False / ParallelJobNumber = @ JobNumber @ / ThreadNumber = @ ThreadNumber @ / InsertSizeStandardDeviation = 40 / ExpectedInsertSize = 300 / MatePair = False / InsertOnSameStrand = False / InsertOnDifferentStrand = True / QualityEncoding = Automatic / CompressionMethod = Gzip / Gzip = True / SearchNovelExonJunction = True / ExcludeUnmappedInBam = False / KeepFullRead = False / Replace = False / Platform = ILLUMINA / CompressBam = False ; Output RNASeqAlignment ; End ; Begin SaveProject ; Project @ ProjectName @; Options / Distributed = True ; End ; Begin CloseProject ; Project @ ProjectName @; End ;","title":"Run Oscript from Array Studio Tools | Run Script"},{"location":"tutorials/Oscript/RunOscript/#run-oscript-from-array-studio-tools-run-script-send-to-queue","text":"If a user has logged into Array Server from Array Studio, the user may click on Run Script (Send To Queue) to submit an oscript to work on a server project and run jobs in HPC cluster. Users may monitor the job status in Server | Manage Server Jobs . Please note that the connectServer proc is not required in the oscript in this case since the user has logged into Array Server. Please also note that the Macro proc can not currently be used for constructing paths if the oscript is submitted via Tools | Run Script (Send To Queue) . Below is an example oscript that can be submit via Run Script (Send To Queue) to run on a server: Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True; Files \" /local_data/TestDataSets/SRR521462_1.fastq /local_data/TestDataSets/SRR521462_2.fastq\"; Reference Human.B38; GeneModel Ensembl.R82; Trimming /Mode=TrimByQuality /ReadTrimQuality=2; Options /PairedEnd=True /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /Greedy=false /IndelPenalty=2 /DetectIndels=False /MaxMiddleInsertionSize=10 /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10 /MinDistalEndSize=3 /ExcludeNonUniqueMapping=False /ReportCutoff=10 /WriteReadsInSeparateFiles=True /OutputFolder=\"/local_data/TestDataSets/tem/tem_20170720/AlignmentProject/BAM\" /GenerateSamFiles=False /ParallelJobNumber=4 /ThreadNumber=6 /InsertSizeStandardDeviation=40 /ExpectedInsertSize=300 /MatePair=False /InsertOnSameStrand=False /InsertOnDifferentStrand=True /QualityEncoding=Automatic /CompressionMethod=Gzip /Gzip=True /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False /KeepFullRead=False /Replace=False /Platform=ILLUMINA /CompressBam=False; Output RNASeqAlignment; End; Begin SaveProject; Project AlignmentProject; Options /Distributed=True; End;","title":"Run Oscript from Array Studio Tools | Run Script (Send To Queue)"},{"location":"tutorials/Oscript/RunOscript/#run-oscript-from-windows-or-linux-oshell-commandline","text":"Users may also run an oscript from a single windows or linux command line (oshell commandline) by using Omicsoft's oshell.exe function in Omicsoft Oshell environment. The Oshell Environment is another Omicsoft package that is independent from Array Server and Array Studio. Users may need to obtain a license from Omicsoft to install the package. Please contact support@omicsoft.com for more information. By running with OShell command line, users do not need to interact with the GUI. The Oshell Environment can work on a local project as a commandline version of Array Studio GUI, and also can interact with an Array Server to work on a server project. The requirements of the oscripts for Oshell commandline is the same as the oscript for Tools | Run Script (Send To Queue) . Specifically, Marco proc allows for path construction. The oscript will be ran in a server (and cluster) if it has connectServer proc and server job compatible procs, and would run in the local machine if otherwise. In fact, the example oscripts in Run Oscript from Array Studio Tools | Run Script can be directly launched from the oshell commandline. Users may save the file as test.oscript and run using command line: If OShell is installed on Windows (one line command): C : \\ Oshell \\ oshell . exe --runscript C : \\ Users \\ user \\ Documents \\ Omicsoft C : \\ tmp \\ test . oscript C : \\ Users \\ user \\ Documents \\ OmicsoftTmpDirectory & gt ; C : \\ tmp \\ testrun . log If Oshell is installed on Linux and can be run using mono (one line command): /opt/mono-2.10.9/bin/mono /home/user/Oshell/oshell.exe --runscript /home/user/OmicsoftHome /tmp/test.oscript /home/user/OmicsoftTmp /opt/mono-2.10.9/bin/mono &gt; /tmp/testrun.log","title":"Run Oscript from Windows or Linux Oshell Commandline"},{"location":"tutorials/Oscript/RunOscript/#wrapping-external-tools-into-oscript","text":"Omicsoft has implemented external script (EScript) integration to build pipelines/workflows using public bioinformatics tools. Since most third-party tools are Linux-only, users should run Escript in Oshell or ArrayServer on a Linux machine. Escript can wrap and run public bioinformatics tools, such as BWA, Bowtie, Tophat, and Cufflink, in OmicSoft Project Environment. The results from public tools can be imported as a table in Array Studio seamlessly. Escript runs can be submitted to the job queue in ArrayServer and run in Grid Engine if the server has been configured. Escript jobs are monitored and tracked in ArrayServer. Here is a local (as opposed to server) Escript using a simple example wrapping Bowtie. The script assumes that: Bowtie is installed and can be found in PATH ebwt indexes are located in /idx Example Script: Begin RunEScript; Files \"/home/user/Test/_Raw/SRR243575.s.1.fastq /home/user/Test/_Raw/SRR243575.s.2.fastq\"; EScriptName Bowtie; Command mkdir \"/tmp/testRun\"; Command bowtie \"/idx/hg19\" -1 \"%Path1%\" -2 \"%Path2%\" -p 8 -a -m 1 -v 2 -t -S \"/tmp/test.sam\"; Options /ParallelJobNumber=1 /ThreadNumberPerJob=8 /Mode=Paired /ErrorOnStdErr=False; End; Begin AddMappedDnaSeqReads /Namespace=NgsLib; Files \"/tmp/test.sam\"; Reference Human.hg19; Options /FileFormat=SAM /ThreadNumber=4 /NoCopy=True; Output BAMFile; End;","title":"Wrapping External Tools into Oscript"},{"location":"tutorials/RNASeq/","text":"RNA-Seq Analysis Tutorial .. toctree:: :maxdepth: 2 Introduction CreateArray_Studio_Project Add From RNA-Seq Pipeline QC_ofRawData_Files Alignment_to_the_Genome QC_of_AlignedData RNA-Seq_Quantification RNA-Seq_Fusion_Gene_Detection RNA-Seq_Mutation_Detection Others Save___Close_Project","title":"Home"},{"location":"tutorials/RNASeq/Add From RNA-Seq Pipeline/","text":"Add From RNA-Seq Pipeline Users have two options to perform RNA-Seq analysis -- one is to run through RNA-Seq pipeline, the other is to run step by step. Add From RNA-Seq Pipeline , as dicussed in this chapter, allows users to finish the whole RNA-Seq analysis in a single click. Based on a user's selections, Array Studio will run the following pipeline: To perform RNA-Seq pipeline analysis, choose Add NGS Data - Add From Pipeline - RNA-Seq Pipeline For each step in the RNA-Seq pipeline, the user can choose the default parameters found in Array Studio or customize settings such as genome version, gene model, alignment stringency and reporting options. To ease in the sharing of data after processing, it is recommended that the user choose the Reporting option to Generate land ALV files . If users want to add more user-defined options in each step, users can perform RNA-Seq analysis step by step starting with raw data QC and alignment. The step-by-step methods will be discussed in the next chapters. If the input files are in FASTQ, FASTA, or QSEQ format, then the data will be aligned in the same way as by Add RNA-Seq Data - Map Reads To Genome (Illumina) which will be discussed in the Chapter 5, with the default parameters. For this module, select the default options, and check \"Reads are paired\" as these reads are paired. These files will be automatically paired during the pipeline analysis. Depending on your server options, adjust the number of threads. Job number will determine how many parallel jobs (such as alignments) will be performed at once. This number should not exceed the number of samples. Click Send to Queue and the analysis will begin. This could take hours, depending on the number of threads/jobs or type of computer (64-bit/32-bit), etc. After alignment, it will load BAM files once and finish all selected downstream analyses. If user is using BAM files as input, the module will use AddGenomeMappedRnaSeqReads to add alignment file as NgsData directly for all downstream analysis. The pipeline has been tested briefly for external BAM files generated by other aligners (outside of Omicsoft). We are recommending users starting from raw (fastq/fasta) files. If you have BAM files and would like to use the Array Studio RNA-Seq Pipeline, you can covert these files back to fastq.gz files by using NGS | Tools | Convert Files . The pipeline module is particularly better than individual modules when enabling cloud based analysis with less file transfers and saving EC2 machine setup time.","title":"Add From RNA-Seq Pipeline"},{"location":"tutorials/RNASeq/Add From RNA-Seq Pipeline/#add-from-rna-seq-pipeline","text":"Users have two options to perform RNA-Seq analysis -- one is to run through RNA-Seq pipeline, the other is to run step by step. Add From RNA-Seq Pipeline , as dicussed in this chapter, allows users to finish the whole RNA-Seq analysis in a single click. Based on a user's selections, Array Studio will run the following pipeline: To perform RNA-Seq pipeline analysis, choose Add NGS Data - Add From Pipeline - RNA-Seq Pipeline For each step in the RNA-Seq pipeline, the user can choose the default parameters found in Array Studio or customize settings such as genome version, gene model, alignment stringency and reporting options. To ease in the sharing of data after processing, it is recommended that the user choose the Reporting option to Generate land ALV files . If users want to add more user-defined options in each step, users can perform RNA-Seq analysis step by step starting with raw data QC and alignment. The step-by-step methods will be discussed in the next chapters. If the input files are in FASTQ, FASTA, or QSEQ format, then the data will be aligned in the same way as by Add RNA-Seq Data - Map Reads To Genome (Illumina) which will be discussed in the Chapter 5, with the default parameters. For this module, select the default options, and check \"Reads are paired\" as these reads are paired. These files will be automatically paired during the pipeline analysis. Depending on your server options, adjust the number of threads. Job number will determine how many parallel jobs (such as alignments) will be performed at once. This number should not exceed the number of samples. Click Send to Queue and the analysis will begin. This could take hours, depending on the number of threads/jobs or type of computer (64-bit/32-bit), etc. After alignment, it will load BAM files once and finish all selected downstream analyses. If user is using BAM files as input, the module will use AddGenomeMappedRnaSeqReads to add alignment file as NgsData directly for all downstream analysis. The pipeline has been tested briefly for external BAM files generated by other aligners (outside of Omicsoft). We are recommending users starting from raw (fastq/fasta) files. If you have BAM files and would like to use the Array Studio RNA-Seq Pipeline, you can covert these files back to fastq.gz files by using NGS | Tools | Convert Files . The pipeline module is particularly better than individual modules when enabling cloud based analysis with less file transfers and saving EC2 machine setup time.","title":"Add From RNA-Seq Pipeline"},{"location":"tutorials/RNASeq/Alignment_to_the_Genome/","text":"Alignment to the Genome The second step in the analysis of most RNA-Seq data is the alignment of the reads to the genome. Alternatively, if the data has already been aligned, the alignment files (BAM/SAM) can be imported using Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads . For this experiment, we will align the data using Array Studio. Please go to the Add Data dropdown menu on the toolbar, then choose Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) . At this point, the Map RNA-Seq Reads to Genome module appears. The first step is to click the Add button to specify the location of the files. Choose the 12 files that were downloaded from SRA or the subset of the dataset downloaded from the OmicSoft website. Note that these files are in the .gz format. The alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files. Since this is a paired experiment, click the Reads are paired checkbox. This will ensure that the pairing information is used in the alignment and counting process. Choose the Genome for the experiment. In this analysis, we used Human.B37.3 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the Gene Model to be used for alignment. Here we use an Omicsoft gene model built on 07/23/2013, but the user can also choose from various Ensembl, UCSC or RefGene builds, or build their own gene model. Options to build genome and gene models can be found in the menu under NGS | Build | Build Reference Library and NGS | Build | Build Gene Model . Leave the quality encoding set to automatic. The files used in this tutorial were encoded using the Sanger quality scoring system. Total penalty should be left as automatic - alignment parameters are described completely in Omicsoft's white paper on alignment link . Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together. Only BAM files will be output. If users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files. Output folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step (for fusion detection). There are a few options in the Advanced Tab (e.g. Indel detection). In general the default values have been tuned and should work well in most cases. Leave the Exclude unmapped reads unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input for the single-end fusion detection algorithm (see the fusion chapter in this tutorial). Click Send to Queue to submit the analysis. This analysis could take hours to complete, depending on the number of threads, type of computer (64-bit/32-bit), etc. As an additional option, in the parameters for mapping the reads, there is an additional Preview tab, which allows the user to specify a percentage of the reads to sample for alignment and QC. This option may be attractive to a user who wishes to test the quality of the data before performing a large-scale analysis on new RNA-seq datasets. After the alignment, you will see a NgsData object and an alignment report table in the solution explorer, and BAM files as well as alignment report summary files in the specified output folder: Add the design table, \"Design.txt\", which can be found in the .zip folder containing the subset of RNA-Seq data downloaded in Chapter 1 of this tutorial. Right click on Design . Select Import | Tab delimited file There will be two options to specify: Append to the existing covariate table : checking this option will append the selected design file contents to the existing design table. Use the name order in the new covariate table : checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table. These two options should be left unchecked for this tutorial (as this is a new design table to import). The study includes 3 K562 cellline samples and 3 MCF7 cellline samples.","title":"Alignment to the Genome"},{"location":"tutorials/RNASeq/Alignment_to_the_Genome/#alignment-to-the-genome","text":"The second step in the analysis of most RNA-Seq data is the alignment of the reads to the genome. Alternatively, if the data has already been aligned, the alignment files (BAM/SAM) can be imported using Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads . For this experiment, we will align the data using Array Studio. Please go to the Add Data dropdown menu on the toolbar, then choose Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) . At this point, the Map RNA-Seq Reads to Genome module appears. The first step is to click the Add button to specify the location of the files. Choose the 12 files that were downloaded from SRA or the subset of the dataset downloaded from the OmicSoft website. Note that these files are in the .gz format. The alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files. Since this is a paired experiment, click the Reads are paired checkbox. This will ensure that the pairing information is used in the alignment and counting process. Choose the Genome for the experiment. In this analysis, we used Human.B37.3 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the Gene Model to be used for alignment. Here we use an Omicsoft gene model built on 07/23/2013, but the user can also choose from various Ensembl, UCSC or RefGene builds, or build their own gene model. Options to build genome and gene models can be found in the menu under NGS | Build | Build Reference Library and NGS | Build | Build Gene Model . Leave the quality encoding set to automatic. The files used in this tutorial were encoded using the Sanger quality scoring system. Total penalty should be left as automatic - alignment parameters are described completely in Omicsoft's white paper on alignment link . Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together. Only BAM files will be output. If users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files. Output folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step (for fusion detection). There are a few options in the Advanced Tab (e.g. Indel detection). In general the default values have been tuned and should work well in most cases. Leave the Exclude unmapped reads unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input for the single-end fusion detection algorithm (see the fusion chapter in this tutorial). Click Send to Queue to submit the analysis. This analysis could take hours to complete, depending on the number of threads, type of computer (64-bit/32-bit), etc. As an additional option, in the parameters for mapping the reads, there is an additional Preview tab, which allows the user to specify a percentage of the reads to sample for alignment and QC. This option may be attractive to a user who wishes to test the quality of the data before performing a large-scale analysis on new RNA-seq datasets. After the alignment, you will see a NgsData object and an alignment report table in the solution explorer, and BAM files as well as alignment report summary files in the specified output folder: Add the design table, \"Design.txt\", which can be found in the .zip folder containing the subset of RNA-Seq data downloaded in Chapter 1 of this tutorial. Right click on Design . Select Import | Tab delimited file There will be two options to specify: Append to the existing covariate table : checking this option will append the selected design file contents to the existing design table. Use the name order in the new covariate table : checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table. These two options should be left unchecked for this tutorial (as this is a new design table to import). The study includes 3 K562 cellline samples and 3 MCF7 cellline samples.","title":"Alignment to the Genome"},{"location":"tutorials/RNASeq/CreateArray_Studio_Project/","text":"Create Array Studio Project Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. In this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project and analysis steps are almost the same as described in this tutorial. Once Array Studio has been opened, under the Server tab at the top of the screen, log in to the server where Array Server is running. Click File | New Server Project from the File Menu (also can be accessed via the New button on the toolbar). Note to \"Local\" mode users: If you are using this tutorial in Local mode for any Next Generation Sequencing datasets, choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset. It is required that the user has approximately 100GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using Tools Menu | Preferences | Advanced . This will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. Click Create to store the project and you will see your empty project in the Solution Explorer :","title":"Create ArrayStudio Project"},{"location":"tutorials/RNASeq/CreateArray_Studio_Project/#create-array-studio-project","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. In this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project and analysis steps are almost the same as described in this tutorial. Once Array Studio has been opened, under the Server tab at the top of the screen, log in to the server where Array Server is running. Click File | New Server Project from the File Menu (also can be accessed via the New button on the toolbar). Note to \"Local\" mode users: If you are using this tutorial in Local mode for any Next Generation Sequencing datasets, choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset. It is required that the user has approximately 100GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using Tools Menu | Preferences | Advanced . This will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. Click Create to store the project and you will see your empty project in the Solution Explorer :","title":"Create Array Studio Project"},{"location":"tutorials/RNASeq/Introduction/","text":"Introduction ArrayStudio Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The tutorial is based on a server-based NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-3770 Processor (# of cores: 4; # of threads: 8) with 16GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" data sets, the Microarray tutorial is an invaluable starting tool. Test Dataset This RNA-Seq tutorial will utilize a public dataset that will be imported into Array Studio. This dataset was run on the Illumina Genome Analyzer platform, and each read is 76bp long. We have selected six SRR run .fastq paired-end files for use in this analysis. The full dataset is available on the SRA archive: SRR521461-521463 from GSM958729: link SRR521522-521524 from GSM958745: link There are two groups of samples in this dataset from the files we have selected (cell line K562 and MCF7). Within ArrayStudio, SRA archives can be downloaded directly by choosing in the menu bar Tools | Data | Download SRA Data (NGS) : Enter in all the SRR run IDs and specify a folder for the download as the \"Output Folder\". Be sure to enable Aspera to optimize efficient and accurate downloads: The whole dataset is ~35GB. For convenience, if you prefer to work with a smaller dataset for this training (i.e. to run a local project - see Chapter 2), we also provide a subset (5% of reads) of the dataset for download: link Note: This download also contains a design table, \"Design.txt\" that will be required and discussed for further analyses during this tutorial. Also, since this tutorial is based on the full dataset, users analyzing the smaller subset of data will obtain results that are different than what is shown in this tutorial. RNA-Seq Analysis Workflow In this tutorial, we will introduce the RNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for RNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, quantification at gene, transcript, exon and exon junction levels, and detection of fusions and mutations, as shown the scheme below:","title":"Introduction"},{"location":"tutorials/RNASeq/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/RNASeq/Introduction/#arraystudio","text":"Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The tutorial is based on a server-based NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-3770 Processor (# of cores: 4; # of threads: 8) with 16GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" data sets, the Microarray tutorial is an invaluable starting tool.","title":"ArrayStudio"},{"location":"tutorials/RNASeq/Introduction/#test-dataset","text":"This RNA-Seq tutorial will utilize a public dataset that will be imported into Array Studio. This dataset was run on the Illumina Genome Analyzer platform, and each read is 76bp long. We have selected six SRR run .fastq paired-end files for use in this analysis. The full dataset is available on the SRA archive: SRR521461-521463 from GSM958729: link SRR521522-521524 from GSM958745: link There are two groups of samples in this dataset from the files we have selected (cell line K562 and MCF7). Within ArrayStudio, SRA archives can be downloaded directly by choosing in the menu bar Tools | Data | Download SRA Data (NGS) : Enter in all the SRR run IDs and specify a folder for the download as the \"Output Folder\". Be sure to enable Aspera to optimize efficient and accurate downloads: The whole dataset is ~35GB. For convenience, if you prefer to work with a smaller dataset for this training (i.e. to run a local project - see Chapter 2), we also provide a subset (5% of reads) of the dataset for download: link Note: This download also contains a design table, \"Design.txt\" that will be required and discussed for further analyses during this tutorial. Also, since this tutorial is based on the full dataset, users analyzing the smaller subset of data will obtain results that are different than what is shown in this tutorial.","title":"Test Dataset"},{"location":"tutorials/RNASeq/Introduction/#rna-seq-analysis-workflow","text":"In this tutorial, we will introduce the RNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for RNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, quantification at gene, transcript, exon and exon junction levels, and detection of fusions and mutations, as shown the scheme below:","title":"RNA-Seq Analysis Workflow"},{"location":"tutorials/RNASeq/Others/","text":"Others Downstream Analyses On Quantification Values After aligning data, there are a number of downstream analyses that can be done on the data. For instance, the generated RPKM(or FPKM) dataset can be used, as a Microarray Data , for clustering (log2 transformation may be necessary). Counts can be used to look for changes between groups of samples through DESeq analysis. We also have a NGS | Inference | Normalize RNA-Seq Data module designed to further normalize RNA-Seq quantification data. Additionally, the user can look for differences in splice alignment using exon and exon junction report table. Both results are stored in table format. They can be converted to Microarray Data ( OmicData ) type via right-clicking on the table and choosing Convert to MicroArray Data : Choose count columns and click on Data to specify them as data columns. Keep others as Annotation . There are more visualization and analysis functions/options available for Microarray Data(OmicData ). Users are encouraged to visit the Microarray Tutorial to examine additional ways to represent their data, such as principal component analysis and heat map clustering. Build Reference and Gene Model Omicsoft provides standard genome reference (such as Human.B37.3, hg19, mm10, Mouse.B38) and gene model (RefGene, Ensembl and UCSC). Prebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis. If genome or gene model are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model. Both functions are located in NGS menu: More details can be found in the following two wiki articles: Build referencel library. link Build NGS general model. link Genome Browser Omicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). It can be used to visualize varied data type, including count/fpkm, exon/exon juncion data, fusion data and many other tracks which have genomic coordinate information. For example, you can right click a gene/trancript ID in RNA-Seq count data and view tracks in Genome Browser. Please read tutorial, Omicsoft Genome Browser , for more details.","title":"Others"},{"location":"tutorials/RNASeq/Others/#others","text":"","title":"Others"},{"location":"tutorials/RNASeq/Others/#downstream-analyses-on-quantification-values","text":"After aligning data, there are a number of downstream analyses that can be done on the data. For instance, the generated RPKM(or FPKM) dataset can be used, as a Microarray Data , for clustering (log2 transformation may be necessary). Counts can be used to look for changes between groups of samples through DESeq analysis. We also have a NGS | Inference | Normalize RNA-Seq Data module designed to further normalize RNA-Seq quantification data. Additionally, the user can look for differences in splice alignment using exon and exon junction report table. Both results are stored in table format. They can be converted to Microarray Data ( OmicData ) type via right-clicking on the table and choosing Convert to MicroArray Data : Choose count columns and click on Data to specify them as data columns. Keep others as Annotation . There are more visualization and analysis functions/options available for Microarray Data(OmicData ). Users are encouraged to visit the Microarray Tutorial to examine additional ways to represent their data, such as principal component analysis and heat map clustering.","title":"Downstream Analyses On Quantification Values"},{"location":"tutorials/RNASeq/Others/#build-reference-and-gene-model","text":"Omicsoft provides standard genome reference (such as Human.B37.3, hg19, mm10, Mouse.B38) and gene model (RefGene, Ensembl and UCSC). Prebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis. If genome or gene model are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model. Both functions are located in NGS menu: More details can be found in the following two wiki articles: Build referencel library. link Build NGS general model. link","title":"Build Reference and Gene Model"},{"location":"tutorials/RNASeq/Others/#genome-browser","text":"Omicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). It can be used to visualize varied data type, including count/fpkm, exon/exon juncion data, fusion data and many other tracks which have genomic coordinate information. For example, you can right click a gene/trancript ID in RNA-Seq count data and view tracks in Genome Browser. Please read tutorial, Omicsoft Genome Browser , for more details.","title":"Genome Browser"},{"location":"tutorials/RNASeq/QC_ofRawData_Files/","text":"QC of RawData Files If users want to run RNA-Seq analysis with more custom options, other than running RNA-Seq pipeline, users can run the whole process step by step. The first step will be raw data QC. Array Studio contains a few modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position. Click Add to find all 12 files for the six samples, check QC metric to run. Optionally, for a quicker analysis, the user can choose Preview mode to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave Quality encoding as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default. Click Send to Queue to begin the analysis. The raw data QC returns multiple raw data QC results/reports in Raw Data QC folder which are described in the following subsections. The corresponding output files can be found in the output directory specified as shown below. Please refer to link for the meaning of specific file extensions in Omicsoft. Basic Statistics The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. Base distribution QC results are located in the Solution Explorer | Raw Data QC folder with name BasicStats . Double click the table view to open if you do not see basic statistics table in the middle window: Base Distribution Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes this can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the Raw Data QC folder with name BaseDistribution . By default, the BaseDistribution ProfileView should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer . In the View Controller window of the right hand side of the screen, the Legend section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot. Notice that there are a total of 12 charts (scroll through them to look at each sample), one for each file that was QC d. Selecting points on the chart will also show additional details in the Details window, as shown below. One can also switch to line plot view by going to View Controller | Task | Customize | Change To Line Type . Read Quality QC The QC results include a PerSequenceQuality (view and table), a QualityBoxPlot (view and table) and a OverallQualityReport (view and table) in the Solution Explorer . Per Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file. In Quality BoxPlot , all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. This can be done easily by changing the view option in the tool strip as in the image below (arrow). From the QualityBoxPlot view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR521461. Scroll through each of the 12 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the Details Window below the plot. The Overall Quality Report summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score. K-Mer analysis The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of K-Mer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each K-Mer. There is no significant (all less than 1%) enrichment of K-Mer in this tutorial dataset.","title":"QC of RawData Files"},{"location":"tutorials/RNASeq/QC_ofRawData_Files/#qc-of-rawdata-files","text":"If users want to run RNA-Seq analysis with more custom options, other than running RNA-Seq pipeline, users can run the whole process step by step. The first step will be raw data QC. Array Studio contains a few modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position. Click Add to find all 12 files for the six samples, check QC metric to run. Optionally, for a quicker analysis, the user can choose Preview mode to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave Quality encoding as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default. Click Send to Queue to begin the analysis. The raw data QC returns multiple raw data QC results/reports in Raw Data QC folder which are described in the following subsections. The corresponding output files can be found in the output directory specified as shown below. Please refer to link for the meaning of specific file extensions in Omicsoft.","title":"QC of RawData Files"},{"location":"tutorials/RNASeq/QC_ofRawData_Files/#basic-statistics","text":"The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. Base distribution QC results are located in the Solution Explorer | Raw Data QC folder with name BasicStats . Double click the table view to open if you do not see basic statistics table in the middle window:","title":"Basic Statistics"},{"location":"tutorials/RNASeq/QC_ofRawData_Files/#base-distribution","text":"Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes this can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the Raw Data QC folder with name BaseDistribution . By default, the BaseDistribution ProfileView should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer . In the View Controller window of the right hand side of the screen, the Legend section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot. Notice that there are a total of 12 charts (scroll through them to look at each sample), one for each file that was QC d. Selecting points on the chart will also show additional details in the Details window, as shown below. One can also switch to line plot view by going to View Controller | Task | Customize | Change To Line Type .","title":"Base Distribution"},{"location":"tutorials/RNASeq/QC_ofRawData_Files/#read-quality-qc","text":"The QC results include a PerSequenceQuality (view and table), a QualityBoxPlot (view and table) and a OverallQualityReport (view and table) in the Solution Explorer . Per Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file. In Quality BoxPlot , all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. This can be done easily by changing the view option in the tool strip as in the image below (arrow). From the QualityBoxPlot view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR521461. Scroll through each of the 12 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the Details Window below the plot. The Overall Quality Report summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.","title":"Read Quality QC"},{"location":"tutorials/RNASeq/QC_ofRawData_Files/#k-mer-analysis","text":"The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of K-Mer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each K-Mer. There is no significant (all less than 1%) enrichment of K-Mer in this tutorial dataset.","title":"K-Mer analysis"},{"location":"tutorials/RNASeq/QC_of_AlignedData/","text":"QC of Aligned Data Alignment Report By default, an alignment report is generated anytime an alignment is done in Array Studio. If it is not already open, go to your Solution Explorer and double click on Report from the AlignmentReport table. This will show, for each pair (or single file if the user did not do a paired alignment), some statistics regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired). Note: Omicsoft is constantly updating algorithms and data to make sure that users have the most accurate results. You may have slightly different results when you compare your results with the tutorial. RNA-Seq Aligned QC This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. It also generates a ProfileView showing a chart for each metric. Here we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome-Mapped Reads . To run the RNA-Seq QC module, go to NGS | Aligned Data QC | RNA-Seq QC Metrics now. You will see the following menu item: Choose the NGS data and leave all other settings as their defaults and click Send to Queue to run the module. Source metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723. The analysis returns Table and Profile Views of QC metrics in the Aligned Data QC folder: In the Table view, as you scroll from top to bottom on the table, you will find the following sections: Alignment Metrics These metrics can be used to give an overall idea of the quality of the alignment for your samples. Coverage Metrics The coverage metrics give you an overall idea of the mean coverage of your experiment. For RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model). It also gives metrics on the number and percentage of genes with coverage. Finally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage. Duplication Metrics The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an RNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values. Feature Metrics Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data. Flag Metrics Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags. Insert Size Metrics Insert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values. Profile Metrics Profile Metrics provide important overall statistics based on the provided gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling. Source Metrics These metrics can be used to get a sense of the overall types of transcripts that are being aligned. For instance, in this experiment shown below, most reads are mapped to hg19 known genes and a small fraction is mapped to mitochondria. Strand Metrics The strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case. Sequencing (Positional) Trend This module is specifically designed to investigate the sequencing positional biases by summarizing the overall coverage along the transcripts. In practice, we find that the module is particularly useful to assess the quality of RNA-Seq data from low input protocols , where we observed severe positional bias due to library preparation steps. You can find the function in NGS | Aligned Data QC | RNA-Seq 5->3 Trend . Choose the NGS data and leave all other settings as their defaults and click Send to Queue to run the module. The analysis returns a QC table in the Aligned Data QC folder with name Trend53 : Double click the Profile View if it is not opened: By Default, all transcripts are classified into seven length groups (0-499bp, 500-999bp, 1000-1999bp, 2000-2999bp, 3000-3999bp, 4000-4999bp, 5000+bp). Coverage values in each length group are linearly scaled to have the maximum to be 1, so that they are comparable among different length groups. Bins 1-100 are from transcript 5' to 3'. The view above shows very minor positional bias toward 5' (little higher coverage on 5' end). Other Aligned Data QC RNA-Seq QC Metrics provides comprehensive assessment of the alignment data. We also provide metrics such as Flag Summary Statistics , Mapping Summary Statistics , Paired End Insert Size , RNA-Seq Mapping Profile as separate functions, where users can specify more analysis options.","title":"QC of AlignedData"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#qc-of-aligned-data","text":"","title":"QC of Aligned Data"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#alignment-report","text":"By default, an alignment report is generated anytime an alignment is done in Array Studio. If it is not already open, go to your Solution Explorer and double click on Report from the AlignmentReport table. This will show, for each pair (or single file if the user did not do a paired alignment), some statistics regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired). Note: Omicsoft is constantly updating algorithms and data to make sure that users have the most accurate results. You may have slightly different results when you compare your results with the tutorial.","title":"Alignment Report"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#rna-seq-aligned-qc","text":"This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. It also generates a ProfileView showing a chart for each metric. Here we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome-Mapped Reads . To run the RNA-Seq QC module, go to NGS | Aligned Data QC | RNA-Seq QC Metrics now. You will see the following menu item: Choose the NGS data and leave all other settings as their defaults and click Send to Queue to run the module. Source metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723. The analysis returns Table and Profile Views of QC metrics in the Aligned Data QC folder: In the Table view, as you scroll from top to bottom on the table, you will find the following sections:","title":"RNA-Seq Aligned QC"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#alignment-metrics","text":"These metrics can be used to give an overall idea of the quality of the alignment for your samples.","title":"Alignment Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#coverage-metrics","text":"The coverage metrics give you an overall idea of the mean coverage of your experiment. For RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model). It also gives metrics on the number and percentage of genes with coverage. Finally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage.","title":"Coverage Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#duplication-metrics","text":"The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an RNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.","title":"Duplication Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#feature-metrics","text":"Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data.","title":"Feature Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#flag-metrics","text":"Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.","title":"Flag Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#insert-size-metrics","text":"Insert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values.","title":"Insert Size Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#profile-metrics","text":"Profile Metrics provide important overall statistics based on the provided gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling.","title":"Profile Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#source-metrics","text":"These metrics can be used to get a sense of the overall types of transcripts that are being aligned. For instance, in this experiment shown below, most reads are mapped to hg19 known genes and a small fraction is mapped to mitochondria.","title":"Source Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#strand-metrics","text":"The strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case.","title":"Strand Metrics"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#sequencing-positional-trend","text":"This module is specifically designed to investigate the sequencing positional biases by summarizing the overall coverage along the transcripts. In practice, we find that the module is particularly useful to assess the quality of RNA-Seq data from low input protocols , where we observed severe positional bias due to library preparation steps. You can find the function in NGS | Aligned Data QC | RNA-Seq 5->3 Trend . Choose the NGS data and leave all other settings as their defaults and click Send to Queue to run the module. The analysis returns a QC table in the Aligned Data QC folder with name Trend53 : Double click the Profile View if it is not opened: By Default, all transcripts are classified into seven length groups (0-499bp, 500-999bp, 1000-1999bp, 2000-2999bp, 3000-3999bp, 4000-4999bp, 5000+bp). Coverage values in each length group are linearly scaled to have the maximum to be 1, so that they are comparable among different length groups. Bins 1-100 are from transcript 5' to 3'. The view above shows very minor positional bias toward 5' (little higher coverage on 5' end).","title":"Sequencing (Positional) Trend"},{"location":"tutorials/RNASeq/QC_of_AlignedData/#other-aligned-data-qc","text":"RNA-Seq QC Metrics provides comprehensive assessment of the alignment data. We also provide metrics such as Flag Summary Statistics , Mapping Summary Statistics , Paired End Insert Size , RNA-Seq Mapping Profile as separate functions, where users can specify more analysis options.","title":"Other Aligned Data QC"},{"location":"tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/","text":"RNA-Seq Fusion Gene Detection In RNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events. In paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion. Three fusion detection functions can be found in NGS | Fusion menu: Report Paired-End Fusion Genes Report Fusion Genes (Paired End) module will detect fusion genes from inter-transcript paired-end reads based on RNA-Seq alignment ( NgsData ). Choose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check Output fusion reads option and specify the directory path, supporting fusion reads will be saved as BAM files which can be used for visual checking in the genome browser. Leave all other settings as their defaults and click Submit to run the module. The output is a paired fusion report table listed under Table in Solution Explorer : In the report table, there are three columns for each sample. The first column shows the number of Unique mapping positions from reads in Gene1 , the second column shows the number of Unique mapping positions from reads in Gene2 , while the third column shows the total Count of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*6=18 columns of data, as well as additional annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs. The information in Filter column in the report table comes from a fusion black list. For more information about the blacklist, please read the following wiki article: link View Controller can be used to set row filters to list only genes of interest. Simply navigate to the View Controller , and under the Row tab, input genes of interest into the Gene1 and Gene2 filters. Below are rows for identified known BCR-ABL1 and NUP214-XKR3 fusion events in K562 samples: When fusion ID is right-clicked, there will be an option to open a new Genome Browser to view selected fusion. In the genome browser view, this feature can be customized to look at individual samples, or to combine tracks within a group. For this example, all samples are examined individually. Use the zoom features (arrows below) or the click wheel of the mouse to zoom in and out of regions of interest. In the example below, notice that the three samples (SRR521461-521463) have a different read coverage of BCR (left) and ABL1 (right) at the 3' and 5' ends, respectively. Report Fusion Genes (Paired End) module reports fusion events by grouping gene pairs by rows in one table. It provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples. Map Fusion Reads Map Fusion Reads module will detect fusion genes from fusion junction-spanning reads which can characterize fusion genes at base pair resolution. It is a preferred approach to detect fusion events, using OmicSoft s fusion alignment method ( FusionMap, Ge,H, et al. Bioinformatics (2011): 1922-1928 ). The fusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM). If user is using the original FASTQ files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click Reads are paired option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample. If user is using BAM files, potential fusion reads (such as reads spanning on two nearby genes) in alignment and unmapped reads will be extracted for fusion detection. It is a preferred approach which saves running time of the filtering step when starting with FASTQ data. Minimal cut size is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners, see wiki page: link The default Cut size is to use value min(25, max(18, readLength/3). For this tutorial dataset, read length is 76, so we use the default. There are more fusion alignment options in the Advanced tab. Leave all settings as their defaults and click Submit to run the module. The output is a fusion report table listed under Table in Solution Explorer : In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion seed reads, while the third column shows number of fusion rescued reads. There are 3*6=18 columns of data, and 21 annotation columns for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predicted fusion gene and open reading frame status, and a \"Filter\" column containing black list information. The annotations characterize fusion events at base pair resolution. We also create rollup columns, such as SplicePatternClass (Canonical or NonCanonical), FrameShiftClass (Frame shift or inFrame), Distance (displayed as \"gap size\" between two breakpoints or \"-1\" if located on two different chromosomes) and OnExonBoundary (Both, Single or None), for users to further filter false positives. Below are two rows for known BCR-ABL1 and NUP214-XKR3 fusion events identified in K562 samples: Like paired end fusions, users can also view fusions detected by \"Map Fusion Reads\" in genome browser by right-clicking the \"Fusion ID\". Map Fusion Reads module reports fusion events by grouping fusion junctions by rows in one table. It provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples. Combined Fusion Analysis Combined Fusion Analysis will run fusion junction spanning + inter-transcript fusion read pairs detection at the same time. Combined fusion analysis can only be run on Paired end NgsData (Add or generate BAM files in ArrayStudio). It detects fusion junction spanning reads from unmapped reads in BAM files and detects inter-transcript fusion read pairs from singletons from BAM alignment entries. It will return a report showing potential fusion genes and counts for each fusion junction with columns showing the number of supporting junction spanning reads and inter-transcript fusion read pairs. For more information about fusion gene detection, please read our \"best practice\" article in wiki: link","title":"RNA-Seq Fusion Gene Detection"},{"location":"tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#rna-seq-fusion-gene-detection","text":"In RNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events. In paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion. Three fusion detection functions can be found in NGS | Fusion menu:","title":"RNA-Seq Fusion Gene Detection"},{"location":"tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#report-paired-end-fusion-genes","text":"Report Fusion Genes (Paired End) module will detect fusion genes from inter-transcript paired-end reads based on RNA-Seq alignment ( NgsData ). Choose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check Output fusion reads option and specify the directory path, supporting fusion reads will be saved as BAM files which can be used for visual checking in the genome browser. Leave all other settings as their defaults and click Submit to run the module. The output is a paired fusion report table listed under Table in Solution Explorer : In the report table, there are three columns for each sample. The first column shows the number of Unique mapping positions from reads in Gene1 , the second column shows the number of Unique mapping positions from reads in Gene2 , while the third column shows the total Count of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*6=18 columns of data, as well as additional annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs. The information in Filter column in the report table comes from a fusion black list. For more information about the blacklist, please read the following wiki article: link View Controller can be used to set row filters to list only genes of interest. Simply navigate to the View Controller , and under the Row tab, input genes of interest into the Gene1 and Gene2 filters. Below are rows for identified known BCR-ABL1 and NUP214-XKR3 fusion events in K562 samples: When fusion ID is right-clicked, there will be an option to open a new Genome Browser to view selected fusion. In the genome browser view, this feature can be customized to look at individual samples, or to combine tracks within a group. For this example, all samples are examined individually. Use the zoom features (arrows below) or the click wheel of the mouse to zoom in and out of regions of interest. In the example below, notice that the three samples (SRR521461-521463) have a different read coverage of BCR (left) and ABL1 (right) at the 3' and 5' ends, respectively. Report Fusion Genes (Paired End) module reports fusion events by grouping gene pairs by rows in one table. It provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples.","title":"Report Paired-End Fusion Genes"},{"location":"tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#map-fusion-reads","text":"Map Fusion Reads module will detect fusion genes from fusion junction-spanning reads which can characterize fusion genes at base pair resolution. It is a preferred approach to detect fusion events, using OmicSoft s fusion alignment method ( FusionMap, Ge,H, et al. Bioinformatics (2011): 1922-1928 ). The fusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM). If user is using the original FASTQ files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click Reads are paired option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample. If user is using BAM files, potential fusion reads (such as reads spanning on two nearby genes) in alignment and unmapped reads will be extracted for fusion detection. It is a preferred approach which saves running time of the filtering step when starting with FASTQ data. Minimal cut size is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners, see wiki page: link The default Cut size is to use value min(25, max(18, readLength/3). For this tutorial dataset, read length is 76, so we use the default. There are more fusion alignment options in the Advanced tab. Leave all settings as their defaults and click Submit to run the module. The output is a fusion report table listed under Table in Solution Explorer : In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion seed reads, while the third column shows number of fusion rescued reads. There are 3*6=18 columns of data, and 21 annotation columns for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predicted fusion gene and open reading frame status, and a \"Filter\" column containing black list information. The annotations characterize fusion events at base pair resolution. We also create rollup columns, such as SplicePatternClass (Canonical or NonCanonical), FrameShiftClass (Frame shift or inFrame), Distance (displayed as \"gap size\" between two breakpoints or \"-1\" if located on two different chromosomes) and OnExonBoundary (Both, Single or None), for users to further filter false positives. Below are two rows for known BCR-ABL1 and NUP214-XKR3 fusion events identified in K562 samples: Like paired end fusions, users can also view fusions detected by \"Map Fusion Reads\" in genome browser by right-clicking the \"Fusion ID\". Map Fusion Reads module reports fusion events by grouping fusion junctions by rows in one table. It provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples.","title":"Map Fusion Reads"},{"location":"tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#combined-fusion-analysis","text":"Combined Fusion Analysis will run fusion junction spanning + inter-transcript fusion read pairs detection at the same time. Combined fusion analysis can only be run on Paired end NgsData (Add or generate BAM files in ArrayStudio). It detects fusion junction spanning reads from unmapped reads in BAM files and detects inter-transcript fusion read pairs from singletons from BAM alignment entries. It will return a report showing potential fusion genes and counts for each fusion junction with columns showing the number of supporting junction spanning reads and inter-transcript fusion read pairs. For more information about fusion gene detection, please read our \"best practice\" article in wiki: link","title":"Combined Fusion Analysis"},{"location":"tutorials/RNASeq/RNA-Seq_Mutation_Detection/","text":"RNA-Seq Mutation Detection Mutation data can be generated for the RNA-Seq data. This allows the user to compare frequencies of mutation, for individual sites, between groups of samples. All mutation functions can be found in NGS | Variation . In this tutorial, we will only cover Summarize Variant Data (Omicsoft) and Annotate Variant Table Report functions and Annotate Variant Files (VCF/BED/GTT/RS_ID) . User can find the documentation for other functions by click the Help button in each function menu. Summarize Variant Data Variants are reported based on the pileup data from alignment data ( NgsData ). Choose the NGS data. In the reference section, all references are selected by default. User can select a list of regions to summarize mutations. Selections can be on \"Gene list\" (a list of gene symbols from project lists), \"Customized regions\" (load a bed file), or a \"Filtered by region\" (i.e. chr9:133710831-133763062, or more regions separated by |). We will leave these selections as default in this tutorial. Specify the base and mapping quality cutoff and choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20, # reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%. Note You should lower the coverage cutoff if you are using the subset (5%) tutorial dataset. In the Advanced tab, users can specify whether to adjust quality based on neighbour base pairs at each position, can check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the mutation annotation step). Maximal frequency specifies the mutation read frequency needed in at least one sample to keep a mutation (i.e if none of the samples has a frequency over 0.10 at one position, then that mutation will not be kept). In addition to summarized reports, it is also helpful to choose Generate merged VCF report for all samples and specify an output folder. That will generate a streamed VCF report for all samples in the output folder. Leave all settings as their defaults and click Submit to run the module. The output is a Mutation2Snp report table listed under Table in solution explorer: In the mutation report table, there are four columns for each sample: Minor allele MutationFrequency . Coverage at this genomic location. Percentage of mutation detected on the plus strand (MutationReadOnPlus/TotalMutationRead). Ideally, mutation should be detected evenly in both plus and minus strand. A percentage near 0 or 100 may imply a strand bias, which introduces false positive mutation calls. Genotype. If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with annotation for each site, including chromosome, position, reference nucleotide and mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dot in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff. Annotate Variant The variants are then annotated with gene coding information, known SNPs and functional prediction databases. Open NGS | Variation | Annotate Variant Table Report module; choose the mutation2snp report in Data , Omicsoft gene model in Gene model . Leave all settings as their defaults in this tab. In the Annotation Sources tab, user can specify more annotation sources, for example 1000Genome and ClinVar as shown below. User also has the option to write the annotated mutation result directly to a text file. Users also have the option to build custom mutation annotators in the Additional Sources tab, using NGS | Build - Build Mutation Annotator . Leave all the other settings as their defaults and click Submit to run the module. The output is a report table listed under Table in solution explorer: The number of rows in annotated report table is more than that in mutation report table, because the annotation was done on each transcript. In the Advanced tab, there is one option: Annotate by the longest transcript only . If this option is checked, only the longest transcript of each gene will be used to perform the annotation. Besides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in the mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the Annotation Sources prior to running the analysis. Using the View Controller , choose filters to focus on items of interest. For example, in this module, we have filtered the results for the gene SERPINB: Annotate Variant Files (VCF/BED/GTT/RS_ID) Here, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the Annotation Source Tab, users can choose annotators to further annotate VCF file. In the Annotation Source tab, users can choose from the following sources: |new_annotators_png| 1000GenomesSimple - Output allele frequency, population allele frequency in 1000 Genomes data CADD - Combined Annotation Dependent Depletion (CADD); scoring the deleteriousness of variants in the human genome. ClinVar - Output health related information based on ClinVar database Conservation - Output conservation scores including GERP++, PhyloP, PhastCons, etc ESP6500 - Output allele frequency in ESP6500 (NHLBI Exome Sequencing Project) data ExAC - Output allele frequency, population allele frequency in ExAC (The Exome Aggregation Consortium) data FunctionalMutation - Output functional mutation information based on dbNSFP (database for nonsynonymous SNPs' functional predictions) GRASP2 - Genome-Wide Repository of Associations between SNPs and Phenotypes GTExEqtl - Output eQTL information based on GTEx project GWASCatalog - Genome-wide Association data from NHGRI-EBI GWAVA - Genome Wide Annotation of VAriants Haploreg - Output annotation on non-coding variants from HaploReg Interpro - Output protein domain based on InterPro database RegulomeDB - Output annotations for SNPs with known and predicted regulatory elements based on RegulomeDB UK10K - Frequency data from the UK10K project Wellderly - applies frequency data from STSI to identify variants present (and absent) in individuals who have reached 80 years of age without chronic disease HGMD - gene lesions in the Human Gene Mutation Database In addition, it is now possible to use alternate annotators, including Cancer-, Gene-, and Region-based versions. After submitting, an annotation file for vcf will be generated. Please note that this is a stream server file, instead of a local file to save searching and storing memory usage.","title":"RNA-Seq Mutation Detection"},{"location":"tutorials/RNASeq/RNA-Seq_Mutation_Detection/#rna-seq-mutation-detection","text":"Mutation data can be generated for the RNA-Seq data. This allows the user to compare frequencies of mutation, for individual sites, between groups of samples. All mutation functions can be found in NGS | Variation . In this tutorial, we will only cover Summarize Variant Data (Omicsoft) and Annotate Variant Table Report functions and Annotate Variant Files (VCF/BED/GTT/RS_ID) . User can find the documentation for other functions by click the Help button in each function menu.","title":"RNA-Seq Mutation Detection"},{"location":"tutorials/RNASeq/RNA-Seq_Mutation_Detection/#summarize-variant-data","text":"Variants are reported based on the pileup data from alignment data ( NgsData ). Choose the NGS data. In the reference section, all references are selected by default. User can select a list of regions to summarize mutations. Selections can be on \"Gene list\" (a list of gene symbols from project lists), \"Customized regions\" (load a bed file), or a \"Filtered by region\" (i.e. chr9:133710831-133763062, or more regions separated by |). We will leave these selections as default in this tutorial. Specify the base and mapping quality cutoff and choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20, # reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%. Note You should lower the coverage cutoff if you are using the subset (5%) tutorial dataset. In the Advanced tab, users can specify whether to adjust quality based on neighbour base pairs at each position, can check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the mutation annotation step). Maximal frequency specifies the mutation read frequency needed in at least one sample to keep a mutation (i.e if none of the samples has a frequency over 0.10 at one position, then that mutation will not be kept). In addition to summarized reports, it is also helpful to choose Generate merged VCF report for all samples and specify an output folder. That will generate a streamed VCF report for all samples in the output folder. Leave all settings as their defaults and click Submit to run the module. The output is a Mutation2Snp report table listed under Table in solution explorer: In the mutation report table, there are four columns for each sample: Minor allele MutationFrequency . Coverage at this genomic location. Percentage of mutation detected on the plus strand (MutationReadOnPlus/TotalMutationRead). Ideally, mutation should be detected evenly in both plus and minus strand. A percentage near 0 or 100 may imply a strand bias, which introduces false positive mutation calls. Genotype. If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with annotation for each site, including chromosome, position, reference nucleotide and mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dot in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff.","title":"Summarize Variant Data"},{"location":"tutorials/RNASeq/RNA-Seq_Mutation_Detection/#annotate-variant","text":"The variants are then annotated with gene coding information, known SNPs and functional prediction databases. Open NGS | Variation | Annotate Variant Table Report module; choose the mutation2snp report in Data , Omicsoft gene model in Gene model . Leave all settings as their defaults in this tab. In the Annotation Sources tab, user can specify more annotation sources, for example 1000Genome and ClinVar as shown below. User also has the option to write the annotated mutation result directly to a text file. Users also have the option to build custom mutation annotators in the Additional Sources tab, using NGS | Build - Build Mutation Annotator . Leave all the other settings as their defaults and click Submit to run the module. The output is a report table listed under Table in solution explorer: The number of rows in annotated report table is more than that in mutation report table, because the annotation was done on each transcript. In the Advanced tab, there is one option: Annotate by the longest transcript only . If this option is checked, only the longest transcript of each gene will be used to perform the annotation. Besides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in the mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the Annotation Sources prior to running the analysis. Using the View Controller , choose filters to focus on items of interest. For example, in this module, we have filtered the results for the gene SERPINB:","title":"Annotate Variant"},{"location":"tutorials/RNASeq/RNA-Seq_Mutation_Detection/#annotate-variant-files-vcfbedgttrs_id","text":"Here, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the Annotation Source Tab, users can choose annotators to further annotate VCF file. In the Annotation Source tab, users can choose from the following sources: |new_annotators_png| 1000GenomesSimple - Output allele frequency, population allele frequency in 1000 Genomes data CADD - Combined Annotation Dependent Depletion (CADD); scoring the deleteriousness of variants in the human genome. ClinVar - Output health related information based on ClinVar database Conservation - Output conservation scores including GERP++, PhyloP, PhastCons, etc ESP6500 - Output allele frequency in ESP6500 (NHLBI Exome Sequencing Project) data ExAC - Output allele frequency, population allele frequency in ExAC (The Exome Aggregation Consortium) data FunctionalMutation - Output functional mutation information based on dbNSFP (database for nonsynonymous SNPs' functional predictions) GRASP2 - Genome-Wide Repository of Associations between SNPs and Phenotypes GTExEqtl - Output eQTL information based on GTEx project GWASCatalog - Genome-wide Association data from NHGRI-EBI GWAVA - Genome Wide Annotation of VAriants Haploreg - Output annotation on non-coding variants from HaploReg Interpro - Output protein domain based on InterPro database RegulomeDB - Output annotations for SNPs with known and predicted regulatory elements based on RegulomeDB UK10K - Frequency data from the UK10K project Wellderly - applies frequency data from STSI to identify variants present (and absent) in individuals who have reached 80 years of age without chronic disease HGMD - gene lesions in the Human Gene Mutation Database In addition, it is now possible to use alternate annotators, including Cancer-, Gene-, and Region-based versions. After submitting, an annotation file for vcf will be generated. Please note that this is a stream server file, instead of a local file to save searching and storing memory usage.","title":"Annotate Variant Files (VCF/BED/GTT/RS_ID)"},{"location":"tutorials/RNASeq/RNA-Seq_Quantification/","text":"RNA-Seq Quantification ArrayStudio provides a number of modules and options for RNA-Seq quantification at gene, transcript, exon and exon junction levels. Report Gene/Transcript Counts Given the alignment, one can summarize the gene expression at both gene and transcript levels, using the Quantification module in NGS | Quantification | Report Gene/Transcript Counts . Both RPKM and Count tables can be generated. In this tutorial we summarize the gene level expression values with both the RPKM and Counts in one step. User can also choose to quantify at transcript level by selecting it in the Summary Level option. By default, option Count fragments instead of reads is selected to use paired reads only (thus FPKM is calculated). Options to count reads based on strands are designed for datasets from strand-specific protocols. In this tutorial, the six samples are not strand-specific as shown in the strand metrics from aligned QC table. Both stranded counting options are checked, and ArrayStudio will quantify expression values based on all mapping data. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. The output includes two Omic datasets, Counts and FPKM. Both Omic datasets have gene and transcript annotation attached which were pre-built when building gene model. The design table attached to Ngsdata previously is automatically attached to these new data. They are treated as OmicData Data and all microarray data analysis functions, such as OmicData | Pattern | Hierarchical Clustering , OmicData | QC | Principal Component Analysis , OmicData | Inference | General Linear Model and other modules can be used for downstream data analyses. Please read the Microarray tutorial to get detailed analysis information. Counts can be used to look for changes between groups of samples through DESeq analysis in NGS | Inference | DESeq (V2) One Way Test or DESeq (V2) General Linear Model . Below shows an example of DESeq One Way Test. DESeq One Way Test offers a statistical method to test whether a gene/transcript is differentially expressed between two or more groups of samples. Choose the newly generated Count table from the Quantification step and specify the analyses you would like performed. Here, we use the default parameters of DESeq, in which we compare the two tissue types (Bone marrow and breast, as specified in our design table). Output options can be customized to include separate lists for enrichment in one sample versus another, and to obtain additional analyses. This step can also be performed locally or on the server (check box if this is preferred). Click Submit to perform the analysis. The results include an Inference Report table with estimates and pvalues, similar to ANOVA test results, and a Dispersion table in \"Summary\" folder. For the volcano plot, users can specify in View Controller which columns to show using Specify Columns , and also add cutoff lines by Specify Cutoff Lines . The volcano plot view is fully customizable and includes the ability to change symbol size/color, add labels, change titles, and export into local programs (as an image or powerpoint slide). Please refer to the microarray tutorial documentation to see some of these features. Report Exon/Exon-Junction Counts Exon/exon junction level counting can be used for detection of alternative splicing. There are two modules for exon level counting: Report known Exons/Exon Junctions Summarize Exon/Exon Junction Count module will do quantification based on known gene models, i.e. exon junctions already annotated by gene model. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. By default, Perform RPKM normalization option is checked. Normalized counts in RPKM fashion are reported for known exons and exon junctions based on the specified gene model. In the output report, each row is one known exon or exon junction annotated by genome coordinates, gene and transcript name. Report All Exon Junctions Report Exon Junctions module quantifies all exon junctions detected by the alignment step. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. In the output report, each row is one exon junction annotated by genome coordinates, intron size, and gene/transcript name. The types of exon junctions include known (annotated by the gene model), novel (not contained in the gene model, or one side of the exon junction lies on a known exon boundary, while the other side of the exon junction is unknown).","title":"RNA-Seq Quantification"},{"location":"tutorials/RNASeq/RNA-Seq_Quantification/#rna-seq-quantification","text":"ArrayStudio provides a number of modules and options for RNA-Seq quantification at gene, transcript, exon and exon junction levels.","title":"RNA-Seq Quantification"},{"location":"tutorials/RNASeq/RNA-Seq_Quantification/#report-genetranscript-counts","text":"Given the alignment, one can summarize the gene expression at both gene and transcript levels, using the Quantification module in NGS | Quantification | Report Gene/Transcript Counts . Both RPKM and Count tables can be generated. In this tutorial we summarize the gene level expression values with both the RPKM and Counts in one step. User can also choose to quantify at transcript level by selecting it in the Summary Level option. By default, option Count fragments instead of reads is selected to use paired reads only (thus FPKM is calculated). Options to count reads based on strands are designed for datasets from strand-specific protocols. In this tutorial, the six samples are not strand-specific as shown in the strand metrics from aligned QC table. Both stranded counting options are checked, and ArrayStudio will quantify expression values based on all mapping data. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. The output includes two Omic datasets, Counts and FPKM. Both Omic datasets have gene and transcript annotation attached which were pre-built when building gene model. The design table attached to Ngsdata previously is automatically attached to these new data. They are treated as OmicData Data and all microarray data analysis functions, such as OmicData | Pattern | Hierarchical Clustering , OmicData | QC | Principal Component Analysis , OmicData | Inference | General Linear Model and other modules can be used for downstream data analyses. Please read the Microarray tutorial to get detailed analysis information. Counts can be used to look for changes between groups of samples through DESeq analysis in NGS | Inference | DESeq (V2) One Way Test or DESeq (V2) General Linear Model . Below shows an example of DESeq One Way Test. DESeq One Way Test offers a statistical method to test whether a gene/transcript is differentially expressed between two or more groups of samples. Choose the newly generated Count table from the Quantification step and specify the analyses you would like performed. Here, we use the default parameters of DESeq, in which we compare the two tissue types (Bone marrow and breast, as specified in our design table). Output options can be customized to include separate lists for enrichment in one sample versus another, and to obtain additional analyses. This step can also be performed locally or on the server (check box if this is preferred). Click Submit to perform the analysis. The results include an Inference Report table with estimates and pvalues, similar to ANOVA test results, and a Dispersion table in \"Summary\" folder. For the volcano plot, users can specify in View Controller which columns to show using Specify Columns , and also add cutoff lines by Specify Cutoff Lines . The volcano plot view is fully customizable and includes the ability to change symbol size/color, add labels, change titles, and export into local programs (as an image or powerpoint slide). Please refer to the microarray tutorial documentation to see some of these features.","title":"Report Gene/Transcript Counts"},{"location":"tutorials/RNASeq/RNA-Seq_Quantification/#report-exonexon-junction-counts","text":"Exon/exon junction level counting can be used for detection of alternative splicing. There are two modules for exon level counting:","title":"Report Exon/Exon-Junction Counts"},{"location":"tutorials/RNASeq/RNA-Seq_Quantification/#report-known-exonsexon-junctions","text":"Summarize Exon/Exon Junction Count module will do quantification based on known gene models, i.e. exon junctions already annotated by gene model. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. By default, Perform RPKM normalization option is checked. Normalized counts in RPKM fashion are reported for known exons and exon junctions based on the specified gene model. In the output report, each row is one known exon or exon junction annotated by genome coordinates, gene and transcript name.","title":"Report known Exons/Exon Junctions"},{"location":"tutorials/RNASeq/RNA-Seq_Quantification/#report-all-exon-junctions","text":"Report Exon Junctions module quantifies all exon junctions detected by the alignment step. Choose the NGS data and leave all other settings as their defaults and click Submit to run the module. In the output report, each row is one exon junction annotated by genome coordinates, intron size, and gene/transcript name. The types of exon junctions include known (annotated by the gene model), novel (not contained in the gene model, or one side of the exon junction lies on a known exon boundary, while the other side of the exon junction is unknown).","title":"Report All Exon Junctions"},{"location":"tutorials/RNASeq/Save___Close_Project/","text":"Save & Close Project Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in the form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don't hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save/Close Project"},{"location":"tutorials/RNASeq/Save___Close_Project/#save-close-project","text":"Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in the form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don't hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save &amp; Close Project"},{"location":"tutorials/RTPCR/","text":"RT-PCR Data Analysis Tutorial .. toctree:: :maxdepth: 2 Introduction Manage_RT-PCR_Raw_Data Import_RT-PCR_Wizard Downstream_Analysis_of_RT-PCR_data","title":"Home"},{"location":"tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/","text":"Downstream Analysis of RT-PCR data Based on this RT-PCR data, downstream analysis can be applied in the same way as Microarray data. Here we will introduce QC wizard, principal component analysis, general linear model, and hierarchical clustering. For more details on other downstream statistical methods, please refer to Microarray tutorial. To better annotate the samples to do the downstream analysis, please first follow the below steps to parse the ID in design table to Treatment and Sample. First choose Parse Column in Analysis | Table , then select the design table As treatment and sample are combined with \"-\" sign. We use \"-\" to split the columns Then design table will add two more columns. Double click the column name of the last column, then change it to \"Sample\" QC wizard QC wizard is a quick and easy way to run multiple QC commands simultaneously. Available options are Pairwise correlation, Correlation based QC, Principal component analysis and Kernel density. From the Workflow tab, select QC Wizard. This menu item can also be found under Omicdata | QC | QCWizard Check \"Kernel density\" and keep all other options as default then click \"Submit\". The results will show in Table and Summary folder. A Density plot will show in the window. It shows the RT-PCR value distribution for each sample. Correlation based QC calculates Median Absolute Deviation (MAD) scores for each group. By default, the cutoff for MAD score is -5. From the scatter plot, we see that there are two blue (FAIL) points that can be considered outliers. Users have the option to remove these outlier points and under View Controller , select \"Exclude Selection\" under the Task tab. To keep the analysis simple for this tutorial we will leave these potential outliers alone, but users are encouraged to explore the results of selecting the \"Exclude Selectin\" option after the completion of this tutorial to see how it affects these analyses. Note When user does choose \"Exclude Selection\" option in this module, QC Analysis will be repeated on remaining samples, which can lead to additional samples failing MADScore filter. PcaScores will show a 2-D plot on the first and the second principal components. A Hotelling T2 ellipse with alpha level of 0.05 is also shown. From this plot, there is no outlier sample. There is also a summary table that shows the average correlation in each group. As group was not selected in QC wizard, the correlation will be based on all samples. Note : As outliers are excluded based on failing MADScore or PCA analyses, this correlation value will creep closer to 1 (100%) . If user-defined options instead of default options are needed for QC analysis, users can perform each QC step, rather than QC wizard. Principal Component Analysis As mentioned previously, QC wizard is used to perform QC analysis with default parameters. Here principal component analysis has more options to change. For example, we want a 3-D plot for PCA. Then a 3-D plot for the first three principal components will be shown. Users can drag the plot and rotate the plot to get a better view. Users can change the symbol properties to make the points color by Treatment, and make it show label ID when selected. The plot shows samples do not cluster with Treatment in this data. But in some other cases the data will be clustered in some specific groups. If there are obvious outlier samples, users can select the samples and choose \"Exclude Selection\". From the PCA plot, there is no outlier sample, so keep all of them. General Linear Model General linear model is an important command to run statistical analysis on data. It allows the user to model the data on a variable-by-variable vasis. The user can specify a fixed, mixed or random model. Estimates, fold change, p-value, significant lists can be generated using this model. Using general linear model can generate more complicated statistical models than one-way ANOVA or two-way ANOVA. In the next example, a general linear model on Treatment with Sample as random factor will be generated. The purpose is to find out the differentially expressed genes in treatment samples compared with DMSO control samples. Go to OmicData | Inference | General Linear Model or in the Workflow tab, select Statistical inference | General linear model : The first step in this process will be to \"Specify Model\": Choose Treatment and Sample on the left (these two columns are in categorical types, so \"Class\" is checked). Then Click \"Add\" to add in the model. Check \"Random\" before Sample as we want sample as a random factor. Then click \"OK\" to finish setting up the model. Now the model has been set. The next step is to \"Specify Test\" (T-test and/or F-test): We want to compare each treatment with DMSO. So check \"For each\" (Treatment), then compare to \"DMSO\". Then we check all the options to generate estimates, fold changes, P-values, and significant lists. Then click \"Add\" For this example, F-test is not needed so we leave it as blank. In future studies, users can use \"FTest (ANOVA)\" tab to specify F-test options. Then click \"OK\". Now the model has been generated. The next step is to change the options for the model, for example changing the cutoff of alpha-value or generating LSMean data. For this example, we just leave it as it is. Then click \"Submit\" to run the model. The results include a report and volcano plots in \"Inference\" folder, and significant gene lists in \"List\" folder of the Solution Explorer . We can change the number of plots shown in one window, and also unify the scale. When a point is selected in one plot, the corresponding point will also highlight in other plots. Details about the selected point will be in \"Detail\" window. Additional view options are available in the View Controller on the right side of the user interface. For example, users can specify the X and Y-axes columns by \"Specify Columns\". Users can also specify p-value and estimate/fold change cutoff lines to better visualize and select the significant genes. Hierarchical Clustering The Hierarchical Clustering command performs hierarchical clustering on data object observations and/or variables. For example, we would like to see how the significant genes in the general linear model step (expressed differently in other treatments compared to DMSO) and how the samples cluster. Then in the Hierarchical clustering, we choose the significant gene list and all samples, and compute both observation and variable trees. Users can access this option by choosing in the Workflow tab Pattern Recognition | Hierarchical Clustering or the menu option OmicData | Pattern | Hierarchical Clustering : We choose the significant gene lists by selecting the \"GLM LinearModel Sig10\" under the \"Customized\" Variables option. Choose the \"Compute variable tree\" and assign an Output name that will allow you recognize this customized clustering report: After clicking \"Submit\", the dendrogram will appear in the main view. Users can change the clustering normalization method by \"Specify Normalization\" in the View Controller | Task | Data . There are additional customization options under the Task tab in the View Controller window. For example, we see that X-axis labels are not showing in full. We can rotate the labels for better visualization by choosing View Controller | Task | Properties | Change Chart Properties : We can also add color bars for observations and variables to better see the clustering feature by selecting View Controller | Task | Customize | Change X-axis or Change Y-axis ColorBars : Our view has chanegd to reflect these changes. The Color Legend is in the top view of View Controller . Colors can be changed by simply right-clicking within this legend. From the dendrogram, we can see how the observations and variables cluster. However, there is not a specific pattern in this example dataset. In some other cases, you may find the samples cluster by specific factors such as gender, age, treatment, etc. Users also have the option of choosing specific branches within the dendrogram to see which genes or samples cluster. Simply click on the dendrogram in the dendrogram view and only those selected branches will appear in the heat map. Additional annotations (i.e. color bars) can also be added as described above. | Congratulations! You are done with the analysis. Feel free to browse other options in the workflow to examine other features of this module. As mentioned above, users are encouraged to examine the consequences of filtering out samples (i.e. ones that did not pass MADScore filters) on subsequent steps (QC, GLM, and hierarchical clustering). Click \"Save\" to save this project. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to RT-PCR preprocessing and analysis. Feel free to try different options along the Import RT-PCR Wizard to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) for sales-related questions.","title":"Downstream Analysis of RT-PCR data"},{"location":"tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#downstream-analysis-of-rt-pcr-data","text":"Based on this RT-PCR data, downstream analysis can be applied in the same way as Microarray data. Here we will introduce QC wizard, principal component analysis, general linear model, and hierarchical clustering. For more details on other downstream statistical methods, please refer to Microarray tutorial. To better annotate the samples to do the downstream analysis, please first follow the below steps to parse the ID in design table to Treatment and Sample. First choose Parse Column in Analysis | Table , then select the design table As treatment and sample are combined with \"-\" sign. We use \"-\" to split the columns Then design table will add two more columns. Double click the column name of the last column, then change it to \"Sample\"","title":"Downstream Analysis of RT-PCR data"},{"location":"tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#qc-wizard","text":"QC wizard is a quick and easy way to run multiple QC commands simultaneously. Available options are Pairwise correlation, Correlation based QC, Principal component analysis and Kernel density. From the Workflow tab, select QC Wizard. This menu item can also be found under Omicdata | QC | QCWizard Check \"Kernel density\" and keep all other options as default then click \"Submit\". The results will show in Table and Summary folder. A Density plot will show in the window. It shows the RT-PCR value distribution for each sample. Correlation based QC calculates Median Absolute Deviation (MAD) scores for each group. By default, the cutoff for MAD score is -5. From the scatter plot, we see that there are two blue (FAIL) points that can be considered outliers. Users have the option to remove these outlier points and under View Controller , select \"Exclude Selection\" under the Task tab. To keep the analysis simple for this tutorial we will leave these potential outliers alone, but users are encouraged to explore the results of selecting the \"Exclude Selectin\" option after the completion of this tutorial to see how it affects these analyses. Note When user does choose \"Exclude Selection\" option in this module, QC Analysis will be repeated on remaining samples, which can lead to additional samples failing MADScore filter. PcaScores will show a 2-D plot on the first and the second principal components. A Hotelling T2 ellipse with alpha level of 0.05 is also shown. From this plot, there is no outlier sample. There is also a summary table that shows the average correlation in each group. As group was not selected in QC wizard, the correlation will be based on all samples. Note : As outliers are excluded based on failing MADScore or PCA analyses, this correlation value will creep closer to 1 (100%) . If user-defined options instead of default options are needed for QC analysis, users can perform each QC step, rather than QC wizard.","title":"QC wizard"},{"location":"tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#principal-component-analysis","text":"As mentioned previously, QC wizard is used to perform QC analysis with default parameters. Here principal component analysis has more options to change. For example, we want a 3-D plot for PCA. Then a 3-D plot for the first three principal components will be shown. Users can drag the plot and rotate the plot to get a better view. Users can change the symbol properties to make the points color by Treatment, and make it show label ID when selected. The plot shows samples do not cluster with Treatment in this data. But in some other cases the data will be clustered in some specific groups. If there are obvious outlier samples, users can select the samples and choose \"Exclude Selection\". From the PCA plot, there is no outlier sample, so keep all of them.","title":"Principal Component Analysis"},{"location":"tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#general-linear-model","text":"General linear model is an important command to run statistical analysis on data. It allows the user to model the data on a variable-by-variable vasis. The user can specify a fixed, mixed or random model. Estimates, fold change, p-value, significant lists can be generated using this model. Using general linear model can generate more complicated statistical models than one-way ANOVA or two-way ANOVA. In the next example, a general linear model on Treatment with Sample as random factor will be generated. The purpose is to find out the differentially expressed genes in treatment samples compared with DMSO control samples. Go to OmicData | Inference | General Linear Model or in the Workflow tab, select Statistical inference | General linear model : The first step in this process will be to \"Specify Model\": Choose Treatment and Sample on the left (these two columns are in categorical types, so \"Class\" is checked). Then Click \"Add\" to add in the model. Check \"Random\" before Sample as we want sample as a random factor. Then click \"OK\" to finish setting up the model. Now the model has been set. The next step is to \"Specify Test\" (T-test and/or F-test): We want to compare each treatment with DMSO. So check \"For each\" (Treatment), then compare to \"DMSO\". Then we check all the options to generate estimates, fold changes, P-values, and significant lists. Then click \"Add\" For this example, F-test is not needed so we leave it as blank. In future studies, users can use \"FTest (ANOVA)\" tab to specify F-test options. Then click \"OK\". Now the model has been generated. The next step is to change the options for the model, for example changing the cutoff of alpha-value or generating LSMean data. For this example, we just leave it as it is. Then click \"Submit\" to run the model. The results include a report and volcano plots in \"Inference\" folder, and significant gene lists in \"List\" folder of the Solution Explorer . We can change the number of plots shown in one window, and also unify the scale. When a point is selected in one plot, the corresponding point will also highlight in other plots. Details about the selected point will be in \"Detail\" window. Additional view options are available in the View Controller on the right side of the user interface. For example, users can specify the X and Y-axes columns by \"Specify Columns\". Users can also specify p-value and estimate/fold change cutoff lines to better visualize and select the significant genes.","title":"General Linear Model"},{"location":"tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#hierarchical-clustering","text":"The Hierarchical Clustering command performs hierarchical clustering on data object observations and/or variables. For example, we would like to see how the significant genes in the general linear model step (expressed differently in other treatments compared to DMSO) and how the samples cluster. Then in the Hierarchical clustering, we choose the significant gene list and all samples, and compute both observation and variable trees. Users can access this option by choosing in the Workflow tab Pattern Recognition | Hierarchical Clustering or the menu option OmicData | Pattern | Hierarchical Clustering : We choose the significant gene lists by selecting the \"GLM LinearModel Sig10\" under the \"Customized\" Variables option. Choose the \"Compute variable tree\" and assign an Output name that will allow you recognize this customized clustering report: After clicking \"Submit\", the dendrogram will appear in the main view. Users can change the clustering normalization method by \"Specify Normalization\" in the View Controller | Task | Data . There are additional customization options under the Task tab in the View Controller window. For example, we see that X-axis labels are not showing in full. We can rotate the labels for better visualization by choosing View Controller | Task | Properties | Change Chart Properties : We can also add color bars for observations and variables to better see the clustering feature by selecting View Controller | Task | Customize | Change X-axis or Change Y-axis ColorBars : Our view has chanegd to reflect these changes. The Color Legend is in the top view of View Controller . Colors can be changed by simply right-clicking within this legend. From the dendrogram, we can see how the observations and variables cluster. However, there is not a specific pattern in this example dataset. In some other cases, you may find the samples cluster by specific factors such as gender, age, treatment, etc. Users also have the option of choosing specific branches within the dendrogram to see which genes or samples cluster. Simply click on the dendrogram in the dendrogram view and only those selected branches will appear in the heat map. Additional annotations (i.e. color bars) can also be added as described above. | Congratulations! You are done with the analysis. Feel free to browse other options in the workflow to examine other features of this module. As mentioned above, users are encouraged to examine the consequences of filtering out samples (i.e. ones that did not pass MADScore filters) on subsequent steps (QC, GLM, and hierarchical clustering). Click \"Save\" to save this project. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to RT-PCR preprocessing and analysis. Feel free to try different options along the Import RT-PCR Wizard to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) for sales-related questions.","title":"Hierarchical Clustering"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/","text":"Import RT-PCR Wizard The Import RT-PCR Wizard can be used to walk the user through the process of importing and normalizing data. It can be opened via the Add RT-PCR Data menu item, or through the Manage RT-PCR Raw Data menu (after adding plate files). Click the File | Import RT-PCR Wizard to continue: At this point, the user is asked to choose an RT-PCR Value source. Options include using the Ct/Cp values , using the abundance values , or using any available abundance values and converting Ct/Cp to abundance where abundance is not available . In this tutorial, since the imported plate file did not contain abundances, choose the first option and click OK now: The Import RT-PCR Wizard is now displayed and contains two main sections. On the left is the workflow section. The Workflow section shows the user on which step of the Import RT-PCR Wizard the user is working. Initially, this will be the Import data step, as shown below but will be updated throughout the completion of the wizard. Also, clicking the Workflow button will allow the user to save the workflow to return at another time. Array Studio supports importing data from the following formats: Standard format (one data point per row)-For this format, Data should be a table containing exactly 7 columns, including a row header column. This table should include the following columns #, PlateID, Well, AssayID, SampleID, Value, and Include. This is the format used in Tools | Data | Manage Taqman Raw Data. Tall skinny data (one data point per row)- For this format, data should be in a table where each row contains the information for a well, and may also include other descriptive information for the sample and assay. Table data (one sample per row)- For this format, data should be in a table where each row contains the information for all the assays and may include other descriptive information for the sample. Table data (one gene per row) - For this format, data should be in a table where each row contains the information for all the genes and may include other descriptive information for the assay. Because the data was imported using the Manage RT-PCR Raw Data module, most of the options on this screen will be filled in by detecting the file automatically. The only option that could possibly be in need of changing at this stage is the Remove assays with no data points and Remove samples with no data points options. The user also has the option to import the original CT data into the project. This is unselected by default. Uses can also import QuantStudio RT-PCR data. Below is an example QuantStudio file As one row is for one data point, the data can be imported as Tall Skinny Data format. Then specify each column Uses can also import TaqMan hPSC Scorecard data, formatted as below: The data can be imported as Table format Select the Next button at the bottom of the window Preview Data The Workflow frame of the Import RT-PCR Wizard window now shows that we have advanced to the Preview data step. The right side frame contains statistics for the data being imported, as well as visualizations (Heatmap Table tab) of the data. Samples can be removed in this screen by clicking on sample IDs on the column header and clicking on Remove selected samples option. Notice that number of sample selected will be updated to reflect how many you have selected. Individual genes can also be deleted by first clicking on the gene ID (header of the row) and clicking on Remove selected assays . Click the HeatmapTable tab to see the heatmap view of the data. This shows a Heatmap view of the gene abundance in different samples. Any missing data points will be a yellow color. The table and heatmap views are fully customizable by selecting the Customize View option. This will return the Customize View window which contains multiple tabs ( Task , Variable , and Observation ) for customization - these are similar to the options available under View Controller in the Microarray tutorial. These can be used to format the display options of the table and heatmap views, as well as filter for specific samples or assays. Through the preview step, now we have made sure that the imported data is correct. Click the Next button to advance to the next step. Attach Design and Annotation This brings up the Attach design/annotation step as indicated in the Workflow section. Your design table will have been created in advance, and should contain each sample in your dataset in a row with the different design annotations in each column. For this particular dataset, a file has already been created that contains the name of each sample, and a treatment column containing the treatment each sample belongs to. Click the Import button to open the already saved design table: Design tables can be imported using a number of different formats. Choose tab delimited file now and click OK . The design table was saved as sds21.design.txt in the same directory as the data file. Select this file now: Once the design file is imported, the design information will be automatically extracted into the biological grouping box. The user should select the column that represents the biological grouping of their design. For the purpose of this tutorial, select Treatment . Click on the Next button to advance to the next step. Combine Technical Replicates The Combine technical replicates is the next step in the Workflow frame. On the right side frame, the user can visualize the technical replicates, auto-filter out \"bad\" replicates as well as manually filter the replicates. Finally, the user can specify the combination method for the replicates (Mean, Geometric Mean, or Median). Click the Auto filter option at the top of the frame. This will return the Auto filter window: The Auto Filter allows the user to automatically filter the technical replicates based on these criteria: Exclude data point if value is greater than the specified value. Exclude data points if value is less than the specified value. Exclude the entire cell if the range of the cell is greater than the specified value. For abundance data, range is defined as log2(max/min). For Ct/Cp data, range is defined as max-min. Exclude outlier data points based on Grubb's test - Can be used for filtering based on technical replicates (minimum of 3 replicates required). See link for more details. Exclude the whole cell if mean is greater than the specified value. For abundance data, mean is defined as mean(log2(value). For Ct/Cp data, range is defined as mean(value). Exclude the whole cell if SEM (Standard error of the mean) is greater than the specified value. Keep the default settings and click on OK . This will generate a new tab Replicate.Summary Table, which summarizes the 2 technical replicates for each variable (AssayID) by range, mean, SEM (Standard error of the mean). Individual points can be selected for exclusion in this table as well. The scatter view will highlight data points that are set as missing by the auto filter. Switch to the Scatter tab now. Each chart shows the 24 points (24 observations) for one variable. There are 24 variables (genes) in total, so there are 24 charts. Users can scroll up and down to visualize each chart. Additional charts can be displayed in the same window by choosing the window size option on the toolbar. Each data point on the chart is the average of the 2 replicates of this gene in each observation. Replicates that have either been selected by the Auto Filter or manually selected will be highlighted (red). Notice that one particular gene (Control Ribosomal 18s) appears to have a large number of data points that are highlighted. This is due to the Auto Filter attempting to exclude data points with a Ct value less than 10. To see which 45 points were selected in the text file, click the option labeled 45 selected and set as missing . This will open up a text file showing the 45 excluded data points: The last step in combining technical replicates is choosing the combination method (bottom of window). The available methods include taking the Mean , Geometric mean or Median of the technical replicates. For the purpose of this demonstration, we will use the mean which is the default option. Click on Next will advance to the next step: Handle missing data . Handle Missing Data The Handle missing Data step provides the user with two views to visualize the missing data. In addition, selected missing data points can be replaced with a value of the user's choosing (35 by default). Proceed to the next step by clicking on Next . Data Transformation The Data transformation provides user several options for the data transformation. If the data imported contains CT values, these values must be converted to abundance values. An editable formula is given for the conversion of these values as indicated above. The user has the options (enabled by default) to perform a log2 transformation on the data and to calculate relative abundance or relative quantification (RQ). For this demonstration, please choose the first option. Click on Next to proceed to the next step Data Normalization . Data Normalization There are multiple methods available for normalizing theRT-PCR data: By using Analysis of Covariance (the default option) , you can use one or more housekeeping genes to compute a robust score and use this score as a covariate to adjust other genes. This method is statistically sound and the user has the best control on the process. By using Simple housekeeper normalization , you can compute a robust score for all of the housekeepers as the normalizer. Missing data will be excluded from the calculation if simple summarization (e.g. mean) is used. By using Global normalization , you can compute the median of all the assays as the normalizer. Missing data will be excluded from the median calculation. Options to calculate the normalizer: Choose the Summarization method for normalizer calculation. PCA -First, a PCA analysis is done based on the housekeeper matrix (housekeepers were centered and scaled). Then the first component is extracted and used to approximate the data matrix. Next, for each sample, the fitted values were averaged to get a single value (normalizer) for each sample. Mean Median Choose I prefer to use the full model if you just need the software to calculate the normalizer for you (not normalizing the data). This option, when selected, will not normalize the data. It provides the normalizer value for the user but does not go through the normalization process. Choose I would like to perform a separate normalization for each group (e.g. tissue type) if you want to specify a group by which to perform separate normalizations. For example, if the user had an experiment with different tissues types, they may want to normalize within each tissue type separately. If this box is selected, the user would have to choose the Sample group column from the columns in design table and perform the remaining normalization steps on each group. For this demonstration, please choose the first option. Clicking on Next will proceed to the Choose Housekeepers section of the Data Normalization step. If you choose Global normalization method, the Choose Housekeepers step will be skipped. Housekeeping Gene Selection The Choose housekeeper(s) step allows the user to specifically select the housekeeping genes that will be used for normalization: Clicking on the Select housekeepers button will present the Select Rows window: This brings up a list of available genes. The user can scroll to their specific housekeeper genes and use Ctrl + click to select multiple genes. Finally use the arrow button, move them to the right panel. For this tutorial, select Control-ACTB , Control-GAPDH and Control-PPIA . Once the housekeepers are selected and moved to the right Listed rows panel, click on OK button to proceed. Array Studio creates a number of different views. The first view is a summary table containing information for each of the housekeepers, including Missing samples, mean, range of values, standard deviation of values, FtestPvalue (based on biological group), Min, Max and Max/Min . Notice that the Control-GAPDH row is colored red to warn the user that the one-way ANOVA test Pvalue falls below 0.1 (housekeeper gene has significant different intensity in the 24 treatment groups. The user could choose to remove this housekeeper and recalculate but for the purpose of this tutorial, leave this as is. Switch to the Variable tab. The VariableView allows the user to see a Scatter View of each housekeeper gene for each of the biological groups (from Attach design step). There are actually 4 data points for each biological group, but they have similar abundance and group close to one other. Click on Customize View , choose Change Symbol Properties and use the Jitter option to get a better visualization of the 4 points. This can be used to manually eliminate \"suspect\" data points from the normalization calculations, by clicking directly on the blue data points and checking the Mark selected points as missing option on top right. Switch to Data tab, the next view for visualization of the housekeepers. This table lists values for all the data points in Variable view. Switch to Profile tab now to see the Profile view , which show the values from Data table. With the visualization and selection of housekeepers complete, click Next now to continue. This will bring up the Show Normalizer step. Show Normalizer The Show Normalizer includes several views of the normalizer, the first being a table, listing the 24 normalizers calculated for each of the 24 observations. Click the Profile tab now to see the profile view for the normalizers values in 24 observations. The Normalizer is shown in blue at the bottom, while the 3 housekeepers are shown in different colors at the top. User can check the legend by clicking on Customize view on top right and clicking on Legend tab. Click the Variable tab now to see the variable view. Like the Variable view in previous step, data points are organized by biological group. On every chart there are 4 data points for each group, and using Jitter can separate them on the chart. Click on Next to continue to the next section of the Data normalization step. Analysis of Covariance In Analysis of Covariance step the user needs to set the model to be used for the normalization. By default, the previously calculated normalizer is included in the model: Click the option Specify full model now to specify the model. This opens up the Specify Linear Model window. This is the same window used in the General Linear Model analysis module. More details on how to use this window can be found in the Microarray Tutorial . For the purpose of this tutorial, our model will consist of the normalizer and treatment. Select Treatment from the left side of the window and then click Add to add it as one of the terms in the model. Notice that for categorical factors, user should make sure that its Class box is checked. Click OK button to finish specifying model and return to the Analysis of Covariance window. At this point, the model is ready and we just need to run it. Notice that the model now shows Normalizer + Treatment . Advanced options for this section include a special outlier filtering option that is enabled by default. Click Run Model now to run the model. Results are returned in the window above, which is empty before running the model. The summary note indicates that there are 20 out of 21 assays (21 genes without counting the 3 housekeepers) that have improved CEFR (Covariate Efficiency Factor Residual). These 20 genes showed smaller RMSE (Root mean square error) in model with normalizer than that without normalizer. The CEFR is calculated by the following formula: The summary note also indicates that there are 3 outliers detected and marked as missing. This summary table shows the number of outliers removed (outlier filtration can be specified in the advanced options), as well as a coefficient for each gene and PValue indicating whether the gene was improved due to normalization. This is used in conjunction with the calculated CEFR value to give the user an idea of how well the normalization went. This table can be opened in Excel or as a text file and saved for later use if interested. After looking at the results of the normalization, click the Next button to continue to the next section of Data normalization . Show Residuals The Show Residuals section provides more detailed statistical views of the results of the normalization. For each assay (gene), there are Observed vs. Fitted plot, Observed plot, Fitted plot, Studentized plot, Jackknife plot. The first 3 views plot observed and fitted values and the last 2 plot Studentized residuals and Jackknife residuals. Observed vs. Fitted plot: Switch the tab to see Observed plot: Switch to the Fitted plot: Switch to the Studentized plot: Switch to the Jackknife plot: Click on Next to go to the Preview data step. Preview Data The Preview Data displays a preview of the data to be imported. Missing values are indicated by dots . . Click Next to go to the final section of the Import RT-PCR Wizard . Finish Click on Finish at the bottom right of the window. This will complete the Import RT-PCR Wizard and will import the data shown in Preview Data step into Array Studio. The data has now been completely imported into Array Studio as RT-PCR data listed under Omic Data folder of the Solution Explorer . Like the Microarray data in Microarray tutorial, this data has design table and annotation table. The 24 normalizer values are listed in the design table for each of the 24 observations.","title":"Import RT-PCR Wizard"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#import-rt-pcr-wizard","text":"The Import RT-PCR Wizard can be used to walk the user through the process of importing and normalizing data. It can be opened via the Add RT-PCR Data menu item, or through the Manage RT-PCR Raw Data menu (after adding plate files). Click the File | Import RT-PCR Wizard to continue: At this point, the user is asked to choose an RT-PCR Value source. Options include using the Ct/Cp values , using the abundance values , or using any available abundance values and converting Ct/Cp to abundance where abundance is not available . In this tutorial, since the imported plate file did not contain abundances, choose the first option and click OK now: The Import RT-PCR Wizard is now displayed and contains two main sections. On the left is the workflow section. The Workflow section shows the user on which step of the Import RT-PCR Wizard the user is working. Initially, this will be the Import data step, as shown below but will be updated throughout the completion of the wizard. Also, clicking the Workflow button will allow the user to save the workflow to return at another time. Array Studio supports importing data from the following formats: Standard format (one data point per row)-For this format, Data should be a table containing exactly 7 columns, including a row header column. This table should include the following columns #, PlateID, Well, AssayID, SampleID, Value, and Include. This is the format used in Tools | Data | Manage Taqman Raw Data. Tall skinny data (one data point per row)- For this format, data should be in a table where each row contains the information for a well, and may also include other descriptive information for the sample and assay. Table data (one sample per row)- For this format, data should be in a table where each row contains the information for all the assays and may include other descriptive information for the sample. Table data (one gene per row) - For this format, data should be in a table where each row contains the information for all the genes and may include other descriptive information for the assay. Because the data was imported using the Manage RT-PCR Raw Data module, most of the options on this screen will be filled in by detecting the file automatically. The only option that could possibly be in need of changing at this stage is the Remove assays with no data points and Remove samples with no data points options. The user also has the option to import the original CT data into the project. This is unselected by default. Uses can also import QuantStudio RT-PCR data. Below is an example QuantStudio file As one row is for one data point, the data can be imported as Tall Skinny Data format. Then specify each column Uses can also import TaqMan hPSC Scorecard data, formatted as below: The data can be imported as Table format Select the Next button at the bottom of the window","title":"Import RT-PCR Wizard"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#preview-data","text":"The Workflow frame of the Import RT-PCR Wizard window now shows that we have advanced to the Preview data step. The right side frame contains statistics for the data being imported, as well as visualizations (Heatmap Table tab) of the data. Samples can be removed in this screen by clicking on sample IDs on the column header and clicking on Remove selected samples option. Notice that number of sample selected will be updated to reflect how many you have selected. Individual genes can also be deleted by first clicking on the gene ID (header of the row) and clicking on Remove selected assays . Click the HeatmapTable tab to see the heatmap view of the data. This shows a Heatmap view of the gene abundance in different samples. Any missing data points will be a yellow color. The table and heatmap views are fully customizable by selecting the Customize View option. This will return the Customize View window which contains multiple tabs ( Task , Variable , and Observation ) for customization - these are similar to the options available under View Controller in the Microarray tutorial. These can be used to format the display options of the table and heatmap views, as well as filter for specific samples or assays. Through the preview step, now we have made sure that the imported data is correct. Click the Next button to advance to the next step.","title":"Preview Data"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#attach-design-and-annotation","text":"This brings up the Attach design/annotation step as indicated in the Workflow section. Your design table will have been created in advance, and should contain each sample in your dataset in a row with the different design annotations in each column. For this particular dataset, a file has already been created that contains the name of each sample, and a treatment column containing the treatment each sample belongs to. Click the Import button to open the already saved design table: Design tables can be imported using a number of different formats. Choose tab delimited file now and click OK . The design table was saved as sds21.design.txt in the same directory as the data file. Select this file now: Once the design file is imported, the design information will be automatically extracted into the biological grouping box. The user should select the column that represents the biological grouping of their design. For the purpose of this tutorial, select Treatment . Click on the Next button to advance to the next step.","title":"Attach Design and Annotation"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#combine-technical-replicates","text":"The Combine technical replicates is the next step in the Workflow frame. On the right side frame, the user can visualize the technical replicates, auto-filter out \"bad\" replicates as well as manually filter the replicates. Finally, the user can specify the combination method for the replicates (Mean, Geometric Mean, or Median). Click the Auto filter option at the top of the frame. This will return the Auto filter window: The Auto Filter allows the user to automatically filter the technical replicates based on these criteria: Exclude data point if value is greater than the specified value. Exclude data points if value is less than the specified value. Exclude the entire cell if the range of the cell is greater than the specified value. For abundance data, range is defined as log2(max/min). For Ct/Cp data, range is defined as max-min. Exclude outlier data points based on Grubb's test - Can be used for filtering based on technical replicates (minimum of 3 replicates required). See link for more details. Exclude the whole cell if mean is greater than the specified value. For abundance data, mean is defined as mean(log2(value). For Ct/Cp data, range is defined as mean(value). Exclude the whole cell if SEM (Standard error of the mean) is greater than the specified value. Keep the default settings and click on OK . This will generate a new tab Replicate.Summary Table, which summarizes the 2 technical replicates for each variable (AssayID) by range, mean, SEM (Standard error of the mean). Individual points can be selected for exclusion in this table as well. The scatter view will highlight data points that are set as missing by the auto filter. Switch to the Scatter tab now. Each chart shows the 24 points (24 observations) for one variable. There are 24 variables (genes) in total, so there are 24 charts. Users can scroll up and down to visualize each chart. Additional charts can be displayed in the same window by choosing the window size option on the toolbar. Each data point on the chart is the average of the 2 replicates of this gene in each observation. Replicates that have either been selected by the Auto Filter or manually selected will be highlighted (red). Notice that one particular gene (Control Ribosomal 18s) appears to have a large number of data points that are highlighted. This is due to the Auto Filter attempting to exclude data points with a Ct value less than 10. To see which 45 points were selected in the text file, click the option labeled 45 selected and set as missing . This will open up a text file showing the 45 excluded data points: The last step in combining technical replicates is choosing the combination method (bottom of window). The available methods include taking the Mean , Geometric mean or Median of the technical replicates. For the purpose of this demonstration, we will use the mean which is the default option. Click on Next will advance to the next step: Handle missing data .","title":"Combine Technical Replicates"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#handle-missing-data","text":"The Handle missing Data step provides the user with two views to visualize the missing data. In addition, selected missing data points can be replaced with a value of the user's choosing (35 by default). Proceed to the next step by clicking on Next .","title":"Handle Missing Data"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#data-transformation","text":"The Data transformation provides user several options for the data transformation. If the data imported contains CT values, these values must be converted to abundance values. An editable formula is given for the conversion of these values as indicated above. The user has the options (enabled by default) to perform a log2 transformation on the data and to calculate relative abundance or relative quantification (RQ). For this demonstration, please choose the first option. Click on Next to proceed to the next step Data Normalization .","title":"Data Transformation"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#data-normalization","text":"There are multiple methods available for normalizing theRT-PCR data: By using Analysis of Covariance (the default option) , you can use one or more housekeeping genes to compute a robust score and use this score as a covariate to adjust other genes. This method is statistically sound and the user has the best control on the process. By using Simple housekeeper normalization , you can compute a robust score for all of the housekeepers as the normalizer. Missing data will be excluded from the calculation if simple summarization (e.g. mean) is used. By using Global normalization , you can compute the median of all the assays as the normalizer. Missing data will be excluded from the median calculation. Options to calculate the normalizer: Choose the Summarization method for normalizer calculation. PCA -First, a PCA analysis is done based on the housekeeper matrix (housekeepers were centered and scaled). Then the first component is extracted and used to approximate the data matrix. Next, for each sample, the fitted values were averaged to get a single value (normalizer) for each sample. Mean Median Choose I prefer to use the full model if you just need the software to calculate the normalizer for you (not normalizing the data). This option, when selected, will not normalize the data. It provides the normalizer value for the user but does not go through the normalization process. Choose I would like to perform a separate normalization for each group (e.g. tissue type) if you want to specify a group by which to perform separate normalizations. For example, if the user had an experiment with different tissues types, they may want to normalize within each tissue type separately. If this box is selected, the user would have to choose the Sample group column from the columns in design table and perform the remaining normalization steps on each group. For this demonstration, please choose the first option. Clicking on Next will proceed to the Choose Housekeepers section of the Data Normalization step. If you choose Global normalization method, the Choose Housekeepers step will be skipped.","title":"Data Normalization"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#housekeeping-gene-selection","text":"The Choose housekeeper(s) step allows the user to specifically select the housekeeping genes that will be used for normalization: Clicking on the Select housekeepers button will present the Select Rows window: This brings up a list of available genes. The user can scroll to their specific housekeeper genes and use Ctrl + click to select multiple genes. Finally use the arrow button, move them to the right panel. For this tutorial, select Control-ACTB , Control-GAPDH and Control-PPIA . Once the housekeepers are selected and moved to the right Listed rows panel, click on OK button to proceed. Array Studio creates a number of different views. The first view is a summary table containing information for each of the housekeepers, including Missing samples, mean, range of values, standard deviation of values, FtestPvalue (based on biological group), Min, Max and Max/Min . Notice that the Control-GAPDH row is colored red to warn the user that the one-way ANOVA test Pvalue falls below 0.1 (housekeeper gene has significant different intensity in the 24 treatment groups. The user could choose to remove this housekeeper and recalculate but for the purpose of this tutorial, leave this as is. Switch to the Variable tab. The VariableView allows the user to see a Scatter View of each housekeeper gene for each of the biological groups (from Attach design step). There are actually 4 data points for each biological group, but they have similar abundance and group close to one other. Click on Customize View , choose Change Symbol Properties and use the Jitter option to get a better visualization of the 4 points. This can be used to manually eliminate \"suspect\" data points from the normalization calculations, by clicking directly on the blue data points and checking the Mark selected points as missing option on top right. Switch to Data tab, the next view for visualization of the housekeepers. This table lists values for all the data points in Variable view. Switch to Profile tab now to see the Profile view , which show the values from Data table. With the visualization and selection of housekeepers complete, click Next now to continue. This will bring up the Show Normalizer step.","title":"Housekeeping Gene Selection"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#show-normalizer","text":"The Show Normalizer includes several views of the normalizer, the first being a table, listing the 24 normalizers calculated for each of the 24 observations. Click the Profile tab now to see the profile view for the normalizers values in 24 observations. The Normalizer is shown in blue at the bottom, while the 3 housekeepers are shown in different colors at the top. User can check the legend by clicking on Customize view on top right and clicking on Legend tab. Click the Variable tab now to see the variable view. Like the Variable view in previous step, data points are organized by biological group. On every chart there are 4 data points for each group, and using Jitter can separate them on the chart. Click on Next to continue to the next section of the Data normalization step.","title":"Show Normalizer"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#analysis-of-covariance","text":"In Analysis of Covariance step the user needs to set the model to be used for the normalization. By default, the previously calculated normalizer is included in the model: Click the option Specify full model now to specify the model. This opens up the Specify Linear Model window. This is the same window used in the General Linear Model analysis module. More details on how to use this window can be found in the Microarray Tutorial . For the purpose of this tutorial, our model will consist of the normalizer and treatment. Select Treatment from the left side of the window and then click Add to add it as one of the terms in the model. Notice that for categorical factors, user should make sure that its Class box is checked. Click OK button to finish specifying model and return to the Analysis of Covariance window. At this point, the model is ready and we just need to run it. Notice that the model now shows Normalizer + Treatment . Advanced options for this section include a special outlier filtering option that is enabled by default. Click Run Model now to run the model. Results are returned in the window above, which is empty before running the model. The summary note indicates that there are 20 out of 21 assays (21 genes without counting the 3 housekeepers) that have improved CEFR (Covariate Efficiency Factor Residual). These 20 genes showed smaller RMSE (Root mean square error) in model with normalizer than that without normalizer. The CEFR is calculated by the following formula: The summary note also indicates that there are 3 outliers detected and marked as missing. This summary table shows the number of outliers removed (outlier filtration can be specified in the advanced options), as well as a coefficient for each gene and PValue indicating whether the gene was improved due to normalization. This is used in conjunction with the calculated CEFR value to give the user an idea of how well the normalization went. This table can be opened in Excel or as a text file and saved for later use if interested. After looking at the results of the normalization, click the Next button to continue to the next section of Data normalization .","title":"Analysis of Covariance"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#show-residuals","text":"The Show Residuals section provides more detailed statistical views of the results of the normalization. For each assay (gene), there are Observed vs. Fitted plot, Observed plot, Fitted plot, Studentized plot, Jackknife plot. The first 3 views plot observed and fitted values and the last 2 plot Studentized residuals and Jackknife residuals. Observed vs. Fitted plot: Switch the tab to see Observed plot: Switch to the Fitted plot: Switch to the Studentized plot: Switch to the Jackknife plot: Click on Next to go to the Preview data step.","title":"Show Residuals"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#preview-data_1","text":"The Preview Data displays a preview of the data to be imported. Missing values are indicated by dots . . Click Next to go to the final section of the Import RT-PCR Wizard .","title":"Preview Data"},{"location":"tutorials/RTPCR/Import_RT-PCR_Wizard/#finish","text":"Click on Finish at the bottom right of the window. This will complete the Import RT-PCR Wizard and will import the data shown in Preview Data step into Array Studio. The data has now been completely imported into Array Studio as RT-PCR data listed under Omic Data folder of the Solution Explorer . Like the Microarray data in Microarray tutorial, this data has design table and annotation table. The 24 normalizer values are listed in the design table for each of the 24 observations.","title":"Finish"},{"location":"tutorials/RTPCR/Introduction/","text":"Introduction Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that users complete the prerequisite for this tutorial: MicroArray Tutorial , which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio. Downloading the SDS21 dataset For this tutorial, the following materials will be required: The SDS21 text file containing the RT-PCR data The SDS21.design.txt file containing the RT-PCR data design information In this dataset, there are 24 observations (6 treatments * 4 samples) and 24 variables. Each variable (AssayID) has 2 technical replicates in each observation. These files are available in a zipped resource file located on the Omicsoft web srver at the following URL: link After downloading the single .zip file, unzip the file to a folder to be used for this tutorial. With the downloaded sample data, this tutorial will cover the steps involved in: Importing data directly from ABI result text files Normalizing data using a number of statistical methods Viewing results using the same visualization tools employed elsewhere in Array Studio The Workflow Window/ The Solution Explorer When Array Studio is first installed, it will look similar to what is displayed below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. The \"Workflow\" window should be visible on the left side of the screen. If the window is not visible, go to the View Menu and select Show Workflow . Click the Workflow tab (next to Solution Explorer ) and the Workflow window should appear similar to the screenshot below. This window provides users, especially new users, with a guide to running different types of analysis. Click the Workflow dropdown box now and select RT-PCR . Notice that the RT-PCR Workflow is separated into different categories, including Getting started , Manage data , Preprocess , Quality control , Statistical inference , and Pattern recognition . While it is possible to access all of these functions via the menu commands in Array Studio, the workflows are designed to make it easier for the new users to work through their data. The first section of the RT-PCR Workflow is the Getting Started section. In this section, it is suggested that the user either create a new project or open a previously created project. To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to the File Menu, then click New Local Project . This opens the New Project window. Note : For the purposes of this tutorial, we will do the analysis under Local Project . However, this module can also be performed under Server mode, by simply clicking File | New Server Project or New | New Server Project Array Studio allows the user to create two different project types: A simple project, in which all the project is saved in a single file (recommended for microarray and RT-PCR projects). A distributed project, where data is saved in separate files (recommended for exon array, CNV, or genotyping projects). Since this project involves an RT-PCR project, choose Create a simple project now. Then, click the Browse button to select a location and name for the project. Once this is complete, click OK to continue. Switch to the Solution Explorer by clicking on the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, open it by going to the View Menu | Show Solution Explorer . The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples).","title":"Introduction"},{"location":"tutorials/RTPCR/Introduction/#introduction","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that users complete the prerequisite for this tutorial: MicroArray Tutorial , which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.","title":"Introduction"},{"location":"tutorials/RTPCR/Introduction/#downloading-the-sds21-dataset","text":"For this tutorial, the following materials will be required: The SDS21 text file containing the RT-PCR data The SDS21.design.txt file containing the RT-PCR data design information In this dataset, there are 24 observations (6 treatments * 4 samples) and 24 variables. Each variable (AssayID) has 2 technical replicates in each observation. These files are available in a zipped resource file located on the Omicsoft web srver at the following URL: link After downloading the single .zip file, unzip the file to a folder to be used for this tutorial. With the downloaded sample data, this tutorial will cover the steps involved in: Importing data directly from ABI result text files Normalizing data using a number of statistical methods Viewing results using the same visualization tools employed elsewhere in Array Studio","title":"Downloading the SDS21 dataset"},{"location":"tutorials/RTPCR/Introduction/#the-workflow-window-the-solution-explorer","text":"When Array Studio is first installed, it will look similar to what is displayed below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. The \"Workflow\" window should be visible on the left side of the screen. If the window is not visible, go to the View Menu and select Show Workflow . Click the Workflow tab (next to Solution Explorer ) and the Workflow window should appear similar to the screenshot below. This window provides users, especially new users, with a guide to running different types of analysis. Click the Workflow dropdown box now and select RT-PCR . Notice that the RT-PCR Workflow is separated into different categories, including Getting started , Manage data , Preprocess , Quality control , Statistical inference , and Pattern recognition . While it is possible to access all of these functions via the menu commands in Array Studio, the workflows are designed to make it easier for the new users to work through their data. The first section of the RT-PCR Workflow is the Getting Started section. In this section, it is suggested that the user either create a new project or open a previously created project. To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to the File Menu, then click New Local Project . This opens the New Project window. Note : For the purposes of this tutorial, we will do the analysis under Local Project . However, this module can also be performed under Server mode, by simply clicking File | New Server Project or New | New Server Project Array Studio allows the user to create two different project types: A simple project, in which all the project is saved in a single file (recommended for microarray and RT-PCR projects). A distributed project, where data is saved in separate files (recommended for exon array, CNV, or genotyping projects). Since this project involves an RT-PCR project, choose Create a simple project now. Then, click the Browse button to select a location and name for the project. Once this is complete, click OK to continue. Switch to the Solution Explorer by clicking on the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, open it by going to the View Menu | Show Solution Explorer . The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples).","title":"The Workflow Window/ The Solution Explorer"},{"location":"tutorials/RTPCR/Manage_RT-PCR_Raw_Data/","text":"Manage RT-PCR Raw Data At this point, we are ready to add RT-PCR data to the Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the Workflow Window , by selecting the Workflow tab at the bottom of the Solution Explorer . Alternatively, go to View Menu | Show Workflow to show the Workflow Window . RT-PCR data can be imported directly from \"ABI SDS 2.x\", \"Roche LC480\" and BioMark exported text files. The module Manage RT-PCR raw data can take any number of these text files and convert them to a format suitable for the Import RT-PCR Wizard (for normalizing and importing RT-PCR data into Array Studio). When selected, this opens the Manage RT-PCR Raw Data window, as shown below: Initially, this will show a blank main window, as well as a section for organizing the plates (initially will just show an \"All plates\" folder with nothing in it). Go to the File menu and select Add Plate File(s) to begin the process of importing RT-PCR data. This will open the Import RT-PCR Plates window The first priority for this screen is to add plate files. This can be accomplished by selecting the Plate type to ABI SDS 2x and clicking the Add button. This opens a window to select your plate file. Choose the \"sds21.txt\" file you downloaded earlier in this tutorial. Once the files have been added to the File name(s) section, information in the files is automatically extracted. Clicking on an individual plate file shows a preview of that file in the Preview box. This allows the user to see if the correct plate files were imported, and also helps to set the Options section. In general, you should pay particular attention to the options on the right, including PlateID column , Well column , SampleID column , AssayID column , Ct/Cp column and Abundance column . Since there is no abundance information in this file, the abundance column indicates (none) , while other information is extracted automatically from the file. By default, undetermined values are set to 40, but users can Set undetermined value to 35, 40 or missing. When finished, click the OK button to return to the Manage RT-PCR Raw Data window to proceed to the next step. Once plates have been added to the Manage RT-PCR Raw Data window, they will be organized in the left-most box. Notice in the example below that there are three plate files. If data needs to be edited at this point (i.e. editing Sample Names, AssayID, etc.) this can be done at this step. To exclude a particular data point, change the Include column from Y to N . Once finished, select from the menu File | Save Raw Data to save the data. The imported raw data will be saved as an Omicsoft RT-PCR raw data (.taqman) file, which can be uploaded anytime in the future through Import RT-PCR Wizard . Now that the raw data has been successfully saved, we can proceed to the Import RT-PCR Wizard to finish the normalization and importing of the data as a regular Array Studio dataset.","title":"Manage RT-PCR Raw Data"},{"location":"tutorials/RTPCR/Manage_RT-PCR_Raw_Data/#manage-rt-pcr-raw-data","text":"At this point, we are ready to add RT-PCR data to the Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the Workflow Window , by selecting the Workflow tab at the bottom of the Solution Explorer . Alternatively, go to View Menu | Show Workflow to show the Workflow Window . RT-PCR data can be imported directly from \"ABI SDS 2.x\", \"Roche LC480\" and BioMark exported text files. The module Manage RT-PCR raw data can take any number of these text files and convert them to a format suitable for the Import RT-PCR Wizard (for normalizing and importing RT-PCR data into Array Studio). When selected, this opens the Manage RT-PCR Raw Data window, as shown below: Initially, this will show a blank main window, as well as a section for organizing the plates (initially will just show an \"All plates\" folder with nothing in it). Go to the File menu and select Add Plate File(s) to begin the process of importing RT-PCR data. This will open the Import RT-PCR Plates window The first priority for this screen is to add plate files. This can be accomplished by selecting the Plate type to ABI SDS 2x and clicking the Add button. This opens a window to select your plate file. Choose the \"sds21.txt\" file you downloaded earlier in this tutorial. Once the files have been added to the File name(s) section, information in the files is automatically extracted. Clicking on an individual plate file shows a preview of that file in the Preview box. This allows the user to see if the correct plate files were imported, and also helps to set the Options section. In general, you should pay particular attention to the options on the right, including PlateID column , Well column , SampleID column , AssayID column , Ct/Cp column and Abundance column . Since there is no abundance information in this file, the abundance column indicates (none) , while other information is extracted automatically from the file. By default, undetermined values are set to 40, but users can Set undetermined value to 35, 40 or missing. When finished, click the OK button to return to the Manage RT-PCR Raw Data window to proceed to the next step. Once plates have been added to the Manage RT-PCR Raw Data window, they will be organized in the left-most box. Notice in the example below that there are three plate files. If data needs to be edited at this point (i.e. editing Sample Names, AssayID, etc.) this can be done at this step. To exclude a particular data point, change the Include column from Y to N . Once finished, select from the menu File | Save Raw Data to save the data. The imported raw data will be saved as an Omicsoft RT-PCR raw data (.taqman) file, which can be uploaded anytime in the future through Import RT-PCR Wizard . Now that the raw data has been successfully saved, we can proceed to the Import RT-PCR Wizard to finish the normalization and importing of the data as a regular Array Studio dataset.","title":"Manage RT-PCR Raw Data"},{"location":"tutorials/SNP/","text":"SNP Data Analysis Tutorial .. toctree:: :maxdepth: 2 Introduction Visualization_of_Data Marker_Statistics__Data_Filtering__and_Population_Structure Association_Analysis Visualizationof_pValues Save_Close_Project","title":"Home"},{"location":"tutorials/SNP/Association_Analysis/","text":"Association Analysis Besides visualization, summarization, and QC data, Array Studio contains a powerful set of tools for SNP association analysis. Users can analyze data using Single-Marker Association tests or Two-Marker Association tests. Available tests include Basic Association , Stratified Association (single marker only), Quantitative Trait , Categorical Trait , Survival Trait , Repeated Measure Trait , as well as Dose Data and Probability Data Association tests (also CNV analysis modules are available). In this tutorial, we will cover basic association, categorical trait, quantitative trait, and survival trait analysis. Basic Association Single Marker Single marker-basic association analysis is based on Fisher s Exact test to test the allele frequency difference between Case/Control traits. To start a single marker-basic association analysis, go to Genotyping Menu | Single Marker Association | Basic Association to open the Basic Association window. As usual, ensure that the Project is Tutorial and Data is GenotypeData and the Variables are set to customized variables using the list GenotypeData.Variable31008 . For all of our association analyses, we only have design information for the JPT group, so use the Observation list GenotypeData.Observation45 that was created in the last chapter during the Filter step (use customized observation list). Under Options , We need to set the design column containing the Trait we wish to analyze, in this case Phenotype (Note: By default, Array Studio should have chosen this as the Trait , due to the selection of Group as the Phenotype column when importing the Design Table ). Next, we need to set the Case level. As the levels of Group are named case and control, we should choose Case as our Case level. User can use following options to decide which statistics to include in the result: Generate the Minor allele (make sure it s checked) Minor allele count Allelic test p-value and odds ratio (make sure it s checked) Genotypic test p-value (uncheck this box) Dominant test p-value Recessive test p-value Additive test p-value Note While it is possible to run this analysis and test for a genotypic p-value, dominant test p-value, recessive test p-value, additive test p-value, and use Fisher Exact test instead of Chi-square test, for the purposes of this tutorial we will only investigate the allelic test Chi-square p-value and asymptotic odds ratio (Fisher Exact test will give exact odds ratio). We can set the Multiplicity adjustment for the test (leave as is with FDR_BH , an Alpha level of 0.05 , and a Confidence interval of 0.95 ). Finally, change the Output name to Basic Association and click Submit to run the basic association test. A new Table will be created in the Solution Explorer under the Inference section. All association analyses in Array Studio will generate Inference Reports . Notice the name of the report, Basic Association.Tests (as this is the name we specified above), and the type the report InferenceReport Data . A TableView called Report will be generated by default and immediately visible in the main view window (make sure filters are cleared to see all variables). All of the requested information is now available for each marker, including the MinorAllele, Allelic.RawPvalue, Allelic.AdjustedPValue, and Allelic.OddsRatio. The Odds Ratio also includes the confidence interval. The last 5 columns are the appended annotation table. Right click in the header of the Allelic.RawPvalue column and select Sort Ascending . The TableView is sorted, showing the most significant markers based on this analysis. We can also choose to filter this view, and we can do so using any of the generated columns (p-value, adjusted p-value etc.) or any of the annotation columns. As we are going to run three more similar analyses (categorical, quantitative and survival traits), we will do some filtering by p-value in later chapters. Categorical Trait Single Marker To run a single marker-categorical trait analysis, go to the Genotyping Menu | Single Marker Analysis | Categorical Trait . As always, ensure that Tutorial is chosen for Project, GenotypeData is chosen for Data , GenotypeData.Variable31008 is chosen for Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list, GenotypeData.Observation45 , is chosen for Customized Observations . Click the Specify Model button to open the Specify Model window: Set the Trait to Group2 . Notice that the type of trait is now recognized as a Categorical Trait , and lists the three categories. Note: for categorical traits, the user can specify whether the data is ordered. If it is ordered, it should be analyzed differently (using cumulative odds logistic regression instead of generalized logistic regression), and the Levels are ordered checkbox should be checked when running the model for this dataset. Check the Levels are ordered checkbox now (Array Studio has the ability to deal with nominal traits or ordinal traits). Additional covariates could be added to the model at this point, including potential principal component analysis components. However, for this tutorial, leave the model as is ( Categorical Trait is Group2 , ordered , model only includes Genotype ). Click OK to return to the Categorical Trait window. At this point, the updated model should be reflected in the window. Ensure that Generate odds ratio data and Generate odds data is selected. Ensure that Genotypic is chosen for the Disease model . Other available diseases models include Additive , Dominant , and Recessive . Multiplicity should be set to FDR_BH , with an Alpha level of 0.05 and a Confidence interval of 0.95. Set the Anova type to Type3, and set the Test type to WaldTest (the other option is LikelihoodRatio test). Finally, set Output name to Categorical Trait . If the user is interested, the equivalent SAS code can be generated after all options are set, by clicking the Show SAS code button. Click Submit to run the Categorical Trait association analysis. Three new Tables will be generated under the Inference section of the Solution Explorer : the standard Tests table, as well as the requested Odds and OddsRatio Tables . Double click on the Categorical Trait.Tests Report to display the TableView in the main view window. If this data is filtered, reset all filters to see all variables. Notice that the Categorical Trait.OddsRatio table contains two views: an OddsRatio view and a Table view. Switch to the OddsRatio view now by double-clicking it. The OddsRatio table will only be generated for significant genotypes. Remove any filters on this view, and notice that there are 3 charts that were generated. To view all 3 charts in the same time, change to 2*2 in the drop down list. The user can also see the TableView information for the OddsRatio by double-clicking the generated table view. In this TableView , each row contains the marker ID, the group that is being compared, and the p-value, as well as the odds ratio and confidence intervals. Annotation information is also included. Finally, a Table has been created for viewing the Odds. This includes a visualization of the Odds , as well as a TableView . Double-click on the Odds view now to open it in the main view window. Double-click on the TableView of Odds now to see the generated Odds for each group. Quantitative Trait Single Marker(General) To run a single marker-quantitative trait, go to Genotyping | Single Marker Analysis | Quantitative Trait (General) , which opens the Quantitative Trait window. As always, ensure that Tutorial is chosen for Project , GenotypeData is chosen for Data , and GenotypeData.Variable31008 is chosen for Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list, GenotypeData.Observation45 , is chosen for Customized Observations. Click the Specify Model button to open the Specify Model window: The first step in this window is to select the quantitative trait to be used for analysis. For Trait , choose the column Qtrait , as this contains our quantitative trait information. If the correct column is selected, the box to the right will indicate that the type of trait is indeed a quantitative trait. Next, we can add any covariates to our model. Normally, this may include generated components from a principal component analysis. For this tutorial, we will just add the columns labeled Covariate 1 and Covariate 2 . They can be added by selecting both of these columns (under Columns ), and clicking the Add button to add them to the model. Notice that Qtrait , Covariate 1 and Covariate 2 are set to Class , uncheck the box for them. Click OK to return to the Quantitative Trait window. At this point, the updated model should be reflected in the window. Under Options , ensure that Generate LSMeans data is selected, as well as Generate contrast data , and that Genotypic is chosen for the Disease model . Other available diseases models include Additive , Dominant , and Recessive . Multiplicity should be set to FDR_BH , with an Alpha level of 0.05 and a Confidence interval of 0.95. Set the Anova type to Type3, and set the Test type to WaldTest (the other option is LikelihoodRatio test). Finally, set Output name to Categorical Trait . Click Submit to run the Quantitative Trait association analysis. Three new Tables will be generated under the Inference tab of the Solution Explorer : an LSMeans (least square mean) Table, a Contrasts Table and a Tests table. The Tests table is similar to the Table encountered with the Basic Association analysis and with the categorical association analysis. Ensure that the Report TableView for Quantitative Trait.Tests is showing in the main view window. Reset any filters if need. Next, let s filter the table, to only show us markers where the GENOTYPE.FDR_BH (adjusted p-value) is less than 0.05 (enter \"<0.05\" into the GENOTYPE.FDR_BH filter). This should show a TableView containing 12 rows. Let s further sort these rows by the adjusted p-value column, so that the most significant markers are shown first, as shown below. Select the top three markers now, by clicking on the header row names in the ID column. Now, let s generate a ChromosomeView for this data. To add a ChromosomeView , right click Quantitative Trait.Tests , click on Add View and then choose ChromosomeView . When added, it should look similar to the following screenshot. Only two chromosomes are shown, because the data was previously filtered. We will un-filter this data in one minute, but first, let s check to see whether the three selected markers (with the same p-values) are in linkage disequilibrium. To generate Linkage Disequilibrium results on demand, click the LD On Demand button in the Task tab of the View Controller . This generates a correlation heatmap of our selected rows, with a red color indicating higher correlation. The coloring scheme can be changed by clicking the Customize View window in this window If the Correlation Heatmap does not look similar to the screen shot above, click the Customize View button and remove any Variable filters. It is clear from the perfect correlation values (=1), that these three markers are in complete linkage disequilibrium. Close the window and return to the ChromosomeView . Now, remove the previously set p-value filter. Your ChromosomeView should now look similar to below. In this view, you can see all of the Chromosomes in your experiment, and then each chromosome has lines colored, based on a certain criteria. Click the Specify Data Source option in the Task tab of the View Controller . Note that the Genotype.RawPValue option is chosen. This means that the color is based on this column. Click OK to return to the view. Now click the Change Color Properties option in the Task tab of the View Controller . This dialog box shows you how the chart is colored. In this case, high p-values are colored as a clear color, while low p-values are colored as blue. The user can also specify what counts as a high and low p-value. Feel free to change the colors, and/or the high and low p-values, and reflect the changes on the chart. The user also has the option of looking at each individual chromosome in its own chart. This can be accomplished by clicking the Trellis by Chromosome option in the Task tab of the View Controller . Click this option now and the view should reflect the screenshot below. Scroll through the charts, to see all of the chromosomes. Notice that the Y-axis of the chart represents the log10 (p-value). This is a fully interactive view as well, so individual data points can be selected and viewed in the Details Window . When selected, points turn a red color. Array Studio also generated LSMeans table and charts for the quantitative data. Switch to the LSMeans view for the Table Quantitative Trait.LSMeans . By default, LSMeans data was generated for each significant marker (as we noted earlier, there are 12 significant markers, with an adjusted p-value<0.05). Scroll through the charts and take a look at the data (unfilter the data if necessary). It is clear that for each significant marker, the different genotypes have different least square mean values for the quantitative trait. A Table view of the LSMeans data was also generated and can be opened and viewed at any time. Finally, a Contrasts Table was generated, with a Contrasts view, as well as a Table view. Double-click the Contrasts view now. On the X-axis is each contrast (i.e. A_T vs. A_A, T_T vs. A_A), with the Y-axis the value of the estimate. A Table view was created for the Contrasts dataset. This can be opened and viewed at any time. Survival Trait Single Marker Survival Trait analysis could be an important component of any SNP study from clinical trials. As we noted earlier, it is possible to generate a SurvivalView in Array Studio . However, we can also perform single-marker and two-marker survival trait association analysis. Single-Marker Survival Trait analysis will be demonstrated in this tutorial. To perform this analysis, go to the menu Genotyping | Single Marker Association | Survival Trait . As always, ensure that Tutorial is chosen for Project , GenotypeData is chosen for Data , GenotypeData.Variable31008 is chosen for Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list, GenotypeData.Observation45 , is chosen for Customized Observations. Click the Specify Model button to open the Specify Model window: For Survival Analysis, the user needs to have design columns containing at least three pieces of information. First, the Time column must be set (in this case, use the SurvivalTime column). Second, the Status column must be set (in this case, use the column Status ). Finally, the Event must be set (using Death from the Status column). Strata and other covariate factors can also be added to the model at this stage as well. However, for this tutorial, just leave Genotype in the model. Click OK to return to the Quantitative Trait window. At this point, the updated model should be reflected in the window. Under Options , ensure that the Generate hazard ratio data is selected, and that Genotypic is chosen for the Disease model . Other available diseases models include Additive , Dominant , and Recessive . Multiplicity should be set to FDR_BH , with an Alpha level of 0.05 and a Confidence interval of 0.95. Set the Anova type to Type3, and set the Test type to WaldTest (the other option is LikelihoodRatio test). Finally, set Output name to Survival Trait . Click Submit to run the Quantitative Trait association analysis. Two tables will be generated in the Inference section of the Solution Explorer , Survival Trait.HazrdRatios and Survival Trait.Tests data . Finally, notice in the Lists section of the Solution Explorer , that each of our analyses has generated lists of significant genes, based on our criteria of an FDR-BH adjusted p-value of 0.05. Let s use our survival analysis List with the previously generated SurvivalView in the GenotypeData dataset to see what these markers look like. First, reopen the SurvivalView of the GenotypeData dataset by double-clicking it in the Solution Explorer . Next, once the SurvivalView is opened, go to the Variables filter in the View Controller . Select the ID column of the filter, and expand it. Note If the main view window shows an error message, stating that there is missing or negative information in Y, you will need to re-filter the Observations to ONLY include the JPT subjects as the remaining subjects do not include survival time information, and this filter had been previously removed. To add a filter based on a list, right click on ID and choose Add List Filter . Select the Survival Trait.Association.Sig6 which contains the six significant markers in the survival trait analysis, and then click OK . The main view window is updated to only show the 6 charts from the significant markers. Congratulations! You have completed four different association analyses in Array Studio . Save your project file, in case you want to go back to it in the future. In the next chapter, we will look at further visualizations that can be used on the analysis results.","title":"Association Analysis"},{"location":"tutorials/SNP/Association_Analysis/#association-analysis","text":"Besides visualization, summarization, and QC data, Array Studio contains a powerful set of tools for SNP association analysis. Users can analyze data using Single-Marker Association tests or Two-Marker Association tests. Available tests include Basic Association , Stratified Association (single marker only), Quantitative Trait , Categorical Trait , Survival Trait , Repeated Measure Trait , as well as Dose Data and Probability Data Association tests (also CNV analysis modules are available). In this tutorial, we will cover basic association, categorical trait, quantitative trait, and survival trait analysis.","title":"Association Analysis"},{"location":"tutorials/SNP/Association_Analysis/#basic-association-single-marker","text":"Single marker-basic association analysis is based on Fisher s Exact test to test the allele frequency difference between Case/Control traits. To start a single marker-basic association analysis, go to Genotyping Menu | Single Marker Association | Basic Association to open the Basic Association window. As usual, ensure that the Project is Tutorial and Data is GenotypeData and the Variables are set to customized variables using the list GenotypeData.Variable31008 . For all of our association analyses, we only have design information for the JPT group, so use the Observation list GenotypeData.Observation45 that was created in the last chapter during the Filter step (use customized observation list). Under Options , We need to set the design column containing the Trait we wish to analyze, in this case Phenotype (Note: By default, Array Studio should have chosen this as the Trait , due to the selection of Group as the Phenotype column when importing the Design Table ). Next, we need to set the Case level. As the levels of Group are named case and control, we should choose Case as our Case level. User can use following options to decide which statistics to include in the result: Generate the Minor allele (make sure it s checked) Minor allele count Allelic test p-value and odds ratio (make sure it s checked) Genotypic test p-value (uncheck this box) Dominant test p-value Recessive test p-value Additive test p-value Note While it is possible to run this analysis and test for a genotypic p-value, dominant test p-value, recessive test p-value, additive test p-value, and use Fisher Exact test instead of Chi-square test, for the purposes of this tutorial we will only investigate the allelic test Chi-square p-value and asymptotic odds ratio (Fisher Exact test will give exact odds ratio). We can set the Multiplicity adjustment for the test (leave as is with FDR_BH , an Alpha level of 0.05 , and a Confidence interval of 0.95 ). Finally, change the Output name to Basic Association and click Submit to run the basic association test. A new Table will be created in the Solution Explorer under the Inference section. All association analyses in Array Studio will generate Inference Reports . Notice the name of the report, Basic Association.Tests (as this is the name we specified above), and the type the report InferenceReport Data . A TableView called Report will be generated by default and immediately visible in the main view window (make sure filters are cleared to see all variables). All of the requested information is now available for each marker, including the MinorAllele, Allelic.RawPvalue, Allelic.AdjustedPValue, and Allelic.OddsRatio. The Odds Ratio also includes the confidence interval. The last 5 columns are the appended annotation table. Right click in the header of the Allelic.RawPvalue column and select Sort Ascending . The TableView is sorted, showing the most significant markers based on this analysis. We can also choose to filter this view, and we can do so using any of the generated columns (p-value, adjusted p-value etc.) or any of the annotation columns. As we are going to run three more similar analyses (categorical, quantitative and survival traits), we will do some filtering by p-value in later chapters.","title":"Basic Association Single Marker"},{"location":"tutorials/SNP/Association_Analysis/#categorical-trait-single-marker","text":"To run a single marker-categorical trait analysis, go to the Genotyping Menu | Single Marker Analysis | Categorical Trait . As always, ensure that Tutorial is chosen for Project, GenotypeData is chosen for Data , GenotypeData.Variable31008 is chosen for Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list, GenotypeData.Observation45 , is chosen for Customized Observations . Click the Specify Model button to open the Specify Model window: Set the Trait to Group2 . Notice that the type of trait is now recognized as a Categorical Trait , and lists the three categories. Note: for categorical traits, the user can specify whether the data is ordered. If it is ordered, it should be analyzed differently (using cumulative odds logistic regression instead of generalized logistic regression), and the Levels are ordered checkbox should be checked when running the model for this dataset. Check the Levels are ordered checkbox now (Array Studio has the ability to deal with nominal traits or ordinal traits). Additional covariates could be added to the model at this point, including potential principal component analysis components. However, for this tutorial, leave the model as is ( Categorical Trait is Group2 , ordered , model only includes Genotype ). Click OK to return to the Categorical Trait window. At this point, the updated model should be reflected in the window. Ensure that Generate odds ratio data and Generate odds data is selected. Ensure that Genotypic is chosen for the Disease model . Other available diseases models include Additive , Dominant , and Recessive . Multiplicity should be set to FDR_BH , with an Alpha level of 0.05 and a Confidence interval of 0.95. Set the Anova type to Type3, and set the Test type to WaldTest (the other option is LikelihoodRatio test). Finally, set Output name to Categorical Trait . If the user is interested, the equivalent SAS code can be generated after all options are set, by clicking the Show SAS code button. Click Submit to run the Categorical Trait association analysis. Three new Tables will be generated under the Inference section of the Solution Explorer : the standard Tests table, as well as the requested Odds and OddsRatio Tables . Double click on the Categorical Trait.Tests Report to display the TableView in the main view window. If this data is filtered, reset all filters to see all variables. Notice that the Categorical Trait.OddsRatio table contains two views: an OddsRatio view and a Table view. Switch to the OddsRatio view now by double-clicking it. The OddsRatio table will only be generated for significant genotypes. Remove any filters on this view, and notice that there are 3 charts that were generated. To view all 3 charts in the same time, change to 2*2 in the drop down list. The user can also see the TableView information for the OddsRatio by double-clicking the generated table view. In this TableView , each row contains the marker ID, the group that is being compared, and the p-value, as well as the odds ratio and confidence intervals. Annotation information is also included. Finally, a Table has been created for viewing the Odds. This includes a visualization of the Odds , as well as a TableView . Double-click on the Odds view now to open it in the main view window. Double-click on the TableView of Odds now to see the generated Odds for each group.","title":"Categorical Trait Single Marker"},{"location":"tutorials/SNP/Association_Analysis/#quantitative-trait-single-markergeneral","text":"To run a single marker-quantitative trait, go to Genotyping | Single Marker Analysis | Quantitative Trait (General) , which opens the Quantitative Trait window. As always, ensure that Tutorial is chosen for Project , GenotypeData is chosen for Data , and GenotypeData.Variable31008 is chosen for Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list, GenotypeData.Observation45 , is chosen for Customized Observations. Click the Specify Model button to open the Specify Model window: The first step in this window is to select the quantitative trait to be used for analysis. For Trait , choose the column Qtrait , as this contains our quantitative trait information. If the correct column is selected, the box to the right will indicate that the type of trait is indeed a quantitative trait. Next, we can add any covariates to our model. Normally, this may include generated components from a principal component analysis. For this tutorial, we will just add the columns labeled Covariate 1 and Covariate 2 . They can be added by selecting both of these columns (under Columns ), and clicking the Add button to add them to the model. Notice that Qtrait , Covariate 1 and Covariate 2 are set to Class , uncheck the box for them. Click OK to return to the Quantitative Trait window. At this point, the updated model should be reflected in the window. Under Options , ensure that Generate LSMeans data is selected, as well as Generate contrast data , and that Genotypic is chosen for the Disease model . Other available diseases models include Additive , Dominant , and Recessive . Multiplicity should be set to FDR_BH , with an Alpha level of 0.05 and a Confidence interval of 0.95. Set the Anova type to Type3, and set the Test type to WaldTest (the other option is LikelihoodRatio test). Finally, set Output name to Categorical Trait . Click Submit to run the Quantitative Trait association analysis. Three new Tables will be generated under the Inference tab of the Solution Explorer : an LSMeans (least square mean) Table, a Contrasts Table and a Tests table. The Tests table is similar to the Table encountered with the Basic Association analysis and with the categorical association analysis. Ensure that the Report TableView for Quantitative Trait.Tests is showing in the main view window. Reset any filters if need. Next, let s filter the table, to only show us markers where the GENOTYPE.FDR_BH (adjusted p-value) is less than 0.05 (enter \"<0.05\" into the GENOTYPE.FDR_BH filter). This should show a TableView containing 12 rows. Let s further sort these rows by the adjusted p-value column, so that the most significant markers are shown first, as shown below. Select the top three markers now, by clicking on the header row names in the ID column. Now, let s generate a ChromosomeView for this data. To add a ChromosomeView , right click Quantitative Trait.Tests , click on Add View and then choose ChromosomeView . When added, it should look similar to the following screenshot. Only two chromosomes are shown, because the data was previously filtered. We will un-filter this data in one minute, but first, let s check to see whether the three selected markers (with the same p-values) are in linkage disequilibrium. To generate Linkage Disequilibrium results on demand, click the LD On Demand button in the Task tab of the View Controller . This generates a correlation heatmap of our selected rows, with a red color indicating higher correlation. The coloring scheme can be changed by clicking the Customize View window in this window If the Correlation Heatmap does not look similar to the screen shot above, click the Customize View button and remove any Variable filters. It is clear from the perfect correlation values (=1), that these three markers are in complete linkage disequilibrium. Close the window and return to the ChromosomeView . Now, remove the previously set p-value filter. Your ChromosomeView should now look similar to below. In this view, you can see all of the Chromosomes in your experiment, and then each chromosome has lines colored, based on a certain criteria. Click the Specify Data Source option in the Task tab of the View Controller . Note that the Genotype.RawPValue option is chosen. This means that the color is based on this column. Click OK to return to the view. Now click the Change Color Properties option in the Task tab of the View Controller . This dialog box shows you how the chart is colored. In this case, high p-values are colored as a clear color, while low p-values are colored as blue. The user can also specify what counts as a high and low p-value. Feel free to change the colors, and/or the high and low p-values, and reflect the changes on the chart. The user also has the option of looking at each individual chromosome in its own chart. This can be accomplished by clicking the Trellis by Chromosome option in the Task tab of the View Controller . Click this option now and the view should reflect the screenshot below. Scroll through the charts, to see all of the chromosomes. Notice that the Y-axis of the chart represents the log10 (p-value). This is a fully interactive view as well, so individual data points can be selected and viewed in the Details Window . When selected, points turn a red color. Array Studio also generated LSMeans table and charts for the quantitative data. Switch to the LSMeans view for the Table Quantitative Trait.LSMeans . By default, LSMeans data was generated for each significant marker (as we noted earlier, there are 12 significant markers, with an adjusted p-value<0.05). Scroll through the charts and take a look at the data (unfilter the data if necessary). It is clear that for each significant marker, the different genotypes have different least square mean values for the quantitative trait. A Table view of the LSMeans data was also generated and can be opened and viewed at any time. Finally, a Contrasts Table was generated, with a Contrasts view, as well as a Table view. Double-click the Contrasts view now. On the X-axis is each contrast (i.e. A_T vs. A_A, T_T vs. A_A), with the Y-axis the value of the estimate. A Table view was created for the Contrasts dataset. This can be opened and viewed at any time.","title":"Quantitative Trait Single Marker(General)"},{"location":"tutorials/SNP/Association_Analysis/#survival-trait-single-marker","text":"Survival Trait analysis could be an important component of any SNP study from clinical trials. As we noted earlier, it is possible to generate a SurvivalView in Array Studio . However, we can also perform single-marker and two-marker survival trait association analysis. Single-Marker Survival Trait analysis will be demonstrated in this tutorial. To perform this analysis, go to the menu Genotyping | Single Marker Association | Survival Trait . As always, ensure that Tutorial is chosen for Project , GenotypeData is chosen for Data , GenotypeData.Variable31008 is chosen for Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list, GenotypeData.Observation45 , is chosen for Customized Observations. Click the Specify Model button to open the Specify Model window: For Survival Analysis, the user needs to have design columns containing at least three pieces of information. First, the Time column must be set (in this case, use the SurvivalTime column). Second, the Status column must be set (in this case, use the column Status ). Finally, the Event must be set (using Death from the Status column). Strata and other covariate factors can also be added to the model at this stage as well. However, for this tutorial, just leave Genotype in the model. Click OK to return to the Quantitative Trait window. At this point, the updated model should be reflected in the window. Under Options , ensure that the Generate hazard ratio data is selected, and that Genotypic is chosen for the Disease model . Other available diseases models include Additive , Dominant , and Recessive . Multiplicity should be set to FDR_BH , with an Alpha level of 0.05 and a Confidence interval of 0.95. Set the Anova type to Type3, and set the Test type to WaldTest (the other option is LikelihoodRatio test). Finally, set Output name to Survival Trait . Click Submit to run the Quantitative Trait association analysis. Two tables will be generated in the Inference section of the Solution Explorer , Survival Trait.HazrdRatios and Survival Trait.Tests data . Finally, notice in the Lists section of the Solution Explorer , that each of our analyses has generated lists of significant genes, based on our criteria of an FDR-BH adjusted p-value of 0.05. Let s use our survival analysis List with the previously generated SurvivalView in the GenotypeData dataset to see what these markers look like. First, reopen the SurvivalView of the GenotypeData dataset by double-clicking it in the Solution Explorer . Next, once the SurvivalView is opened, go to the Variables filter in the View Controller . Select the ID column of the filter, and expand it. Note If the main view window shows an error message, stating that there is missing or negative information in Y, you will need to re-filter the Observations to ONLY include the JPT subjects as the remaining subjects do not include survival time information, and this filter had been previously removed. To add a filter based on a list, right click on ID and choose Add List Filter . Select the Survival Trait.Association.Sig6 which contains the six significant markers in the survival trait analysis, and then click OK . The main view window is updated to only show the 6 charts from the significant markers. Congratulations! You have completed four different association analyses in Array Studio . Save your project file, in case you want to go back to it in the future. In the next chapter, we will look at further visualizations that can be used on the analysis results.","title":"Survival Trait Single Marker"},{"location":"tutorials/SNP/Introduction/","text":"Introduction Array studio Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio. Downloading the SNP Sample Data This chapter will cover the import of the .MAP and .PED file sample dataset, as well as the attachment of the pedigree and phenotype covariate information to the dataset (the Design Table ). For this tutorial, the following files will be required: The GenotypeData.ped file The GenotypeData.map file The SNP.design.txt file, derived from the simulated sample covariate information for this study. These files are available in a zipped resource file located on the Omicsoft web server at the following URL: link The SNP sample data contains 90 samples and 45,930 SNPs. The 90 observations are split into their two sources, Japanese and Chinese (JPT and CHN). Additional covariate information includes a simulated Group column (for an example of case/control association analysis), a simulated Group2 column (for an example of categorical trait association analysis), a simulated Qtrait column (for an example of quantitative trait association analysis), and simulated Survival Time and Status columns (for an example of survival trait association analysis). The size of the original dataset has been reduced because of the large size of the imported data files, but Array Studio can handle millions of SNPs and many thousands of observations. The SNP.Design.txt file contains the design information for the tutorial s study, including columns for Source, Sex, Group, Group2, Qtrait, Covariate 1, Covariate 2, Survival Time, and Status . A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed ID , that contains the exact file names of the SNP arrays used in the experiment (it has to match the names of the Affymetrix .CHP files, or the names listed in the Illumina text file, etc.). Additional columns usually include disease status, quantitative traits, etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into Array Studio . An example design table is shown below. After downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial). Creating a New Project When Array Studio is first installed, it will look similar to what is displayed below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. The Workflow window should be visible on the left side of the screen. If the window is not visible, go to the View Menu | Show Workflow . The Workflow window should appear similar to the screenshot below. This window provides users, especially new users, with a guide to running different types of analysis. Click the Workflow dropdown box now and select Genotype . To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window. Array Studio allows the user to create two different project types: A simple project, in which the project is saved in a single file (recommended for microarray and RT-PCR projects). A distributed project, where data are saved in separate files (recommended for exon array, CNV, or genotyping projects). Choose the Create a distributed project option. Click the Browse button to choose a location and name for the project. Click OK to continue. Switch to the Solution Explorer by clicking on the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, open to it by going to the menu bar and choosing View | Show Solution Explorer . The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples). Importing SNP Data and Attaching Design Table To import our sample SNP data, click Add genotype data in the Workflow Window, or click the Add Data |Add -Omic Data button in the toolbar, and then choose Add Genotype Data . This opens the Specify Genotype Data Source window. In this window, the user can choose the Genotype Data Source for input. Choices include using the import Wizard , SNP Data: PED file + Map file , SNP Data: Transposed PED file + Family file , SNP Data: PLINK binary file (.bed) , SNP Data: Affymetrix CEL files , SNP Data: Affymetrix .CHP files , SNP Data: Illumina genotype final report (standard) , Genotype data: PED file + Map file , Genotype data: Transposed PED file +Family file , SNP Dose data: output from MACH(.mldose) , and SNP Probability data: output from MACH(.mlprob) . In Array Studio, with SNP data, all markers are assumed to be biallelic, with support for millions of SNPs and thousands of samples. With Genotype data, all markers are not assumed to be biallelic, with support in Array Studio of up to 100K markers and hundreds of samples. The sample data is stored in the SNP Data: PED file + Map file format, so choose that option now, and click OK to continue. This brings up the Import PED File window. The first step in this window is to click the Browse button, and navigate to the GenotypeData.ped file downloaded earlier. Once the PED file is selected, the MAP file will be automatically selected as well. Array Studio assumes that the MAP file is located in the same directory as the PED file, so if this is not the case, the user can change the location of the MAP file. Once a file name has been selected, the user should verify any other information in the MAP and PED files, and set the checkboxes accordingly ( i.e. Family ID, Father ID, etc. ). Once all the information is confirmed click OK to continue. The import process should take approximately 10 seconds. Upon completion of importing, Array Studio will prompt the user to attach a Design to the data. If the user wishes to attach a design at a later time, this can be done as well (by right-clicking the Design folder of the dataset in the Solution Explorer ), however, it is recommended to build and have your design table ready for use upon import of the data. Click Yes to begin the Design import process. Array Studio will prompt the user to specify a table source. As the design table for the sample data is in a tab delimited file format, choose that option now, and click OK . When prompted, choose the SNP.design.txt file that was unzipped earlier, and click Open to attach the design table to the dataset. Once the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to Append to the existing covariate table (if one exists) and to Use the name order in the new covariate table . Leave these options as default. After choosing a design file, the user is prompted with a Set Columns window. In this window, the user can inform Array Studio if any of the imported design columns pertains to FamilyID , IndividualID , FatherID , MotherID , Sex , or Phenotype . Some of this information is used in different modules for analysis. By default, these columns should be set correctly, since this data was included in the .PED and .MAP files. If the user chooses not to set the columns at this time, they can later reopen the design table, and later use the Table Menu | Columns | Column Properties to set the column mode. For this tutorial, these columns need not be set and can you can just select the \"OK\" button. Once imported, Array Studio should look similar to the following screenshot. By default, a TableView is created for the imported dataset. Also, note that a new data object has been added under the Omic Data section of the Solution Explorer (on the left-hand side of the screen). The Solution Explorer can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset, GenotypeData , Array Studio lists the number of rows and columns (or markers and observations) in the dataset. In this case, there are 45,930 markers and 90 observations. The Solution Explorer also provides the user with information on the different views that have been created. Notice that there is a TableView for dataset GenotypeData , as well as for Annotation and Design (Expand the nodes to see this). User can double-click either of these views (named Table ), and open them in the main view window. Congratulations! You have successfully imported your first SNP dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.","title":"Introduction"},{"location":"tutorials/SNP/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/SNP/Introduction/#array-studio","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer , which organizes each project into Data, QC, Table, List, Cluster, Text, Attachments and other categories. Multiple projects can be opened simultaneously in the Solution Explorer , and data can be shared among projects. Each view is controlled by a View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the Details Window and Web Details On-Demand . It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.","title":"Array studio"},{"location":"tutorials/SNP/Introduction/#downloading-the-snp-sample-data","text":"This chapter will cover the import of the .MAP and .PED file sample dataset, as well as the attachment of the pedigree and phenotype covariate information to the dataset (the Design Table ). For this tutorial, the following files will be required: The GenotypeData.ped file The GenotypeData.map file The SNP.design.txt file, derived from the simulated sample covariate information for this study. These files are available in a zipped resource file located on the Omicsoft web server at the following URL: link The SNP sample data contains 90 samples and 45,930 SNPs. The 90 observations are split into their two sources, Japanese and Chinese (JPT and CHN). Additional covariate information includes a simulated Group column (for an example of case/control association analysis), a simulated Group2 column (for an example of categorical trait association analysis), a simulated Qtrait column (for an example of quantitative trait association analysis), and simulated Survival Time and Status columns (for an example of survival trait association analysis). The size of the original dataset has been reduced because of the large size of the imported data files, but Array Studio can handle millions of SNPs and many thousands of observations. The SNP.Design.txt file contains the design information for the tutorial s study, including columns for Source, Sex, Group, Group2, Qtrait, Covariate 1, Covariate 2, Survival Time, and Status . A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed ID , that contains the exact file names of the SNP arrays used in the experiment (it has to match the names of the Affymetrix .CHP files, or the names listed in the Illumina text file, etc.). Additional columns usually include disease status, quantitative traits, etc. (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into Array Studio . An example design table is shown below. After downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial).","title":"Downloading the SNP Sample Data"},{"location":"tutorials/SNP/Introduction/#creating-a-new-project","text":"When Array Studio is first installed, it will look similar to what is displayed below. If you have previously opened projects in Array Studio, you will see the Last Opened Projects window. If so, just click cancel so that Array Studio looks similar to below. The Workflow window should be visible on the left side of the screen. If the window is not visible, go to the View Menu | Show Workflow . The Workflow window should appear similar to the screenshot below. This window provides users, especially new users, with a guide to running different types of analysis. Click the Workflow dropdown box now and select Genotype . To create a new project, click the New Project button in the Workflow, or the New button on the toolbar, or go to File Menu, then click New Project . This opens the New Project window. Array Studio allows the user to create two different project types: A simple project, in which the project is saved in a single file (recommended for microarray and RT-PCR projects). A distributed project, where data are saved in separate files (recommended for exon array, CNV, or genotyping projects). Choose the Create a distributed project option. Click the Browse button to choose a location and name for the project. Click OK to continue. Switch to the Solution Explorer by clicking on the Solution Explorer tab, which should be found at the bottom of the Workflow Window . If the Solution Explorer tab is not visible, open to it by going to the menu bar and choosing View | Show Solution Explorer . The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples).","title":"Creating a New Project"},{"location":"tutorials/SNP/Introduction/#importing-snp-data-and-attaching-design-table","text":"To import our sample SNP data, click Add genotype data in the Workflow Window, or click the Add Data |Add -Omic Data button in the toolbar, and then choose Add Genotype Data . This opens the Specify Genotype Data Source window. In this window, the user can choose the Genotype Data Source for input. Choices include using the import Wizard , SNP Data: PED file + Map file , SNP Data: Transposed PED file + Family file , SNP Data: PLINK binary file (.bed) , SNP Data: Affymetrix CEL files , SNP Data: Affymetrix .CHP files , SNP Data: Illumina genotype final report (standard) , Genotype data: PED file + Map file , Genotype data: Transposed PED file +Family file , SNP Dose data: output from MACH(.mldose) , and SNP Probability data: output from MACH(.mlprob) . In Array Studio, with SNP data, all markers are assumed to be biallelic, with support for millions of SNPs and thousands of samples. With Genotype data, all markers are not assumed to be biallelic, with support in Array Studio of up to 100K markers and hundreds of samples. The sample data is stored in the SNP Data: PED file + Map file format, so choose that option now, and click OK to continue. This brings up the Import PED File window. The first step in this window is to click the Browse button, and navigate to the GenotypeData.ped file downloaded earlier. Once the PED file is selected, the MAP file will be automatically selected as well. Array Studio assumes that the MAP file is located in the same directory as the PED file, so if this is not the case, the user can change the location of the MAP file. Once a file name has been selected, the user should verify any other information in the MAP and PED files, and set the checkboxes accordingly ( i.e. Family ID, Father ID, etc. ). Once all the information is confirmed click OK to continue. The import process should take approximately 10 seconds. Upon completion of importing, Array Studio will prompt the user to attach a Design to the data. If the user wishes to attach a design at a later time, this can be done as well (by right-clicking the Design folder of the dataset in the Solution Explorer ), however, it is recommended to build and have your design table ready for use upon import of the data. Click Yes to begin the Design import process. Array Studio will prompt the user to specify a table source. As the design table for the sample data is in a tab delimited file format, choose that option now, and click OK . When prompted, choose the SNP.design.txt file that was unzipped earlier, and click Open to attach the design table to the dataset. Once the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to Append to the existing covariate table (if one exists) and to Use the name order in the new covariate table . Leave these options as default. After choosing a design file, the user is prompted with a Set Columns window. In this window, the user can inform Array Studio if any of the imported design columns pertains to FamilyID , IndividualID , FatherID , MotherID , Sex , or Phenotype . Some of this information is used in different modules for analysis. By default, these columns should be set correctly, since this data was included in the .PED and .MAP files. If the user chooses not to set the columns at this time, they can later reopen the design table, and later use the Table Menu | Columns | Column Properties to set the column mode. For this tutorial, these columns need not be set and can you can just select the \"OK\" button. Once imported, Array Studio should look similar to the following screenshot. By default, a TableView is created for the imported dataset. Also, note that a new data object has been added under the Omic Data section of the Solution Explorer (on the left-hand side of the screen). The Solution Explorer can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset, GenotypeData , Array Studio lists the number of rows and columns (or markers and observations) in the dataset. In this case, there are 45,930 markers and 90 observations. The Solution Explorer also provides the user with information on the different views that have been created. Notice that there is a TableView for dataset GenotypeData , as well as for Annotation and Design (Expand the nodes to see this). User can double-click either of these views (named Table ), and open them in the main view window. Congratulations! You have successfully imported your first SNP dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.","title":"Importing SNP Data and Attaching Design Table"},{"location":"tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/","text":"Marker Statistics, Data Filtering, and Population Structure Marker Statistics In Array Studio , the user can generate a number of different summary and QC statistics. In particular, the user can generate Marker Statistics or Subject Statistics . In this tutorial, we will just generate marker statistics, but the generation of subject statistics is very similar, and can be done by the user on their own. Go to Genotyping | Summarize/QC | Marker Statistics now. This brings up the Marker Statistics window. All module windows in Array Studio follow a similar pattern to this one. First, the user can select the Project and Data to be analyzed; in this case the only project opened is Tutorial SNP and our only Data is Genotype Data . Next, if the user has generated a list of variables/markers (subset) for analysis, this can be selected. The user can also manually choose particular chromosomes for analysis. As we are really only interested in marker statistics for the Japanese population, and since these samples are currently filtered and are visible, choose Visible Observations (45) now, to ensure that only the visible subjects (i.e. the Japanese subjects) will be analyzed. First, a Group may be specified, and the marker statistics will be calculated separately for each group. Next, the user can choose to report a number of statistics, including Allele frequencies Minor allele frequency Missing genotype count Effective genotype count Missing genotype proportion Genotype frequencies Observed heterozygosity Gene Diversity HWE chi square p-value HWE exact p-value Inbreeding coefficient Silhouettes width (requires SNP intensity data, i.e. Affymetrix or Illumina). Leave the other settings as default, and click Submit to run the module. A new Table is generated under the Table | Summary folder of the Solution Explorer , called GenotypeData.MarkerSummary . It s evident from the solution explorer that this data contains 45930 rows (or markers) and 9 columns of information. Make sure that all variable filters are cleared. Once unfiltered, the TableView should look as follows. It contains a column for the minor allele frequency (Maf), missing genotype count and percentage, as well as the covariate information (AlleleA, AlleleB, Chromosome, and BasePairPosition). This table, like any other table views, can be filtered, sorted and customized using View Controller . Data Filtering Prior to SNP analysis, it is a good idea to filter the markers and subjects, to exclude markers and subjects with high missing data percentage, as well as exclude markers where the minor allele frequency (MAF) is below a certain cutoff. Other options include removing markers due to an extremely significant Hardy Weinberg Equilibrium (HWE) p-value. To filter genotype or SNP data in Array Studio , go to the Genotyping Menu | Summarize/QC | Filter to open the Filter window, as shown below. In this window, make sure that the Project is set to Tutorial , Data is set to GenotypeData , Variables to All Variables , and Observations are set to Visible Observations (45) so that we filter only on the JPT subjects. For the options, First, a Group may be specified, and the marker statistics will be calculated separately for each group. By default the filter will exclude subjects with a missing percentage > 10% Exclude markers with a missing percentage > 10%. Change Exclude markers with MAF< to 0.05 (from default of 0.01). This is done because of the small number of subjects we have. This is a subjective criterion and the user can change. If we were interested, it is also possible to exclude markers with a HWE p-value < a cutoff. Also, note the Output type is Variable and Observation list for this module. This means that two Lists will be generated in the Solution Explorer as a result of filtering, a List of markers that passed the criteria, and a List of observations that passed the criteria. Optionally, the user can name the list as well. Click Submit to run the filtering. As can be seen below, two new Lists were generated by the module. All 45 JPN subjects passed the filter, as did 31008 markers. These Lists will be used for all further analysis. Population Structure - Principal Component Analysis Principle Component Analysis can be used with SNP and Genotyping data to get an idea of population structure. The components generated from this data can then be used as covariates when running the analysis model. In this tutorial, we will demonstrate how to run Principle Component Analysis (on the CHN and JPN subjects), but we will not use the generated component information for our modeling, because in our modeling we are not interested in CHN subjects. However, this can be easily accomplished with other experiment designs, if the necessary design information is available. To run Principle Component Analysis (PCA) , go to the Genotyping Menu | Pattern | Principle Component Analysis to open the Principle Component Analysis window. As always, ensure that the Project is set to Tutorial and GenotypeData is set as the Data . To choose the markers that passed the filters from our last step, choose the Select button next to Customized variables to open the Select List window. This allows the user to choose any variable list, including those from any open project in the Solution Explorer (as we only have one open project, the only lists shown are from the Tutorial SNP project). Choose the variable list31008 and click on OK to continue. Notice the Variables section in Principal Component Analysis window is updated. Observations should be left as the default All observations . Component number can be set to the user s choice number of components, but is set at 10 by default. Change the Group drop-down menu to Source . This does not affect the generation of the data; rather it provides automatic coloring using a group of the user s choosing. Source is chosen, so we distinguish between the CHN subjects and the JPT subjects to better visualize the population difference. For Coding , choose Eigenstrat which is a publicly recognized method for Principle Component Analysis, and probably most familiar to users. A classical genotypic method is also available. Ensure that Scale Markers and Output Scores are selected, as well as Calculate Hotelling T2 with alpha level of 0.05. Click Submit to run the Principle Component Analysis. Initially, the output only showing one group because our filter of JPT subjects has been carried over to every view. Now, choose CHN population or reset all filters using the button Clear All Filters . By default, Array Studio shows the first two components of the PCA, but this can be changed by using the Specify X Column and Specify Y Column options in the Task tab of the View Controller . Note: The outliers from the PCA analysis is a result of the default EigenStrat coding. Using the classical coding (genotypic) will remove this effect from the output. In practice, we recommend classical coding (using dummy variables to represent genotypes), although EigenStrat has been very popular in academia. Please contact Omicsoft to learn more details. The PCA has also generated a new PcaScore Table in the Table | Pattern section of the Solution Explorer . As stated earlier, all of the generated components can be used as covariates in the model. This will not be done in this tutorial, but to visualize all 10 components in a TableView , open up the view PcaScores by double clicking on it. This TableView could, in other circumstances, be incorporated into the design table of your SNP data, so that it could be used as covariates in further analysis. Congratulations! You have learned about Marker Analysis , Data Filtering , and Principal Component Analysis . In the next chapter, we will focus on different types of association analysis.","title":"Marker Statistics Data Filtering and Population Structure"},{"location":"tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#marker-statistics-data-filtering-and-population-structure","text":"","title":"Marker Statistics, Data Filtering, and Population Structure"},{"location":"tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#marker-statistics","text":"In Array Studio , the user can generate a number of different summary and QC statistics. In particular, the user can generate Marker Statistics or Subject Statistics . In this tutorial, we will just generate marker statistics, but the generation of subject statistics is very similar, and can be done by the user on their own. Go to Genotyping | Summarize/QC | Marker Statistics now. This brings up the Marker Statistics window. All module windows in Array Studio follow a similar pattern to this one. First, the user can select the Project and Data to be analyzed; in this case the only project opened is Tutorial SNP and our only Data is Genotype Data . Next, if the user has generated a list of variables/markers (subset) for analysis, this can be selected. The user can also manually choose particular chromosomes for analysis. As we are really only interested in marker statistics for the Japanese population, and since these samples are currently filtered and are visible, choose Visible Observations (45) now, to ensure that only the visible subjects (i.e. the Japanese subjects) will be analyzed. First, a Group may be specified, and the marker statistics will be calculated separately for each group. Next, the user can choose to report a number of statistics, including Allele frequencies Minor allele frequency Missing genotype count Effective genotype count Missing genotype proportion Genotype frequencies Observed heterozygosity Gene Diversity HWE chi square p-value HWE exact p-value Inbreeding coefficient Silhouettes width (requires SNP intensity data, i.e. Affymetrix or Illumina). Leave the other settings as default, and click Submit to run the module. A new Table is generated under the Table | Summary folder of the Solution Explorer , called GenotypeData.MarkerSummary . It s evident from the solution explorer that this data contains 45930 rows (or markers) and 9 columns of information. Make sure that all variable filters are cleared. Once unfiltered, the TableView should look as follows. It contains a column for the minor allele frequency (Maf), missing genotype count and percentage, as well as the covariate information (AlleleA, AlleleB, Chromosome, and BasePairPosition). This table, like any other table views, can be filtered, sorted and customized using View Controller .","title":"Marker Statistics"},{"location":"tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#data-filtering","text":"Prior to SNP analysis, it is a good idea to filter the markers and subjects, to exclude markers and subjects with high missing data percentage, as well as exclude markers where the minor allele frequency (MAF) is below a certain cutoff. Other options include removing markers due to an extremely significant Hardy Weinberg Equilibrium (HWE) p-value. To filter genotype or SNP data in Array Studio , go to the Genotyping Menu | Summarize/QC | Filter to open the Filter window, as shown below. In this window, make sure that the Project is set to Tutorial , Data is set to GenotypeData , Variables to All Variables , and Observations are set to Visible Observations (45) so that we filter only on the JPT subjects. For the options, First, a Group may be specified, and the marker statistics will be calculated separately for each group. By default the filter will exclude subjects with a missing percentage > 10% Exclude markers with a missing percentage > 10%. Change Exclude markers with MAF< to 0.05 (from default of 0.01). This is done because of the small number of subjects we have. This is a subjective criterion and the user can change. If we were interested, it is also possible to exclude markers with a HWE p-value < a cutoff. Also, note the Output type is Variable and Observation list for this module. This means that two Lists will be generated in the Solution Explorer as a result of filtering, a List of markers that passed the criteria, and a List of observations that passed the criteria. Optionally, the user can name the list as well. Click Submit to run the filtering. As can be seen below, two new Lists were generated by the module. All 45 JPN subjects passed the filter, as did 31008 markers. These Lists will be used for all further analysis.","title":"Data Filtering"},{"location":"tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#population-structure-principal-component-analysis","text":"Principle Component Analysis can be used with SNP and Genotyping data to get an idea of population structure. The components generated from this data can then be used as covariates when running the analysis model. In this tutorial, we will demonstrate how to run Principle Component Analysis (on the CHN and JPN subjects), but we will not use the generated component information for our modeling, because in our modeling we are not interested in CHN subjects. However, this can be easily accomplished with other experiment designs, if the necessary design information is available. To run Principle Component Analysis (PCA) , go to the Genotyping Menu | Pattern | Principle Component Analysis to open the Principle Component Analysis window. As always, ensure that the Project is set to Tutorial and GenotypeData is set as the Data . To choose the markers that passed the filters from our last step, choose the Select button next to Customized variables to open the Select List window. This allows the user to choose any variable list, including those from any open project in the Solution Explorer (as we only have one open project, the only lists shown are from the Tutorial SNP project). Choose the variable list31008 and click on OK to continue. Notice the Variables section in Principal Component Analysis window is updated. Observations should be left as the default All observations . Component number can be set to the user s choice number of components, but is set at 10 by default. Change the Group drop-down menu to Source . This does not affect the generation of the data; rather it provides automatic coloring using a group of the user s choosing. Source is chosen, so we distinguish between the CHN subjects and the JPT subjects to better visualize the population difference. For Coding , choose Eigenstrat which is a publicly recognized method for Principle Component Analysis, and probably most familiar to users. A classical genotypic method is also available. Ensure that Scale Markers and Output Scores are selected, as well as Calculate Hotelling T2 with alpha level of 0.05. Click Submit to run the Principle Component Analysis. Initially, the output only showing one group because our filter of JPT subjects has been carried over to every view. Now, choose CHN population or reset all filters using the button Clear All Filters . By default, Array Studio shows the first two components of the PCA, but this can be changed by using the Specify X Column and Specify Y Column options in the Task tab of the View Controller . Note: The outliers from the PCA analysis is a result of the default EigenStrat coding. Using the classical coding (genotypic) will remove this effect from the output. In practice, we recommend classical coding (using dummy variables to represent genotypes), although EigenStrat has been very popular in academia. Please contact Omicsoft to learn more details. The PCA has also generated a new PcaScore Table in the Table | Pattern section of the Solution Explorer . As stated earlier, all of the generated components can be used as covariates in the model. This will not be done in this tutorial, but to visualize all 10 components in a TableView , open up the view PcaScores by double clicking on it. This TableView could, in other circumstances, be incorporated into the design table of your SNP data, so that it could be used as covariates in further analysis. Congratulations! You have learned about Marker Analysis , Data Filtering , and Principal Component Analysis . In the next chapter, we will focus on different types of association analysis.","title":"Population Structure - Principal Component Analysis"},{"location":"tutorials/SNP/Save_Close_Project/","text":"Save & Close Project Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to Genotyping analysis and visualization. Feel free to try different options in the Task tab or the Genotyping menu to get a feel for what Array Studio can do. For additional information, don't hesitate to contact Omicsoft's support team ( support@omicsoft.com ). Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) for sales-related questions.","title":"Save/Close Project"},{"location":"tutorials/SNP/Save_Close_Project/#save-close-project","text":"Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in for form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of, with reference to Genotyping analysis and visualization. Feel free to try different options in the Task tab or the Genotyping menu to get a feel for what Array Studio can do. For additional information, don't hesitate to contact Omicsoft's support team ( support@omicsoft.com ). Thank you for using Array Studio. Please contact Omicsoft Support ( support@omicsoft.com ) or Omicsoft Sales ( sales@omicsoft.com ) for sales-related questions.","title":"Save &amp; Close Project"},{"location":"tutorials/SNP/Visualization_of_Data/","text":"Visualization of Data The TableView Upon import, Array Studio will automatically generate a TableView for the genotyping or SNP data. The TableView in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each marker is a row. Genotype information is shown in each cell (in this case, A_A, C_C, C_T, etc.). Scroll through the data now to see the speed that Array Studio can display data. Please refer to Microarray Tutorial for different options and filters for table view. The Details Window and Web Details Array Studio includes a feature called Details on Demand . In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the Details Window (at the bottom of the screen). Click on a marker in the row header of the TableView , and notice that the marker name changes to green. This indicates that this row has been selected, and information is available in the Details Window . If the Details Window is not currently visible at the bottom of the screen, switch to it by selecting View Menu | Show Details Window . Note that all of the annotation information for the selected row or rows is shown in the Details Window . The Details Window can also be used to show information about a particular observation (subject in this tutorial). Click the header row of one of the subjects now. Array Studio also includes a feature called Web Details on Demand , supported by default for Illumina and Affymetrix chips. This allows the user to find out detailed information on particular marker from a few public databases/websites (available websites depend on the user s choice and the chip type). To access Web Details , right click on any marker row header column, in either the TableView or Details Window . Available Web Details for this particular marker and chip are Hapmap, NCBI, and UCSC. Select any one of the three options. This will open a new Internet Explorer browser window. An example Hapmap Web Details window is shown below (if the link does not work, open HapMap homepage first and then try again). Now clear all row and column selections for next step: visualization in HistogramView and AlleleSignalView . HistogramView and AlleleSignalView While the speed and flexibility of the TableView are nice, it is the other views in Array Studio that really allow it to stand out over other programs when it comes to visualizations. The HistogramView , along with the AlleleSignalView (only available for Illumina imported and Affymetrix imported data), will allow the user to further investigate individual markers in the dataset. To add a HistogramView , right-click on GenotypeData , and click Add View . This brings up the now familiar Add View window. Choose HistogramView and click OK . Array Studio should now display a HistogramView . This view shows one chart for each marker, split by the three genotypes. Scroll through the charts, and notice that you are scrolling through almost 46,000 charts. At this point, let s filter by the marker rs2235523 . The view should now look similar to below. Notice that all three genotypes are represented in the data. We can use any of our covariate design information to make this view more informative. For most of the rest of the tutorial, we are going to work with only the JPT population from this study. The reason for this is that we only have simulated covariate information for the JPT population. So, to filter to only see the JPT population, switch to the Observation tab in the View Controller and expand the Source filter and choose JPT. The chart will update to show only the JPT population. Go back to the Task tab in the View Controller and click Specify Split Column . This allows the user to split each genotype, by a specified column in the Design Table . Choose Phenotype from the Choose Split Column window and click OK. The view is updated so that each genotype is now split by Status (Death and Censored). It is clear from looking at the chart that there is a difference between the two groups for some of the genotypes. Change to the Legend tab of the View Controller to see the Legend for the chart. Note The colors of the Legend can be changed by right-clicking on the different options in the Legend (alternatively, the colors can be changed using the options in the Task tab of the View Controller . The user can also change the Column properties for the selected field which links back to the design table. Array Studio can show on-the-fly p-value information (using a Fisher Exact test) for any marker in the Histogram View . Click the Show Summary Information button in the Customize section of the Task tab in the View Controller . Another view, called the AlleleSignalView , is available for data that include allele signal file (this view is not available for this tutorial as the allele signal information is not contained in the data imported via PED/MAP files). An example AlleleSignalView is shown below, along with the Silhouette values (in practice, the closer to 1 each silhouette value is, the better the genotype call. If you would like to get some recommendations for the empirical cutoff values, contact the Omicsoft support team). This view is not available for data imported via PED/MAP files, as the allele signal information is not contained in those files. The VariableView The VariableView is another useful view, as it can show numeric values for each marker. If the user has a quantitative trait (i.e., cholesterol level, systolic blood pressure, etc.), they can visualize individual markers for each genotype based on that trait. Add a VariableView now by right-clicking the -Omic data object and choosing Add View . When complete, the new view should look similar to below. By default, Array Studio has chosen a column to the response variable (using a numeric column). To verify that the response column is set as we want it to be (to the column Qtrait), go to the Task tab of the View Controller , and click the Specify Response Column button now. As we have a quantitative trait in our design table under the column Qtrait, ensure that it is chosen in the Choose Response Column window and click OK . Since the correct column was already chosen, the view is not changed. As we have the view filtered for the one specific marker, there is only one chart available. However, if we removed the filter, we\\'d be able to scroll through all 46000+ markers in the dataset, and look at the response by genotype. The VariableView can be further customized, using the Specify Split Column button in the Task tab of the View Controller . The split column will split each genotype by whatever categorical design column we choose, and automatically distinguish different groups by color. Click Specify Split Column now. For demonstration purposes, choose Phenotype from the Choose Split Column window now. The view is once again updated, with the two statuses now colored differently. Again, these views can be opened in PowerPoint, or the legend can be viewed by going to the Legend tab of the View Controller . The next customization is to jitter the data points so that they don t overlap to each other by using the Change Symbol Properties button in the Task tab of the View Controller (found in the Properties section). Choose this now. The Symbol Properties window allows the user to configure a number of different options. Notice that the Color By section has already been set to Status . Other options include changing the size of the symbols, rotation, shape, labels, and opacity. For demonstration purposes, let s increase the Jitter about \u2155 of the way to max. Then close this window to see the updated view. The view is updated, with each group now jittered so that the user can now see all the data points. The SurvivalView In SNP-related experiments from clinical trials, usually there is survival information available. Array Studio includes a special SurvivalView , for visualizing the time to event data. Let s add that now, in the usual way. When completed, it should look similar to the following. Array Studio is informing the user that the time column has not yet been specified. Click OK to continue and then specify the Time column in Task tab of View Controller . In the Task tab of the View Controller , click the Specify Time Column button. Choose SurvivalTime in the Choose Time Column window. The SurvivalTime column in our design table contains the information on time, needed for this view. Array Studio now informs the user that the Status column has not yet been specified. Click the Specify Status Column button in the Task tab of the View Controller , and then choose Status in the Choose Status Column window. Array Studio now informs the user to specify an Event . Click the Specify Event button in the Task tab of the View Controller . Array Studio now lists all the levels of events in the status column. For this study, available choices include Death or Censored . Choose Death and click OK . The SurvivalView is finally configured. Censored events are marked with a vertical line. The user can use this view to investigate different markers, based on survival time. It is clear in this case that there is a difference between the three genotypes, when it comes to survival time. Note: If you see the following message: Missing/negative data found in Y . Assure that that under the Observation tab in the View Controller has the source selected as below: At this point, it is recommended that the user save the project ( File Menu | Save) . If interested, the user can stop at this time. All filters, views, tables, etc., that have been generated in Array Studio are saved with the project, so the user could conceivably close the project, then reopen it, and continue right where they left off. Congratulations! You\\'ve now used many of the important views in Array Studio for analyzing SNP data. In the next chapter, we will investigate Marker Statistics, Data Filtering, and Population Structure.","title":"Visualization of Data"},{"location":"tutorials/SNP/Visualization_of_Data/#visualization-of-data","text":"","title":"Visualization of Data"},{"location":"tutorials/SNP/Visualization_of_Data/#the-tableview","text":"Upon import, Array Studio will automatically generate a TableView for the genotyping or SNP data. The TableView in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each marker is a row. Genotype information is shown in each cell (in this case, A_A, C_C, C_T, etc.). Scroll through the data now to see the speed that Array Studio can display data. Please refer to Microarray Tutorial for different options and filters for table view.","title":"The TableView"},{"location":"tutorials/SNP/Visualization_of_Data/#the-details-window-and-web-details","text":"Array Studio includes a feature called Details on Demand . In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the Details Window (at the bottom of the screen). Click on a marker in the row header of the TableView , and notice that the marker name changes to green. This indicates that this row has been selected, and information is available in the Details Window . If the Details Window is not currently visible at the bottom of the screen, switch to it by selecting View Menu | Show Details Window . Note that all of the annotation information for the selected row or rows is shown in the Details Window . The Details Window can also be used to show information about a particular observation (subject in this tutorial). Click the header row of one of the subjects now. Array Studio also includes a feature called Web Details on Demand , supported by default for Illumina and Affymetrix chips. This allows the user to find out detailed information on particular marker from a few public databases/websites (available websites depend on the user s choice and the chip type). To access Web Details , right click on any marker row header column, in either the TableView or Details Window . Available Web Details for this particular marker and chip are Hapmap, NCBI, and UCSC. Select any one of the three options. This will open a new Internet Explorer browser window. An example Hapmap Web Details window is shown below (if the link does not work, open HapMap homepage first and then try again). Now clear all row and column selections for next step: visualization in HistogramView and AlleleSignalView .","title":"The Details Window and Web Details"},{"location":"tutorials/SNP/Visualization_of_Data/#histogramview-and-allelesignalview","text":"While the speed and flexibility of the TableView are nice, it is the other views in Array Studio that really allow it to stand out over other programs when it comes to visualizations. The HistogramView , along with the AlleleSignalView (only available for Illumina imported and Affymetrix imported data), will allow the user to further investigate individual markers in the dataset. To add a HistogramView , right-click on GenotypeData , and click Add View . This brings up the now familiar Add View window. Choose HistogramView and click OK . Array Studio should now display a HistogramView . This view shows one chart for each marker, split by the three genotypes. Scroll through the charts, and notice that you are scrolling through almost 46,000 charts. At this point, let s filter by the marker rs2235523 . The view should now look similar to below. Notice that all three genotypes are represented in the data. We can use any of our covariate design information to make this view more informative. For most of the rest of the tutorial, we are going to work with only the JPT population from this study. The reason for this is that we only have simulated covariate information for the JPT population. So, to filter to only see the JPT population, switch to the Observation tab in the View Controller and expand the Source filter and choose JPT. The chart will update to show only the JPT population. Go back to the Task tab in the View Controller and click Specify Split Column . This allows the user to split each genotype, by a specified column in the Design Table . Choose Phenotype from the Choose Split Column window and click OK. The view is updated so that each genotype is now split by Status (Death and Censored). It is clear from looking at the chart that there is a difference between the two groups for some of the genotypes. Change to the Legend tab of the View Controller to see the Legend for the chart. Note The colors of the Legend can be changed by right-clicking on the different options in the Legend (alternatively, the colors can be changed using the options in the Task tab of the View Controller . The user can also change the Column properties for the selected field which links back to the design table. Array Studio can show on-the-fly p-value information (using a Fisher Exact test) for any marker in the Histogram View . Click the Show Summary Information button in the Customize section of the Task tab in the View Controller . Another view, called the AlleleSignalView , is available for data that include allele signal file (this view is not available for this tutorial as the allele signal information is not contained in the data imported via PED/MAP files). An example AlleleSignalView is shown below, along with the Silhouette values (in practice, the closer to 1 each silhouette value is, the better the genotype call. If you would like to get some recommendations for the empirical cutoff values, contact the Omicsoft support team). This view is not available for data imported via PED/MAP files, as the allele signal information is not contained in those files.","title":"HistogramView and AlleleSignalView"},{"location":"tutorials/SNP/Visualization_of_Data/#the-variableview","text":"The VariableView is another useful view, as it can show numeric values for each marker. If the user has a quantitative trait (i.e., cholesterol level, systolic blood pressure, etc.), they can visualize individual markers for each genotype based on that trait. Add a VariableView now by right-clicking the -Omic data object and choosing Add View . When complete, the new view should look similar to below. By default, Array Studio has chosen a column to the response variable (using a numeric column). To verify that the response column is set as we want it to be (to the column Qtrait), go to the Task tab of the View Controller , and click the Specify Response Column button now. As we have a quantitative trait in our design table under the column Qtrait, ensure that it is chosen in the Choose Response Column window and click OK . Since the correct column was already chosen, the view is not changed. As we have the view filtered for the one specific marker, there is only one chart available. However, if we removed the filter, we\\'d be able to scroll through all 46000+ markers in the dataset, and look at the response by genotype. The VariableView can be further customized, using the Specify Split Column button in the Task tab of the View Controller . The split column will split each genotype by whatever categorical design column we choose, and automatically distinguish different groups by color. Click Specify Split Column now. For demonstration purposes, choose Phenotype from the Choose Split Column window now. The view is once again updated, with the two statuses now colored differently. Again, these views can be opened in PowerPoint, or the legend can be viewed by going to the Legend tab of the View Controller . The next customization is to jitter the data points so that they don t overlap to each other by using the Change Symbol Properties button in the Task tab of the View Controller (found in the Properties section). Choose this now. The Symbol Properties window allows the user to configure a number of different options. Notice that the Color By section has already been set to Status . Other options include changing the size of the symbols, rotation, shape, labels, and opacity. For demonstration purposes, let s increase the Jitter about \u2155 of the way to max. Then close this window to see the updated view. The view is updated, with each group now jittered so that the user can now see all the data points.","title":"The VariableView"},{"location":"tutorials/SNP/Visualization_of_Data/#the-survivalview","text":"In SNP-related experiments from clinical trials, usually there is survival information available. Array Studio includes a special SurvivalView , for visualizing the time to event data. Let s add that now, in the usual way. When completed, it should look similar to the following. Array Studio is informing the user that the time column has not yet been specified. Click OK to continue and then specify the Time column in Task tab of View Controller . In the Task tab of the View Controller , click the Specify Time Column button. Choose SurvivalTime in the Choose Time Column window. The SurvivalTime column in our design table contains the information on time, needed for this view. Array Studio now informs the user that the Status column has not yet been specified. Click the Specify Status Column button in the Task tab of the View Controller , and then choose Status in the Choose Status Column window. Array Studio now informs the user to specify an Event . Click the Specify Event button in the Task tab of the View Controller . Array Studio now lists all the levels of events in the status column. For this study, available choices include Death or Censored . Choose Death and click OK . The SurvivalView is finally configured. Censored events are marked with a vertical line. The user can use this view to investigate different markers, based on survival time. It is clear in this case that there is a difference between the three genotypes, when it comes to survival time. Note: If you see the following message: Missing/negative data found in Y . Assure that that under the Observation tab in the View Controller has the source selected as below: At this point, it is recommended that the user save the project ( File Menu | Save) . If interested, the user can stop at this time. All filters, views, tables, etc., that have been generated in Array Studio are saved with the project, so the user could conceivably close the project, then reopen it, and continue right where they left off. Congratulations! You\\'ve now used many of the important views in Array Studio for analyzing SNP data. In the next chapter, we will investigate Marker Statistics, Data Filtering, and Population Structure.","title":"The SurvivalView"},{"location":"tutorials/SNP/Visualizationof_pValues/","text":"Visualization of P-Values Array Studio also includes a number of other views, specifically for visualizing p-values after running an analysis. For this tutorial, we will investigate the p-values generated by the quantitative trait analysis in the previous chapter. Specifically, this includes ChromosomeView , HistogramView , PvaluePlotView , GenomeView , and RegionView . As we already discussed the ChromosomeView in the previous chapter, it will not be discussed again here. But, feel free to investigate the ChromosomeView again on your own. HistogramView Add a HistogramView to the Quantitative Trait.Tests table in the Inference section of the Solution Explorer . Right click on Quantitative Trait.Tests , and choose Add View . Choose HistogramView from the list. Once the view is open, it will look similar to the following. On the x-axis is the p-value, while the y-axis is the count of each p-value. To change the column used for the p-value, use the Specify Histogram Columns option in the Task tab of the View Controller . This opens the Choose Columns window. Add GENOTYPE.FDR_BH to the Listed columns and click OK to return to the view. Notice now that there are 2 charts in the view. Scroll to the chart to see the initial HistogramView for the adjusted p-values. Filtering on p-values can reveal more significant ones in this view. Try this now, by filtering the GENOTYPE.FDR_BH to those markers less than 0.05 (enter \"<0.05\" into the GENOTYPE.FDR_BH filter). Click on any bar in the HistogramView to see the details of variables in that bar. Selected bars are highlighted in red. Notice that the Details window is updated to show the selected variables. PValuePlotView (PValueQQPlot now) Besides the HistogramView , Array Studio provides a PValuePlotView for looking at analyzed data. Add this view to the Quantitative Trait.Tests table by adding it in the usual manner. Once added, it should look similar to the screenshot below. If you have an active filter (e.g. raw-pvalue < 0.05), reset the filter now. The PvaluePlotView plot the expected p-value versus the observed p-value and can be used for examining the distribution of the p-value results. In this view, the x-axis shows the Log10 of the expected PValue, while the y-axis shows the Log10 of the observed PValue. The expected p-value line can be drawn by clicking the Show Line option in the Customize section of the Task tab of the Solution Explorer . The view is updated with the expected p-value line in red and the 95% confidence interval values in green. It appears from this graph the observed p-values do deviate from the expected distribution. Other options in the Task tab of the View Controller include removing the Log10 transformation from the graph, and specifying which columns to be used as p-value columns. Like all the other views in Array Studio, PValuePlot view is also fully interactive. GenomeView Another view that can be added is the GenomeView . In this view, the x-axis represents the whole genome, while the y-axis represents the p-value. The user can set a specific p-value cutoff for visualization (by default 0.01). Add a new GenomeView to the Quantitative Trait.Tests table now. When added, it should look similar to the screenshot below. Points shown by default have p-value < 0.01. To change the P-value cutoff, click the Specify PValue Cutoff in the Task tab of the View Controller . This opens the Specify PValue Cutoff window. The user can either choose one of the preset p-values, or enter the value in the box. Change the PValue cutoff to 1 in order to display all data points. Click OK to continue. The graph is updated. Note that by default the symbols are colored by chromosome. This works well, as the user can easily distinguish between the data points on each chromosome. Finally, the user can also trellis the chart by chromosome, so that each chart represents one chromosome. Do this by selecting the Trellis By Row Covariate option in the Task tab of the Solution Explorer . This opens the Choose Columns window. Add Chromosome to the Listed Columns and click OK to trellis the chart by chromosome. The view is updated so that there is one chart per chromosome. In total, there are 32 charts. The chart of chromosome 16 is shown below. Region View Another view that can be added is the RegionView . In this view, the user can use the latest Ensembl build to visualize their results across the chromosomes. In addition, they can easily find particular genes of interest and automatically zoom to that region. Clear all filters on the Quantitative Trait.Tests report now. Add a new RegionView to the Quantitative Trait.Tests table now. When added, it should look similar to the screenshot below. Note: The first time a RegionView is added, it may take a few minutes to download the Ensembl and Hapmap information. The RegionView contains multiple parts. Each part is fully interactive, and contains options that can be accessed by right-clicking. The first section is the Overview of the chromosome. The chromosome in view can be set, either by manually setting the Start and End points or by using the zoom in and zoom out. For the Overview section, the user can right-click to switch between panning and zoom modes. Selecting particular sections of the chromosome will zoom in the main view. The next section contains the cytoband for that chromosome. The next visible section is the transcript view. This will show the names of the transcripts for the currently visible region. It becomes very useful as you zoom in. Again, right-clicking allows a number of options. Right click on that region and choose Find Gene from the dropdown box. This opens the Autofill window where the user can search for their gene of interest. Type Prdm2 and move it over to the right-hand side, and then choose the region. Click OK to continue. The transcript view is now zoomed to the region of PRDM2, where the user can visualize all the p-values associated with this region. The current chromosome region we are viewing is highlighted in red on the cytoband. Again, all of these sections can be further customized by using right-click, and switching between modes. By default, the main view will contain 1 chart of p-values. The x-axis is the position of the chromosome, while the y-axis shows the Log10 Pvalue. Use the Specify Value Columns from the Task tab of View Controller to display more numerical columns. Add GENOTYPE.FDR_BH from the left panel to the right Listed columns panel. The main view is updated to have 2 parallel plots. Congratulations! You have now explored your results of your analysis, using a number of different visualizations.","title":"Visualizationof pValues"},{"location":"tutorials/SNP/Visualizationof_pValues/#visualization-of-p-values","text":"Array Studio also includes a number of other views, specifically for visualizing p-values after running an analysis. For this tutorial, we will investigate the p-values generated by the quantitative trait analysis in the previous chapter. Specifically, this includes ChromosomeView , HistogramView , PvaluePlotView , GenomeView , and RegionView . As we already discussed the ChromosomeView in the previous chapter, it will not be discussed again here. But, feel free to investigate the ChromosomeView again on your own.","title":"Visualization of P-Values"},{"location":"tutorials/SNP/Visualizationof_pValues/#histogramview","text":"Add a HistogramView to the Quantitative Trait.Tests table in the Inference section of the Solution Explorer . Right click on Quantitative Trait.Tests , and choose Add View . Choose HistogramView from the list. Once the view is open, it will look similar to the following. On the x-axis is the p-value, while the y-axis is the count of each p-value. To change the column used for the p-value, use the Specify Histogram Columns option in the Task tab of the View Controller . This opens the Choose Columns window. Add GENOTYPE.FDR_BH to the Listed columns and click OK to return to the view. Notice now that there are 2 charts in the view. Scroll to the chart to see the initial HistogramView for the adjusted p-values. Filtering on p-values can reveal more significant ones in this view. Try this now, by filtering the GENOTYPE.FDR_BH to those markers less than 0.05 (enter \"<0.05\" into the GENOTYPE.FDR_BH filter). Click on any bar in the HistogramView to see the details of variables in that bar. Selected bars are highlighted in red. Notice that the Details window is updated to show the selected variables.","title":"HistogramView"},{"location":"tutorials/SNP/Visualizationof_pValues/#pvalueplotview-pvalueqqplot-now","text":"Besides the HistogramView , Array Studio provides a PValuePlotView for looking at analyzed data. Add this view to the Quantitative Trait.Tests table by adding it in the usual manner. Once added, it should look similar to the screenshot below. If you have an active filter (e.g. raw-pvalue < 0.05), reset the filter now. The PvaluePlotView plot the expected p-value versus the observed p-value and can be used for examining the distribution of the p-value results. In this view, the x-axis shows the Log10 of the expected PValue, while the y-axis shows the Log10 of the observed PValue. The expected p-value line can be drawn by clicking the Show Line option in the Customize section of the Task tab of the Solution Explorer . The view is updated with the expected p-value line in red and the 95% confidence interval values in green. It appears from this graph the observed p-values do deviate from the expected distribution. Other options in the Task tab of the View Controller include removing the Log10 transformation from the graph, and specifying which columns to be used as p-value columns. Like all the other views in Array Studio, PValuePlot view is also fully interactive.","title":"PValuePlotView (PValueQQPlot now)"},{"location":"tutorials/SNP/Visualizationof_pValues/#genomeview","text":"Another view that can be added is the GenomeView . In this view, the x-axis represents the whole genome, while the y-axis represents the p-value. The user can set a specific p-value cutoff for visualization (by default 0.01). Add a new GenomeView to the Quantitative Trait.Tests table now. When added, it should look similar to the screenshot below. Points shown by default have p-value < 0.01. To change the P-value cutoff, click the Specify PValue Cutoff in the Task tab of the View Controller . This opens the Specify PValue Cutoff window. The user can either choose one of the preset p-values, or enter the value in the box. Change the PValue cutoff to 1 in order to display all data points. Click OK to continue. The graph is updated. Note that by default the symbols are colored by chromosome. This works well, as the user can easily distinguish between the data points on each chromosome. Finally, the user can also trellis the chart by chromosome, so that each chart represents one chromosome. Do this by selecting the Trellis By Row Covariate option in the Task tab of the Solution Explorer . This opens the Choose Columns window. Add Chromosome to the Listed Columns and click OK to trellis the chart by chromosome. The view is updated so that there is one chart per chromosome. In total, there are 32 charts. The chart of chromosome 16 is shown below.","title":"GenomeView"},{"location":"tutorials/SNP/Visualizationof_pValues/#region-view","text":"Another view that can be added is the RegionView . In this view, the user can use the latest Ensembl build to visualize their results across the chromosomes. In addition, they can easily find particular genes of interest and automatically zoom to that region. Clear all filters on the Quantitative Trait.Tests report now. Add a new RegionView to the Quantitative Trait.Tests table now. When added, it should look similar to the screenshot below. Note: The first time a RegionView is added, it may take a few minutes to download the Ensembl and Hapmap information. The RegionView contains multiple parts. Each part is fully interactive, and contains options that can be accessed by right-clicking. The first section is the Overview of the chromosome. The chromosome in view can be set, either by manually setting the Start and End points or by using the zoom in and zoom out. For the Overview section, the user can right-click to switch between panning and zoom modes. Selecting particular sections of the chromosome will zoom in the main view. The next section contains the cytoband for that chromosome. The next visible section is the transcript view. This will show the names of the transcripts for the currently visible region. It becomes very useful as you zoom in. Again, right-clicking allows a number of options. Right click on that region and choose Find Gene from the dropdown box. This opens the Autofill window where the user can search for their gene of interest. Type Prdm2 and move it over to the right-hand side, and then choose the region. Click OK to continue. The transcript view is now zoomed to the region of PRDM2, where the user can visualize all the p-values associated with this region. The current chromosome region we are viewing is highlighted in red on the cytoband. Again, all of these sections can be further customized by using right-click, and switching between modes. By default, the main view will contain 1 chart of p-values. The x-axis is the position of the chromosome, while the y-axis shows the Log10 Pvalue. Use the Specify Value Columns from the Task tab of View Controller to display more numerical columns. Add GENOTYPE.FDR_BH from the left panel to the right Listed columns panel. The main view is updated to have 2 parallel plots. Congratulations! You have now explored your results of your analysis, using a number of different visualizations.","title":"Region View"},{"location":"tutorials/SampleManagement/","text":"Server Sample Management Tutorial .. toctree:: :maxdepth: 2 Introduction SampleManagement Integration Others","title":"Home"},{"location":"tutorials/SampleManagement/Integration/","text":"Integration Pipeline Integration Pipeline Scripts User can run a pre-configured pipeline on a sample set. Pipeline can be as simple as raw data QC, alignment and then do quantification analysis on NGS data. Pipeline scripts are managed by ArrayServer administrators in Server | Manage | Manage Scripts : Run Pipeline Script in Analysis To run a pipeline on a SampleSet, open or create a server project in the Analysis tab. Then go to Add Data | Add Data From Server : Select a SampleSet Select a pipeline script: Fill required parameter values and click OK to run: Run Pipeline Script during Sample Registration User can run pipeline script during sample registration process by adding [Pipeline] section in sample registration file. By using the sample registration file above, a server job will be submitted at the end of sample registration to create a server project with ID TutorialRNASeq1 , using pipeline script Tutorial.RNASeq.v1.pscript and specified parameter values. Genome Browser Integration As we mentioned above, sample registration supports multiple file formats, including BAM (NGS alignment) files. User can modify the old registration file, adding a file path to BAM files: Registering this file ( Server Sample | Register Samples ) will update samples with BAM path. Now, the alignment files (BAM files) of samples can be loaded in the Genome Browser tab directly through Add Track | Add Track From Server Samples : User can add individual samples or the whole sample set. Here we choose the TutorialRNASeq.fullData sampleset: User has the option to add one sample as one genome browser track: Or create tracks for groups defined by sample registration meta data: Choose Cellline as group which will create two genome browser tracks: K562 and MCF7. User can split the combined tracks to individual samples by right click and select Split Into Multiple Tracks : For more information and features available in the genome browser, please read the Genome Browser Tutorial .","title":"Integration"},{"location":"tutorials/SampleManagement/Integration/#integration","text":"","title":"Integration"},{"location":"tutorials/SampleManagement/Integration/#pipeline-integration","text":"","title":"Pipeline Integration"},{"location":"tutorials/SampleManagement/Integration/#pipeline-scripts","text":"User can run a pre-configured pipeline on a sample set. Pipeline can be as simple as raw data QC, alignment and then do quantification analysis on NGS data. Pipeline scripts are managed by ArrayServer administrators in Server | Manage | Manage Scripts :","title":"Pipeline Scripts"},{"location":"tutorials/SampleManagement/Integration/#run-pipeline-script-in-analysis","text":"To run a pipeline on a SampleSet, open or create a server project in the Analysis tab. Then go to Add Data | Add Data From Server : Select a SampleSet Select a pipeline script: Fill required parameter values and click OK to run:","title":"Run Pipeline Script in Analysis"},{"location":"tutorials/SampleManagement/Integration/#run-pipeline-script-during-sample-registration","text":"User can run pipeline script during sample registration process by adding [Pipeline] section in sample registration file. By using the sample registration file above, a server job will be submitted at the end of sample registration to create a server project with ID TutorialRNASeq1 , using pipeline script Tutorial.RNASeq.v1.pscript and specified parameter values.","title":"Run Pipeline Script during Sample Registration"},{"location":"tutorials/SampleManagement/Integration/#genome-browser-integration","text":"As we mentioned above, sample registration supports multiple file formats, including BAM (NGS alignment) files. User can modify the old registration file, adding a file path to BAM files: Registering this file ( Server Sample | Register Samples ) will update samples with BAM path. Now, the alignment files (BAM files) of samples can be loaded in the Genome Browser tab directly through Add Track | Add Track From Server Samples : User can add individual samples or the whole sample set. Here we choose the TutorialRNASeq.fullData sampleset: User has the option to add one sample as one genome browser track: Or create tracks for groups defined by sample registration meta data: Choose Cellline as group which will create two genome browser tracks: K562 and MCF7. User can split the combined tracks to individual samples by right click and select Split Into Multiple Tracks : For more information and features available in the genome browser, please read the Genome Browser Tutorial .","title":"Genome Browser Integration"},{"location":"tutorials/SampleManagement/Introduction/","text":"Introduction Overview Samples and sample sets are registered and managed on the server, along with their corresponding meta data. An Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic elements for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria. Test Dataset This tutorial will cover sample and sampleset registration, and integration to pipeline using a mock dataset. You can download the same tutorial dataset and registration text files on our website: link","title":"Introduction"},{"location":"tutorials/SampleManagement/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/SampleManagement/Introduction/#overview","text":"Samples and sample sets are registered and managed on the server, along with their corresponding meta data. An Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic elements for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria.","title":"Overview"},{"location":"tutorials/SampleManagement/Introduction/#test-dataset","text":"This tutorial will cover sample and sampleset registration, and integration to pipeline using a mock dataset. You can download the same tutorial dataset and registration text files on our website: link","title":"Test Dataset"},{"location":"tutorials/SampleManagement/Others/","text":"Others Register Multiple Sequence Files for One Sample In next generation sequencing (NGS) experiments, user may have multiple files from multiple lanes for one NGS sample. They should be considered as a single sample during NGS analysis. In sample registration, multiple files can be specified in FilePath using the same file type name, separated by |. For more details, please read the following wiki page: link","title":"Others"},{"location":"tutorials/SampleManagement/Others/#others","text":"","title":"Others"},{"location":"tutorials/SampleManagement/Others/#register-multiple-sequence-files-for-one-sample","text":"In next generation sequencing (NGS) experiments, user may have multiple files from multiple lanes for one NGS sample. They should be considered as a single sample during NGS analysis. In sample registration, multiple files can be specified in FilePath using the same file type name, separated by |. For more details, please read the following wiki page: link","title":"Register Multiple Sequence Files for One Sample"},{"location":"tutorials/SampleManagement/SampleManagement/","text":"Sample Management Sample Registration Array Server provides a simple way to allow users to register, annotate and manage the samples through one one-click submission of a text file. Sample registration is limited to the LabManager user group or higher. Below is a sample input file for sample registration: User can get this text file from downloaded tutorial data. The input file has one required section and one optional section: Samples : this required section lists samples, associated file path, and meta data for the samples. Fields are tab delimited. First row must be column headers, and the first two columns must be SampleID and FilePath. SampleID must be unique across the full database, and FilePath must be a relative path that s exposed by the Array Server FTP server (usually it points to a mapped folder). Multiple files, separated by \"|\", can be specified for each sample. The user can contain as many additional columns (e.g. LIMS fields, treatments and other grouping information, etc.) as needed, but it is recommended to control the vocabulary for both the column name and column value. Depending on server configurations, certain columns in your input file are set to MANDATORY . These settings can be viewed by the server administrator under Manage | Server Information | Show Sample Template . This will open a Table where users can see which columns are needed in the Samples section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial. ArraySuite supports multiple file types in FilePath, including CEL, FASTQ, BAM and etc. For more details, please read the following wiki page: link SampleSet : this section is optional and lists the meta data for the sample set that will be automatically generated based on the listed samples in the Samples section. The user can set Editor and Reader for the sample set but these two fields are not required. To register the sample, go to Server | Server Sample | Register Samples : Users can choose to register samples using a file located in server or local: Choose the sample registration file prepared as shown above and click OK . Once finished, you will get Some users might encounter an error like this: The error hints users that information including Organism, Platform, and Platform type has not been defined ahead by the server admin. In this situation, users should contact the server admin. To define these fields, the server admin can go to Manage => Manage Predefined list : Next, add corresponding information from lists of Organism, Platform, and Platform type. Be sure to add one item per line in the lists. Another error that may be encountered appears like this: Depending on server configurations, certain columns in your input file are set to MANDATORY . These settings can be viewed by the server administrator under Manage | Server Information | Show Sample Template . This Sample Template is discussed further below in the Browse Samples section. This will open a Table where users can see which columns are needed in the Samples section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial. Browse Samples To browse samples, go to Server Sample | Browse Samples Categories used in the tree for SampleSets are ones defined as Organizable=TRUE in the server configuration file: default.template . Here is the wiki page for more details about default.template : link Categories used in the tree for Samples are ones defined as Organizable=TRUE in the server configuration file: sample.template . Here is the wiki page for more details about sample.template : link Users can always check the predefined sample and sampleset columns in Server | Manage | Show Sample or SampleSet Template : Create New SampleSets New sample sets can be created from registered samples that are belong to existing sample Sets. User can select samples of interest and right-click to Create SampleSet . User can also create sampleset using sample registration file with Sample ID only: Register this sample using Add SampleSet function: Search Samples To search sample or sample set, go to Server Sample | Search Samples . The search function has the power of full text search. Type Bone and select tissue bone marrow in the autofill. Click OK and then Add to the search criteria field: User can narrow down the search space by adding more search criteria. Click OK to search samples. A new sample tab will appear with a table of identified samples:","title":"Sample Management"},{"location":"tutorials/SampleManagement/SampleManagement/#sample-management","text":"","title":"Sample Management"},{"location":"tutorials/SampleManagement/SampleManagement/#sample-registration","text":"Array Server provides a simple way to allow users to register, annotate and manage the samples through one one-click submission of a text file. Sample registration is limited to the LabManager user group or higher. Below is a sample input file for sample registration: User can get this text file from downloaded tutorial data. The input file has one required section and one optional section: Samples : this required section lists samples, associated file path, and meta data for the samples. Fields are tab delimited. First row must be column headers, and the first two columns must be SampleID and FilePath. SampleID must be unique across the full database, and FilePath must be a relative path that s exposed by the Array Server FTP server (usually it points to a mapped folder). Multiple files, separated by \"|\", can be specified for each sample. The user can contain as many additional columns (e.g. LIMS fields, treatments and other grouping information, etc.) as needed, but it is recommended to control the vocabulary for both the column name and column value. Depending on server configurations, certain columns in your input file are set to MANDATORY . These settings can be viewed by the server administrator under Manage | Server Information | Show Sample Template . This will open a Table where users can see which columns are needed in the Samples section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial. ArraySuite supports multiple file types in FilePath, including CEL, FASTQ, BAM and etc. For more details, please read the following wiki page: link SampleSet : this section is optional and lists the meta data for the sample set that will be automatically generated based on the listed samples in the Samples section. The user can set Editor and Reader for the sample set but these two fields are not required. To register the sample, go to Server | Server Sample | Register Samples : Users can choose to register samples using a file located in server or local: Choose the sample registration file prepared as shown above and click OK . Once finished, you will get Some users might encounter an error like this: The error hints users that information including Organism, Platform, and Platform type has not been defined ahead by the server admin. In this situation, users should contact the server admin. To define these fields, the server admin can go to Manage => Manage Predefined list : Next, add corresponding information from lists of Organism, Platform, and Platform type. Be sure to add one item per line in the lists. Another error that may be encountered appears like this: Depending on server configurations, certain columns in your input file are set to MANDATORY . These settings can be viewed by the server administrator under Manage | Server Information | Show Sample Template . This Sample Template is discussed further below in the Browse Samples section. This will open a Table where users can see which columns are needed in the Samples section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial.","title":"Sample Registration"},{"location":"tutorials/SampleManagement/SampleManagement/#browse-samples","text":"To browse samples, go to Server Sample | Browse Samples Categories used in the tree for SampleSets are ones defined as Organizable=TRUE in the server configuration file: default.template . Here is the wiki page for more details about default.template : link Categories used in the tree for Samples are ones defined as Organizable=TRUE in the server configuration file: sample.template . Here is the wiki page for more details about sample.template : link Users can always check the predefined sample and sampleset columns in Server | Manage | Show Sample or SampleSet Template :","title":"Browse Samples"},{"location":"tutorials/SampleManagement/SampleManagement/#create-new-samplesets","text":"New sample sets can be created from registered samples that are belong to existing sample Sets. User can select samples of interest and right-click to Create SampleSet . User can also create sampleset using sample registration file with Sample ID only: Register this sample using Add SampleSet function:","title":"Create New SampleSets"},{"location":"tutorials/SampleManagement/SampleManagement/#search-samples","text":"To search sample or sample set, go to Server Sample | Search Samples . The search function has the power of full text search. Type Bone and select tissue bone marrow in the autofill. Click OK and then Add to the search criteria field: User can narrow down the search space by adding more search criteria. Click OK to search samples. A new sample tab will appear with a table of identified samples:","title":"Search Samples"},{"location":"tutorials/ServerAnalysisBasics/","text":"Server Analysis (Basics) Tutorial .. toctree:: :maxdepth: 2 Introduction Connecting_to_a_Server_and_Uploading_Files Creating_and_Publishing_a_Server_Project Array_Server_on_Cluster Array_Server_on_Cloud","title":"Home"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/","text":"Array Server on Cloud Array Server can also run jobs on the cloud. It only requires the ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cloud jobs. This tutorial is drafted for standard users. To configure Server with Cloud, please contact Omicsoft Support to get the manual for Server on Cloud admin. After ArrayServer admin has configured the Server with Cloud, standard users do not need to set up Cloud Preferences but only need to connect to the server with cloud integration through the Server tab: When connected, the window looks the same as the server window. Notice that the Cloud tab will not appear. Uploading Files to Server cloud Before running server jobs on cloud, the users should upload the data files on the specific cloud folder they have been assigned. Go to Server File | Browse Files window: Then go to the cloud folder configured in advance. Please contact the admin if the user does not know where their cloud folder can be found. In the folder, users can create their own folder and upload the data the same way as running a server project: Run Server Project on Cloud Once files are uploaded to the cloud folder, users can not run a server project on the cloud. Please create a server project in the Analysis tab first. The analysis window and analysis steps are the same as running a server project. When adding data to a project, remember to browse the right cloud folder for your files: After sending the data to queue, the job progress could be monitored the same way as server project: Run Multiple Jobs on Cloud When running multiple jobs (For example, multiple samples sequencing data alignment), multiple cloud instances will be allocated. This makes it much faster to perform the analyses. To test this, users can use the RNA-seq data downloaded in the previous chapter. For illustration purpose, we will only use two samples to reduce the process time. Again, remember to go to load the data to the correct cloud folder prior to starting the project: The demo dataset is paired-end sequencing data; please check the Reads are paired check box. For Server project to run on cloud, the users must specify output folder. The directory has to be under the cloud folder (not necessary to be the same cloud folder as the raw data). The principle is that all data, including raw and analyzed data, are on the cloud, while users' local machines and company server only store small data objects linking to the files on cloud. Upon job submission, again, the job could be monitored: The users can right click on the job and select View Full Log : In the Log window, as you can see, the jobs are being submitted to cloud NGS instances, 2 cloud instances will be started as we have two samples to align: As a general user, you cannot monitor the Cloud Instances for Server Cloud. The users can go back to the Analysis tab and continue any downstream analyses and visualization: Congratulations! Now you can successfully run server projects on cloud!","title":"Array Server on Cloud"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#array-server-on-cloud","text":"Array Server can also run jobs on the cloud. It only requires the ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cloud jobs. This tutorial is drafted for standard users. To configure Server with Cloud, please contact Omicsoft Support to get the manual for Server on Cloud admin. After ArrayServer admin has configured the Server with Cloud, standard users do not need to set up Cloud Preferences but only need to connect to the server with cloud integration through the Server tab: When connected, the window looks the same as the server window. Notice that the Cloud tab will not appear.","title":"Array Server on Cloud"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#uploading-files-to-server-cloud","text":"Before running server jobs on cloud, the users should upload the data files on the specific cloud folder they have been assigned. Go to Server File | Browse Files window: Then go to the cloud folder configured in advance. Please contact the admin if the user does not know where their cloud folder can be found. In the folder, users can create their own folder and upload the data the same way as running a server project:","title":"Uploading Files to Server cloud"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#run-server-project-on-cloud","text":"Once files are uploaded to the cloud folder, users can not run a server project on the cloud. Please create a server project in the Analysis tab first. The analysis window and analysis steps are the same as running a server project. When adding data to a project, remember to browse the right cloud folder for your files: After sending the data to queue, the job progress could be monitored the same way as server project:","title":"Run Server Project on Cloud"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#run-multiple-jobs-on-cloud","text":"When running multiple jobs (For example, multiple samples sequencing data alignment), multiple cloud instances will be allocated. This makes it much faster to perform the analyses. To test this, users can use the RNA-seq data downloaded in the previous chapter. For illustration purpose, we will only use two samples to reduce the process time. Again, remember to go to load the data to the correct cloud folder prior to starting the project: The demo dataset is paired-end sequencing data; please check the Reads are paired check box. For Server project to run on cloud, the users must specify output folder. The directory has to be under the cloud folder (not necessary to be the same cloud folder as the raw data). The principle is that all data, including raw and analyzed data, are on the cloud, while users' local machines and company server only store small data objects linking to the files on cloud. Upon job submission, again, the job could be monitored: The users can right click on the job and select View Full Log : In the Log window, as you can see, the jobs are being submitted to cloud NGS instances, 2 cloud instances will be started as we have two samples to align: As a general user, you cannot monitor the Cloud Instances for Server Cloud. The users can go back to the Analysis tab and continue any downstream analyses and visualization: Congratulations! Now you can successfully run server projects on cloud!","title":"Run Multiple Jobs on Cloud"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cluster/","text":"Array Server on Cluster Array Server can run jobs on clusters. It only requires ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cluster jobs. Actually, Array Server on Cluster is pretty similar with that on a common server. The underlying difference is that running jobs are automatically assigned to different nodes of the cluster, greatly utilizing the power of a cluster that enhances computing speed and saves time. To configure a Server on Cluster, please contact Omicsoft Support to get the manual for Server deployment on Cluster. After ArrayServer admin configures the Server on Cluster, standard users do not need to set up Cluster Preferences but only need to connect to the ArrayServer: To run server jobs on Cluster, users just follow the tutorial of running Array server on common server to upload data files, create project and run server project as in Chapter 3 of this tutorial. Run Multiple Jobs on Cluster When running multiple jobs (For example, multiple samples sequencing data alignment), multiple Cluster nodes will be used. This makes it much faster to perform the analyses. To test this, please download the RNA-seq demo dataset from: link More detailed description of the dataset can be found in the accompanied RNA-Seq Analysis Tutorial. Here, we will only use two samples to save the process time. Make sure to load the data in the right Cluster folder and then, in the Analysis tab, choose: Add Data | Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) . Click Add and navigate to your downloaded RNA-seq demo dataset. Select all four fastq files and click OK. The demo dataset is paired-end sequencing data; please check the Reads are paired check box and Send to Queue : The job can be monitored in the Server | Server Jobs tab: The users can right click on the job and select View Full Log or Cancel Job : In the Log window, the jobs are being submitted to Cluster, 2 Cluster nodes (users can check qsub on cluster if they have permission) will be started with job IDs as we have two samples to align. Right-clicking on the job and viewing the log, we can see that SRR521461 and SRR521462 have been submitted as two separate jobs: Once the job finishes, user could go back to Analysis tab to update the project as above and continue any downstream analyses and visualization (Clicking Update Project in the analysis tab to see the results):","title":"Array Server on Cluster"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cluster/#array-server-on-cluster","text":"Array Server can run jobs on clusters. It only requires ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cluster jobs. Actually, Array Server on Cluster is pretty similar with that on a common server. The underlying difference is that running jobs are automatically assigned to different nodes of the cluster, greatly utilizing the power of a cluster that enhances computing speed and saves time. To configure a Server on Cluster, please contact Omicsoft Support to get the manual for Server deployment on Cluster. After ArrayServer admin configures the Server on Cluster, standard users do not need to set up Cluster Preferences but only need to connect to the ArrayServer: To run server jobs on Cluster, users just follow the tutorial of running Array server on common server to upload data files, create project and run server project as in Chapter 3 of this tutorial.","title":"Array Server on Cluster"},{"location":"tutorials/ServerAnalysisBasics/Array_Server_on_Cluster/#run-multiple-jobs-on-cluster","text":"When running multiple jobs (For example, multiple samples sequencing data alignment), multiple Cluster nodes will be used. This makes it much faster to perform the analyses. To test this, please download the RNA-seq demo dataset from: link More detailed description of the dataset can be found in the accompanied RNA-Seq Analysis Tutorial. Here, we will only use two samples to save the process time. Make sure to load the data in the right Cluster folder and then, in the Analysis tab, choose: Add Data | Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) . Click Add and navigate to your downloaded RNA-seq demo dataset. Select all four fastq files and click OK. The demo dataset is paired-end sequencing data; please check the Reads are paired check box and Send to Queue : The job can be monitored in the Server | Server Jobs tab: The users can right click on the job and select View Full Log or Cancel Job : In the Log window, the jobs are being submitted to Cluster, 2 Cluster nodes (users can check qsub on cluster if they have permission) will be started with job IDs as we have two samples to align. Right-clicking on the job and viewing the log, we can see that SRR521461 and SRR521462 have been submitted as two separate jobs: Once the job finishes, user could go back to Analysis tab to update the project as above and continue any downstream analyses and visualization (Clicking Update Project in the analysis tab to see the results):","title":"Run Multiple Jobs on Cluster"},{"location":"tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/","text":"Connecting to a Server and Uploading Files Connecting to a Server Before creating a server project, first connect to a server by clicking the Server tab on the top of Array Studio. Fill in the server information (where Server name can be anything given by the user to help remember the server) and log-in credentials. Select the Connect button. Depending on the server setup, another window may appear prompting the user to choose which analytical server to connect to. Upon successful login, the default Wizard window will appear in the Server window: Uploading Files One requirement for performing server-bases analysis is that the raw data ( e.g. cel, fastq or bam files) has to be located on the server. One can use Array Studio to transfer local files to the server easily. In the Server tab, go to Server File | Browse Files : The ServerFiles tab will appear with a listing of the current folders in the /Users/username directory: In the example above, we are in the user folder ( /Users/admin ) and with the user id as admin . The User folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting Create New Folder from the dropdown menu. Create a new folder and name it SampleData . Enter the SampleData folder and click Upload to transfer files from local computer to the server. Select the ServerTest.bam file and click Open . As the files load, the progress is monitored in the lower portion of the ServerFiles window: Once the uploading has finished and the ftp transfer is complete, the files will appear in the SampleData folder.","title":"Connecting to a Server and Uploading Files"},{"location":"tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/#connecting-to-a-server-and-uploading-files","text":"","title":"Connecting to a Server and Uploading Files"},{"location":"tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/#connecting-to-a-server","text":"Before creating a server project, first connect to a server by clicking the Server tab on the top of Array Studio. Fill in the server information (where Server name can be anything given by the user to help remember the server) and log-in credentials. Select the Connect button. Depending on the server setup, another window may appear prompting the user to choose which analytical server to connect to. Upon successful login, the default Wizard window will appear in the Server window:","title":"Connecting to a Server"},{"location":"tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/#uploading-files","text":"One requirement for performing server-bases analysis is that the raw data ( e.g. cel, fastq or bam files) has to be located on the server. One can use Array Studio to transfer local files to the server easily. In the Server tab, go to Server File | Browse Files : The ServerFiles tab will appear with a listing of the current folders in the /Users/username directory: In the example above, we are in the user folder ( /Users/admin ) and with the user id as admin . The User folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting Create New Folder from the dropdown menu. Create a new folder and name it SampleData . Enter the SampleData folder and click Upload to transfer files from local computer to the server. Select the ServerTest.bam file and click Open . As the files load, the progress is monitored in the lower portion of the ServerFiles window: Once the uploading has finished and the ftp transfer is complete, the files will appear in the SampleData folder.","title":"Uploading Files"},{"location":"tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/","text":"Creating and Publishing a Server Project Creating A Server Project To create a server project, in Analysis tab go to File | New Server Project . The user will be prompted to enter some basic meta data about the project, including an option to categorize the project using the Category tab. After filling in the required information (indicated by asterisks), click Create button. Now an empty project will be created (below): Notice that the project name includes Server Project - Distributed in the name so that the user can quickly see that this is a server project and the type is Distributed . Distributed indicates that data objects are saved in separate files. From here, we can perform all the analysis tasks on the server using the interface of Array Studio. For example, we can add the alignment analysis file (that we loaded to the server earlier) by going to the toolbar Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads : then choose the file uploaded in previous section ( ServerTest.bam ). Then click Send to Queue . A ServerJobs window will show, listing all the jobs on the server. Now switch back to the Analysis tab. Once the job is completed, the user will see an Update Project on the far right in the menu selection of Array Studio (below): Click Update Project to show the results of finished job: one NgsData is created for this BAM file. If the user would like to see the parameters used for the alignment, select the data set name NgsData and right click, then choose View Source Users can run all data analysis based on this NgsData in the same way as they run in Array Studio locally. They will see Send to Queue button and all analyses will be done on server. Publishing a Server Project At this point, the project that we are working on is stored in our ServerProject folder on the server (along with a cache on the local machine). Note: BAM files are not cached in local machine. The data object of NgsData only stores the link to the BAM file. The server project is only accessible to the user who created it. The user can also publish this project to the server to allow other users to access it. This will also make it searchable in the Wizard on the server. If the project is active in Array Studio, simply select from the menu File | Publish . If the project is not active, the user first has to select Open | Open Server Project which will then make it active: Selecting Publish will open the Publish Project window. The user has the options to Choose data/items to publish and Choose data to enable full text search . Meta data fields (some required and some optional) are filled in and indexed when published. Go into the Server tab of Array Studio and select the Wizard tab and select Search Server ; the newly published TutorialServerProject will be visible in autofill: If you leave the search fields empty and click Search Server , all published server projects will be listed including the TutorialServerProject . Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.","title":"Creating and Publishing a Server Project"},{"location":"tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/#creating-and-publishing-a-server-project","text":"","title":"Creating and Publishing a Server Project"},{"location":"tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/#creating-a-server-project","text":"To create a server project, in Analysis tab go to File | New Server Project . The user will be prompted to enter some basic meta data about the project, including an option to categorize the project using the Category tab. After filling in the required information (indicated by asterisks), click Create button. Now an empty project will be created (below): Notice that the project name includes Server Project - Distributed in the name so that the user can quickly see that this is a server project and the type is Distributed . Distributed indicates that data objects are saved in separate files. From here, we can perform all the analysis tasks on the server using the interface of Array Studio. For example, we can add the alignment analysis file (that we loaded to the server earlier) by going to the toolbar Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads : then choose the file uploaded in previous section ( ServerTest.bam ). Then click Send to Queue . A ServerJobs window will show, listing all the jobs on the server. Now switch back to the Analysis tab. Once the job is completed, the user will see an Update Project on the far right in the menu selection of Array Studio (below): Click Update Project to show the results of finished job: one NgsData is created for this BAM file. If the user would like to see the parameters used for the alignment, select the data set name NgsData and right click, then choose View Source Users can run all data analysis based on this NgsData in the same way as they run in Array Studio locally. They will see Send to Queue button and all analyses will be done on server.","title":"Creating A Server Project"},{"location":"tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/#publishing-a-server-project","text":"At this point, the project that we are working on is stored in our ServerProject folder on the server (along with a cache on the local machine). Note: BAM files are not cached in local machine. The data object of NgsData only stores the link to the BAM file. The server project is only accessible to the user who created it. The user can also publish this project to the server to allow other users to access it. This will also make it searchable in the Wizard on the server. If the project is active in Array Studio, simply select from the menu File | Publish . If the project is not active, the user first has to select Open | Open Server Project which will then make it active: Selecting Publish will open the Publish Project window. The user has the options to Choose data/items to publish and Choose data to enable full text search . Meta data fields (some required and some optional) are filled in and indexed when published. Go into the Server tab of Array Studio and select the Wizard tab and select Search Server ; the newly published TutorialServerProject will be visible in autofill: If you leave the search fields empty and click Search Server , all published server projects will be listed including the TutorialServerProject . Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.","title":"Publishing a Server Project"},{"location":"tutorials/ServerAnalysisBasics/Introduction/","text":"Introduction ArrayServer Array Server is an enterprise solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. Easily share analyzed data with clients and colleagues. ArrayServer also hosts shared genome browsers. The following diagram demonstrates the functionality of Array Server: Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, Array Server has a built-in scheduling system that supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS/Omics data. All the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces are almost the same. Server Project A \"Server Project\" is a project that is created on the server, rather than on the user's client machine. This project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user s home folder, typically My Documents/Omicsoft/ServerProjects . A Server Project, when stored locally in the cache folder, has a different filename suffix ( .ossprj ) compared to a regular project ( .osprj ) and can only be opened when the user is connected to the server. The concept behind the Server Project is that any data that is added to a project must first be stored on the server. When the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Server instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the server file system. Most of companies are storing data in network drives, they can map these drives directly in Array Server and all users will be able to access data easily during server analysis. All data addition and extraction is done on the server side, by Array Server, instead of the users client machine. It allows the user to use the power of the server, instead of their individual client machine for the importing of data. This is extremely important for some memory/CPU intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc. Anytime the user saves the project, it is synchronized with the version on the server. Test Dataset In this tutorial, we will show how to create a server project for server-based analysis. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be accessed from the following URL: link","title":"Introduction"},{"location":"tutorials/ServerAnalysisBasics/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/ServerAnalysisBasics/Introduction/#arrayserver","text":"Array Server is an enterprise solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. Easily share analyzed data with clients and colleagues. ArrayServer also hosts shared genome browsers. The following diagram demonstrates the functionality of Array Server: Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, Array Server has a built-in scheduling system that supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS/Omics data. All the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces are almost the same.","title":"ArrayServer"},{"location":"tutorials/ServerAnalysisBasics/Introduction/#server-project","text":"A \"Server Project\" is a project that is created on the server, rather than on the user's client machine. This project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user s home folder, typically My Documents/Omicsoft/ServerProjects . A Server Project, when stored locally in the cache folder, has a different filename suffix ( .ossprj ) compared to a regular project ( .osprj ) and can only be opened when the user is connected to the server. The concept behind the Server Project is that any data that is added to a project must first be stored on the server. When the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Server instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the server file system. Most of companies are storing data in network drives, they can map these drives directly in Array Server and all users will be able to access data easily during server analysis. All data addition and extraction is done on the server side, by Array Server, instead of the users client machine. It allows the user to use the power of the server, instead of their individual client machine for the importing of data. This is extremely important for some memory/CPU intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc. Anytime the user saves the project, it is synchronized with the version on the server.","title":"Server Project"},{"location":"tutorials/ServerAnalysisBasics/Introduction/#test-dataset","text":"In this tutorial, we will show how to create a server project for server-based analysis. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be accessed from the following URL: link","title":"Test Dataset"},{"location":"tutorials/ServerExplorer/","text":"Server Explorer Tutorial .. toctree:: :maxdepth: 2 Getting_Started Searching_Projects Publishing_Data Server_FileManagement Server_Sample_Management Server_Administration","title":"Home"},{"location":"tutorials/ServerExplorer/Getting_Started/","text":"Getting Started Server explorer contains functions to search and display data stored in Array Server. Both Array Studio and Array Viewer contain the Server tab. Array Viewer is a separate product to view data shared in Array Server, having the same functionalities as ones in Server/Land/Browser tabs in ArrayStudio. In this tutorial, we focus on modules in the Server tab in Array Viewer. They are the same in Array Studio Server tab. The tutorial is based on published projects in Array Server. Installation and Setup To start Array Viewer for the first time, click on the following link: link Make sure to use Internet Explorer for this process. Array Viewer in Internet Explorer requires the installation of the .NET 3.5 framework. For users with the .NET framework already installed, clicking Install will proceed to login and launch of Array Viewer, as shown below. Click the Edit button to edit the Omicsoft server of your choice and enter username and password information, or for internal servers, click the Add button to add a new server to the list. This opens the Server Information window. The user has the ability to edit the name of the server, server address, as well as User ID and Password. At this point, the user should enter the User ID and Password provided to them by their Array Server Administrator. Some internal servers may not require user authorization , and this should also be indicated by the Administrator. Click OK to save the Server Information. After editing the server, click the Connect button to connect to the server of your choice. After a successful login to the server, Array Viewer should look similar to the following screenshot: Click on the Server tab where the default view will be the Wizard. Wizard When the user initially opens the Server tab in Array Viewer, a wizard is shown, that allows the user to quickly get started. All search functionality can be done from the wizard. At this point, the user can click the Search Server button and should see a window similar to the following (note: the number of projects and name of tabs may not match exactly). Project Browser, Tagging, and Meta Data The left hand side of the screen provides the user a way to manually browse projects, either by Category, or using the advanced Filter option for projects. ArrayStudio makes filtering projects very easy. Users can use the check box to filter projects. Besides using the check box, users can click on the icons and located besides each filtering column. In the popup window, users can search for projects and make single or multiple selections. Single clicking on a project in the Project Browser will show the meta data related to this project in the main view window. Click on any project. The Project tab of the main view window is updated with the published information for this project. The Project tab contains a number of meta data tabs, including General, Platform, Contact, Custom, Content, Design, Inference Report, Category, and Publish. Click on each of these tabs now to see the different meta data that can be seen for each project. Notice the Category tab, which contains meta data on the category to which the project belongs. This is the tab that is used to populate the Category browser. When uploading a project (only if the user has write access to a project), this information can be edited. Notice that the Publish tab shows information about how the project was published, including Published by, Publish date, Readers, Editors, and Contributors. Readers and Editors show the user groups that have read and write access to this particular project. In addition, for users connected to internal servers, there is the option to upload private projects, which cannot be viewed by other users (other than administrators). There is also an option to View Project Audit Trail , which will show the Audit Trail, in OmicScript form, of every major action taken by the analyst when analyzing the project (or the steps performed by Omicsoft to analyze the public projects). Notice that the Content tab contains a list of all data that was uploaded with the project, as well as the index status of the data. If a dataset or table is Indexed , it can be searched within Array Viewer. This would mean that the testing results contain rows that are indexed (probesets) that can be searched, while the summary Table does not, and thus it cannot be searched. The Design tab shows the design table information (sample information) for each project. For projects with multiple datasets, there will be multiple dataset names available in the Data name dropdown box. This is useful in getting information about the samples contained in each project, without having to download data for that project. Note that any of these tables can be easily exported to Excel or saved as text using the toolbar above the table. The InferenceReport tab contains information on any inference reports created. For each tests table in the Data name dropdown box, each comparison is shown, with information as to whether Raw p-value, Adjusted p-value, Estimate, Fold change, and Max(LSMean) (to be used as an intensity filter ) are available. Contrasts can be categorized into a Test type, and this can be shown here as well (and used for filtering with the Search Inference Report module). A description of each contrast (or test) can also be entered by the user upon uploading a project (or edited by a user with write access to that project). For users not familiar with the concept of a contrast or test , think of it as a ratio , complete with p-value and fold change information, as well as the maximum intensity for each group in the test.","title":"Getting Started"},{"location":"tutorials/ServerExplorer/Getting_Started/#getting-started","text":"Server explorer contains functions to search and display data stored in Array Server. Both Array Studio and Array Viewer contain the Server tab. Array Viewer is a separate product to view data shared in Array Server, having the same functionalities as ones in Server/Land/Browser tabs in ArrayStudio. In this tutorial, we focus on modules in the Server tab in Array Viewer. They are the same in Array Studio Server tab. The tutorial is based on published projects in Array Server.","title":"Getting Started"},{"location":"tutorials/ServerExplorer/Getting_Started/#installation-and-setup","text":"To start Array Viewer for the first time, click on the following link: link Make sure to use Internet Explorer for this process. Array Viewer in Internet Explorer requires the installation of the .NET 3.5 framework. For users with the .NET framework already installed, clicking Install will proceed to login and launch of Array Viewer, as shown below. Click the Edit button to edit the Omicsoft server of your choice and enter username and password information, or for internal servers, click the Add button to add a new server to the list. This opens the Server Information window. The user has the ability to edit the name of the server, server address, as well as User ID and Password. At this point, the user should enter the User ID and Password provided to them by their Array Server Administrator. Some internal servers may not require user authorization , and this should also be indicated by the Administrator. Click OK to save the Server Information. After editing the server, click the Connect button to connect to the server of your choice. After a successful login to the server, Array Viewer should look similar to the following screenshot: Click on the Server tab where the default view will be the Wizard.","title":"Installation and Setup"},{"location":"tutorials/ServerExplorer/Getting_Started/#wizard","text":"When the user initially opens the Server tab in Array Viewer, a wizard is shown, that allows the user to quickly get started. All search functionality can be done from the wizard. At this point, the user can click the Search Server button and should see a window similar to the following (note: the number of projects and name of tabs may not match exactly).","title":"Wizard"},{"location":"tutorials/ServerExplorer/Getting_Started/#project-browser-tagging-and-meta-data","text":"The left hand side of the screen provides the user a way to manually browse projects, either by Category, or using the advanced Filter option for projects. ArrayStudio makes filtering projects very easy. Users can use the check box to filter projects. Besides using the check box, users can click on the icons and located besides each filtering column. In the popup window, users can search for projects and make single or multiple selections. Single clicking on a project in the Project Browser will show the meta data related to this project in the main view window. Click on any project. The Project tab of the main view window is updated with the published information for this project. The Project tab contains a number of meta data tabs, including General, Platform, Contact, Custom, Content, Design, Inference Report, Category, and Publish. Click on each of these tabs now to see the different meta data that can be seen for each project. Notice the Category tab, which contains meta data on the category to which the project belongs. This is the tab that is used to populate the Category browser. When uploading a project (only if the user has write access to a project), this information can be edited. Notice that the Publish tab shows information about how the project was published, including Published by, Publish date, Readers, Editors, and Contributors. Readers and Editors show the user groups that have read and write access to this particular project. In addition, for users connected to internal servers, there is the option to upload private projects, which cannot be viewed by other users (other than administrators). There is also an option to View Project Audit Trail , which will show the Audit Trail, in OmicScript form, of every major action taken by the analyst when analyzing the project (or the steps performed by Omicsoft to analyze the public projects). Notice that the Content tab contains a list of all data that was uploaded with the project, as well as the index status of the data. If a dataset or table is Indexed , it can be searched within Array Viewer. This would mean that the testing results contain rows that are indexed (probesets) that can be searched, while the summary Table does not, and thus it cannot be searched. The Design tab shows the design table information (sample information) for each project. For projects with multiple datasets, there will be multiple dataset names available in the Data name dropdown box. This is useful in getting information about the samples contained in each project, without having to download data for that project. Note that any of these tables can be easily exported to Excel or saved as text using the toolbar above the table. The InferenceReport tab contains information on any inference reports created. For each tests table in the Data name dropdown box, each comparison is shown, with information as to whether Raw p-value, Adjusted p-value, Estimate, Fold change, and Max(LSMean) (to be used as an intensity filter ) are available. Contrasts can be categorized into a Test type, and this can be shown here as well (and used for filtering with the Search Inference Report module). A description of each contrast (or test) can also be entered by the user upon uploading a project (or edited by a user with write access to that project). For users not familiar with the concept of a contrast or test , think of it as a ratio , complete with p-value and fold change information, as well as the maximum intensity for each group in the test.","title":"Project Browser, Tagging, and Meta Data"},{"location":"tutorials/ServerExplorer/Publishing_Data/","text":"Publishing Data Any Array Studio user has the ability to publish data to the server. This can also be done through Array Viewer, and only requires the user to have access to a project file. If the user of this tutorial does not have access to a project file, and to an internal server, this section can be skipped. Click Publish Project from the Publish dropdown box. Choose the project .osprj file that you have saved and are ready to publish. The project cannot be opened while being published in Server Explorer. This opens the Publish Project window. In this window, you must first choose the data/items to publish. Any number of data, tables, and lists can be published. Next, you must choose which of these published data and tables will be enabled for full-text search. This is an extremely important step, as only those selected data and tables will be searchable (those not chosen will be uploaded, and available for download, but not searchable). Next, the Meta Data needs to be entered. If you are replacing an existing project, you can use the Load Meta Data From Existing Project button to choose an existing project s meta data. Meta data tabs include General, Platform, Contact, Custom, Category, and Publish (Note: For internal servers, the administrator has the ability to completely customize meta data, so this may look different). The ProjectID field can be used to replace a project. If a project with a particular ProjectID already exists on the server, the user will receive a warning message asking if they want to replace that project. Leaving the ProjectID field blank will generate an automatic ProjectID for that project. Click the Publish tab, as this tab contains important information. This allows the user to select which User Groups will have Read and Editor Access to a project. A Project is Private checkbox allows the user to upload a project for private use only. Clicking the Publish button will upload your Array Studio project to the server, where it will be fully searchable and available to the selected User Groups. Note: Certain fields may be required in order to publish a project (when it is not private). These fields may differ depending on the administrator. More information on options for publishing can be found in the individual help module.","title":"Publishing Data"},{"location":"tutorials/ServerExplorer/Publishing_Data/#publishing-data","text":"Any Array Studio user has the ability to publish data to the server. This can also be done through Array Viewer, and only requires the user to have access to a project file. If the user of this tutorial does not have access to a project file, and to an internal server, this section can be skipped. Click Publish Project from the Publish dropdown box. Choose the project .osprj file that you have saved and are ready to publish. The project cannot be opened while being published in Server Explorer. This opens the Publish Project window. In this window, you must first choose the data/items to publish. Any number of data, tables, and lists can be published. Next, you must choose which of these published data and tables will be enabled for full-text search. This is an extremely important step, as only those selected data and tables will be searchable (those not chosen will be uploaded, and available for download, but not searchable). Next, the Meta Data needs to be entered. If you are replacing an existing project, you can use the Load Meta Data From Existing Project button to choose an existing project s meta data. Meta data tabs include General, Platform, Contact, Custom, Category, and Publish (Note: For internal servers, the administrator has the ability to completely customize meta data, so this may look different). The ProjectID field can be used to replace a project. If a project with a particular ProjectID already exists on the server, the user will receive a warning message asking if they want to replace that project. Leaving the ProjectID field blank will generate an automatic ProjectID for that project. Click the Publish tab, as this tab contains important information. This allows the user to select which User Groups will have Read and Editor Access to a project. A Project is Private checkbox allows the user to upload a project for private use only. Clicking the Publish button will upload your Array Studio project to the server, where it will be fully searchable and available to the selected User Groups. Note: Certain fields may be required in order to publish a project (when it is not private). These fields may differ depending on the administrator. More information on options for publishing can be found in the individual help module.","title":"Publishing Data"},{"location":"tutorials/ServerExplorer/Searching_Projects/","text":"Searching Projects Array Viewer/Server Explorer offers the ability to quickly search meta data for particular terms. For instance, if the user wants to search all projects for the term cancer , this can easily be done. All searches in Array Viewer can be done using the Search dropdown box at the top of the screen and choosing Wizard . In Array Viewer/Server Explorer, it s possible to search the Project, the Variable, and the Observation (sample information). First, we will demonstrate searching just the project meta data, but you will soon see that both projects and variables can be searched. Note In Array Viewer, searching variables is equivalent to searching genes, SNPs, CNVs, etc. Searching Project Meta Data To search project meta data, use the Filter Project tab. Options for this tab include searching by full text search, or sub setting the data via the Disease, Organism, Platform, or Custom tabs. Type neoplasms into the search field for Project (full text search). Notice that Array Viewer has an auto-fill feature, that attempts to fill in known meta data information as you type (This is a good indicator of terms contained on the server, and can be helpful when searching). This is extremely helpful for finding projects of interest. For instance, in the example below, typing \"cancer\" into the search box will either search all project meta data fields for cancer, or search particular columns or levels for the term. The user can choose to return, for instance, any project where the column DiseaseState, contains \"cancer\". Another common search would be searching for projects that contain Age, Ethnicity, Gender, etc. The best way to search for projects related to cancer would be to use the disease classifications built into the GEO data in Array Server, and to search for a term like neoplasms. Choose Category neoplasms , as shown below, pertaining to any project that belongs to the category of neoplasms. Click OK to save the pattern (Array Server uses its own pattern system to tell the server how to search, although this never has to be learned by the user). Click Search Server to begin the search. The server will search for all projects with the disease classification of neoplasms . The Report Tab After every search in Array Viewer, a new tab is opened, containing all the search information and results for each search. These are named incrementally, from Project, Project_2, Project_3, etc. Notice that after performing the search for cancer, a new tab is created, called Project_2. Selecting All Tasks | Show Project Report will return the report of all projects returned from that search. Click this now. This opens a floating window with a table of the projects that matched the results of the search. This table contains the list of projects that have meta data that match the results of the search, as well as a link to Download the data (demonstrated later), Organism, Study Type, Sample #, Platform, PublishDate, Category information, PublishedBy information, Title of project, and the number of rows that match the symbol searched. As we did not search a symbol, the Matched column should return the total number of rows (or variables/markers/probesets) in each project. The floating report can be sorted by right-clicking on any header in the table. In addition, it can be exported to Excel or saved as a text file by using the toolbar above the report (this is standard in any table view in Array Viewer). Project tab meta data Now, let s take a look at which projects were returned by our search. If the floating report window is still open, close it now. Scroll to and click on gse10063, to see the meta data for this particular project. Switching to the Category tab will show that this project belongs to the Neoplasm disease classification, specifically Leukoplakia, Oral. Downloading Project for Analysis in Array Studio For users with internal servers and licensed copies of Array Studio, projects can be downloaded to be further analyzed and refined by the user. This can be done by clicking on any of the returned projects in the Project Browser and clicking the All Tasks dropdown menu at the top of the Project Browser. Then, choose Download Filtered Project To Local from this menu. This opens a dialog box for saving the project, which will be downloaded in its entirety to the user s local machine in the specified folder. For the purposes of this tutorial, this is not necessary, but it should be noted that the project is downloaded in the exact state that it was originally uploaded, including any views, analyses, etc. Alternatively, users can double-click the selected project. Multiple options are provided for downloading the project: Filtering Variables One of the real powers of Array Viewer lies in its ability to visualize analysis results and views that were uploaded by the original analyst, as well as the ability to add new views for projects. While it is possible to view all the rows in a project in the server, this is not always recommended. Sometimes the recommended option is to do a search for a particular Variable (Gene names or Probe/ProbeSet names). The result will be a list of projects in the Project Browser containing the number of rows matching the Variable we have searched. Let s do a search again, but this time, we will look for projects containing category neoplasms, and the gene symbol egr1 . Click Search Server to begin the search. Matching projects are returned in the Results window. Now, let s take a look at one of these projects. Scroll to and click on gse10063. By taking a look at the meta data, we can see that this is a project looking at the effects of tobacco smoke on gene expression and cellular pathways in a cellular model of oral leukoplakia. To take a closer look at the data for this project, we have four options. Double-click on gse10063 now. The user will be prompted with multiple options for downloading the project: Select the second option and click OK . (The first time an annotation-type is downloaded as cache to your machine, the binary annotation will be downloaded as well. Each subsequent time will be faster as the annotation will not need to be re-downloaded). This returns all of the data related to the ID egr1 for this project. In the Project Browser, notice that there is now a tree, containing a number of datasets and results tables. These are the exact datasets and results tables that were uploaded by the original analyst, containing all of the observations (60 chips) and 3 of the rows (expand the nodes of the explorer to see similar to below). Open up the .Tests table, containing the results of any statistical tests performed on this project, and double-click on the Report view. Before we delve too far into this project, note the Gene Symbol column. We ve returned only symbols that are EGR1, as we might have expected. Views and Customizations Customizing a view Now expand the dataset GSE10063 HG-U133_Plus_2 and double-click on the view Variable to see the view created by the user that uploaded the data. This view shows all of the 60 chips from this experiment and their expression. For many projects, this will be automatically grouped using BiologicalGroup, which is the group that was used for the creation of any analysis and inference report. There are 3 charts, one for each variable representing egr1 . The important point to take home from this is that this view was created by the analyst. Any and all views created by the analyst are visible in Array Viewer. Notice the Task tab on the right-hand side of the screen. This is the exact same Task tab that is contained in Array Studio, and allows the user of Array Viewer to further customize a view. In addition, the user has the option to further filter the view using the Observation and Variable tabs as well. The screenshot above is after flip X/Y . Click on Change Profile Gallery in the Task tab (under Customize) now. Change the gallery type to Boxplot and click OK . Notice that the view has been updated to show a boxplot plot representation of this particular probeset s expression across all of its chips in each group. This view can be further customized, if needed in change symbol properties for dot color, shape, jitter and etc. Filtering a View Besides using the Task tab, the user has the option of customizing a view, by using the Variable and Observation tabs in view controller to further filter the data. Click on the Observation tab to see the available filters for this dataset. Expand the filter Treatment to see the treatments that can be filtered. Click on Tobacco smoke to see only those samples that were treated with tobacco smoke. Notice that the main view window is updated to now only show those chips associated with tobacco smoke treatment. The available filters in the Observation tab are from the Design table of this project, and are dependent on what the analyst uploaded when uploading the project. Right-clicking on a filter column will usually allow the user to change the type of filter, from a Radio filter (allowing selection of one group or all groups), a Checkbox filter (allowing the selection of multiple groups, all, or none), and a String filter (allowing the entering of a string for filtering). Sometimes not all of these options are available, as it is dependent on the column type for that column (i.e. numeric, factor, character, etc.). Change the filter back to (all) before continuing. Note that all the views can be saved as pictures/texts, or opened in Excel or PowerPoint by using the toolbar contained over the views. Creating A New View Besides the ability to look at views that were created by the original analyst, the user has the ability to add new views for their own purposes. These views are not saved back to the server with the project (unless the user shares the view in which case a static representation of the view is saved to the server), but can be opened and saved as pictures, in Excel, or in PowerPoint. To add a new view, click the View menu and then Add View . Then, choose the dataset or table to which you want to add the view (in this case GSE10063 HG-U133_Plus_2). Array Viewer and Array Studio always give the user the choice as to which dataset or table to add a view. Alternatively, you can right-click on the dataset of which you want to add a view, and click Add View. This opens the Add View dialog box. Click HeatmapView and click OK to add a HeatmapView to the dataset. This window is context-sensitive and contains all the views available for that type of data or table. Inference tables have different views available than MicroArray data, which has different views available than copy number data, etc. The HeatmapView is created and can be further customized, filtered, etc., and then be saved by the user in Excel, PowerPoint, or as a picture. Data Menu When using Array Viewer, you cannot perform additional analysis on the data. Analysis can only be performed by using Array Studio. However, Array Viewer does offer the user the option to perform some manipulation features on datasets and tables. These manipulations are not permanent, and are not uploaded to the server. However, they can be used for temporary purposes. For OMIC datasets, the Data menu is available for manipulations. Also, for manipulation of table data, the Table menu can be used. Click the OmicData menu now to see the list of manipulation options available for microarray data. Options include subsetting data, splitting data, merging data, concatenating data, deleting data, sort variables, sort observations, generating contrast data, exporting data, and uploading the results of an inference report to GeneGo. Choose Split now to split the dataset into multiple parts, using the design table. This opens the Select Data window. Choose the dataset we have been working with, and click OK. Note, it is possible to have multiple projects data downloaded at the same time, and thus you may be given the option of which project and dataset upon which to perform the split. In this case, there was only one dataset downloaded (although there were other tables and inference reports). This opens the Split Data window. Choose Split observations, and choose Treatment from the drop-down menu. Click Check All to split the data into all 3 of the Groups. Click OK to continue. Notice that after splitting, 2 new datasets have been created and views are now accessible in the project browser. Note: These changes are not permanent, and are not stored on the server, but are for temporary purposes only. Sharing a View One of the key features of Array Viewer is the ability to share any customized view with another user. This view is saved statically (like a snapshot of the data), so even if the original data changes, this view is still the same. Let s share the view we just created (the HeatmapView). If this view is not the current view, switch to it now. You can switch the open view using the list of views at the top of the main section of the window, or by finding it again and double-clicking in the Project Browser. To share a view, click the Share dropdown box and choose Share View . This opens the Share View window. The user has the ability to create a Title and Description for the view, as well as to set the User groups and/or individual Users that can see the view. Enter a Title and a Description now, and then click OK to continue. Array Viewer will inform you that the view has been shared, and assign it a view ID. Click OK. In addition, Array Viewer will automatically open up your default email program, containing a link to the shared view, which you can use to send to a colleague, similar to the screenshot below. Other options regarding Shared Views include opening a previously shared view, re-sharing a view (to once again create an email link), and un-sharing a previously shared view, all available from the Share dropdown menu. Batch Searching Projects Besides being able to search for a project using a single project search term and single symbol term, Array Studio offers the ability to do a batch search. This time, instead of filtering projects by full-text search, we will use the tabs for Organism, Platform, and Custom. These tabs allow the user to filter by predefined fields, specified by the administrator. Click on the Custom tab to see the options for filtering by multiple projects in a customized manner. Add Criterion can be used to add a filter for a specific field to the batch search. Alternatively, Add List can be used to filter by a general criterion, or a project list. Click Add List to add a filter criterion to the batch search. This opens the Input Project List window. Change Input list is to (anything) and enter hypoxia, heart failure, and cholesterol in the search box. Click OK to continue. The Custom tab is updated to reflect the added filters. Here, we specify the field to be anything. We can explicitly specify the field to be ProjectID and other metadata design columns.","title":"Searching Projects"},{"location":"tutorials/ServerExplorer/Searching_Projects/#searching-projects","text":"Array Viewer/Server Explorer offers the ability to quickly search meta data for particular terms. For instance, if the user wants to search all projects for the term cancer , this can easily be done. All searches in Array Viewer can be done using the Search dropdown box at the top of the screen and choosing Wizard . In Array Viewer/Server Explorer, it s possible to search the Project, the Variable, and the Observation (sample information). First, we will demonstrate searching just the project meta data, but you will soon see that both projects and variables can be searched. Note In Array Viewer, searching variables is equivalent to searching genes, SNPs, CNVs, etc.","title":"Searching Projects"},{"location":"tutorials/ServerExplorer/Searching_Projects/#searching-project-meta-data","text":"To search project meta data, use the Filter Project tab. Options for this tab include searching by full text search, or sub setting the data via the Disease, Organism, Platform, or Custom tabs. Type neoplasms into the search field for Project (full text search). Notice that Array Viewer has an auto-fill feature, that attempts to fill in known meta data information as you type (This is a good indicator of terms contained on the server, and can be helpful when searching). This is extremely helpful for finding projects of interest. For instance, in the example below, typing \"cancer\" into the search box will either search all project meta data fields for cancer, or search particular columns or levels for the term. The user can choose to return, for instance, any project where the column DiseaseState, contains \"cancer\". Another common search would be searching for projects that contain Age, Ethnicity, Gender, etc. The best way to search for projects related to cancer would be to use the disease classifications built into the GEO data in Array Server, and to search for a term like neoplasms. Choose Category neoplasms , as shown below, pertaining to any project that belongs to the category of neoplasms. Click OK to save the pattern (Array Server uses its own pattern system to tell the server how to search, although this never has to be learned by the user). Click Search Server to begin the search. The server will search for all projects with the disease classification of neoplasms .","title":"Searching Project Meta Data"},{"location":"tutorials/ServerExplorer/Searching_Projects/#the-report-tab","text":"After every search in Array Viewer, a new tab is opened, containing all the search information and results for each search. These are named incrementally, from Project, Project_2, Project_3, etc. Notice that after performing the search for cancer, a new tab is created, called Project_2. Selecting All Tasks | Show Project Report will return the report of all projects returned from that search. Click this now. This opens a floating window with a table of the projects that matched the results of the search. This table contains the list of projects that have meta data that match the results of the search, as well as a link to Download the data (demonstrated later), Organism, Study Type, Sample #, Platform, PublishDate, Category information, PublishedBy information, Title of project, and the number of rows that match the symbol searched. As we did not search a symbol, the Matched column should return the total number of rows (or variables/markers/probesets) in each project. The floating report can be sorted by right-clicking on any header in the table. In addition, it can be exported to Excel or saved as a text file by using the toolbar above the report (this is standard in any table view in Array Viewer).","title":"The Report Tab"},{"location":"tutorials/ServerExplorer/Searching_Projects/#project-tab-meta-data","text":"Now, let s take a look at which projects were returned by our search. If the floating report window is still open, close it now. Scroll to and click on gse10063, to see the meta data for this particular project. Switching to the Category tab will show that this project belongs to the Neoplasm disease classification, specifically Leukoplakia, Oral.","title":"Project tab meta data"},{"location":"tutorials/ServerExplorer/Searching_Projects/#downloading-project-for-analysis-in-array-studio","text":"For users with internal servers and licensed copies of Array Studio, projects can be downloaded to be further analyzed and refined by the user. This can be done by clicking on any of the returned projects in the Project Browser and clicking the All Tasks dropdown menu at the top of the Project Browser. Then, choose Download Filtered Project To Local from this menu. This opens a dialog box for saving the project, which will be downloaded in its entirety to the user s local machine in the specified folder. For the purposes of this tutorial, this is not necessary, but it should be noted that the project is downloaded in the exact state that it was originally uploaded, including any views, analyses, etc. Alternatively, users can double-click the selected project. Multiple options are provided for downloading the project:","title":"Downloading Project for Analysis in Array Studio"},{"location":"tutorials/ServerExplorer/Searching_Projects/#filtering-variables","text":"One of the real powers of Array Viewer lies in its ability to visualize analysis results and views that were uploaded by the original analyst, as well as the ability to add new views for projects. While it is possible to view all the rows in a project in the server, this is not always recommended. Sometimes the recommended option is to do a search for a particular Variable (Gene names or Probe/ProbeSet names). The result will be a list of projects in the Project Browser containing the number of rows matching the Variable we have searched. Let s do a search again, but this time, we will look for projects containing category neoplasms, and the gene symbol egr1 . Click Search Server to begin the search. Matching projects are returned in the Results window. Now, let s take a look at one of these projects. Scroll to and click on gse10063. By taking a look at the meta data, we can see that this is a project looking at the effects of tobacco smoke on gene expression and cellular pathways in a cellular model of oral leukoplakia. To take a closer look at the data for this project, we have four options. Double-click on gse10063 now. The user will be prompted with multiple options for downloading the project: Select the second option and click OK . (The first time an annotation-type is downloaded as cache to your machine, the binary annotation will be downloaded as well. Each subsequent time will be faster as the annotation will not need to be re-downloaded). This returns all of the data related to the ID egr1 for this project. In the Project Browser, notice that there is now a tree, containing a number of datasets and results tables. These are the exact datasets and results tables that were uploaded by the original analyst, containing all of the observations (60 chips) and 3 of the rows (expand the nodes of the explorer to see similar to below). Open up the .Tests table, containing the results of any statistical tests performed on this project, and double-click on the Report view. Before we delve too far into this project, note the Gene Symbol column. We ve returned only symbols that are EGR1, as we might have expected.","title":"Filtering Variables"},{"location":"tutorials/ServerExplorer/Searching_Projects/#views-and-customizations","text":"","title":"Views and Customizations"},{"location":"tutorials/ServerExplorer/Searching_Projects/#customizing-a-view","text":"Now expand the dataset GSE10063 HG-U133_Plus_2 and double-click on the view Variable to see the view created by the user that uploaded the data. This view shows all of the 60 chips from this experiment and their expression. For many projects, this will be automatically grouped using BiologicalGroup, which is the group that was used for the creation of any analysis and inference report. There are 3 charts, one for each variable representing egr1 . The important point to take home from this is that this view was created by the analyst. Any and all views created by the analyst are visible in Array Viewer. Notice the Task tab on the right-hand side of the screen. This is the exact same Task tab that is contained in Array Studio, and allows the user of Array Viewer to further customize a view. In addition, the user has the option to further filter the view using the Observation and Variable tabs as well. The screenshot above is after flip X/Y . Click on Change Profile Gallery in the Task tab (under Customize) now. Change the gallery type to Boxplot and click OK . Notice that the view has been updated to show a boxplot plot representation of this particular probeset s expression across all of its chips in each group. This view can be further customized, if needed in change symbol properties for dot color, shape, jitter and etc.","title":"Customizing a view"},{"location":"tutorials/ServerExplorer/Searching_Projects/#filtering-a-view","text":"Besides using the Task tab, the user has the option of customizing a view, by using the Variable and Observation tabs in view controller to further filter the data. Click on the Observation tab to see the available filters for this dataset. Expand the filter Treatment to see the treatments that can be filtered. Click on Tobacco smoke to see only those samples that were treated with tobacco smoke. Notice that the main view window is updated to now only show those chips associated with tobacco smoke treatment. The available filters in the Observation tab are from the Design table of this project, and are dependent on what the analyst uploaded when uploading the project. Right-clicking on a filter column will usually allow the user to change the type of filter, from a Radio filter (allowing selection of one group or all groups), a Checkbox filter (allowing the selection of multiple groups, all, or none), and a String filter (allowing the entering of a string for filtering). Sometimes not all of these options are available, as it is dependent on the column type for that column (i.e. numeric, factor, character, etc.). Change the filter back to (all) before continuing. Note that all the views can be saved as pictures/texts, or opened in Excel or PowerPoint by using the toolbar contained over the views.","title":"Filtering a View"},{"location":"tutorials/ServerExplorer/Searching_Projects/#creating-a-new-view","text":"Besides the ability to look at views that were created by the original analyst, the user has the ability to add new views for their own purposes. These views are not saved back to the server with the project (unless the user shares the view in which case a static representation of the view is saved to the server), but can be opened and saved as pictures, in Excel, or in PowerPoint. To add a new view, click the View menu and then Add View . Then, choose the dataset or table to which you want to add the view (in this case GSE10063 HG-U133_Plus_2). Array Viewer and Array Studio always give the user the choice as to which dataset or table to add a view. Alternatively, you can right-click on the dataset of which you want to add a view, and click Add View. This opens the Add View dialog box. Click HeatmapView and click OK to add a HeatmapView to the dataset. This window is context-sensitive and contains all the views available for that type of data or table. Inference tables have different views available than MicroArray data, which has different views available than copy number data, etc. The HeatmapView is created and can be further customized, filtered, etc., and then be saved by the user in Excel, PowerPoint, or as a picture.","title":"Creating A New View"},{"location":"tutorials/ServerExplorer/Searching_Projects/#data-menu","text":"When using Array Viewer, you cannot perform additional analysis on the data. Analysis can only be performed by using Array Studio. However, Array Viewer does offer the user the option to perform some manipulation features on datasets and tables. These manipulations are not permanent, and are not uploaded to the server. However, they can be used for temporary purposes. For OMIC datasets, the Data menu is available for manipulations. Also, for manipulation of table data, the Table menu can be used. Click the OmicData menu now to see the list of manipulation options available for microarray data. Options include subsetting data, splitting data, merging data, concatenating data, deleting data, sort variables, sort observations, generating contrast data, exporting data, and uploading the results of an inference report to GeneGo. Choose Split now to split the dataset into multiple parts, using the design table. This opens the Select Data window. Choose the dataset we have been working with, and click OK. Note, it is possible to have multiple projects data downloaded at the same time, and thus you may be given the option of which project and dataset upon which to perform the split. In this case, there was only one dataset downloaded (although there were other tables and inference reports). This opens the Split Data window. Choose Split observations, and choose Treatment from the drop-down menu. Click Check All to split the data into all 3 of the Groups. Click OK to continue. Notice that after splitting, 2 new datasets have been created and views are now accessible in the project browser. Note: These changes are not permanent, and are not stored on the server, but are for temporary purposes only.","title":"Data Menu"},{"location":"tutorials/ServerExplorer/Searching_Projects/#sharing-a-view","text":"One of the key features of Array Viewer is the ability to share any customized view with another user. This view is saved statically (like a snapshot of the data), so even if the original data changes, this view is still the same. Let s share the view we just created (the HeatmapView). If this view is not the current view, switch to it now. You can switch the open view using the list of views at the top of the main section of the window, or by finding it again and double-clicking in the Project Browser. To share a view, click the Share dropdown box and choose Share View . This opens the Share View window. The user has the ability to create a Title and Description for the view, as well as to set the User groups and/or individual Users that can see the view. Enter a Title and a Description now, and then click OK to continue. Array Viewer will inform you that the view has been shared, and assign it a view ID. Click OK. In addition, Array Viewer will automatically open up your default email program, containing a link to the shared view, which you can use to send to a colleague, similar to the screenshot below. Other options regarding Shared Views include opening a previously shared view, re-sharing a view (to once again create an email link), and un-sharing a previously shared view, all available from the Share dropdown menu.","title":"Sharing a View"},{"location":"tutorials/ServerExplorer/Searching_Projects/#batch-searching-projects","text":"Besides being able to search for a project using a single project search term and single symbol term, Array Studio offers the ability to do a batch search. This time, instead of filtering projects by full-text search, we will use the tabs for Organism, Platform, and Custom. These tabs allow the user to filter by predefined fields, specified by the administrator. Click on the Custom tab to see the options for filtering by multiple projects in a customized manner. Add Criterion can be used to add a filter for a specific field to the batch search. Alternatively, Add List can be used to filter by a general criterion, or a project list. Click Add List to add a filter criterion to the batch search. This opens the Input Project List window. Change Input list is to (anything) and enter hypoxia, heart failure, and cholesterol in the search box. Click OK to continue. The Custom tab is updated to reflect the added filters. Here, we specify the field to be anything. We can explicitly specify the field to be ProjectID and other metadata design columns.","title":"Batch Searching Projects"},{"location":"tutorials/ServerExplorer/Server_Administration/","text":"Server Administration If you are administrator, you can manage server jobs, user profile, pipeline scripts, chip/gene annotation and other predefined list/sets in the Manage dropdown list menu:","title":"Server Administration"},{"location":"tutorials/ServerExplorer/Server_Administration/#server-administration","text":"If you are administrator, you can manage server jobs, user profile, pipeline scripts, chip/gene annotation and other predefined list/sets in the Manage dropdown list menu:","title":"Server Administration"},{"location":"tutorials/ServerExplorer/Server_FileManagement/","text":"Server File Management The user has the option of accessing the raw data management system via Server Explorer in Array Studio. They can do so by choosing Server Files | Browse Files in the Server Explorer. Browse Files In the screenshot below, notice that there are two levels to the ServerFiles tab that is opened when you choose Browse Files. On the top level is a browser. The user can go up or down a level, create new folders (where appropriate), download files, or upload files. The user can also refresh the FTP folder they were previously viewing. When uploading or downloading from the raw data management system, progress for the transfer is shown on the lower part of the screen. This FTP transfer system supports a queue, so one file is transferred at a time until the queue is completed. The user can right click to stop and start a file in the queue. The user can also right-click on individual files to Download the file, Create New Folder, Refresh, Delete (only allowed by administrators), Rename (only allowed by administrators), Copy URLs (to get a copy of the exact location of the file of interest), or move the file to other locations in the server. Browse Files in Windows Explorer The user can also access the FTP site using Windows Explorer by choosing Server File | Browse Files in Windows Explorer from the Server Explorer menu. This can be useful for quickly uploading data by drag and drop from folders in Windows. Browse Files in Master Server If ArrayServer has been set up using Master-Analytic setting, users can only browse the analytic server they are logged into with Browse Files . The user can choose to browse contents in Master server by Server File | Browse Files (Master Server) from the Server Explorer menu. For more details regarding master and analytic server, please read the following wiki article: link","title":"Server File Management"},{"location":"tutorials/ServerExplorer/Server_FileManagement/#server-file-management","text":"The user has the option of accessing the raw data management system via Server Explorer in Array Studio. They can do so by choosing Server Files | Browse Files in the Server Explorer.","title":"Server File Management"},{"location":"tutorials/ServerExplorer/Server_FileManagement/#browse-files","text":"In the screenshot below, notice that there are two levels to the ServerFiles tab that is opened when you choose Browse Files. On the top level is a browser. The user can go up or down a level, create new folders (where appropriate), download files, or upload files. The user can also refresh the FTP folder they were previously viewing. When uploading or downloading from the raw data management system, progress for the transfer is shown on the lower part of the screen. This FTP transfer system supports a queue, so one file is transferred at a time until the queue is completed. The user can right click to stop and start a file in the queue. The user can also right-click on individual files to Download the file, Create New Folder, Refresh, Delete (only allowed by administrators), Rename (only allowed by administrators), Copy URLs (to get a copy of the exact location of the file of interest), or move the file to other locations in the server.","title":"Browse Files"},{"location":"tutorials/ServerExplorer/Server_FileManagement/#browse-files-in-windows-explorer","text":"The user can also access the FTP site using Windows Explorer by choosing Server File | Browse Files in Windows Explorer from the Server Explorer menu. This can be useful for quickly uploading data by drag and drop from folders in Windows.","title":"Browse Files in Windows Explorer"},{"location":"tutorials/ServerExplorer/Server_FileManagement/#browse-files-in-master-server","text":"If ArrayServer has been set up using Master-Analytic setting, users can only browse the analytic server they are logged into with Browse Files . The user can choose to browse contents in Master server by Server File | Browse Files (Master Server) from the Server Explorer menu. For more details regarding master and analytic server, please read the following wiki article: link","title":"Browse Files in Master Server"},{"location":"tutorials/ServerExplorer/Server_Sample_Management/","text":"Server Sample Management Samples and sample sets are registered and managed on the server, along with their corresponding meta data. An -Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic element for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria. Please read more details in the Sample Management tutorial.","title":"Server Sample Management"},{"location":"tutorials/ServerExplorer/Server_Sample_Management/#server-sample-management","text":"Samples and sample sets are registered and managed on the server, along with their corresponding meta data. An -Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic element for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria. Please read more details in the Sample Management tutorial.","title":"Server Sample Management"},{"location":"tutorials/Transgene/DataAnalysis/","text":"Data Analysis In this tutorial, we will show how to run the following analysis: build genome reference, raw data QC, pre-processing, coverage analysis, transgene detection, consensus inference and variation detection, . The general analysis workflow can be illustrated as below: We will show each step one by one in this tutorial. All these steps can be concatenated together using OmicScript to be a standard pipeline and generate report using ExportToReport function. Build plasmid Reference and Gene Model For transgene analysis, the user has to build a genome reference for the plasmid sequence. To build a reference library, use NGS | Build | Build Reference Library to build the reference from a FASTA file: Input any name for Reference Library ID: If the user also has the gene model files (GTF or GFF) for the plasmid, a gene model can also be built in NGS | Build | Build Gene Model . It is optional for transgene analysis. With a gene model, the genome browser can show the transgene integration site along with gene annotation on the genome. The mutation analysis can also use a gene model to assess the impact of the variation (in order to check whether it is causing amino acid changes or not). Once built, the user can check how the reference and gene model look like in the Genome Browser: Note If you do not see your new reference in the drop-down menu, de-select the option \"List Server components\". This is because the reference you have build that is stored in your local cache, not the server. If you wish to perform this tutorial, please connect to ArrayServer, and create a Server Project before building your reference genome and gene model. You will get a genome browser view of the plasmid in linear scale: Raw Data QC Once user gets raw data from NGS machine, it is best to go through the raw data QC step to check data quality. Array Studio contains modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard , which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. Click Add to find all fastq files, and check the QC metrics to run. Optionally, for a faster analysis, the user can choose preview mode to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave File format to AUTO and Quality encoding as Automatic to automatically set the correct quality encoding method. Click Submit to begin the analysis. The raw data QC returns multiple raw data QC results/reports in Raw Data QC folder: The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. The Sequence length report shows the distribution of read length. For original data from the sequencer, read length should be the same. After the user runs pre-processing such as trimming and adapter stripping, the read lengths will be different. The distribution of sequence length will show the final read length after trimming and stripping. Base distribution of each raw data file is useful for ensuring that the base distribution is as expected (sometimes can be used to notice adapter sequences if the user is not aware that they are there as well). Quality BoxPlot shows, for each base pair position in a file, information on the quality scoring at that position. This gives the user an idea of where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality of multiple samples. The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of a kmer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each KMer. There is no significant (all less than 1%) enrichment of k-mer in this tutorial dataset. Alignment Align to Host User should then align reads to host genome. At this moment, we provided two CHO reference genomes: CriGri.B1.0: the original BGI version CriGri.B1.1: based on NCBI, Genome reference \"C_griseus_v1.0\". Check \" Reads are paired \", and specify output name in the Advanced tab. The user can leave all other options as default in general tab. Some companies may require users to specify the output folder too. The Advanced menu has more options to specify the indel length. By default, it detects deletion up to 1000bp and insertion up to 10bp. However, it is designed for regular human/mouse DNA-Seq samples. For mutation detection in plasmids, it is recommended to decrease the upper limit of deletion length to 10bp. The expected insert size in this dataset is 800bp since the data was simulated based on SRA dataset SRX091184. It will align to host, CHO reference, and generate NgsData (BAM files) and alignment statistics. NgsData in ArrayStudio Projects: Alignment reports summarize the alignment statistics, such as fragment size of paired end reads, # and % of reads uniquely aligned. In the coverage analysis step, users can further use the NgsData to count the # of reads mapped to each contig, and get coverage report/views at base pair resolution. Align to Plasmid Before alignment to plasmid, the user will have to pre-build plasmid genome reference from FASTA files. As mentioned in the previous step, the user has to build a plasmid reference: pGRG36, for this tutorial. More options can be found under the Advanced tab: It will align to plasmid reference, and generate NgsData (BAM files) and alignment statistics. NgsData in ArrayStudio Projects: Alignment reports: Coverage analysis on host genome Quantify Coverage on contigs Since the CHO genome reference is not yet well defined, there are many contigs from CHO, and the user will get lost by looking at coverage directly. The user can first quantify the coverage on each contig, and get the percentage of mapped reads in each contig. The NGS | Quantification | Report Gene/Transcript Count function is designed to quantify gene expression from RNA-Seq data. If the input is DNA-Seq data, it will quantify the read counts on each contig/chr: Choose the host alignment NgsData, and choose expression measurement to be Count ; Count fragments instead of reads will count properly paired reads only; EM algorithm will assign reads mapped to multiple contigs based on EM iterations. It will generate an OmicData with rows for contigs and columns for samples: The default data object name still contains \"Transcript\" since it was designed for RNA-Seq. User can always rename it to other names such as AlignToHost.ContigReadCount . The data values are EM read counts for each contig. User can further convert them to percentages of mapped reads in each contig by using NGS | Inference | Normalize RNA-Seq Data (again, the function was designed for RNA-Seq, but can be applied to DNA-Seq data). Use the TotalCount method and scale the total count to 1, then the count of reads will be normalized as percentage of reads mapped to each contigs. In the table, user can right click the header and sort the table column descending. It shows top contigs which have been enriched in the NGS library. By selecting top contigs, user can create a list of them for filtering purpose in other tables. Right click on List , \"Add list from selected rows\" and name it \"TopContigs\": Summarize Coverage The NGS | Coverage | Coverage Summary Statistics module can be used to calculate the coverage of the mapping at defined bin resolution or export as a bedgraph file at base pair resolution. Pick the Host alignment NgsData as Data input. Exclude multi-reads: Multi reads are considered non-unique (i.e. reads that align to multiple genomic locations with equal or similar numbers of mismatches). Selecting this option will include unique reads only when performing the coverage summarization. Exclude duplicates: duplicate reads are reads mapped to the exact same location. Duplicated reads are excluded by default in most NGS modules. The coverage will be summarized in each bin size specified. If user wants to have the basepair resolution coverage, he/she can choose to output bedGraph files. The output is a table of coverage values in each bin for each sample. It also generates a histogram of coverage on all contigs. However, there are so many contigs in CHO, it is recommended to use top contigs as a filter to filter the table, then open the histogram plot. In the View Controller on the right, select the Row tab, then right-click on \"Chromosome\" and select \"Add List Filter\". For some tables, it has been set as check box by default. If you do not see \"Add list Filter\", please change the column to \"String Filter\". User can also type the following contigs in the String filter in to check contigs: Check coverage at base pair resolution using BedGraph file in Genome Browser The bedGraph files contain continuous coverage data in track format. It is generated by the coverage analysis and loads much faster in genome browser than loading the actual BAM files. Steps: Create new genome browser: Add Track | Add Track from Server Files | Numeric Tracks | BedGraph file Select the bedgraph files generated in the output folder: Jump to contigs of interest to browse coverage at base pair resolution: Integration Detection Tag Split If the NGS library fragments are generated from digestion with a cutting enzyme, it may generate random chimeric DNA fragments which results in false positives in transgene detection. If the cutting enzyme relies on short restriction NT sites, it can bring a lot of false positives in the downstream analysis. If we know the restriction NT combinations, users can first split the reads when finding an enzyme cutting site. It can greatly reduce the false positives in transgene detection. Users can split reads by Tag in the Analysis tab by navigating to NGS | Preprocess | Split by Tag : Add the sample fastq data from server folder: Input format: choose AUTO and it will check file format automatically Quality encoding: the encoding for quality score; recommend using Automatic. Tag sequence: The sequence tag which will be recognized by restriction enzyme. Minimal sequence length: The read will be thrown again if length < MinLength after split Zip format: no gzip or bzip format. The program will go over each fastq file and split reads recursively based on the tag: New fastq.gz files will be generated in the output folder. Note, it is also possible that there are enzyme sites near the true integration site. These sites will not be detected when running Transgene Detection using split reads. Transgene Detection From the raw data (or split read data if Split by Tag has been run), user can start to run transgene detection in NGS | Fusion | Transgene Integration Analysis : Add data from server folder and follow the following options: Input format: choose AUTO and it will check file format automatically Reads are paired Check box: if the box is checked, read1 and read2 files will be automatically paired based on read names as one sample for integration analysis. Host genome: the host genome to detect integration; Make sure you pick the same host reference as in the previous alignment step. Plasmid genome: the custom plasmid genome built by user. Quality encoding: the encoding for quality score; we recommend using Automatic. Zip format: no gzip or bzip format. Thread number: Number of Threads for each job. Job number: Number of parallel jobs to run. Cut size: the minimum size of read end to be aligned to host or plasmid. For read length > 75 bp, we recommend using 25. If read length is less than 75bp, please use the formula (ReadLength/3). Extension: display the left and right extension length of integration junction sequence in the report; will be used to filter false positives caused by restriction enzyme. Perform consensus analysis for partially aligned reads: If checked, the function will scan reads partilly aligned to plasmid reference, and infer the consensus on soft clipped read sequences. Since the CHO genome is not a complete reference, the consensus analysis for partially aligned reads potentially will find integration sites which are not part of the current CHO genome reference. Minimal clipping: The minimal length of clipping region of the read to be used for consensus analysis Minimal read#: The minmal number of reads to report a integration site from consensus analysis Output folder: Browse to specify the output folder. In the Advanced tab: More options: Read Trimming : We recommend the default settings as filtering will typically be done before users get to this step. Mask fuzzy plasmid/host fusion : check this box if user wants to mask regions that are the same in plasmid and host, such as the EASE region in CHO. Exclude fusion if cutting position# : number of cutting position means number of unique reads. The default cut off is one single read support. Misc : generate table land to support big report tables; checking this option will make it easier to share this data with others when complete. Set an output name in ArraySuite project. Click Send to Queue and it will send the job to run on server. Once the job finishes, you can update the project with results and will see three NgsData objects and three result tables: TransgeneReport_PlasmidHost : reports the number of support reads for each transgene integration site for each sample, with information of the integration positions in host and plasmid. For better characterization of integration site, a column named \"Integration Type\" is reported, based on the definition in the schematic below: Example: TRANS_1140_165663373(--) is an integration site between plasmid position 1141 to CHO NW_003613610.1, with 9 reads (8 unique read sequences) supporting from the this dataset. From integration type, user can tell that plasmid sequence starting 1141 has been integrated after CHO NW_003613610.1 position 3346702. TRANS_10161_165672719(++) is an integration site between plasmid position 10162 to CHO NW_003613610.1, with 23 reads (19 unique read sequences) supporting from this dataset. From integration type, user can tell that integration of plasmid ends at 10162 and then continues with CHO seqeunce starting from NW_003613610.1 position 3356048. This data is quite clean and does not have any false positives. Due to the nature of enrichment technology, it is possible to have many false positives introduced, as mentioned in the \"Split by Tag\" section. If user does not run the transgene detection using fastq files from \"Split by Tag\" run, user should filter the detection table based on integration junction sequence (such as not containing \"CATG\" for Targeted Locus Amplification (TLA) datasets, using filter \"not catg\" in the junction sequence), top contigs, and # of supporting reads. Note that the \"Split by Tag\" option, while useful to filter out false positives, has the potential to generate false negatives. Users of this tutorial will notice that only one of the two fusions are detected when using the split fastq files. Thus, filtering of false positives should be done on a case-by-case basis, with users defining how many false positives they can tolerate. For a table with multiple samples, user can get the summary statistics on read counts, such as max of unique reads in any samples, using Table | Columns | Add Columns | Column Summarization | Pick columns and pick summarization method . TransgeneReport_PlasmidPlasmid : report the number of support reads for each plasmid-to-plasmid integration in each sample, with information of the integration positions in host and plasmid. Transgene.TransgeneReport_Consensus : report the number of supporting reads from consensus analysis. The direction indicates the location of consensus sequence relative to the plasmid breakpoint. The consensus sequences that are inferred from soft clipped reads should be part of the host (such as CHO) genome. It reports the number of supporting clipped reads and total number of reads (the total coverage) at the breakpoint. Users can further visualize these integration sites in genome browser based on the NgsData. Genome Browser Of Transgene Integration Within the transgene report, right click on the row ID, user will have the option to open a new genome browser: In the example above, right click on TRANS_1140_165663373(--), which it has option to open one of two NgsData objects. Because we are in the plasmid-to-host transgene report table, choose to open the PlasmidHostFusion NgsData object. It will jump to the Genome browser tab, and list available NGS samples to open: Leave all samples checked and click OK . It will first load the coverage of these supporting reads on two panels, one for plasmid and the other for the host: User can switch the two panes to have the breakpoints facing each other if necessary. Note, although we jump to this genome browser based on one transgene integration site, it loads the NgsData containing all integration site supporting reads. If the current region contains multiple integration sites, the genome browser will show all supporting reads for them. User can filter reads by transgene integration ID in the tag filter in genome browser track property: User can mouse over the sample genome browser track name and it will pop up a tooltip allowing user to display the supporting reads. If the option is grey, please zoom in a little bit to < 200bp region: Strikethrough of part of the read means the read part is not aligned to the region: Part of the read is aligned to plasmid and the rest of the read is aligned to host. User can also view the consensus inference in genome browser. User can filter genome browser alignment by Cigar filter to softclipping reads only, and set minimal length of softclip to be 5 or 10. From the alignment of softclipped region (read parts with strike), the genome view can help user visually check the consensus seqeunce, starting with ACATCAGCCCACGTTTCCAGTTGATGA. User can use PCR to verify the integration site if the reported consensus sequence is not a part of current host genome sequence. For more information about genome browser such as sharing a genome browser, please read Omicsoft Genome Browser Tutorial Here is a general key for genome browser: Variation detection on transgene Based on the alignment of NGS data to plasmid, we can further detect variation based on consensus mutations calls. To do so, user can use the NGS | Variation | Summarize Variant Data (Omicsoft) : Pick the Data to the NgsData of Plasmid alignment, change the Mutation options . The default mutation options are designed for regular human/mouse studies. For production cell lines with enrichment on transgene regions, user should use high cutoff of position coverage and # of reads supporting mutation, while lowering the cutoff for mutation frequency. In this way, user can detect confident variation, at very low frequency level since there might be hundreds of plasmid integrations to the host. Also make sure to reduce the \"exclude mutation if maximal frequency\" option to zero to maximize the sensitivity: The mutation report will contain three columns (coverage, read frequency and %Plus strand) for each data file, and additional annotation for the mutation, such as positions, reference and mutations: Sorting this table by the mutation frequency, we can see that the most frequent mutation is MUT00000026. The mutation position on the plasmid is base pair 6930, reference is A and Variation is G, or an A->G. The position is covered by 87 reads and 87*0.6667=58 reads are supporting G in this position. User can also create a view of Mutation Frequency vs. Coverage by adding a scatterplot view: Selecting data points will show details for these positions. User can further customize the view using options highlighted in the screenshot below: Right click on the row names and show the mutation in genome browser with detailed pile-ups from reads: The genome browser might be slow due to high coverage on these regions: If gene model was built with CDS information for the plasmid, user can add the gene model in the genome browser using: With the gene model, user can further use NGS | Variation | Annotate Variant Table Report to find Non-Synonymous changes. If any exist, it will also annotate the exact amino acid changes. The annotated mutation report will look like below, and can be filtered for certain mutation types (i.e. synonymous) in the View Controller on the right:","title":"Analysis Workflow"},{"location":"tutorials/Transgene/DataAnalysis/#data-analysis","text":"In this tutorial, we will show how to run the following analysis: build genome reference, raw data QC, pre-processing, coverage analysis, transgene detection, consensus inference and variation detection, . The general analysis workflow can be illustrated as below: We will show each step one by one in this tutorial. All these steps can be concatenated together using OmicScript to be a standard pipeline and generate report using ExportToReport function.","title":"Data Analysis"},{"location":"tutorials/Transgene/DataAnalysis/#build-plasmid-reference-and-gene-model","text":"For transgene analysis, the user has to build a genome reference for the plasmid sequence. To build a reference library, use NGS | Build | Build Reference Library to build the reference from a FASTA file: Input any name for Reference Library ID: If the user also has the gene model files (GTF or GFF) for the plasmid, a gene model can also be built in NGS | Build | Build Gene Model . It is optional for transgene analysis. With a gene model, the genome browser can show the transgene integration site along with gene annotation on the genome. The mutation analysis can also use a gene model to assess the impact of the variation (in order to check whether it is causing amino acid changes or not). Once built, the user can check how the reference and gene model look like in the Genome Browser: Note If you do not see your new reference in the drop-down menu, de-select the option \"List Server components\". This is because the reference you have build that is stored in your local cache, not the server. If you wish to perform this tutorial, please connect to ArrayServer, and create a Server Project before building your reference genome and gene model. You will get a genome browser view of the plasmid in linear scale:","title":"Build plasmid Reference and Gene Model"},{"location":"tutorials/Transgene/DataAnalysis/#raw-data-qc","text":"Once user gets raw data from NGS machine, it is best to go through the raw data QC step to check data quality. Array Studio contains modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard , which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. Click Add to find all fastq files, and check the QC metrics to run. Optionally, for a faster analysis, the user can choose preview mode to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave File format to AUTO and Quality encoding as Automatic to automatically set the correct quality encoding method. Click Submit to begin the analysis. The raw data QC returns multiple raw data QC results/reports in Raw Data QC folder: The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. The Sequence length report shows the distribution of read length. For original data from the sequencer, read length should be the same. After the user runs pre-processing such as trimming and adapter stripping, the read lengths will be different. The distribution of sequence length will show the final read length after trimming and stripping. Base distribution of each raw data file is useful for ensuring that the base distribution is as expected (sometimes can be used to notice adapter sequences if the user is not aware that they are there as well). Quality BoxPlot shows, for each base pair position in a file, information on the quality scoring at that position. This gives the user an idea of where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality of multiple samples. The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of a kmer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each KMer. There is no significant (all less than 1%) enrichment of k-mer in this tutorial dataset.","title":"Raw Data QC"},{"location":"tutorials/Transgene/DataAnalysis/#alignment","text":"","title":"Alignment"},{"location":"tutorials/Transgene/DataAnalysis/#align-to-host","text":"User should then align reads to host genome. At this moment, we provided two CHO reference genomes: CriGri.B1.0: the original BGI version CriGri.B1.1: based on NCBI, Genome reference \"C_griseus_v1.0\". Check \" Reads are paired \", and specify output name in the Advanced tab. The user can leave all other options as default in general tab. Some companies may require users to specify the output folder too. The Advanced menu has more options to specify the indel length. By default, it detects deletion up to 1000bp and insertion up to 10bp. However, it is designed for regular human/mouse DNA-Seq samples. For mutation detection in plasmids, it is recommended to decrease the upper limit of deletion length to 10bp. The expected insert size in this dataset is 800bp since the data was simulated based on SRA dataset SRX091184. It will align to host, CHO reference, and generate NgsData (BAM files) and alignment statistics. NgsData in ArrayStudio Projects: Alignment reports summarize the alignment statistics, such as fragment size of paired end reads, # and % of reads uniquely aligned. In the coverage analysis step, users can further use the NgsData to count the # of reads mapped to each contig, and get coverage report/views at base pair resolution.","title":"Align to Host"},{"location":"tutorials/Transgene/DataAnalysis/#align-to-plasmid","text":"Before alignment to plasmid, the user will have to pre-build plasmid genome reference from FASTA files. As mentioned in the previous step, the user has to build a plasmid reference: pGRG36, for this tutorial. More options can be found under the Advanced tab: It will align to plasmid reference, and generate NgsData (BAM files) and alignment statistics. NgsData in ArrayStudio Projects: Alignment reports:","title":"Align to Plasmid"},{"location":"tutorials/Transgene/DataAnalysis/#coverage-analysis-on-host-genome","text":"","title":"Coverage analysis on host genome"},{"location":"tutorials/Transgene/DataAnalysis/#quantify-coverage-on-contigs","text":"Since the CHO genome reference is not yet well defined, there are many contigs from CHO, and the user will get lost by looking at coverage directly. The user can first quantify the coverage on each contig, and get the percentage of mapped reads in each contig. The NGS | Quantification | Report Gene/Transcript Count function is designed to quantify gene expression from RNA-Seq data. If the input is DNA-Seq data, it will quantify the read counts on each contig/chr: Choose the host alignment NgsData, and choose expression measurement to be Count ; Count fragments instead of reads will count properly paired reads only; EM algorithm will assign reads mapped to multiple contigs based on EM iterations. It will generate an OmicData with rows for contigs and columns for samples: The default data object name still contains \"Transcript\" since it was designed for RNA-Seq. User can always rename it to other names such as AlignToHost.ContigReadCount . The data values are EM read counts for each contig. User can further convert them to percentages of mapped reads in each contig by using NGS | Inference | Normalize RNA-Seq Data (again, the function was designed for RNA-Seq, but can be applied to DNA-Seq data). Use the TotalCount method and scale the total count to 1, then the count of reads will be normalized as percentage of reads mapped to each contigs. In the table, user can right click the header and sort the table column descending. It shows top contigs which have been enriched in the NGS library. By selecting top contigs, user can create a list of them for filtering purpose in other tables. Right click on List , \"Add list from selected rows\" and name it \"TopContigs\":","title":"Quantify Coverage on contigs"},{"location":"tutorials/Transgene/DataAnalysis/#summarize-coverage","text":"The NGS | Coverage | Coverage Summary Statistics module can be used to calculate the coverage of the mapping at defined bin resolution or export as a bedgraph file at base pair resolution. Pick the Host alignment NgsData as Data input. Exclude multi-reads: Multi reads are considered non-unique (i.e. reads that align to multiple genomic locations with equal or similar numbers of mismatches). Selecting this option will include unique reads only when performing the coverage summarization. Exclude duplicates: duplicate reads are reads mapped to the exact same location. Duplicated reads are excluded by default in most NGS modules. The coverage will be summarized in each bin size specified. If user wants to have the basepair resolution coverage, he/she can choose to output bedGraph files. The output is a table of coverage values in each bin for each sample. It also generates a histogram of coverage on all contigs. However, there are so many contigs in CHO, it is recommended to use top contigs as a filter to filter the table, then open the histogram plot. In the View Controller on the right, select the Row tab, then right-click on \"Chromosome\" and select \"Add List Filter\". For some tables, it has been set as check box by default. If you do not see \"Add list Filter\", please change the column to \"String Filter\". User can also type the following contigs in the String filter in to check contigs:","title":"Summarize Coverage"},{"location":"tutorials/Transgene/DataAnalysis/#check-coverage-at-base-pair-resolution-using-bedgraph-file-in-genome-browser","text":"The bedGraph files contain continuous coverage data in track format. It is generated by the coverage analysis and loads much faster in genome browser than loading the actual BAM files. Steps: Create new genome browser: Add Track | Add Track from Server Files | Numeric Tracks | BedGraph file Select the bedgraph files generated in the output folder: Jump to contigs of interest to browse coverage at base pair resolution:","title":"Check coverage at base pair resolution using BedGraph file in Genome Browser"},{"location":"tutorials/Transgene/DataAnalysis/#integration-detection","text":"","title":"Integration Detection"},{"location":"tutorials/Transgene/DataAnalysis/#tag-split","text":"If the NGS library fragments are generated from digestion with a cutting enzyme, it may generate random chimeric DNA fragments which results in false positives in transgene detection. If the cutting enzyme relies on short restriction NT sites, it can bring a lot of false positives in the downstream analysis. If we know the restriction NT combinations, users can first split the reads when finding an enzyme cutting site. It can greatly reduce the false positives in transgene detection. Users can split reads by Tag in the Analysis tab by navigating to NGS | Preprocess | Split by Tag : Add the sample fastq data from server folder: Input format: choose AUTO and it will check file format automatically Quality encoding: the encoding for quality score; recommend using Automatic. Tag sequence: The sequence tag which will be recognized by restriction enzyme. Minimal sequence length: The read will be thrown again if length < MinLength after split Zip format: no gzip or bzip format. The program will go over each fastq file and split reads recursively based on the tag: New fastq.gz files will be generated in the output folder. Note, it is also possible that there are enzyme sites near the true integration site. These sites will not be detected when running Transgene Detection using split reads.","title":"Tag Split"},{"location":"tutorials/Transgene/DataAnalysis/#transgene-detection","text":"From the raw data (or split read data if Split by Tag has been run), user can start to run transgene detection in NGS | Fusion | Transgene Integration Analysis : Add data from server folder and follow the following options: Input format: choose AUTO and it will check file format automatically Reads are paired Check box: if the box is checked, read1 and read2 files will be automatically paired based on read names as one sample for integration analysis. Host genome: the host genome to detect integration; Make sure you pick the same host reference as in the previous alignment step. Plasmid genome: the custom plasmid genome built by user. Quality encoding: the encoding for quality score; we recommend using Automatic. Zip format: no gzip or bzip format. Thread number: Number of Threads for each job. Job number: Number of parallel jobs to run. Cut size: the minimum size of read end to be aligned to host or plasmid. For read length > 75 bp, we recommend using 25. If read length is less than 75bp, please use the formula (ReadLength/3). Extension: display the left and right extension length of integration junction sequence in the report; will be used to filter false positives caused by restriction enzyme. Perform consensus analysis for partially aligned reads: If checked, the function will scan reads partilly aligned to plasmid reference, and infer the consensus on soft clipped read sequences. Since the CHO genome is not a complete reference, the consensus analysis for partially aligned reads potentially will find integration sites which are not part of the current CHO genome reference. Minimal clipping: The minimal length of clipping region of the read to be used for consensus analysis Minimal read#: The minmal number of reads to report a integration site from consensus analysis Output folder: Browse to specify the output folder. In the Advanced tab: More options: Read Trimming : We recommend the default settings as filtering will typically be done before users get to this step. Mask fuzzy plasmid/host fusion : check this box if user wants to mask regions that are the same in plasmid and host, such as the EASE region in CHO. Exclude fusion if cutting position# : number of cutting position means number of unique reads. The default cut off is one single read support. Misc : generate table land to support big report tables; checking this option will make it easier to share this data with others when complete. Set an output name in ArraySuite project. Click Send to Queue and it will send the job to run on server. Once the job finishes, you can update the project with results and will see three NgsData objects and three result tables: TransgeneReport_PlasmidHost : reports the number of support reads for each transgene integration site for each sample, with information of the integration positions in host and plasmid. For better characterization of integration site, a column named \"Integration Type\" is reported, based on the definition in the schematic below: Example: TRANS_1140_165663373(--) is an integration site between plasmid position 1141 to CHO NW_003613610.1, with 9 reads (8 unique read sequences) supporting from the this dataset. From integration type, user can tell that plasmid sequence starting 1141 has been integrated after CHO NW_003613610.1 position 3346702. TRANS_10161_165672719(++) is an integration site between plasmid position 10162 to CHO NW_003613610.1, with 23 reads (19 unique read sequences) supporting from this dataset. From integration type, user can tell that integration of plasmid ends at 10162 and then continues with CHO seqeunce starting from NW_003613610.1 position 3356048. This data is quite clean and does not have any false positives. Due to the nature of enrichment technology, it is possible to have many false positives introduced, as mentioned in the \"Split by Tag\" section. If user does not run the transgene detection using fastq files from \"Split by Tag\" run, user should filter the detection table based on integration junction sequence (such as not containing \"CATG\" for Targeted Locus Amplification (TLA) datasets, using filter \"not catg\" in the junction sequence), top contigs, and # of supporting reads. Note that the \"Split by Tag\" option, while useful to filter out false positives, has the potential to generate false negatives. Users of this tutorial will notice that only one of the two fusions are detected when using the split fastq files. Thus, filtering of false positives should be done on a case-by-case basis, with users defining how many false positives they can tolerate. For a table with multiple samples, user can get the summary statistics on read counts, such as max of unique reads in any samples, using Table | Columns | Add Columns | Column Summarization | Pick columns and pick summarization method . TransgeneReport_PlasmidPlasmid : report the number of support reads for each plasmid-to-plasmid integration in each sample, with information of the integration positions in host and plasmid. Transgene.TransgeneReport_Consensus : report the number of supporting reads from consensus analysis. The direction indicates the location of consensus sequence relative to the plasmid breakpoint. The consensus sequences that are inferred from soft clipped reads should be part of the host (such as CHO) genome. It reports the number of supporting clipped reads and total number of reads (the total coverage) at the breakpoint. Users can further visualize these integration sites in genome browser based on the NgsData.","title":"Transgene Detection"},{"location":"tutorials/Transgene/DataAnalysis/#genome-browser-of-transgene-integration","text":"Within the transgene report, right click on the row ID, user will have the option to open a new genome browser: In the example above, right click on TRANS_1140_165663373(--), which it has option to open one of two NgsData objects. Because we are in the plasmid-to-host transgene report table, choose to open the PlasmidHostFusion NgsData object. It will jump to the Genome browser tab, and list available NGS samples to open: Leave all samples checked and click OK . It will first load the coverage of these supporting reads on two panels, one for plasmid and the other for the host: User can switch the two panes to have the breakpoints facing each other if necessary. Note, although we jump to this genome browser based on one transgene integration site, it loads the NgsData containing all integration site supporting reads. If the current region contains multiple integration sites, the genome browser will show all supporting reads for them. User can filter reads by transgene integration ID in the tag filter in genome browser track property: User can mouse over the sample genome browser track name and it will pop up a tooltip allowing user to display the supporting reads. If the option is grey, please zoom in a little bit to < 200bp region: Strikethrough of part of the read means the read part is not aligned to the region: Part of the read is aligned to plasmid and the rest of the read is aligned to host. User can also view the consensus inference in genome browser. User can filter genome browser alignment by Cigar filter to softclipping reads only, and set minimal length of softclip to be 5 or 10. From the alignment of softclipped region (read parts with strike), the genome view can help user visually check the consensus seqeunce, starting with ACATCAGCCCACGTTTCCAGTTGATGA. User can use PCR to verify the integration site if the reported consensus sequence is not a part of current host genome sequence. For more information about genome browser such as sharing a genome browser, please read Omicsoft Genome Browser Tutorial Here is a general key for genome browser:","title":"Genome Browser Of Transgene Integration"},{"location":"tutorials/Transgene/DataAnalysis/#variation-detection-on-transgene","text":"Based on the alignment of NGS data to plasmid, we can further detect variation based on consensus mutations calls. To do so, user can use the NGS | Variation | Summarize Variant Data (Omicsoft) : Pick the Data to the NgsData of Plasmid alignment, change the Mutation options . The default mutation options are designed for regular human/mouse studies. For production cell lines with enrichment on transgene regions, user should use high cutoff of position coverage and # of reads supporting mutation, while lowering the cutoff for mutation frequency. In this way, user can detect confident variation, at very low frequency level since there might be hundreds of plasmid integrations to the host. Also make sure to reduce the \"exclude mutation if maximal frequency\" option to zero to maximize the sensitivity: The mutation report will contain three columns (coverage, read frequency and %Plus strand) for each data file, and additional annotation for the mutation, such as positions, reference and mutations: Sorting this table by the mutation frequency, we can see that the most frequent mutation is MUT00000026. The mutation position on the plasmid is base pair 6930, reference is A and Variation is G, or an A->G. The position is covered by 87 reads and 87*0.6667=58 reads are supporting G in this position. User can also create a view of Mutation Frequency vs. Coverage by adding a scatterplot view: Selecting data points will show details for these positions. User can further customize the view using options highlighted in the screenshot below: Right click on the row names and show the mutation in genome browser with detailed pile-ups from reads: The genome browser might be slow due to high coverage on these regions: If gene model was built with CDS information for the plasmid, user can add the gene model in the genome browser using: With the gene model, user can further use NGS | Variation | Annotate Variant Table Report to find Non-Synonymous changes. If any exist, it will also annotate the exact amino acid changes. The annotated mutation report will look like below, and can be filtered for certain mutation types (i.e. synonymous) in the View Controller on the right:","title":"Variation detection on transgene"},{"location":"tutorials/Transgene/Introduction/","text":"Introduction Transgene A transgene is genetic material transferred to a host genome by genetic engineering techniques, either by (1) integration by insertion or (2) integration by homologous recombination. The transgene detection functions described here are designed to identify transgene integration. The workflow reports a list of detected transgene integration sites, statistics of supporting reads, as well as genomic locations of breakpoints, which characterize transgene sites comprehensively at base-pair resolution. Alignment files (NgsData) will also be generated to visualize transgene events in the genome browser, and variation detection of the product. Test Dataset Download link: http://omicsoft.com/downloads/data/Tutorial/Transgene.zip The test data contains files below Plasmid reference sequence in FASTA format Plasmid gene model in GTF format. Plasmid gene location in BED format 2x100bp paired end fastq.gz files containing NGS reads from regions surrounding the transgene. It is a semi-simulated dataset mimicking enrichment of transgene regions using pull down techniques.","title":"Introduction"},{"location":"tutorials/Transgene/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/Transgene/Introduction/#transgene","text":"A transgene is genetic material transferred to a host genome by genetic engineering techniques, either by (1) integration by insertion or (2) integration by homologous recombination. The transgene detection functions described here are designed to identify transgene integration. The workflow reports a list of detected transgene integration sites, statistics of supporting reads, as well as genomic locations of breakpoints, which characterize transgene sites comprehensively at base-pair resolution. Alignment files (NgsData) will also be generated to visualize transgene events in the genome browser, and variation detection of the product.","title":"Transgene"},{"location":"tutorials/Transgene/Introduction/#test-dataset","text":"Download link: http://omicsoft.com/downloads/data/Tutorial/Transgene.zip The test data contains files below Plasmid reference sequence in FASTA format Plasmid gene model in GTF format. Plasmid gene location in BED format 2x100bp paired end fastq.gz files containing NGS reads from regions surrounding the transgene. It is a semi-simulated dataset mimicking enrichment of transgene regions using pull down techniques.","title":"Test Dataset"},{"location":"tutorials/Transgene/Others/","text":"Others Below are some other useful options/functions. NGS Pre-Processing: Filter Reads Besides split read by tags, there are a few of NGS data pre-processing steps which can improve the data quality and reduce background noise. To filter bad reads and remove adapter sequences, use NGS | Preprocess | Filter : Choose the appropriate file format: AUTO or FASTQ based on your data, then click Add to find input data. Use the default options but check \" input files are paired \" option if your data is paired end or mate pair reads. Choose an Output folder for new fastq files : In the Advanced tab, click Customize for the adapter Stripping section. There are two adapter types users can specify: 3' end adapters : these are usually the type of adapters used in paired end reads. When NGS read length is short, the sequencer will get the adapter sequence as part of read sequences. The 3' adapter stripping does a localized alignment at the right end of the read and removes the adapter part of read ends. More details can be found in this wiki page: http://www.arrayserver.com/wiki/index.php?title=AdapterStripping_3%27End Right adapter: it is usually the type of short adapters used in mate pair reads. The adapter sequence has become a part of read sequence, in the middle of the read, but close to the 3' end. Array Studio aligns the adapter sequence against read sequence to strip up to where the best alignment to the adapter ends. All nucleotides after the adapter sequence are stripped away. More details can be found in this wiki page: http://www.arrayserver.com/wiki/index.php?title=AdapterStripping_Right After the filtering step, new fastq files will be generated. Again, this step is optional if data quality is good. Use Grouping File In Omicsoft, we consider one file as one sample, or two files as one sample if option \"reads are paired\" is checked. In some cases, the user may have multiple files from multiple lanes for one NGS sample, such as one flow cell as one sample. Omicsoft provides a solution to input multiple files for one sample using the GroupingFile parameter. The parameter should work for any NGS modules that take raw read files as input. For more information about grouping files, please read: http://www.arrayserver.com/wiki/index.php?title=How_to_use_multiple_sequence_files_for_one_sample%3F Integration Site Repository Users can export selected integration sites and save them to tab-delimitated text files. The flat file can serve as an integration site repository. Users can also use the file to annotate new transgene detection reports. To export, select integration site Fusion ID, and click \"Export Integration Sites\". It will ask user to either create a new file or select an exisiting repository to append. To annotate new tables with repository file, click \"Append Integration Sites Project Info\", select the repository text file, then two new columns (Project Name and Sample) will be appended to the report. It annotates the table with names of old samples analyzed in old projects having the same integration site. It is matched by the same host and plasmid reference ID, and their integration locations/directions. Target Reads Extraction Target reads extraction is designed to extract target reads based on the read pair connectivity, such as pair-end and mate-pair linkage. Below is one example using mate pair, the Target Reads Extraction function is trying to extract target reads with its mate mapped to the designed capture region (transgene region): This tool is useful when there are multiple transgene regions, such as tnsA and tnsD in the tutorial dataset. User can design the capture region to be specific to the transgene and then use the target reads to do transgene integration site analysis. The result (integration site) will be transgene-specific since we only use the reads that are uniquely linked to the transgene region. To run transgene target reads extraction, go to the NGS menu below: In the analysis menu: Select input format and click \"Add\" to add paired-end or mate pair raw data. It is better to add a filtered (filtered + adapter stripped) data set. Input format: the read file format, fastq, qseq or fasta; most datasets from current next-generation sequencing machines are fastq Add data from server; input files have to be paired based on regular paired or mate pair read file names Host genome: the host genome to detect integration; Plasmid genome: the plasmid genome built by user; Quality encoding: the encoding for quality score; recommend using Automatic; Zip format: no gzip or gzip format; Bait BED file : Bait file defines regions that are used to capture read pairs. For transgene studies, it is usually a file listing the transgene regions in the plasmid genome. Taking the tutorial data as one example, the following bed file defined tnsA and tnsD region on the plasmid: Plasmid Start End Name pGRG36 1453 2274 tnsA pGRG36 6036 7562 tnsD The file extension is .bed and is a tab-delimited text file. The BED file contains four columns: chr, start, end and region name. Alignment length: the length of read that required to be aligned to the bait region. It is designed to align part of the reads in case there are low quality nucleotides on the right side of read ends. For example, when read length is 100bp and alignment length set to 50, it only requires the first 50bp of the read aligned to the bait region. Multiple hit cutoff : usually, we set cutoff=1, requiring one read uniquely aligned to the bait region and it cannot be aligned to any other locations in plasmid and host genome. When there is a known similarity between the bait region and other regions, such as a region shared in two plasmid backbones, user can set the cutoff to be 2 to allow multiple mapping of the bait reads. Thread number: Number of Threads for each job; Job number: Number of parallel jobs to run Output folder: Browse to specify the output folder User will get two files for each target region from every sample: .bait.fastq and .target.fastq. Below, for the same input sample, there is a bait.fastq and a target.fastq for the tnsA region and tnsD region as defined by the BED file. User can run raw data QC and also align the fastq files to plasmid genome and check the read coverage statistics and enrichment efficiency. The figure below is one example from a mate pair dataset. Congratulations! Now you can successfully run a transgene detection analysis! If you have any questions, please feel free to contact Omicsoft support@omicsoft.com .","title":"Others"},{"location":"tutorials/Transgene/Others/#others","text":"Below are some other useful options/functions.","title":"Others"},{"location":"tutorials/Transgene/Others/#ngs-pre-processing-filter-reads","text":"Besides split read by tags, there are a few of NGS data pre-processing steps which can improve the data quality and reduce background noise. To filter bad reads and remove adapter sequences, use NGS | Preprocess | Filter : Choose the appropriate file format: AUTO or FASTQ based on your data, then click Add to find input data. Use the default options but check \" input files are paired \" option if your data is paired end or mate pair reads. Choose an Output folder for new fastq files : In the Advanced tab, click Customize for the adapter Stripping section. There are two adapter types users can specify: 3' end adapters : these are usually the type of adapters used in paired end reads. When NGS read length is short, the sequencer will get the adapter sequence as part of read sequences. The 3' adapter stripping does a localized alignment at the right end of the read and removes the adapter part of read ends. More details can be found in this wiki page: http://www.arrayserver.com/wiki/index.php?title=AdapterStripping_3%27End Right adapter: it is usually the type of short adapters used in mate pair reads. The adapter sequence has become a part of read sequence, in the middle of the read, but close to the 3' end. Array Studio aligns the adapter sequence against read sequence to strip up to where the best alignment to the adapter ends. All nucleotides after the adapter sequence are stripped away. More details can be found in this wiki page: http://www.arrayserver.com/wiki/index.php?title=AdapterStripping_Right After the filtering step, new fastq files will be generated. Again, this step is optional if data quality is good.","title":"NGS Pre-Processing: Filter Reads"},{"location":"tutorials/Transgene/Others/#use-grouping-file","text":"In Omicsoft, we consider one file as one sample, or two files as one sample if option \"reads are paired\" is checked. In some cases, the user may have multiple files from multiple lanes for one NGS sample, such as one flow cell as one sample. Omicsoft provides a solution to input multiple files for one sample using the GroupingFile parameter. The parameter should work for any NGS modules that take raw read files as input. For more information about grouping files, please read: http://www.arrayserver.com/wiki/index.php?title=How_to_use_multiple_sequence_files_for_one_sample%3F","title":"Use Grouping File"},{"location":"tutorials/Transgene/Others/#integration-site-repository","text":"Users can export selected integration sites and save them to tab-delimitated text files. The flat file can serve as an integration site repository. Users can also use the file to annotate new transgene detection reports. To export, select integration site Fusion ID, and click \"Export Integration Sites\". It will ask user to either create a new file or select an exisiting repository to append. To annotate new tables with repository file, click \"Append Integration Sites Project Info\", select the repository text file, then two new columns (Project Name and Sample) will be appended to the report. It annotates the table with names of old samples analyzed in old projects having the same integration site. It is matched by the same host and plasmid reference ID, and their integration locations/directions.","title":"Integration Site Repository"},{"location":"tutorials/Transgene/Others/#target-reads-extraction","text":"Target reads extraction is designed to extract target reads based on the read pair connectivity, such as pair-end and mate-pair linkage. Below is one example using mate pair, the Target Reads Extraction function is trying to extract target reads with its mate mapped to the designed capture region (transgene region): This tool is useful when there are multiple transgene regions, such as tnsA and tnsD in the tutorial dataset. User can design the capture region to be specific to the transgene and then use the target reads to do transgene integration site analysis. The result (integration site) will be transgene-specific since we only use the reads that are uniquely linked to the transgene region. To run transgene target reads extraction, go to the NGS menu below: In the analysis menu: Select input format and click \"Add\" to add paired-end or mate pair raw data. It is better to add a filtered (filtered + adapter stripped) data set. Input format: the read file format, fastq, qseq or fasta; most datasets from current next-generation sequencing machines are fastq Add data from server; input files have to be paired based on regular paired or mate pair read file names Host genome: the host genome to detect integration; Plasmid genome: the plasmid genome built by user; Quality encoding: the encoding for quality score; recommend using Automatic; Zip format: no gzip or gzip format; Bait BED file : Bait file defines regions that are used to capture read pairs. For transgene studies, it is usually a file listing the transgene regions in the plasmid genome. Taking the tutorial data as one example, the following bed file defined tnsA and tnsD region on the plasmid: Plasmid Start End Name pGRG36 1453 2274 tnsA pGRG36 6036 7562 tnsD The file extension is .bed and is a tab-delimited text file. The BED file contains four columns: chr, start, end and region name. Alignment length: the length of read that required to be aligned to the bait region. It is designed to align part of the reads in case there are low quality nucleotides on the right side of read ends. For example, when read length is 100bp and alignment length set to 50, it only requires the first 50bp of the read aligned to the bait region. Multiple hit cutoff : usually, we set cutoff=1, requiring one read uniquely aligned to the bait region and it cannot be aligned to any other locations in plasmid and host genome. When there is a known similarity between the bait region and other regions, such as a region shared in two plasmid backbones, user can set the cutoff to be 2 to allow multiple mapping of the bait reads. Thread number: Number of Threads for each job; Job number: Number of parallel jobs to run Output folder: Browse to specify the output folder User will get two files for each target region from every sample: .bait.fastq and .target.fastq. Below, for the same input sample, there is a bait.fastq and a target.fastq for the tnsA region and tnsD region as defined by the BED file. User can run raw data QC and also align the fastq files to plasmid genome and check the read coverage statistics and enrichment efficiency. The figure below is one example from a mate pair dataset. Congratulations! Now you can successfully run a transgene detection analysis! If you have any questions, please feel free to contact Omicsoft support@omicsoft.com .","title":"Target Reads Extraction"},{"location":"tutorials/miRNAseq/","text":"miRNA-Seq Analysis Tutorial .. toctree:: :maxdepth: 2 Introduction CreateArray_Studio_Project workflow_and_pipeline QC_ofRaw_Data_Files Filtering_Trimming_Reads Alignment_to_the_Genome QC_of_Aligned_Data miRNA-Seq_Quantification Others","title":"Home"},{"location":"tutorials/miRNAseq/Alignment_to_the_Genome/","text":"Alignment to the Genome After QC and filtering raw reads, the next step in most miRNA-Seq analysis is the alignment of the reads to the genome. Please go to the Add Data dropdown menu on the toolbar, then choose Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) . At this point, the Map miRNA-Seq Reads to Genome module appears. First click the Add button to specify the location of the filtered fastq files from the previous section. Note that these files are in .gz format. The alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files. Choose the Genome for the experiment. In this analysis, we will use Human.hg38 . Choose the Gene model . We will use miRBase.R21. In general for miRNA-seq, results will be much more successful when mapping exclusively to known miRNAs. Note If your goal is miRNA discovery, there are several specialized tools for this purpose, such as miRDeep2. Leave the quality encoding set to automatic. However for your information, these files were encoded using the Sanger quality scoring system. Adapter Stripping allows trimming (under Advanced ) and adapter-stripping of reads. Since we have already trimmed and stripped the tutorial reads, there is no need to do it again here. In Performance and Reporting , Total penalty should be left as automatic, and is described completely in Omicsoft's white paper on alignment. Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together. Only BAM files will be output. If users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files. Output folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step. There are a few options in the Advanced Tab. In general the default values have been tuned and should work well in most cases. Leave the Exclude unmapped reads unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain mapped and unmapped reads) can be directly used as input for subsequent steps. Click Submit to start mapping. The mapping stage could take anywhere from several minutes to over an hour, depending on the number of threads, type of computer (64-bit/32-bit), etc. After the alignment, you will see a NgsData object with an alignment report table (1) and design table (2) in the solution explorer, and BAM files as well as alignment report summary files in the specified output folder. To help downstream analysis, we will add grouping columns to the design table. First, double-click the new NGS data Design table in the Solution Explorer to view the Design Table in Array Studio. Next, click either the (1) Open as Text or (2) Open as Excel buttons: To the design table, add a column named Group , then enter group labels \"Normal\", \"Psoriatic_Uninvolved\", and \"Psoriatic_Involved\" as follows: SRX091742-SRX091744 are Normal SRX091719-SRX091721 are Psoriatic_Uninvolved SRX091695-SRX091697 are Psoriatic_Involved You may add additional columns if you like, such as the StudyID, source organism, etc. Save the file as a tab-delimited file, named \"Design.txt\", in the same folder as your .BAM files. Then, right click on the Design folder for the NgsData, and select Import | Tab delimited file : Navigate to \"Design.txt\". Two options for importing will be offered: Append to the existing covariate table : checking this option will append the selected design file contents to the existing design table, using the first column to match rows. Use the name order in the new covariate table : checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table. These two options should be left unchecked for this tutorial (as we will just over-write the design table). Now save your project, then we can quantify reads mapped to each known miRNA and identify differentially-expressed miRNAs.","title":"Alignment to the Genome"},{"location":"tutorials/miRNAseq/Alignment_to_the_Genome/#alignment-to-the-genome","text":"After QC and filtering raw reads, the next step in most miRNA-Seq analysis is the alignment of the reads to the genome. Please go to the Add Data dropdown menu on the toolbar, then choose Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) . At this point, the Map miRNA-Seq Reads to Genome module appears. First click the Add button to specify the location of the filtered fastq files from the previous section. Note that these files are in .gz format. The alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files. Choose the Genome for the experiment. In this analysis, we will use Human.hg38 . Choose the Gene model . We will use miRBase.R21. In general for miRNA-seq, results will be much more successful when mapping exclusively to known miRNAs. Note If your goal is miRNA discovery, there are several specialized tools for this purpose, such as miRDeep2. Leave the quality encoding set to automatic. However for your information, these files were encoded using the Sanger quality scoring system. Adapter Stripping allows trimming (under Advanced ) and adapter-stripping of reads. Since we have already trimmed and stripped the tutorial reads, there is no need to do it again here. In Performance and Reporting , Total penalty should be left as automatic, and is described completely in Omicsoft's white paper on alignment. Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together. Only BAM files will be output. If users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files. Output folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step. There are a few options in the Advanced Tab. In general the default values have been tuned and should work well in most cases. Leave the Exclude unmapped reads unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain mapped and unmapped reads) can be directly used as input for subsequent steps. Click Submit to start mapping. The mapping stage could take anywhere from several minutes to over an hour, depending on the number of threads, type of computer (64-bit/32-bit), etc. After the alignment, you will see a NgsData object with an alignment report table (1) and design table (2) in the solution explorer, and BAM files as well as alignment report summary files in the specified output folder. To help downstream analysis, we will add grouping columns to the design table. First, double-click the new NGS data Design table in the Solution Explorer to view the Design Table in Array Studio. Next, click either the (1) Open as Text or (2) Open as Excel buttons: To the design table, add a column named Group , then enter group labels \"Normal\", \"Psoriatic_Uninvolved\", and \"Psoriatic_Involved\" as follows: SRX091742-SRX091744 are Normal SRX091719-SRX091721 are Psoriatic_Uninvolved SRX091695-SRX091697 are Psoriatic_Involved You may add additional columns if you like, such as the StudyID, source organism, etc. Save the file as a tab-delimited file, named \"Design.txt\", in the same folder as your .BAM files. Then, right click on the Design folder for the NgsData, and select Import | Tab delimited file : Navigate to \"Design.txt\". Two options for importing will be offered: Append to the existing covariate table : checking this option will append the selected design file contents to the existing design table, using the first column to match rows. Use the name order in the new covariate table : checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table. These two options should be left unchecked for this tutorial (as we will just over-write the design table). Now save your project, then we can quantify reads mapped to each known miRNA and identify differentially-expressed miRNAs.","title":"Alignment to the Genome"},{"location":"tutorials/miRNAseq/CreateArray_Studio_Project/","text":"Create Array Studio Project Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. In this tutorial, we are using local projects. If user has Array Server installed, user can run the tutorial as a server project and analysis steps are almost the same as described in this tutorial. Once Array Studio has been opened, click File | New Local Project from the File Menu (also can be accessed via the New button on the toolbar). For any Next Generation Sequencing datasets, the user should choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset. Note: It is required that the user has approximately 3GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using Tools Menu | Preferences | Advanced . This will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. Click Browse to choose a location to store the data and click OK to create an empty project:","title":"CreateArray Studio Project"},{"location":"tutorials/miRNAseq/CreateArray_Studio_Project/#create-array-studio-project","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. In this tutorial, we are using local projects. If user has Array Server installed, user can run the tutorial as a server project and analysis steps are almost the same as described in this tutorial. Once Array Studio has been opened, click File | New Local Project from the File Menu (also can be accessed via the New button on the toolbar). For any Next Generation Sequencing datasets, the user should choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset. Note: It is required that the user has approximately 3GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using Tools Menu | Preferences | Advanced . This will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. Click Browse to choose a location to store the data and click OK to create an empty project:","title":"Create Array Studio Project"},{"location":"tutorials/miRNAseq/Filtering_Trimming_Reads/","text":"Filtering And Trimming Raw Reads If we look closely at the Kmer pattern from the raw QC report, it is clear that the same sequence is at the 5' and 3' ends, and that these sequences both match the Illumina 3' adapter sequence. It is likely that reads with the adapter sequence toward the 5' end are simply adapter-dimers. In contrast, reads with adapters at the 3' end, starting ~22-24 nucleotides, are the reads we want to map. However, the user must strip (remove) the adapters before mapping these reads. This can be performed multiple ways in Array Studio. Trim the last 36 - 22 = 14 nucleotides (read length - processed miRNA length), which will remove adapters from proper reads. Use the Array Studio Adapter Stripping method to dynamically detect and remove substrings matching adapter sequences. Regardless of which technique is used, we can also filter out reads that are comprised entirely of adapter sequences, or match common NGS contaminants such as rRNA and tRNA. To filter and strip the raw reads, open the Filtering module by clicking NGS | Preprocess | Filter : This will open a window with multiple methods for stripping, trimming, and filtering our reads: Click Add to find all 9 files for the samples, then select filtering options: Filter by read length ( set to <20 in this case ) Per-read quality scores Abnormally high single-nucleotide frequency Paired-end quality filtering (tutorial reads are not paired, so this option is not used) If the user wants to generate a new set of fastq files containing filtered/trimmed reads, specify the full path to the output folder. Alternatively, the user can choose \"Generate flag files only\", which will generate a flat file with filter status for reads in each file, instead of generating new fastq files. However, \"Generate flag files only\" is overridden if adapter stripping is enabled. To perform adapter stripping or trimming, the user should click on the Advanced tab, revealing several additional options: To trim reads to 22 nucleotides, select the Advanced trimming radio button, and click the Customize button: Alternatively, to dynamically strip away 3' adapter sequences, Click Customize in the Adapter Stripping section, then change the radio button to Strip 3' end adapters : Enter in the sequence ATCTCGTATGCCGTCTTCTGCTTG , which was found in the miRNA adapter search module (or you can copy-paste from this document). This sequence matches the 3' adapter used by the study authors. If multiple adapter sequences were found by the adapter search module, they could also be entered as a list in Strip multiple 3' end adapters . An additional option within Adapter Stripping is Trim reads first . Trim reads first controls the Order of Operations for Trimming and Stripping. For example, if reads were 3' barcoded such that the read was miRNA-Barcode-Adapter, setting Trim reads first to false would allow stripping of the adapter, followed by removal of the barcoded portion. The final set of Advanced Options is Filter By Source , where common contaminant sequences can be automatically removed. By default, several sets of sequences are included (e.g. adapters, rRNA, tRNA), but additional sequences can be also included as a FASTA file. For this tutorial, we will take a simple approach to sequencing trimming: We will trim to 22 nucleotides (i.e. select Trim Reads First under Adapter Stripping ), then strip any 3' nucleotides exactly matching 3' adapters, then filter reads that are <20 nucleotides or match known adapter sequences, and save fastq files to a new folder. Re-running Raw Data QC will reveal that the reads are now all trimmed to 22 nucleotides, and the frequency of kmers has been significantly reduced (notice the Y-axis scale). We can now move on to mapping the reads to the genome.","title":"Filtering Trimming Reads"},{"location":"tutorials/miRNAseq/Filtering_Trimming_Reads/#filtering-and-trimming-raw-reads","text":"If we look closely at the Kmer pattern from the raw QC report, it is clear that the same sequence is at the 5' and 3' ends, and that these sequences both match the Illumina 3' adapter sequence. It is likely that reads with the adapter sequence toward the 5' end are simply adapter-dimers. In contrast, reads with adapters at the 3' end, starting ~22-24 nucleotides, are the reads we want to map. However, the user must strip (remove) the adapters before mapping these reads. This can be performed multiple ways in Array Studio. Trim the last 36 - 22 = 14 nucleotides (read length - processed miRNA length), which will remove adapters from proper reads. Use the Array Studio Adapter Stripping method to dynamically detect and remove substrings matching adapter sequences. Regardless of which technique is used, we can also filter out reads that are comprised entirely of adapter sequences, or match common NGS contaminants such as rRNA and tRNA. To filter and strip the raw reads, open the Filtering module by clicking NGS | Preprocess | Filter : This will open a window with multiple methods for stripping, trimming, and filtering our reads: Click Add to find all 9 files for the samples, then select filtering options: Filter by read length ( set to <20 in this case ) Per-read quality scores Abnormally high single-nucleotide frequency Paired-end quality filtering (tutorial reads are not paired, so this option is not used) If the user wants to generate a new set of fastq files containing filtered/trimmed reads, specify the full path to the output folder. Alternatively, the user can choose \"Generate flag files only\", which will generate a flat file with filter status for reads in each file, instead of generating new fastq files. However, \"Generate flag files only\" is overridden if adapter stripping is enabled. To perform adapter stripping or trimming, the user should click on the Advanced tab, revealing several additional options: To trim reads to 22 nucleotides, select the Advanced trimming radio button, and click the Customize button: Alternatively, to dynamically strip away 3' adapter sequences, Click Customize in the Adapter Stripping section, then change the radio button to Strip 3' end adapters : Enter in the sequence ATCTCGTATGCCGTCTTCTGCTTG , which was found in the miRNA adapter search module (or you can copy-paste from this document). This sequence matches the 3' adapter used by the study authors. If multiple adapter sequences were found by the adapter search module, they could also be entered as a list in Strip multiple 3' end adapters . An additional option within Adapter Stripping is Trim reads first . Trim reads first controls the Order of Operations for Trimming and Stripping. For example, if reads were 3' barcoded such that the read was miRNA-Barcode-Adapter, setting Trim reads first to false would allow stripping of the adapter, followed by removal of the barcoded portion. The final set of Advanced Options is Filter By Source , where common contaminant sequences can be automatically removed. By default, several sets of sequences are included (e.g. adapters, rRNA, tRNA), but additional sequences can be also included as a FASTA file. For this tutorial, we will take a simple approach to sequencing trimming: We will trim to 22 nucleotides (i.e. select Trim Reads First under Adapter Stripping ), then strip any 3' nucleotides exactly matching 3' adapters, then filter reads that are <20 nucleotides or match known adapter sequences, and save fastq files to a new folder. Re-running Raw Data QC will reveal that the reads are now all trimmed to 22 nucleotides, and the frequency of kmers has been significantly reduced (notice the Y-axis scale). We can now move on to mapping the reads to the genome.","title":"Filtering And Trimming Raw Reads"},{"location":"tutorials/miRNAseq/Introduction/","text":"Introduction ArrayStudio Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool. Test Dataset This miRNA-Seq tutorial will cover the importing and analysis of a published dataset. This dataset was run on the Illumina HiSeq platform. We selected three miRNA-seq files each from involved and uninvolved psoriatic skin, as well as three normal skin samples, for use in this analysis. The full dataset is available from 'SRA SRP007825'. SRA SRP007825: http://www.ncbi.nlm.nih.gov/sra?term=SRP007825 | Sample Type | Accession IDs | SRA IDs | Run IDs | |:----------------------------|:--------------------|:--------------------|:------------------+ | Normal Skin | GSM768988-GSM768990 | SRX091742-SRX091744 |SRR330904-SRR330906| | Uninvolved Psoriatic Skin | GSM768965-GSM768967 | SRX091719-SRX091721 |SRR330881-SRR330883| | Involved Psoriatic Skin | GSM768941-GSM768943 | SRX091695-SRX091697 |SRR330857-SRR330859| These data can be downloaded from the NCBI web site, using SRA toolkit, or directly through Array Studio: After retrieving these data, you can begin the tutorial.","title":"Introduction"},{"location":"tutorials/miRNAseq/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/miRNAseq/Introduction/#arraystudio","text":"Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.","title":"ArrayStudio"},{"location":"tutorials/miRNAseq/Introduction/#test-dataset","text":"This miRNA-Seq tutorial will cover the importing and analysis of a published dataset. This dataset was run on the Illumina HiSeq platform. We selected three miRNA-seq files each from involved and uninvolved psoriatic skin, as well as three normal skin samples, for use in this analysis. The full dataset is available from 'SRA SRP007825'. SRA SRP007825: http://www.ncbi.nlm.nih.gov/sra?term=SRP007825 | Sample Type | Accession IDs | SRA IDs | Run IDs | |:----------------------------|:--------------------|:--------------------|:------------------+ | Normal Skin | GSM768988-GSM768990 | SRX091742-SRX091744 |SRR330904-SRR330906| | Uninvolved Psoriatic Skin | GSM768965-GSM768967 | SRX091719-SRX091721 |SRR330881-SRR330883| | Involved Psoriatic Skin | GSM768941-GSM768943 | SRX091695-SRX091697 |SRR330857-SRR330859| These data can be downloaded from the NCBI web site, using SRA toolkit, or directly through Array Studio: After retrieving these data, you can begin the tutorial.","title":"Test Dataset"},{"location":"tutorials/miRNAseq/Others/","text":"Others Downstream Analyses On Quantification Values After aligning data, there are a number of downstream analyses that can be done on the data. In particular, the normalized Count -Omic data can be used in the analyses designed for MicroArray Data , including several visualization and analysis functions. Build Reference and Gene Model Omicsoft provides standard genome reference (such as Human.B37.3, hg38, mm10, Mouse.B38) and gene models (RefGene, Ensembl and UCSC). Prebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis. If genome or gene models are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model. Both functions are located in NGS menu. More details can be found in the following two wiki articles: Build reference library. link Build Gene model. link Server-based Analysis Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. All the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces and workflow are almost the same. Please read tutorial, Server-Based Analysis Basics , for more details. Users are encouraged to use Server-based Analyses for larger data sets (for example, with the entire dataset used for the miRNA study here). This also allows users to easily share access to analyses to other users within the same user group. We recommend users read through the Server Explorer and Server Analysis Basics Tutorials to familiarize themselves with these features. Genome Browser Omicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). It can be used to visualize varied data types, including count/fpkm, exon/exon junction data, fusion data and many other tracks which have genomic coordinate information. For example, you can right click a transcript ID (e.g. miR-135) in miRNA-Seq count data and view tracks in Genome Browser. You can, by default, either view each track independently, or by Group (select Create a track for each group and choose Group ). By default, the coverage tracks will be auto-scaled, so differences in coverage between groups may not be apparent. First, use the scroll wheel to zoom out. Then, right-click a track and select Set Track Properties . This will open a window to control details of how each track is displayed. Hold down shift and select NGSData_Normal , NGSData_Psoriatic_Uninvolved , and NGSData_Psoriatic_Involved . This way, the changes will be applied to all three tracks. Change Auto Scale to \"False\", change Custom Max Value to \"500\", and change Height to \"100\". Then close the Properties window. Now, the Genome Browser shows that Psoriatic Involved samples express mir-135b much more highly (in raw reads) than the other two samples. Please read the tutorial for the Omicsoft Genome Browser for more details.","title":"Others"},{"location":"tutorials/miRNAseq/Others/#others","text":"","title":"Others"},{"location":"tutorials/miRNAseq/Others/#downstream-analyses-on-quantification-values","text":"After aligning data, there are a number of downstream analyses that can be done on the data. In particular, the normalized Count -Omic data can be used in the analyses designed for MicroArray Data , including several visualization and analysis functions.","title":"Downstream Analyses On Quantification Values"},{"location":"tutorials/miRNAseq/Others/#build-reference-and-gene-model","text":"Omicsoft provides standard genome reference (such as Human.B37.3, hg38, mm10, Mouse.B38) and gene models (RefGene, Ensembl and UCSC). Prebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis. If genome or gene models are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model. Both functions are located in NGS menu. More details can be found in the following two wiki articles: Build reference library. link Build Gene model. link","title":"Build Reference and Gene Model"},{"location":"tutorials/miRNAseq/Others/#server-based-analysis","text":"Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. All the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces and workflow are almost the same. Please read tutorial, Server-Based Analysis Basics , for more details. Users are encouraged to use Server-based Analyses for larger data sets (for example, with the entire dataset used for the miRNA study here). This also allows users to easily share access to analyses to other users within the same user group. We recommend users read through the Server Explorer and Server Analysis Basics Tutorials to familiarize themselves with these features.","title":"Server-based Analysis"},{"location":"tutorials/miRNAseq/Others/#genome-browser","text":"Omicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). It can be used to visualize varied data types, including count/fpkm, exon/exon junction data, fusion data and many other tracks which have genomic coordinate information. For example, you can right click a transcript ID (e.g. miR-135) in miRNA-Seq count data and view tracks in Genome Browser. You can, by default, either view each track independently, or by Group (select Create a track for each group and choose Group ). By default, the coverage tracks will be auto-scaled, so differences in coverage between groups may not be apparent. First, use the scroll wheel to zoom out. Then, right-click a track and select Set Track Properties . This will open a window to control details of how each track is displayed. Hold down shift and select NGSData_Normal , NGSData_Psoriatic_Uninvolved , and NGSData_Psoriatic_Involved . This way, the changes will be applied to all three tracks. Change Auto Scale to \"False\", change Custom Max Value to \"500\", and change Height to \"100\". Then close the Properties window. Now, the Genome Browser shows that Psoriatic Involved samples express mir-135b much more highly (in raw reads) than the other two samples. Please read the tutorial for the Omicsoft Genome Browser for more details.","title":"Genome Browser"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/","text":"QC of Raw Data Files The first step to ensure reliable miRNA-seq results is to check and filter the raw data, to use only high-quality reads. Array Studio contains several modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position. Adapter detection and trimming A QC step especially important to miRNA-seq is checking for/stripping adapter sequences. Because miRNAs are ~22 nucleotides long, standard high-throughput sequencing read lengths will read the entire miRNA, as well as the 3' adapter. In the tutorial set, reads are 36 nucleotides long. Thus, it is important to check that these adapters have been removed before continuing. This module is not included in the Raw Data QC Wizard , so must be run separately before mapping reads. You will find the \"Search Adapters\" module under NGS | Preprocess | Search Adapters Click Add to add the fastq files for the nine samples. You can choose to search for the default set of Illumina adapters, or search for a custom list of FASTA-formatted sequences. Specify the Job Number as the number of processes to run. Specify Sampling Percentage to change what fraction of your data to sample for adapter sequences. In this dataset, 1% is sufficient to capture adapter sequences. By default, this module searches for matches to adapter sequences at the 3' ends of reads, but does not allow additional bases to the right of the read match. To enable a Smith-Waterman algorithm to identify adapters with additional bases to the right, check \"Search right adapters\". In this sample, no additional adapters will be found by this procedure, so we will leave this option unchecked. Confirm that the Zip format is correct, optionally specify the Output name, and click \"Submit\". When the analysis is complete, a new table will be available in the Solution Explorer, under Table | Preprocessing : This table contains a list of all identified adapter sequences in each file, along with occurrence count and percentage per-file. In these samples, the majority of reads contain an adapter sequence, so this should be stripped before mapping. We will explore this in the next chapter. Raw Data QC Wizard To check overall sequence quality, n-mer over-representation, and sequence length, the Raw Data QC Wizard can be run. Alternatively, each module within can be run, enabling additional options. To run the wizard, click NGS | Raw Data QC | Raw Data QC Wizard . Click Add to find all 9 files for the samples, and check the boxes for each QC metric to run. For a quicker analysis, the user can choose Preview mode to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave Quality encoding as Automatic to automatically set the correct quality encoding method. Specify Job Number as the number of processes to run in parallel. Leave Maximal duplication level at the default of 10 . Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default. Then click Submit to begin the analysis. The raw data QC returns multiple raw data QC Views and tables in the Table Data section, under the Raw Data QC folder. In this screenshot, new subfolders were generated to cluster different QC analyses, by right-clicking the Raw Data QC folder and selecting New Folder . Basic Statistics The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. In this example, you will see that the reads (if untrimmed) are all 36 nucleotides long. Base distribution QC results are located in the Raw Data QC folder with name BasicStats . Double click the table view to open if you do not see basic statistics table in the middle window: Base Distribution Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the Raw Data QC folder with name BaseDistribution . By default, the BaseDistribution ProfileView should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer. In View Controller , Legend section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot. Notice that there are a total of 9 charts (scroll through them to look at each sample), one for each file that was QC d. Selecting points on the chart will also show additional details in the Details Window. One can also switch to line plot view by going to View Controller | Task | Customize | Change To Line Type . Read Quality QC The QC results include a PerSequenceQuality (view and table), a QualityBoxPlot (view and table) and a OverallQualityReport (view and table) in the Solution Explorer. Per Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file. Note that the first two files have far more poor-quality reads than the other files. In Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. From the QualityBoxPlot view (shown above), it is clear that the quality of two files drops off earlier than the others. Scroll through each of the 9 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the Details Window below the plot. The Overall Quality Report summarizes the quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score. K-Mer analysis The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of kmer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.1 means 10%) that contain each KMer. Without filtering, there is significant Kmer enrichment at the ends. For a miRNA-seq experiment, this is expected - in the next step, we will trim and filter reads to clean up the raw read data.","title":"QC of Raw Data Files"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/#qc-of-raw-data-files","text":"The first step to ensure reliable miRNA-seq results is to check and filter the raw data, to use only high-quality reads. Array Studio contains several modules for QC of raw data files. The easiest way is to run Raw Data QC Wizard which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position.","title":"QC of Raw Data Files"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/#adapter-detection-and-trimming","text":"A QC step especially important to miRNA-seq is checking for/stripping adapter sequences. Because miRNAs are ~22 nucleotides long, standard high-throughput sequencing read lengths will read the entire miRNA, as well as the 3' adapter. In the tutorial set, reads are 36 nucleotides long. Thus, it is important to check that these adapters have been removed before continuing. This module is not included in the Raw Data QC Wizard , so must be run separately before mapping reads. You will find the \"Search Adapters\" module under NGS | Preprocess | Search Adapters Click Add to add the fastq files for the nine samples. You can choose to search for the default set of Illumina adapters, or search for a custom list of FASTA-formatted sequences. Specify the Job Number as the number of processes to run. Specify Sampling Percentage to change what fraction of your data to sample for adapter sequences. In this dataset, 1% is sufficient to capture adapter sequences. By default, this module searches for matches to adapter sequences at the 3' ends of reads, but does not allow additional bases to the right of the read match. To enable a Smith-Waterman algorithm to identify adapters with additional bases to the right, check \"Search right adapters\". In this sample, no additional adapters will be found by this procedure, so we will leave this option unchecked. Confirm that the Zip format is correct, optionally specify the Output name, and click \"Submit\". When the analysis is complete, a new table will be available in the Solution Explorer, under Table | Preprocessing : This table contains a list of all identified adapter sequences in each file, along with occurrence count and percentage per-file. In these samples, the majority of reads contain an adapter sequence, so this should be stripped before mapping. We will explore this in the next chapter.","title":"Adapter detection and trimming"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/#raw-data-qc-wizard","text":"To check overall sequence quality, n-mer over-representation, and sequence length, the Raw Data QC Wizard can be run. Alternatively, each module within can be run, enabling additional options. To run the wizard, click NGS | Raw Data QC | Raw Data QC Wizard . Click Add to find all 9 files for the samples, and check the boxes for each QC metric to run. For a quicker analysis, the user can choose Preview mode to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave Quality encoding as Automatic to automatically set the correct quality encoding method. Specify Job Number as the number of processes to run in parallel. Leave Maximal duplication level at the default of 10 . Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default. Then click Submit to begin the analysis. The raw data QC returns multiple raw data QC Views and tables in the Table Data section, under the Raw Data QC folder. In this screenshot, new subfolders were generated to cluster different QC analyses, by right-clicking the Raw Data QC folder and selecting New Folder .","title":"Raw Data QC Wizard"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/#basic-statistics","text":"The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment. In this example, you will see that the reads (if untrimmed) are all 36 nucleotides long. Base distribution QC results are located in the Raw Data QC folder with name BasicStats . Double click the table view to open if you do not see basic statistics table in the middle window:","title":"Basic Statistics"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/#base-distribution","text":"Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the Raw Data QC folder with name BaseDistribution . By default, the BaseDistribution ProfileView should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer. In View Controller , Legend section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot. Notice that there are a total of 9 charts (scroll through them to look at each sample), one for each file that was QC d. Selecting points on the chart will also show additional details in the Details Window. One can also switch to line plot view by going to View Controller | Task | Customize | Change To Line Type .","title":"Base Distribution"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/#read-quality-qc","text":"The QC results include a PerSequenceQuality (view and table), a QualityBoxPlot (view and table) and a OverallQualityReport (view and table) in the Solution Explorer. Per Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file. Note that the first two files have far more poor-quality reads than the other files. In Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. From the QualityBoxPlot view (shown above), it is clear that the quality of two files drops off earlier than the others. Scroll through each of the 9 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the Details Window below the plot. The Overall Quality Report summarizes the quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.","title":"Read Quality QC"},{"location":"tutorials/miRNAseq/QC_ofRaw_Data_Files/#k-mer-analysis","text":"The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of kmer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short. In the KMerAnalysis profile view, Y-axis is the percentage of reads (0.1 means 10%) that contain each KMer. Without filtering, there is significant Kmer enrichment at the ends. For a miRNA-seq experiment, this is expected - in the next step, we will trim and filter reads to clean up the raw read data.","title":"K-Mer analysis"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/","text":"QC of Aligned Data Alignment Report By default, an alignment report is generated anytime an alignment is done in Array Studio. If it is not already open, go to your Solution Explorer and double click on Report from the AlignmentReport table. This will show, for each file, some statistics regarding mapping. One of the key statistics is the uniquely mapped reads. miRNA-Seq Aligned QC To get more detailed statistics of mapping rate, the RNA-Seq QC metrics can be used: This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. It also generates a ProfileView showing a chart for each metric. To run the RNA-Seq QC module, go to NGS | Aligned Data QC | RNA-Seq QC Metrics now. Choose the NGS data object and leave all other settings as their defaults and click Submit to run the module. Source metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we will use the same gene model as with mapping ( miRBase.R21 ). The analysis returns a Table View of QC metrics and Profile view in the Aligned Data QC folder: In the Table view, you will find the following sections: Alignment Metrics These metrics can be used to give an overall idea of the quality of the alignment for your samples. Coverage Metrics The coverage metrics give you an overall idea of the mean coverage of your experiment. For RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model). It also gives metrics on the number and percentage of genes with coverage. Finally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage. Duplication Metrics The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an miRNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values. Flag Metrics Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags. Insert Size Metrics Insert size metrics provide some basic metrics on the insert sizes for paired end experiments. Profile Metrics Profile Metrics provide important overall statistics based on the provided gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Since we mapped only to known miRNAs, this should be reflected in the profile metrics (i.e. all mapped reads are in exons). Source Metrics These metrics can be used to get a sense of the overall types of transcripts that are being aligned. For miRNAs, these statistics will not reflect anything informative. Strand Metrics The strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, such as the small rna sample prep kit that generated these data, this is not the case. Feature Metrics Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data. Other Aligned Data QC RNA-Seq QC Metrics provides comprehensive assessment of the alignment data. We also provide metrics such as Flag Summary Statistics , Mapping Summary Statistics , Paired End Insert Size , RNA-Seq Mapping Profile as separate functions, where users can specify more analysis options.","title":"QC of Aligned Data"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#qc-of-aligned-data","text":"","title":"QC of Aligned Data"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#alignment-report","text":"By default, an alignment report is generated anytime an alignment is done in Array Studio. If it is not already open, go to your Solution Explorer and double click on Report from the AlignmentReport table. This will show, for each file, some statistics regarding mapping. One of the key statistics is the uniquely mapped reads.","title":"Alignment Report"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#mirna-seq-aligned-qc","text":"To get more detailed statistics of mapping rate, the RNA-Seq QC metrics can be used: This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. It also generates a ProfileView showing a chart for each metric. To run the RNA-Seq QC module, go to NGS | Aligned Data QC | RNA-Seq QC Metrics now. Choose the NGS data object and leave all other settings as their defaults and click Submit to run the module. Source metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we will use the same gene model as with mapping ( miRBase.R21 ). The analysis returns a Table View of QC metrics and Profile view in the Aligned Data QC folder: In the Table view, you will find the following sections:","title":"miRNA-Seq Aligned QC"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#alignment-metrics","text":"These metrics can be used to give an overall idea of the quality of the alignment for your samples.","title":"Alignment Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#coverage-metrics","text":"The coverage metrics give you an overall idea of the mean coverage of your experiment. For RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model). It also gives metrics on the number and percentage of genes with coverage. Finally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage.","title":"Coverage Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#duplication-metrics","text":"The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an miRNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.","title":"Duplication Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#flag-metrics","text":"Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.","title":"Flag Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#insert-size-metrics","text":"Insert size metrics provide some basic metrics on the insert sizes for paired end experiments.","title":"Insert Size Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#profile-metrics","text":"Profile Metrics provide important overall statistics based on the provided gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Since we mapped only to known miRNAs, this should be reflected in the profile metrics (i.e. all mapped reads are in exons).","title":"Profile Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#source-metrics","text":"These metrics can be used to get a sense of the overall types of transcripts that are being aligned. For miRNAs, these statistics will not reflect anything informative.","title":"Source Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#strand-metrics","text":"The strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, such as the small rna sample prep kit that generated these data, this is not the case.","title":"Strand Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#feature-metrics","text":"Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data.","title":"Feature Metrics"},{"location":"tutorials/miRNAseq/QC_of_Aligned_Data/#other-aligned-data-qc","text":"RNA-Seq QC Metrics provides comprehensive assessment of the alignment data. We also provide metrics such as Flag Summary Statistics , Mapping Summary Statistics , Paired End Insert Size , RNA-Seq Mapping Profile as separate functions, where users can specify more analysis options.","title":"Other Aligned Data QC"},{"location":"tutorials/miRNAseq/Save_Close_Project/","text":"Save & Close Project Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in the form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save and Close Project"},{"location":"tutorials/miRNAseq/Save_Close_Project/#save-close-project","text":"Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in the form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save &amp; Close Project"},{"location":"tutorials/miRNAseq/miRNA-Seq_Quantification/","text":"miRNA-Seq Quantification ArrayStudio provides modules and options for miRNA-Seq quantification. Report miRNA Counts Given the alignment, one can summarize miRNA expression, using the Quantification module in NGS | Quantification | Report Gene/Transcript Counts . User can choose to quantify at transcript level by selecting it in the Expression measurement option. At Summary Level , If Gene level is selected, miRNA expression will be quantified at pre-miRNA gene level. If Transcript level is selected, miRNA expression will be quantified at mature miRNA transcript level. By default, option Count fragments instead of reads is selected, unselect as this is not paired-end (in this case, it makes no difference). Exclude multi-reads does not count non-unique mapped reads. In the source paper, multi-reads were distributed to all matching sites, so we will also use multi-reads. Options to count reads based on strand are design for dataset from strand-specific protocol. In this tutorial, the samples are strand-specific, as shown in the strand metrics from aligned QC table. Only the first strand counting option is checked. We will examine mature miRNA expression levels, so select Transcript level . Click Submit to run the module. The output counts can be found under the -Omic data header in the Solution Explorer . The counts table has miRNA IDs listed down the first column, and the sample IDs listed across the top row. -Omic data have an L-shaped metadata structure, where the row IDs are linked to the Annotation table (provided by the gene model), and the column IDs are linked to the Design table (which we attached after aligning). -Omic data can be treated as MicroArray Data and all microarray data analysis functions, such as OmicData | Pattern | Hierarchical Clustering , OmicData | QC | Principal Component Analysis , OmicData | Inference | General Linear Model and other modules can be used for downstream data analyses. Please read the Microarray tutorial to get detailed analysis information. For this tutorial, we will look for changes between groups of samples, but first we recommended that you normalize the data by total counts. This normalization function can be found in NGS | Inference | Normalize RNASeq data . The Normalize RNA-Seq Data module provides a number of different ways to normalize data; we will use TotalCount. Select TotalCount in the Normalization method list, set the Scale Target to 1,000,000 and click submit. If you choose, you can check the normalization by selecting OmicData | Summarize | Summary Statistics , then summarizing by Observation , using Sum (it should equal 1,000,000). ANOVA to identify differentially-expressed miRNAs Now that our miRNA-seq count data are normalized, we can now use ANOVA to identify differentially-expressed miRNAs. Please be aware that our small sample set is not large enough to give a robust test. If the user wishes, the full set of miRNA-seq data can be run through this tutorial, and be compared to the original paper's results. For example, this volcano plot of a One-way ANOVA of Psoriatic Involved vs Normal samples, using all miRNA-seq data (instead of the tutorial subset), known miRNAs that were reported as being most up- or down-regulated in Joyce et al. are color-coded as purple and blue, respectively. Although using only the tutorial subset is not statistically robust, let's walk through the process. First, we will log2-transform our scaled data, using OmicData | Preprocess | Transform : Specify an output name (otherwise the normalized count data will be over-written) , add a constant of 0.1 (to avoid Log2 of 0 ), and select \"Log2\" as the Transformation method . Once we have transformed our data, several tests, including ANOVA, can be performed. These can be found under OmicData | Inference | Standard Tests : In the One-Way ANOVA Window, first ensure that the scaled data set is selected, and specify an output name. Select \"Group\" as our Group (specified when we modified the Design Table ). Select \"Pairwise\" Comparison , to compare between each pair of groups. We will use \"FDR_BH\" multiplicity correction. Leave FC transformation as \"Exp2\", and click Submit . Volcano plots will show fold-change vs P-values for the 2813 miRNAs measured, across each pairwise comparison of normal, uninvolved, and involved psoriasis samples. Cut-off lines can be selected in View Controller | Specify Cutoff Lines for p value cut-offs (y-axis) and fold-change (x-axis) as shown above. Select a few dots on the Psoriatic_Involved vs Normal plot. Detailed information about the measurements will be displayed in the Details *Window , including the Estimate, which is the difference in means of log2-transformed miRNA expression in the samples, fold-change, which is unlogged Estimate, but the value's sign indicates whether the treatment sample is increased (+) or decreased (-), as well as raw and adjusted P-values. In the details window, hover the mouse over one of the miRNA genes; the corresponding point on the volcano plot will be indicated. Although this tutorial used only a subset of the original study's data, this analysis detects many of the same differentially-expressed miRNAs, including upregulation of miR-135b. These genes can be found in the Volcano plot by searching in the search box. (1) Type \"mir-135b\" in the search box, (2) click the search icon (binoculars). All matches to this string (in this case, two miR-135b transcripts) will be selected in the Volcano plot, and details will be displayed in the the Details window.","title":"miRNA-Seq Quantification"},{"location":"tutorials/miRNAseq/miRNA-Seq_Quantification/#mirna-seq-quantification","text":"ArrayStudio provides modules and options for miRNA-Seq quantification.","title":"miRNA-Seq Quantification"},{"location":"tutorials/miRNAseq/miRNA-Seq_Quantification/#report-mirna-counts","text":"Given the alignment, one can summarize miRNA expression, using the Quantification module in NGS | Quantification | Report Gene/Transcript Counts . User can choose to quantify at transcript level by selecting it in the Expression measurement option. At Summary Level , If Gene level is selected, miRNA expression will be quantified at pre-miRNA gene level. If Transcript level is selected, miRNA expression will be quantified at mature miRNA transcript level. By default, option Count fragments instead of reads is selected, unselect as this is not paired-end (in this case, it makes no difference). Exclude multi-reads does not count non-unique mapped reads. In the source paper, multi-reads were distributed to all matching sites, so we will also use multi-reads. Options to count reads based on strand are design for dataset from strand-specific protocol. In this tutorial, the samples are strand-specific, as shown in the strand metrics from aligned QC table. Only the first strand counting option is checked. We will examine mature miRNA expression levels, so select Transcript level . Click Submit to run the module. The output counts can be found under the -Omic data header in the Solution Explorer . The counts table has miRNA IDs listed down the first column, and the sample IDs listed across the top row. -Omic data have an L-shaped metadata structure, where the row IDs are linked to the Annotation table (provided by the gene model), and the column IDs are linked to the Design table (which we attached after aligning). -Omic data can be treated as MicroArray Data and all microarray data analysis functions, such as OmicData | Pattern | Hierarchical Clustering , OmicData | QC | Principal Component Analysis , OmicData | Inference | General Linear Model and other modules can be used for downstream data analyses. Please read the Microarray tutorial to get detailed analysis information. For this tutorial, we will look for changes between groups of samples, but first we recommended that you normalize the data by total counts. This normalization function can be found in NGS | Inference | Normalize RNASeq data . The Normalize RNA-Seq Data module provides a number of different ways to normalize data; we will use TotalCount. Select TotalCount in the Normalization method list, set the Scale Target to 1,000,000 and click submit. If you choose, you can check the normalization by selecting OmicData | Summarize | Summary Statistics , then summarizing by Observation , using Sum (it should equal 1,000,000).","title":"Report miRNA Counts"},{"location":"tutorials/miRNAseq/miRNA-Seq_Quantification/#anova-to-identify-differentially-expressed-mirnas","text":"Now that our miRNA-seq count data are normalized, we can now use ANOVA to identify differentially-expressed miRNAs. Please be aware that our small sample set is not large enough to give a robust test. If the user wishes, the full set of miRNA-seq data can be run through this tutorial, and be compared to the original paper's results. For example, this volcano plot of a One-way ANOVA of Psoriatic Involved vs Normal samples, using all miRNA-seq data (instead of the tutorial subset), known miRNAs that were reported as being most up- or down-regulated in Joyce et al. are color-coded as purple and blue, respectively. Although using only the tutorial subset is not statistically robust, let's walk through the process. First, we will log2-transform our scaled data, using OmicData | Preprocess | Transform : Specify an output name (otherwise the normalized count data will be over-written) , add a constant of 0.1 (to avoid Log2 of 0 ), and select \"Log2\" as the Transformation method . Once we have transformed our data, several tests, including ANOVA, can be performed. These can be found under OmicData | Inference | Standard Tests : In the One-Way ANOVA Window, first ensure that the scaled data set is selected, and specify an output name. Select \"Group\" as our Group (specified when we modified the Design Table ). Select \"Pairwise\" Comparison , to compare between each pair of groups. We will use \"FDR_BH\" multiplicity correction. Leave FC transformation as \"Exp2\", and click Submit . Volcano plots will show fold-change vs P-values for the 2813 miRNAs measured, across each pairwise comparison of normal, uninvolved, and involved psoriasis samples. Cut-off lines can be selected in View Controller | Specify Cutoff Lines for p value cut-offs (y-axis) and fold-change (x-axis) as shown above. Select a few dots on the Psoriatic_Involved vs Normal plot. Detailed information about the measurements will be displayed in the Details *Window , including the Estimate, which is the difference in means of log2-transformed miRNA expression in the samples, fold-change, which is unlogged Estimate, but the value's sign indicates whether the treatment sample is increased (+) or decreased (-), as well as raw and adjusted P-values. In the details window, hover the mouse over one of the miRNA genes; the corresponding point on the volcano plot will be indicated. Although this tutorial used only a subset of the original study's data, this analysis detects many of the same differentially-expressed miRNAs, including upregulation of miR-135b. These genes can be found in the Volcano plot by searching in the search box. (1) Type \"mir-135b\" in the search box, (2) click the search icon (binoculars). All matches to this string (in this case, two miR-135b transcripts) will be selected in the Volcano plot, and details will be displayed in the the Details window.","title":"ANOVA to identify differentially-expressed miRNAs"},{"location":"tutorials/miRNAseq/workflow_and_pipeline/","text":"miRNA-Seq Analysis Workflow In this tutorial, we will introduce the miRNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for miRNA-Seq data processing, including raw data quality control (QC), adapter trimming, alignment, aligned data QC, quantification, and differential expression This workflow can be followed by the steps listed in the Workflow window: or by running the individual modules from the menu items. For convenience, especially for new users, we also have a single-command pipeline that will use default settings to take miRNA-seq data from raw fastq files to mapped, QC'd, and quantified data, which follows the workflow below: In this tutorial, we will go step by step through all the options specified in this pipeline to give users a detailed understanding of each option selected above and how they can impact your study.","title":"workflow and pipeline"},{"location":"tutorials/miRNAseq/workflow_and_pipeline/#mirna-seq-analysis-workflow","text":"In this tutorial, we will introduce the miRNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for miRNA-Seq data processing, including raw data quality control (QC), adapter trimming, alignment, aligned data QC, quantification, and differential expression This workflow can be followed by the steps listed in the Workflow window: or by running the individual modules from the menu items. For convenience, especially for new users, we also have a single-command pipeline that will use default settings to take miRNA-seq data from raw fastq files to mapped, QC'd, and quantified data, which follows the workflow below: In this tutorial, we will go step by step through all the options specified in this pipeline to give users a detailed understanding of each option selected above and how they can impact your study.","title":"miRNA-Seq Analysis Workflow"},{"location":"tutorials/scRNAseq/AdditionalOptions/","text":"Remove Duplicate This module is optional for this tutorial, user can run this or just skip this part, and jump to the step for Quantification. Remove Duplicate can be used to remove duplication for Single Cell Bam files. The module will be useful if the user wants to have a clean (duplicate removed) BAM file for downstream analysis. To access this module, user can go to Analysis | NGS | Single Cell RNA-Seq | Remove Duplicates : Use the default options and just input the Output name and output folder, then click Send To Queue to submit this job: Once this job is finished, user should be able to see a new NgsData object in Array Studio GUI, as well as new BAM files in the specified output folder:","title":"Addtional Options"},{"location":"tutorials/scRNAseq/AdditionalOptions/#remove-duplicate","text":"This module is optional for this tutorial, user can run this or just skip this part, and jump to the step for Quantification. Remove Duplicate can be used to remove duplication for Single Cell Bam files. The module will be useful if the user wants to have a clean (duplicate removed) BAM file for downstream analysis. To access this module, user can go to Analysis | NGS | Single Cell RNA-Seq | Remove Duplicates : Use the default options and just input the Output name and output folder, then click Send To Queue to submit this job: Once this job is finished, user should be able to see a new NgsData object in Array Studio GUI, as well as new BAM files in the specified output folder:","title":"Remove Duplicate"},{"location":"tutorials/scRNAseq/Alignment_to_the_Genome/","text":"Alignment to the Genome After the preprocessing of single cell fastq files, the major step of the SC RNASeq analysis is the alignment of the reads to the genome. For this tutorial, we will align the data using OShell (same to normal RNASeq alignment), but with a special module to include the information in the tag file. To access this module, please go to NGS | Single Cell RNA-Seq | Barcoded Alignment: Add filtered reads If you used the 10X Preprocessing menu you can simply Click the Add List link to specify the location of the files. This will automatically populate the File names field with the filtered reads. If you have used the non-10X UMI data tutorial to run the filtering step, simply use the fastq files resulted from filtering process, clicking the Add link to choose the location of these files. The associated tag.gz file will be expected in the same folder as fastq.gz file. Although our original fastq files are paired end reads, while the read1 only contains cell barcode and UMI information, the fastq file after preprocessing is now single end reads now, so leave the option for Reads are paired empty. Choose the Genome for the experiment. In the 10X data analysis, we used Mouse.B38 , and for the non-10X dataset, Human.hg19 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the Gene Model to be used for alignment. Here we use Ensembl.R92 (10X) and Ensembl.R75 (non-10X), but the user can always choose to use their own gene model. Leave the quality encoding set to automatic. However, for your information, these files were encoded using the Sanger quality scoring system. Total penalty should be left as automatic, and is described completely in Omicsoft\u2019s white paper on alignment. Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \u201cties\u201d for non-unique reads should be reported, or whether they should be excluded all together. Different from the normal RNASeq alignment, in this module, Barcoded BAM files will be generated. Basically, there will be several extra columns in the bam file for each read, showing the corresponding information about cell barcode and UMI. Output folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in the next step (for fusion detection). There are a few options in the Advanced Tab (e.g. Indel detection). In general, the default values have been tuned and should work well in most cases. Click Send To Queue to submit the analysis. This could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc. Alignment reports and output files After the alignment, you will see a NgsData object and an alignment report table in the solution explorer. BAM files as well as alignment report summary files will be generated in the specified output folder:","title":"Alignment to the Genome"},{"location":"tutorials/scRNAseq/Alignment_to_the_Genome/#alignment-to-the-genome","text":"After the preprocessing of single cell fastq files, the major step of the SC RNASeq analysis is the alignment of the reads to the genome. For this tutorial, we will align the data using OShell (same to normal RNASeq alignment), but with a special module to include the information in the tag file. To access this module, please go to NGS | Single Cell RNA-Seq | Barcoded Alignment:","title":"Alignment to the Genome"},{"location":"tutorials/scRNAseq/Alignment_to_the_Genome/#add-filtered-reads","text":"If you used the 10X Preprocessing menu you can simply Click the Add List link to specify the location of the files. This will automatically populate the File names field with the filtered reads. If you have used the non-10X UMI data tutorial to run the filtering step, simply use the fastq files resulted from filtering process, clicking the Add link to choose the location of these files. The associated tag.gz file will be expected in the same folder as fastq.gz file. Although our original fastq files are paired end reads, while the read1 only contains cell barcode and UMI information, the fastq file after preprocessing is now single end reads now, so leave the option for Reads are paired empty. Choose the Genome for the experiment. In the 10X data analysis, we used Mouse.B38 , and for the non-10X dataset, Human.hg19 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the Gene Model to be used for alignment. Here we use Ensembl.R92 (10X) and Ensembl.R75 (non-10X), but the user can always choose to use their own gene model. Leave the quality encoding set to automatic. However, for your information, these files were encoded using the Sanger quality scoring system. Total penalty should be left as automatic, and is described completely in Omicsoft\u2019s white paper on alignment. Thread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \u201cties\u201d for non-unique reads should be reported, or whether they should be excluded all together. Different from the normal RNASeq alignment, in this module, Barcoded BAM files will be generated. Basically, there will be several extra columns in the bam file for each read, showing the corresponding information about cell barcode and UMI. Output folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in the next step (for fusion detection). There are a few options in the Advanced Tab (e.g. Indel detection). In general, the default values have been tuned and should work well in most cases. Click Send To Queue to submit the analysis. This could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc.","title":"Add filtered reads"},{"location":"tutorials/scRNAseq/Alignment_to_the_Genome/#alignment-reports-and-output-files","text":"After the alignment, you will see a NgsData object and an alignment report table in the solution explorer. BAM files as well as alignment report summary files will be generated in the specified output folder:","title":"Alignment reports and output files"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/","text":"Downstream Analysis of Single Cell Data Normalization In ArrayStudio, we provide different methods for normalization. For Single cell RNA-seq data, we use TPM (transcript per million) for samples without UMI incorporated, and RPM (Counts/reads per million) for samples that contain UMI (due to the 5\u2019 or 3\u2019 biases). For both UMI datasets quantified in this tutorial, we will use RPM to normalize the data as we do have UMI for these samples. If user haven\u2019t check the option for Convert UMI count to transcript number in the advanced option for Report Single Cell Counts (like for the 10X data set) , the Quantification module will only output one ZIM file and ZIM data object in GUI, and different from microarray type data, ZIM data might not be compatible with several other modules we are going to use, so before we do the normalization, user should right click on the UMI count data object, and convert it to MicroArray Data: While in our tutorial case, if use did check the option for Convert UMI count to transcript number in the advanced option for Report Single Cell Counts , the Quantification module will output a ZIM data object and a normal microarray type data object for the converted count in GUI, user can just use the converted count data directly to do the normalization as follows. For RPM normalization, we can go to NGS | Inference | Normalize RNA-Seq Data: And choose TotalCount for the Normalization method, setting the scale target to 1,000,000, so the resulted data will be reads per million: Interpretation of Single Cell Counts Data The analysis of Single Cell RNA-seq analysis is a rapidly evolving field. OmicSoft has implemented several widely used R packages within ArrayStudio to allow users to conveniently use the GUI interface to interact with the data and further interpret their single cell data: Cluster Classification The Rtsne module in Array Studio will allow the user to cluster different cells with UMI counts, using the Rtsne package in R: T-Distributed Stochastic Neighbor Embedding using a Barnes-Hut Implementation RTSNE . To access this module, please go to Analysis | NGS | Single Cell RNA-Seq | t-SNE Clustering : Most options can be saved as default. Users have the option to scale the data prior to PCA if desired. In this tutorial, we have left this option blank. We have also added an option for users to select the number of clusters expected (lower and upper bound of a range). Select the expected number of clusters, leave all other options as default and run the R t-SNE: If user found that the Package compatibility is not ready for either local job or server job, please follow our instruction to set it up: R implementation of t-SNE t-SNE Module in ArrayStudio . Once the job is finished, user can find a table report and a scatter plot view for this table in ArrayStudio: The table report will look like this: And the scatter plot will use \u201cV1\u201d as x-axis and \u201cV2\u201d as y-axis based on the table report: Users can use the Kmeans columns to color the cells by cluster assignment, by clicking on Change Symbol Properties in the View Controller on the right side of the screen. Simply choose the columns to Color the view: Clicking Close, you will now see the clustering will be shown for each cell: Differential expression analysis - Seurat Seurat is an R package developed by the Satija Lab, which has gradually become a popular package for QC, analysis, and exploration of single cell RNA-seq data. The Seurat module in Array Studio has not adopted the full Seurat package, but will allow users to run several modules in the Seurat package: FindVariableGenes : Identifies \"noisy genes\" that account for the variation among single cells. FindMarkers: Finds markers (differentially expressed genes) for identified clusters. This function is intended to use Single Cell UMI count data, and directly runs the Seurat in the R engine integrated with ArrayStudio. To use this function, the ArrayServer admin can follow the instructions to integrate Seurat, or the user could run the analysis on their local server ( http://www.arrayserver.com/wiki/index.php?title=R_packages_integration_with_ArrayStudio ). The current implementation of Seurat requires the cells used in the analysis to be present as List objects in the project. To generate lists of cells in each cluster, users can use the tSNE scores table and: Repeat this with each cluster in the tSNE scores table, and you will have a group of lists (8 in the example above): Now, you can input the choices in Seurat for the analysis you would like to perform: In the screenshot above, notice how users can do pairwise comparisons of cluster to cluster (i.e. Cluster1 to Cluster3), or simply identify which genes are differentially expressed in the chosen cluster compared to all other cells. If interested in the highly variable genes, choose this option and click Send to Queue. A number of objects will be output after the job is complete: Inference Report: The inference report (and a volcano plot) generated will appear very similar to other differential expression modules in ArrayStudio, such as DESeq and General Linear Model: HVG table This table is output from Seurat and shows each gene's average expression and dispersion, along with the gene's metadata (such as common gene name, genome location) HVG List This will simply provide users a list of the highly variable genes identified by Seurat. Differential expression analysis - SCDE If users want to analyze the differential gene expression across different subset of cells, for instance, in upper chart, user want to see which genes show different expression level significantly between cluster 1 cluster 2, they can use the SCDE module in ArrayStudio. This function is intended to use Single Cell count data, and directly runs the R implementation of SCDE . SCDE was designed with small cell numbers in mind, such as a SMART-Seq experiment, and is not recommended for >1000 cells. To run the SCDE to compare different clusters, user should have a design table to include the cluster information for each cell. Here are the steps to add the cluster information (based on the t-SNE result) to the design table: Once the R-tsne is done and the scatter plot is generated, users can add the Kmeans cluster assignment from the tSNE scores table to the Design table for the Omic-Data object of SC counts. Now user can run SCDE. To open this module, please go to Analysis | NGS | Single Cell RNA-Seq | Single Cell Differential Expression Analysis . User can set the comparisons of cluster to cluster using the Group column and the newly added Kmeans assignment, and leave all other options in default and submit the job: if user found that the package compatibility is not OK, it means that the R integrated with ArrayStudio is not ready to run scde package, please check with How to setup SCDE in R engine SCDE in R Engine to configure SCDE in ArrayStudio. The SCDE module will generate an inference table and a volcano plot view for this table in ArrayStudio: A SCDE report table similar to DESeq Inference Report will be generated, containing fold-change and p-values for each tested variable. The default visualization, a volcano plot, will also be generated. Here is an example of output table: An example of volcano plot is shown below: Visualize gene expression ArrayStudio has developed a large number of rich visualizations to further explore data from OmicData and examine the results of downstream analyses. In addition to the inference reports and the associated Volcano plot views that allow users to visualize the distribution of fold change of all genes from say, one cluster to another, or one cluster to all cells, users can also visualize the normalized read counts and overlay the results with other cell metadata, such as cluster identity. Generate Violin plot A simply way to visualize expression of the highly variable or differentially expressed genes identified by Seurat would be to generate a Variable view in the RPM-Normalized OmicData object with all the single-cell counts: As shown in the preview above, for each cell, the expression level of each gene will be plotted. In order to better view the data, users can first add cluster metadata to the Design table of this OmicData object. Simply select all the lists of clusters identified in the tSNE view, right-click and choose Add List Membership to table: Simply choose the design table of the OmicData object with the RPM-normalized counts: In the Variable View that was added to this OmicData object, notice that each cell is represented on the X-axis. Users can Specify Profile Column to group cells based on metadata, such as the Cluster Identity (from the added List Membership): The scatter plot can be changed to a different style, such as the violin plot by selecting Change Profile Gallery The resulting view will be a violin plot for all variables (genes) represented in the experiment. From here, users can search their gene of interest: The view can be customized to show the gene symbol or color by cluster type: However, in single-cell analyses, many genes will have zero counts, and users may want to quickly filter out genes. Using the View Controller on the right side of the screen, users can filter to specific gene lists, such at the list of Highly Variable Genes produced by Seurat in the previous steps. Simply right-click on the GeneID and add list: Now, the view will be filtered down to the genes in the list, and users can scroll the view to visualize how genes are expressed in the clusters identified: Overlay Expression onto tSNE plot Another useful visualization would be to overlay gene expression onto the defined clusters from the tSNE view generated earlier. Within ArrayStudio, users can use Table | Overlay OmicData Features option: In this function count data from an OmicData object is transposed onto the tSNE scatter plot generated using the tSNE function. Users can simply choose the target data (the tSNE plot) and the source data (the counts table), and either input a single gene ID or a list of up to 200 genes to visualize on the tSNE plot: This will generate a new table object with the expression for the desired gene(s) added onto the tSNE table. In addition, a new view, called the ColorScatterView will be plotted, where each gene will be overlaid on a tSNE scatter view:","title":"Downstream Analyses of SC Data"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#downstream-analysis-of-single-cell-data","text":"","title":"Downstream Analysis of Single Cell Data"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#normalization","text":"In ArrayStudio, we provide different methods for normalization. For Single cell RNA-seq data, we use TPM (transcript per million) for samples without UMI incorporated, and RPM (Counts/reads per million) for samples that contain UMI (due to the 5\u2019 or 3\u2019 biases). For both UMI datasets quantified in this tutorial, we will use RPM to normalize the data as we do have UMI for these samples. If user haven\u2019t check the option for Convert UMI count to transcript number in the advanced option for Report Single Cell Counts (like for the 10X data set) , the Quantification module will only output one ZIM file and ZIM data object in GUI, and different from microarray type data, ZIM data might not be compatible with several other modules we are going to use, so before we do the normalization, user should right click on the UMI count data object, and convert it to MicroArray Data: While in our tutorial case, if use did check the option for Convert UMI count to transcript number in the advanced option for Report Single Cell Counts , the Quantification module will output a ZIM data object and a normal microarray type data object for the converted count in GUI, user can just use the converted count data directly to do the normalization as follows. For RPM normalization, we can go to NGS | Inference | Normalize RNA-Seq Data: And choose TotalCount for the Normalization method, setting the scale target to 1,000,000, so the resulted data will be reads per million:","title":"Normalization"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#interpretation-of-single-cell-counts-data","text":"The analysis of Single Cell RNA-seq analysis is a rapidly evolving field. OmicSoft has implemented several widely used R packages within ArrayStudio to allow users to conveniently use the GUI interface to interact with the data and further interpret their single cell data:","title":"Interpretation of Single Cell Counts Data"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#cluster-classification","text":"The Rtsne module in Array Studio will allow the user to cluster different cells with UMI counts, using the Rtsne package in R: T-Distributed Stochastic Neighbor Embedding using a Barnes-Hut Implementation RTSNE . To access this module, please go to Analysis | NGS | Single Cell RNA-Seq | t-SNE Clustering : Most options can be saved as default. Users have the option to scale the data prior to PCA if desired. In this tutorial, we have left this option blank. We have also added an option for users to select the number of clusters expected (lower and upper bound of a range). Select the expected number of clusters, leave all other options as default and run the R t-SNE: If user found that the Package compatibility is not ready for either local job or server job, please follow our instruction to set it up: R implementation of t-SNE t-SNE Module in ArrayStudio . Once the job is finished, user can find a table report and a scatter plot view for this table in ArrayStudio: The table report will look like this: And the scatter plot will use \u201cV1\u201d as x-axis and \u201cV2\u201d as y-axis based on the table report: Users can use the Kmeans columns to color the cells by cluster assignment, by clicking on Change Symbol Properties in the View Controller on the right side of the screen. Simply choose the columns to Color the view: Clicking Close, you will now see the clustering will be shown for each cell:","title":"Cluster Classification"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#differential-expression-analysis-seurat","text":"Seurat is an R package developed by the Satija Lab, which has gradually become a popular package for QC, analysis, and exploration of single cell RNA-seq data. The Seurat module in Array Studio has not adopted the full Seurat package, but will allow users to run several modules in the Seurat package: FindVariableGenes : Identifies \"noisy genes\" that account for the variation among single cells. FindMarkers: Finds markers (differentially expressed genes) for identified clusters. This function is intended to use Single Cell UMI count data, and directly runs the Seurat in the R engine integrated with ArrayStudio. To use this function, the ArrayServer admin can follow the instructions to integrate Seurat, or the user could run the analysis on their local server ( http://www.arrayserver.com/wiki/index.php?title=R_packages_integration_with_ArrayStudio ). The current implementation of Seurat requires the cells used in the analysis to be present as List objects in the project. To generate lists of cells in each cluster, users can use the tSNE scores table and: Repeat this with each cluster in the tSNE scores table, and you will have a group of lists (8 in the example above): Now, you can input the choices in Seurat for the analysis you would like to perform: In the screenshot above, notice how users can do pairwise comparisons of cluster to cluster (i.e. Cluster1 to Cluster3), or simply identify which genes are differentially expressed in the chosen cluster compared to all other cells. If interested in the highly variable genes, choose this option and click Send to Queue. A number of objects will be output after the job is complete: Inference Report: The inference report (and a volcano plot) generated will appear very similar to other differential expression modules in ArrayStudio, such as DESeq and General Linear Model: HVG table This table is output from Seurat and shows each gene's average expression and dispersion, along with the gene's metadata (such as common gene name, genome location) HVG List This will simply provide users a list of the highly variable genes identified by Seurat.","title":"Differential expression analysis - Seurat"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#differential-expression-analysis-scde","text":"If users want to analyze the differential gene expression across different subset of cells, for instance, in upper chart, user want to see which genes show different expression level significantly between cluster 1 cluster 2, they can use the SCDE module in ArrayStudio. This function is intended to use Single Cell count data, and directly runs the R implementation of SCDE . SCDE was designed with small cell numbers in mind, such as a SMART-Seq experiment, and is not recommended for >1000 cells. To run the SCDE to compare different clusters, user should have a design table to include the cluster information for each cell. Here are the steps to add the cluster information (based on the t-SNE result) to the design table: Once the R-tsne is done and the scatter plot is generated, users can add the Kmeans cluster assignment from the tSNE scores table to the Design table for the Omic-Data object of SC counts. Now user can run SCDE. To open this module, please go to Analysis | NGS | Single Cell RNA-Seq | Single Cell Differential Expression Analysis . User can set the comparisons of cluster to cluster using the Group column and the newly added Kmeans assignment, and leave all other options in default and submit the job: if user found that the package compatibility is not OK, it means that the R integrated with ArrayStudio is not ready to run scde package, please check with How to setup SCDE in R engine SCDE in R Engine to configure SCDE in ArrayStudio. The SCDE module will generate an inference table and a volcano plot view for this table in ArrayStudio: A SCDE report table similar to DESeq Inference Report will be generated, containing fold-change and p-values for each tested variable. The default visualization, a volcano plot, will also be generated. Here is an example of output table: An example of volcano plot is shown below:","title":"Differential expression analysis - SCDE"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#visualize-gene-expression","text":"ArrayStudio has developed a large number of rich visualizations to further explore data from OmicData and examine the results of downstream analyses. In addition to the inference reports and the associated Volcano plot views that allow users to visualize the distribution of fold change of all genes from say, one cluster to another, or one cluster to all cells, users can also visualize the normalized read counts and overlay the results with other cell metadata, such as cluster identity.","title":"Visualize gene expression"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#generate-violin-plot","text":"A simply way to visualize expression of the highly variable or differentially expressed genes identified by Seurat would be to generate a Variable view in the RPM-Normalized OmicData object with all the single-cell counts: As shown in the preview above, for each cell, the expression level of each gene will be plotted. In order to better view the data, users can first add cluster metadata to the Design table of this OmicData object. Simply select all the lists of clusters identified in the tSNE view, right-click and choose Add List Membership to table: Simply choose the design table of the OmicData object with the RPM-normalized counts: In the Variable View that was added to this OmicData object, notice that each cell is represented on the X-axis. Users can Specify Profile Column to group cells based on metadata, such as the Cluster Identity (from the added List Membership): The scatter plot can be changed to a different style, such as the violin plot by selecting Change Profile Gallery The resulting view will be a violin plot for all variables (genes) represented in the experiment. From here, users can search their gene of interest: The view can be customized to show the gene symbol or color by cluster type: However, in single-cell analyses, many genes will have zero counts, and users may want to quickly filter out genes. Using the View Controller on the right side of the screen, users can filter to specific gene lists, such at the list of Highly Variable Genes produced by Seurat in the previous steps. Simply right-click on the GeneID and add list: Now, the view will be filtered down to the genes in the list, and users can scroll the view to visualize how genes are expressed in the clusters identified:","title":"Generate Violin plot"},{"location":"tutorials/scRNAseq/Downstream Analyses of SC Data/#overlay-expression-onto-tsne-plot","text":"Another useful visualization would be to overlay gene expression onto the defined clusters from the tSNE view generated earlier. Within ArrayStudio, users can use Table | Overlay OmicData Features option: In this function count data from an OmicData object is transposed onto the tSNE scatter plot generated using the tSNE function. Users can simply choose the target data (the tSNE plot) and the source data (the counts table), and either input a single gene ID or a list of up to 200 genes to visualize on the tSNE plot: This will generate a new table object with the expression for the desired gene(s) added onto the tSNE table. In addition, a new view, called the ColorScatterView will be plotted, where each gene will be overlaid on a tSNE scatter view:","title":"Overlay Expression onto tSNE plot"},{"location":"tutorials/scRNAseq/Introduction/","text":"Introduction ArrayStudio Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local NGS analysis using a Windows Workstation with (Window 10 Pro) with 3.60GHz Intel\u00ae Core TM i7-4790 Processor (# of cores: 4; # of threads: 8) with 16GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool. Single Cell Solutions Single-cell RNA-seq is a rapidly developing field with many methods of isolating single cells, and generating libraries for NGS sequencing. Below is an example that demonstrates the varying types of methodologies available to isolate single cells: As shown in the diagram, single cell RNA-seq can be split into two categories, UMI ( Unique Molecular Identifier ) and non-UMI studies. With Single-Cell studies, since the input material is relatively low, there can be an amplification bias that is introduced during library preparation. UMIs have been developed to uniquely tag RNA molecules to reduce this amplification bias. For these UMI studies, this requires users to incorporate these tags into the design and analyses of the RNA-seq. Often, there are barcodes attributed to each cell and UMIs for each molecule. Depending on the experiment, this information can be stored in different parts of the .fastq files that are obtained from a sequecning facility. OmicSoft has developed modules to allow its users to analyze these complex datasets with the simple interface in the ArrayStudio GUI. The workflow consists of a number of modules for SCRNA-Seq data processing, including pre-processing, filtering reads, tag-based QC, alignment, quantification, and a series of optional downstream analysis, as shown in the schematic chart below: These modules can be joined together to allow the user to step through the pre-processing through quantification in a single action. Tutorials A very popular platform for obtaining single cell RNA-seq data is available through 10X Genomics. For this reason, we have developed modules and training material for 10X Genomics and for all other UMI-based . For non-UMI based scRNA-seq datasets, the standard RNA-seq workflow can be used to align the raw data. For all the single cell datasets described, OmicSoft has a number of downstream analyses options to aid in classification of clusters of cells, differential expression and marker gene identification. Create Server Project Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. Users can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. In this tutorial, we are using server projects. If a user doesn't have Array Server installed, user can run the tutorial as a local project and analysis steps are almost the same as described in this tutorial. Note : If user is using local project to analyze the SingleCell data in this tutorial, please refer to our tutorial for \u201cRNA-Seq Analysis\u201d about creating ArrayStudio local Project: Create Projects . In order to analyze the data in server project, users should firstly connect to a server and upload the fastq files if they are not accessible on server folder: Connect to Server and Upload Files Then user can create a server project following analysis: Create Server Project for","title":"Introduction"},{"location":"tutorials/scRNAseq/Introduction/#introduction","text":"","title":"Introduction"},{"location":"tutorials/scRNAseq/Introduction/#arraystudio","text":"Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local NGS analysis using a Windows Workstation with (Window 10 Pro) with 3.60GHz Intel\u00ae Core TM i7-4790 Processor (# of cores: 4; # of threads: 8) with 16GB RAM. It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.","title":"ArrayStudio"},{"location":"tutorials/scRNAseq/Introduction/#single-cell-solutions","text":"Single-cell RNA-seq is a rapidly developing field with many methods of isolating single cells, and generating libraries for NGS sequencing. Below is an example that demonstrates the varying types of methodologies available to isolate single cells: As shown in the diagram, single cell RNA-seq can be split into two categories, UMI ( Unique Molecular Identifier ) and non-UMI studies. With Single-Cell studies, since the input material is relatively low, there can be an amplification bias that is introduced during library preparation. UMIs have been developed to uniquely tag RNA molecules to reduce this amplification bias. For these UMI studies, this requires users to incorporate these tags into the design and analyses of the RNA-seq. Often, there are barcodes attributed to each cell and UMIs for each molecule. Depending on the experiment, this information can be stored in different parts of the .fastq files that are obtained from a sequecning facility. OmicSoft has developed modules to allow its users to analyze these complex datasets with the simple interface in the ArrayStudio GUI. The workflow consists of a number of modules for SCRNA-Seq data processing, including pre-processing, filtering reads, tag-based QC, alignment, quantification, and a series of optional downstream analysis, as shown in the schematic chart below: These modules can be joined together to allow the user to step through the pre-processing through quantification in a single action.","title":"Single Cell Solutions"},{"location":"tutorials/scRNAseq/Introduction/#tutorials","text":"A very popular platform for obtaining single cell RNA-seq data is available through 10X Genomics. For this reason, we have developed modules and training material for 10X Genomics and for all other UMI-based . For non-UMI based scRNA-seq datasets, the standard RNA-seq workflow can be used to align the raw data. For all the single cell datasets described, OmicSoft has a number of downstream analyses options to aid in classification of clusters of cells, differential expression and marker gene identification.","title":"Tutorials"},{"location":"tutorials/scRNAseq/Introduction/#create-server-project","text":"Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. Users can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. In this tutorial, we are using server projects. If a user doesn't have Array Server installed, user can run the tutorial as a local project and analysis steps are almost the same as described in this tutorial. Note : If user is using local project to analyze the SingleCell data in this tutorial, please refer to our tutorial for \u201cRNA-Seq Analysis\u201d about creating ArrayStudio local Project: Create Projects . In order to analyze the data in server project, users should firstly connect to a server and upload the fastq files if they are not accessible on server folder: Connect to Server and Upload Files Then user can create a server project following analysis: Create Server Project for","title":"Create Server Project"},{"location":"tutorials/scRNAseq/QC of Aligned Data/","text":"Quality control on the cells Single Cell alignment/quantification will result in hundreds/thousands of cells, during which there will be various qualities for different cells. Low-quality cells need to be removed to ensure that technical effects do not distort downstream analysis results. We would like to propose this criteria for filtering low quality cells, with which we have been used for curating our data for SingleCell lands: Mapped rate: >=40% for human ; >=30% for mouse Mapped reads: >=50,000 for Non UMI ; >= 1000 for UMI Gene coverage: >=1000 for Non UMI ; >=250 for UMI Mitochondrial rate: < 20% Spike-in RNA rate (if there is Spike-in and calculated): < 20% Based on this criterion, we consider the cells with small number of mapped reads have low quality, as well as the alignment mapped rate. The minimal gene coverage is defined as the number of genes with non-zero counts for that cell, and we set the threshold as 1000 for reads containing UMI, 50,000 for reads don\u2019t have UMI. Any cells with very few expressed genes are considered with poor quality, probably due to the failure of capturing the diverse transcript population. Besides that, we also measure the proportion of reads mapped to genes in the mitochondrial genome. High proportion of reads mapped to mitochondrial might be an indication of increased apoptosis and/or loss of cytoplasmic RNA from lysed cells. Similar consideration applies to the ratio of genes mapped to Spike-in RNA. If the portion mapped to spike-in RNA is high, these cells might have lost the major portion of endogenous RNA, thus considered as low quality. If there is no spike-in RNA included in the sample, then this part can be removed from the criteria. scRNA-Seq QC Metrics: ArrayStudio has provided a module to do Alignment data QC especially designed for Single Cell RNA-seq, which can be accessed by going to NGS | Single Cell RNA-seq | SC RNA-seq QC Metrics: This module takes bam file resulted from barcoded alignment as input file, user can click Add to import the formally aligned bam files, and choose the corresponding genome and gene model used for the alignment, and input the output folder to run the job: To reduce the file size, OmicSoft has added features to this module to output only the results desired by the user. In the Advanced Tab: By default, OmicSoft will report the four main criteria used to QC cells in OmicSoft Lands that are outlined above. If users would like to report additional QC summary statistics, this can be done by moving from the All columns (left pane) to the selected columns (right pane) with the arrows. When the job finishes, an SC RNA Seq QC Metrics Table will be generated. Different from the RNASeq QC metrics report for bulk RNASeq, this SC RNA Seq QC Metrics Table will have the cell name as the row ID, and different alignment statistics as the column name. In addition, only the metrics specified in the advanced tab will be specified: User can filter for these columns for the quality control accordingly: Mapped rate \u2013 Alignment_MappedRate : >=40% for human ; >=30% for mouse Mapped reads \u2013 Alignment_Mapped : >=50,000 for Non UMI ; >= 1000 for UMI Gene coverage \u2013 Coverage_GeneWithCoverage : >=1000 for Non UMI ; >=250 for UMI Mitochondrial rate \u2013 Source_MitochondrialRate : < 20%","title":"QC of Aligned Data"},{"location":"tutorials/scRNAseq/QC of Aligned Data/#quality-control-on-the-cells","text":"Single Cell alignment/quantification will result in hundreds/thousands of cells, during which there will be various qualities for different cells. Low-quality cells need to be removed to ensure that technical effects do not distort downstream analysis results. We would like to propose this criteria for filtering low quality cells, with which we have been used for curating our data for SingleCell lands: Mapped rate: >=40% for human ; >=30% for mouse Mapped reads: >=50,000 for Non UMI ; >= 1000 for UMI Gene coverage: >=1000 for Non UMI ; >=250 for UMI Mitochondrial rate: < 20% Spike-in RNA rate (if there is Spike-in and calculated): < 20% Based on this criterion, we consider the cells with small number of mapped reads have low quality, as well as the alignment mapped rate. The minimal gene coverage is defined as the number of genes with non-zero counts for that cell, and we set the threshold as 1000 for reads containing UMI, 50,000 for reads don\u2019t have UMI. Any cells with very few expressed genes are considered with poor quality, probably due to the failure of capturing the diverse transcript population. Besides that, we also measure the proportion of reads mapped to genes in the mitochondrial genome. High proportion of reads mapped to mitochondrial might be an indication of increased apoptosis and/or loss of cytoplasmic RNA from lysed cells. Similar consideration applies to the ratio of genes mapped to Spike-in RNA. If the portion mapped to spike-in RNA is high, these cells might have lost the major portion of endogenous RNA, thus considered as low quality. If there is no spike-in RNA included in the sample, then this part can be removed from the criteria.","title":"Quality control on the cells"},{"location":"tutorials/scRNAseq/QC of Aligned Data/#scrna-seq-qc-metrics","text":"ArrayStudio has provided a module to do Alignment data QC especially designed for Single Cell RNA-seq, which can be accessed by going to NGS | Single Cell RNA-seq | SC RNA-seq QC Metrics: This module takes bam file resulted from barcoded alignment as input file, user can click Add to import the formally aligned bam files, and choose the corresponding genome and gene model used for the alignment, and input the output folder to run the job: To reduce the file size, OmicSoft has added features to this module to output only the results desired by the user. In the Advanced Tab: By default, OmicSoft will report the four main criteria used to QC cells in OmicSoft Lands that are outlined above. If users would like to report additional QC summary statistics, this can be done by moving from the All columns (left pane) to the selected columns (right pane) with the arrows. When the job finishes, an SC RNA Seq QC Metrics Table will be generated. Different from the RNASeq QC metrics report for bulk RNASeq, this SC RNA Seq QC Metrics Table will have the cell name as the row ID, and different alignment statistics as the column name. In addition, only the metrics specified in the advanced tab will be specified: User can filter for these columns for the quality control accordingly: Mapped rate \u2013 Alignment_MappedRate : >=40% for human ; >=30% for mouse Mapped reads \u2013 Alignment_Mapped : >=50,000 for Non UMI ; >= 1000 for UMI Gene coverage \u2013 Coverage_GeneWithCoverage : >=1000 for Non UMI ; >=250 for UMI Mitochondrial rate \u2013 Source_MitochondrialRate : < 20%","title":"scRNA-Seq QC Metrics:"},{"location":"tutorials/scRNAseq/Save_Close_Project/","text":"Save & Close Project Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in the form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save and Close Project"},{"location":"tutorials/scRNAseq/Save_Close_Project/#save-close-project","text":"Go to the File Menu | Save to save your results. Please refer to the MicroArray tutorial for more details on the Audit Trial , which records all the analysis steps in the form of Omic script. Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc. This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ). Thank you for using Array Studio.","title":"Save &amp; Close Project"},{"location":"tutorials/scRNAseq/scRNASeq_Quantification/","text":"scRNA-Seq Quantification ArrayStudio provides modules and options for scRNA-Seq quantification. Report Barcoded BAM Counts For single cell sequencing data analysis, one of the most important parts is to get the transcript count for each cell, and this module in ArrayStudio can be accessed by going to Analysis | NGS | Single Cell RNA-Seq | Barcoded BAM Based Counting: This module will quantify unique UMI counts for each gene from the BAM files. Optionally, if the user would like to completely remove the duplicates from the BAM file, they can use the Remove Duplicates function here This window will be similar to the normal RNASeq quantification, user can leave all the settings on the left as default. For the Options on the right section, Gene model and Cell barcode tag will be automatically assigned based on the bam file information; User can modify the setting for Cell count safe harbor - this parameter will filter for cells that have at least the specified number of genes represented. For UMI studies, as shown for the AlignQC step, we recommend using 250 as a safe harbor. Leave settings as default and specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default. On the Advanced tab, there are three additional options for UMI counting: Cluster UMI - Similar to barcode correction performed during pre-processing, sequencing errors in the UMI tags can be corrected using this option. For more details on clustering UMI reads, please see the wiki page here: http://www.arrayserver.com/wiki/index.php?title=Ngs_ReportSingleCellCounts.pdf#Cluster_UMI For both datasets provided for Tutorials by OmicSoft, Cluster UMI can be used. Convert UMI count to transcript number is an option we designed for the correction of \u201cUMI saturation\u201d, please refer to our wiki: UMI to Transcript for the detailed explanation. This option is not needed for the 10X dataset analyzed in these tutorials, as they use 10 bp for the UMI tag. However, for the CEL-Seq experiment , the UMI tag is only 4 nucleotides long, leading to possible saturation. In this case, users can use this option to convert UMI counts to account for this saturation. RPM Scaling - this option allows users to normalize cell counts as part of the quantification step (to reads per million). By checking this option, users skip this further processing that is described here . Please note if running a server project, this step requires ArrayServer version 10.0.1.96 or newer. Once the appropriate options are chosen, click Send To Queue to submit the job. Output files and tables When the job is done, there will be an -Omic Data object (a zero inflated binary matrix, or ZIM, data object), with a counts table representing all kept cells as columns and all genes as rows. If the user chooses to convert UMI counts to transcript number, there will be two -Omic data objects: a zero inflated binary matrix (ZIM) data object to store the UMI count, and another MicroArray type data object to store the converted UMI count: This is the ZIM data object file which has 256 as the maximum UMI count: And this will be the normal MicroArray type -Omic data which store the converted theoretical UMI count, which has the maximum UMI as 1420: If the user chooses to normalize UMI counts to reads per million, an addtional -Omic data object will be generated with each cell normalized to one million counts:","title":"scRNA-Seq Quantification"},{"location":"tutorials/scRNAseq/scRNASeq_Quantification/#scrna-seq-quantification","text":"ArrayStudio provides modules and options for scRNA-Seq quantification.","title":"scRNA-Seq Quantification"},{"location":"tutorials/scRNAseq/scRNASeq_Quantification/#report-barcoded-bam-counts","text":"For single cell sequencing data analysis, one of the most important parts is to get the transcript count for each cell, and this module in ArrayStudio can be accessed by going to Analysis | NGS | Single Cell RNA-Seq | Barcoded BAM Based Counting: This module will quantify unique UMI counts for each gene from the BAM files. Optionally, if the user would like to completely remove the duplicates from the BAM file, they can use the Remove Duplicates function here This window will be similar to the normal RNASeq quantification, user can leave all the settings on the left as default. For the Options on the right section, Gene model and Cell barcode tag will be automatically assigned based on the bam file information; User can modify the setting for Cell count safe harbor - this parameter will filter for cells that have at least the specified number of genes represented. For UMI studies, as shown for the AlignQC step, we recommend using 250 as a safe harbor. Leave settings as default and specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default. On the Advanced tab, there are three additional options for UMI counting: Cluster UMI - Similar to barcode correction performed during pre-processing, sequencing errors in the UMI tags can be corrected using this option. For more details on clustering UMI reads, please see the wiki page here: http://www.arrayserver.com/wiki/index.php?title=Ngs_ReportSingleCellCounts.pdf#Cluster_UMI For both datasets provided for Tutorials by OmicSoft, Cluster UMI can be used. Convert UMI count to transcript number is an option we designed for the correction of \u201cUMI saturation\u201d, please refer to our wiki: UMI to Transcript for the detailed explanation. This option is not needed for the 10X dataset analyzed in these tutorials, as they use 10 bp for the UMI tag. However, for the CEL-Seq experiment , the UMI tag is only 4 nucleotides long, leading to possible saturation. In this case, users can use this option to convert UMI counts to account for this saturation. RPM Scaling - this option allows users to normalize cell counts as part of the quantification step (to reads per million). By checking this option, users skip this further processing that is described here . Please note if running a server project, this step requires ArrayServer version 10.0.1.96 or newer. Once the appropriate options are chosen, click Send To Queue to submit the job.","title":"Report Barcoded BAM Counts"},{"location":"tutorials/scRNAseq/scRNASeq_Quantification/#output-files-and-tables","text":"When the job is done, there will be an -Omic Data object (a zero inflated binary matrix, or ZIM, data object), with a counts table representing all kept cells as columns and all genes as rows. If the user chooses to convert UMI counts to transcript number, there will be two -Omic data objects: a zero inflated binary matrix (ZIM) data object to store the UMI count, and another MicroArray type data object to store the converted UMI count: This is the ZIM data object file which has 256 as the maximum UMI count: And this will be the normal MicroArray type -Omic data which store the converted theoretical UMI count, which has the maximum UMI as 1420: If the user chooses to normalize UMI counts to reads per million, an addtional -Omic data object will be generated with each cell normalized to one million counts:","title":"Output files and tables"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/","text":"10X Genomics Test Data Set This Single Cell RNA-Seq (scRNA-Seq) tutorial will focus on a popular platform for Single Cell RNA-seq, 10X Genomics. OmicSoft has developed two modules for handling the different chemistries of 10X Genomics datasets, V1 (now deprecated at 10X Genomics) and V2. Since the V1 method is deprecated, this tutorial will demonstrate how to analyze a dataset using the V2 chemistry. For details on how to analyze a dataset generated using V1 chemistry, please visit here: http://www.arrayserver.com/wiki/index.php?title=Ngs_10X_V1_Preprocess.pdf This tutorial will focus on single nuclei obtained from a mouse brain using the 10X V2 platform. The expected number of nuclei for this experiment was 900. This dataset can be accessed from 10X Genomics: here . There is one sample that has been sequenced over two lanes (Illumina), using paired-end sequencing. In the case of 10X Genomics V2, the first mate from the paired-end data will contain the Cell Barcode and UMI information, while read 2 will be used to align back to the genome: In addition to the raw fastq files in the .zip file above, there are two additional files that are available: a mapping file that will be used to group multiple fastq files to samples. Please note: you will need to adjust the file path to the final location of this mapping file on ArrayServer. a barcode list provided by 10X Genomics - these are all the possible barcode combinations that would be available with the V2 chemistry. Before processing this data in ArrayStudio, we recommend that users place these data files onto a drive mapped on ArrayServer. Pre-Processing The first step in analyzing single-cell RNA-seq results is to determine how many cells and reads there are and to group reads for each cell. In ArrayStudio, this can be done in the NGS\u2192Single-Cell RNA-Seq\u219210X Preprocessing menu: In this interface, in a single-step, users can: Filter the cells based on the total reads number Do cell barcode correction with the similar logic applied by CellRanger Rank the cells based on the read number, extract the top N cells Filter the reads by cell barcode and UMI quality Generate a knee plot to show the reads number distribution across all cells Pre-Processing (General) During the first phase of preprocessing, users can simply provide the mapping file under \"Add List\" and the file names in the mapping file will automatically be added to the window. Three parameters unique to single-cell analysis are also defined in this menu: Minimal cell read count Users can define read quality using this parameter here by defining a minimal number of total reads a cell must have to be called a cell. Default value=1000. Barcode white list file Simply provide the barcode list provided in the .zip file provided in this tutorial. Users could also download this list directly here . The white list will help filter for cells whose barcodes are provided in the list. In addition, this module will apply a logic to recover cells by correcting barcodes due to sequencing errors, using the white list as the target for barcodes. Top rich cell count This parameter allows the user to input the amount of cells expected in each sample/experiment. In addition to filtering cells based on quality and total of reads per cell, this module will allow users to limit the number of cells in the analysis. Additional filtering will occur during quantification, so we recommend for input to use 25%-50% more cells than expected. For example, in the dataset provided in this tutorial, there were 900 nuclei expected. We have benchmarked this dataset using a top rich cell count of 1300. Additional parameters will be available to adjust for the user, including: Thread number indicates the number of threads to use for each sample. Increasing the thread number to 4-6 can increase the speed of processing by spreading the load of the CPU to multiple threads. Job number refers to the number of parallel jobs (independent processes). If processing multiple samples, this number can be set higher Non-unique mapping indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together. Only BAM files will be output. If users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files. Output folder Pre-processed files, including those from kept cells and skipped, will be output to this folder, along with an auto-generated mapping file that can be used for the alignment step. Output Users can define a name for the output to distinguish the objects in the project. This name will also be assigned to the mapping file that will be output at the end of this procedure. Pre-Processing (Advanced) The Advanced tab of the preprocessing menu allows users to define parameters for filtering of the 10X Genomics data and visualize the quality of reads in a knee plot. Filtering: By default, ArrayStudio will examine the Barcode and UMI information in read 1 of the fastq files, and discard reads where these tags have poor sequencing quality or improper length. This option can be left as default. Quality control/knee plot: Users can also generate a knee plot to visualize a pile-up of all individual barcodes (cells) and total reads per cell. Leaving this number lower than the Minimal cell read count on the General tab will allow users the opportunity to see how many \"cells\" will be excluded from the analysis. When satisfied will all options chosen, click on Send to Queue . For reference, this process takes about two hours on our test. Results The pre-processing step of 10X V2 data will output results in two locations that users will need, 1) the project within ArrayStudio and 2) the Output Folder. Results - OmicSoft project Within the OmicSoft Project Environment, users will see two table objects: SCPreprocessReport: This table will simply provide results of the pre-processing, including the total number of reads in each sample, how many were kept, and how many filtered (skipped) during pre-processing. Finally, the last column will provide the fraction of total reads that were retained during pre-processing. SCSortedReadCount: A table will be generated to report each cell (barcode) that was identified in the raw fastq files, ranked by the number of reads per cell: The ranking (Read Count Order Index) and the read count are plotted in the knee plot, and colored by whether the cell was kept (green) or skipped (blue) in the ReadCountDistribution view. This visualization can be used to examine the filtering conditions and reset filters if need. Results - Output Folder In addition to the reports that are generated in the project, the processed fastq files can be found in the output folder: As shown in the diagram above, the \"MergedMapping\" file is what is needed for the alignment step. Similar to the mapping file used for the pre-processing step, this file will provide a list of all the fastq files that will be used. Note that the kept reads from the pre-processing step will have the format: SampleID _prepReads_chunk(1-n).fastq.gz and SampleID _prepReads_chunk(1-n).tag.gz. The prepReads.fastq files will have the kept reads that will be aligned to the genome, while the tag.gz files will retain the information about the cell barcode and UMI. The skipped reads will also be retained after preprocessing if users would like to perform further analysis with them. For users that would like to use Oscript/Pscript to submit analyses directly to ArrayServer without using the GUI menu for alignment, the MergedChunkFiles.txt file can be used as input. Once these results are generated, you are ready to align reads to the genome! Please skip ahead to the Alignment to Genome section","title":"10X Genomics Data"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#10x-genomics","text":"","title":"10X Genomics"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#test-data-set","text":"This Single Cell RNA-Seq (scRNA-Seq) tutorial will focus on a popular platform for Single Cell RNA-seq, 10X Genomics. OmicSoft has developed two modules for handling the different chemistries of 10X Genomics datasets, V1 (now deprecated at 10X Genomics) and V2. Since the V1 method is deprecated, this tutorial will demonstrate how to analyze a dataset using the V2 chemistry. For details on how to analyze a dataset generated using V1 chemistry, please visit here: http://www.arrayserver.com/wiki/index.php?title=Ngs_10X_V1_Preprocess.pdf This tutorial will focus on single nuclei obtained from a mouse brain using the 10X V2 platform. The expected number of nuclei for this experiment was 900. This dataset can be accessed from 10X Genomics: here . There is one sample that has been sequenced over two lanes (Illumina), using paired-end sequencing. In the case of 10X Genomics V2, the first mate from the paired-end data will contain the Cell Barcode and UMI information, while read 2 will be used to align back to the genome: In addition to the raw fastq files in the .zip file above, there are two additional files that are available: a mapping file that will be used to group multiple fastq files to samples. Please note: you will need to adjust the file path to the final location of this mapping file on ArrayServer. a barcode list provided by 10X Genomics - these are all the possible barcode combinations that would be available with the V2 chemistry. Before processing this data in ArrayStudio, we recommend that users place these data files onto a drive mapped on ArrayServer.","title":"Test Data Set"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#pre-processing","text":"The first step in analyzing single-cell RNA-seq results is to determine how many cells and reads there are and to group reads for each cell. In ArrayStudio, this can be done in the NGS\u2192Single-Cell RNA-Seq\u219210X Preprocessing menu: In this interface, in a single-step, users can: Filter the cells based on the total reads number Do cell barcode correction with the similar logic applied by CellRanger Rank the cells based on the read number, extract the top N cells Filter the reads by cell barcode and UMI quality Generate a knee plot to show the reads number distribution across all cells","title":"Pre-Processing"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#pre-processing-general","text":"During the first phase of preprocessing, users can simply provide the mapping file under \"Add List\" and the file names in the mapping file will automatically be added to the window. Three parameters unique to single-cell analysis are also defined in this menu: Minimal cell read count Users can define read quality using this parameter here by defining a minimal number of total reads a cell must have to be called a cell. Default value=1000. Barcode white list file Simply provide the barcode list provided in the .zip file provided in this tutorial. Users could also download this list directly here . The white list will help filter for cells whose barcodes are provided in the list. In addition, this module will apply a logic to recover cells by correcting barcodes due to sequencing errors, using the white list as the target for barcodes. Top rich cell count This parameter allows the user to input the amount of cells expected in each sample/experiment. In addition to filtering cells based on quality and total of reads per cell, this module will allow users to limit the number of cells in the analysis. Additional filtering will occur during quantification, so we recommend for input to use 25%-50% more cells than expected. For example, in the dataset provided in this tutorial, there were 900 nuclei expected. We have benchmarked this dataset using a top rich cell count of 1300. Additional parameters will be available to adjust for the user, including: Thread number indicates the number of threads to use for each sample. Increasing the thread number to 4-6 can increase the speed of processing by spreading the load of the CPU to multiple threads. Job number refers to the number of parallel jobs (independent processes). If processing multiple samples, this number can be set higher Non-unique mapping indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together. Only BAM files will be output. If users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files. Output folder Pre-processed files, including those from kept cells and skipped, will be output to this folder, along with an auto-generated mapping file that can be used for the alignment step. Output Users can define a name for the output to distinguish the objects in the project. This name will also be assigned to the mapping file that will be output at the end of this procedure.","title":"Pre-Processing (General)"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#pre-processing-advanced","text":"The Advanced tab of the preprocessing menu allows users to define parameters for filtering of the 10X Genomics data and visualize the quality of reads in a knee plot. Filtering: By default, ArrayStudio will examine the Barcode and UMI information in read 1 of the fastq files, and discard reads where these tags have poor sequencing quality or improper length. This option can be left as default. Quality control/knee plot: Users can also generate a knee plot to visualize a pile-up of all individual barcodes (cells) and total reads per cell. Leaving this number lower than the Minimal cell read count on the General tab will allow users the opportunity to see how many \"cells\" will be excluded from the analysis. When satisfied will all options chosen, click on Send to Queue . For reference, this process takes about two hours on our test.","title":"Pre-Processing (Advanced)"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#results","text":"The pre-processing step of 10X V2 data will output results in two locations that users will need, 1) the project within ArrayStudio and 2) the Output Folder.","title":"Results"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#results-omicsoft-project","text":"Within the OmicSoft Project Environment, users will see two table objects: SCPreprocessReport: This table will simply provide results of the pre-processing, including the total number of reads in each sample, how many were kept, and how many filtered (skipped) during pre-processing. Finally, the last column will provide the fraction of total reads that were retained during pre-processing. SCSortedReadCount: A table will be generated to report each cell (barcode) that was identified in the raw fastq files, ranked by the number of reads per cell: The ranking (Read Count Order Index) and the read count are plotted in the knee plot, and colored by whether the cell was kept (green) or skipped (blue) in the ReadCountDistribution view. This visualization can be used to examine the filtering conditions and reset filters if need.","title":"Results - OmicSoft project"},{"location":"tutorials/scRNAseq/Pre-processing/10X Data Sets/#results-output-folder","text":"In addition to the reports that are generated in the project, the processed fastq files can be found in the output folder: As shown in the diagram above, the \"MergedMapping\" file is what is needed for the alignment step. Similar to the mapping file used for the pre-processing step, this file will provide a list of all the fastq files that will be used. Note that the kept reads from the pre-processing step will have the format: SampleID _prepReads_chunk(1-n).fastq.gz and SampleID _prepReads_chunk(1-n).tag.gz. The prepReads.fastq files will have the kept reads that will be aligned to the genome, while the tag.gz files will retain the information about the cell barcode and UMI. The skipped reads will also be retained after preprocessing if users would like to perform further analysis with them. For users that would like to use Oscript/Pscript to submit analyses directly to ArrayServer without using the GUI menu for alignment, the MergedChunkFiles.txt file can be used as input. Once these results are generated, you are ready to align reads to the genome! Please skip ahead to the Alignment to Genome section","title":"Results - Output Folder"},{"location":"tutorials/scRNAseq/Pre-processing/OtherFilteringOptions/","text":"TAG Based QC We can use this module to summarize the data quality based on the tag file. Go to Analysis | NGS | Single Cell RNA-Seq | Tag Based QC: Click Add to load the tag.gz files generated from the former step; Leave Quality encoding as Automatic to automatically set the correct quality encoding method. Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default. In the box of # of quantiles for QC summary , set the number to be 20 , which means there will be 20 quantiles (0, 0.05, 0.10, 0.15 \u2026\u2026, 0.95, 1) for the cells for each sample, ranked based on the count for each cell. scRNA Read Count Report Check the option for Export all cell barcode counts , and leave others as default. Click Send To Queue to run this module on server. Once the analysis is done, user can see two tables generated under the Table section, in the folder named \u201cSC Raw Data QC\u201d, each has a corresponding view: The SCReadCountReport table will have 3 columns, for each sample, there will be 21 rows (20 quantiles), and the Column of Cell Read Counts shows the read counts for the corresponding cells: Cell Read Counts View And the CellReadCounts view is the variable view trellis by samples, which shows the read count across different quantiles of the cells for each sample in a more straightforward manner. Similarly, the SCReadQSReport table shows the quality score for each quantile of the cells for each sample: And the corresponding view shows a more straightforward view, during which user can see the green line for cell barcode quality (CY), and blue line for UMI quality (UY):","title":"TAG Based QC"},{"location":"tutorials/scRNAseq/Pre-processing/OtherFilteringOptions/#tag-based-qc","text":"We can use this module to summarize the data quality based on the tag file. Go to Analysis | NGS | Single Cell RNA-Seq | Tag Based QC: Click Add to load the tag.gz files generated from the former step; Leave Quality encoding as Automatic to automatically set the correct quality encoding method. Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default. In the box of # of quantiles for QC summary , set the number to be 20 , which means there will be 20 quantiles (0, 0.05, 0.10, 0.15 \u2026\u2026, 0.95, 1) for the cells for each sample, ranked based on the count for each cell.","title":"TAG Based QC"},{"location":"tutorials/scRNAseq/Pre-processing/OtherFilteringOptions/#scrna-read-count-report","text":"Check the option for Export all cell barcode counts , and leave others as default. Click Send To Queue to run this module on server. Once the analysis is done, user can see two tables generated under the Table section, in the folder named \u201cSC Raw Data QC\u201d, each has a corresponding view: The SCReadCountReport table will have 3 columns, for each sample, there will be 21 rows (20 quantiles), and the Column of Cell Read Counts shows the read counts for the corresponding cells:","title":"scRNA Read Count Report"},{"location":"tutorials/scRNAseq/Pre-processing/OtherFilteringOptions/#cell-read-counts-view","text":"And the CellReadCounts view is the variable view trellis by samples, which shows the read count across different quantiles of the cells for each sample in a more straightforward manner. Similarly, the SCReadQSReport table shows the quality score for each quantile of the cells for each sample: And the corresponding view shows a more straightforward view, during which user can see the green line for cell barcode quality (CY), and blue line for UMI quality (UY):","title":"Cell Read Counts View"},{"location":"tutorials/scRNAseq/Pre-processing/non10XData/","text":"Introduction - Non-10X Umi Experiments Test Dataset This Single Cell RNA-Seq (scRNA-Seq) tutorial will cover the importing and some analysis of a public dataset. This dataset can be accessed from NCBI GEO database: GEO GSE85241 which was run on the Illumina NextSeq 500(GPL18573) platform, and adopting the method of CEL-Seq2. There are 32 samples in total and each sample has 2 fastq files as input, as it\u2019s paired-end sequencing data. As described in the document (GSE85241_readme_demultiplexing_Cel-seq_data.pdf) downloaded from GEO database, read 1 should be parsed in the following manner: \u201cthe first 8 basepairs are the Cel-Seq cell barcodes (see list at the bottom of the same document). The following four basepairs are random basepairs of the unique molecular identifier, which can be used to count individual molecules for each transcript. The rest of read 1 consists of mostly polyT and is not used. Read two is then mapped to the reference genome of choice (hg19 in our case).\u201d Based on this description, in this tutorial we will extract the cell barcode and UMI information from read1, then align read2 to human genome, and perform downstream quantification and clustering analysis. If users are interested in testing with this project, the data can be downloaded from NCBI: SRP080991 , or using our GUI for downloading SRA to download the fastq files: Download SRA in ArrayStudio . After retrieving these data, you can begin the tutorial. Pre-Process Pre-process Compared to normal fastq files, Single-Cell RNASeq fastq files contain extra information for barcode and Unique Molecular Identifiers (UMIs). The purpose of pre-processing fastq files is to extract these features from fastq files, and store them into a tag file. This module can be accessed by going to NGS | SingleCell RNA-Seq | Single Cell Preprocessing: Click Add to find all fastq files for these 32 samples (64 fastq files). Leave Quality encoding as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.fastq.gz and .tag.gz) will be saved, otherwise the files will go to the project folder by default. Check the option for Reads are paired as we are using paired end data in this tutorial, and check the option for Reads contain UMI . Leave the box for Demultiplex with cell barcode empty here, as we don\u2019t want to demultiplex at fastq file level, which will generate too many files. Barcode UMI Source In the Barcode/UMI Source section, check the option for Read Sequences as the barcode and UMI are included in the read1 for our data, then click R1 pattern to bring up the regular expression window: For our testing data, in the read 1 files, the first 8 basepairs are the Cel-Seq cell barcodes , and the following 4 basepairs are random basepairs of the unique molecular identifier . We can modify the length for barcode and UMI like this in the box, and click Match , user can see how the fastq read1 sequences get mapped by this regular expression pattern: Click OK will bring this regular expression phrase to the Single Cell Preprocessing window. In the last option, choose Read2 as the read sequence exists in Read2 for our testing data. Click Send To Queue to run this job on server. When the job is done, user can find four files generated for each sample in the output folder: Mainly, we will use _prepReads.fastq.gz file and _prepReads.tag.gz file for the following analysis. Filter Raw reads After the pre-processing of SC fastq files (resulting prepReads.fastq.gz and _prepReads.tag.gz files), user can filter the reads based on several criteria as follows: 1. Fastq read sequence quality 2. A valid barcode list to filter for the barcode in the tag file for valid read 3. A barcode remap file to group different barcode sequences (normally containing 1 mismatch) to be the same barcode 4. Filter reads by cell barcode quality (General tab) 5. Filter reads by UMI quality (General tab) To open this module, user can go to Analysis | NGS | Single Cell RNA-Seq | Filter Single Cell Raw Reads . Click Add to find all 32 files, pay attention to the files names, and make sure you are loading the .prepReads.fastq.gz files. Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default. In this window, user can provide a ValidBarcode list if they have such list to verify valid barcode sequence, and provide a barcode remap file to group different barcode sequence to be the same barcode. For out tutorial project, the valid barcode list can be found in the GEO website: https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE85241&format=file&file=GSE85241%5Freadme%5Fdemultiplexing%5FCel%2Dseq%5Fdata%2Epdf%2Egz . To make it more convenient, we have created a validbarcode.txt file on our server and user can go to this link ( http://omicsoft.com/downloads/data/Tutorial/Help/SCTest/ ) to download the GSE85241_ValidBarcode.txt to your local folder. Browse to load the downloaded GSE85241_validbarcode.txt file. Check the option for Filter reads with cell barcode quality and Filter reads with UMI quality . Leave the box for \u201cReads are paired\u201d empty, and check Read2 for Single end read source , as our fastq data is originated from paired end data and Read2 is read source. Click Send To Queue to run the module on server. When the job is done, user will be able to see 5 files generated for each sample: The prepReads.filter.fastq.gz file and filterReads.filter.tag.gz files will be used for the following analysis. User can move the rest of the files into a sub-folder for better management.","title":"Other UMI Data sets"},{"location":"tutorials/scRNAseq/Pre-processing/non10XData/#introduction-non-10x-umi-experiments","text":"","title":"Introduction - Non-10X Umi Experiments"},{"location":"tutorials/scRNAseq/Pre-processing/non10XData/#test-dataset","text":"This Single Cell RNA-Seq (scRNA-Seq) tutorial will cover the importing and some analysis of a public dataset. This dataset can be accessed from NCBI GEO database: GEO GSE85241 which was run on the Illumina NextSeq 500(GPL18573) platform, and adopting the method of CEL-Seq2. There are 32 samples in total and each sample has 2 fastq files as input, as it\u2019s paired-end sequencing data. As described in the document (GSE85241_readme_demultiplexing_Cel-seq_data.pdf) downloaded from GEO database, read 1 should be parsed in the following manner: \u201cthe first 8 basepairs are the Cel-Seq cell barcodes (see list at the bottom of the same document). The following four basepairs are random basepairs of the unique molecular identifier, which can be used to count individual molecules for each transcript. The rest of read 1 consists of mostly polyT and is not used. Read two is then mapped to the reference genome of choice (hg19 in our case).\u201d Based on this description, in this tutorial we will extract the cell barcode and UMI information from read1, then align read2 to human genome, and perform downstream quantification and clustering analysis. If users are interested in testing with this project, the data can be downloaded from NCBI: SRP080991 , or using our GUI for downloading SRA to download the fastq files: Download SRA in ArrayStudio . After retrieving these data, you can begin the tutorial.","title":"Test Dataset"},{"location":"tutorials/scRNAseq/Pre-processing/non10XData/#pre-process","text":"","title":"Pre-Process"},{"location":"tutorials/scRNAseq/Pre-processing/non10XData/#pre-process_1","text":"Compared to normal fastq files, Single-Cell RNASeq fastq files contain extra information for barcode and Unique Molecular Identifiers (UMIs). The purpose of pre-processing fastq files is to extract these features from fastq files, and store them into a tag file. This module can be accessed by going to NGS | SingleCell RNA-Seq | Single Cell Preprocessing: Click Add to find all fastq files for these 32 samples (64 fastq files). Leave Quality encoding as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.fastq.gz and .tag.gz) will be saved, otherwise the files will go to the project folder by default. Check the option for Reads are paired as we are using paired end data in this tutorial, and check the option for Reads contain UMI . Leave the box for Demultiplex with cell barcode empty here, as we don\u2019t want to demultiplex at fastq file level, which will generate too many files.","title":"Pre-process"},{"location":"tutorials/scRNAseq/Pre-processing/non10XData/#barcode-umi-source","text":"In the Barcode/UMI Source section, check the option for Read Sequences as the barcode and UMI are included in the read1 for our data, then click R1 pattern to bring up the regular expression window: For our testing data, in the read 1 files, the first 8 basepairs are the Cel-Seq cell barcodes , and the following 4 basepairs are random basepairs of the unique molecular identifier . We can modify the length for barcode and UMI like this in the box, and click Match , user can see how the fastq read1 sequences get mapped by this regular expression pattern: Click OK will bring this regular expression phrase to the Single Cell Preprocessing window. In the last option, choose Read2 as the read sequence exists in Read2 for our testing data. Click Send To Queue to run this job on server. When the job is done, user can find four files generated for each sample in the output folder: Mainly, we will use _prepReads.fastq.gz file and _prepReads.tag.gz file for the following analysis.","title":"Barcode UMI Source"},{"location":"tutorials/scRNAseq/Pre-processing/non10XData/#filter-raw-reads","text":"After the pre-processing of SC fastq files (resulting prepReads.fastq.gz and _prepReads.tag.gz files), user can filter the reads based on several criteria as follows: 1. Fastq read sequence quality 2. A valid barcode list to filter for the barcode in the tag file for valid read 3. A barcode remap file to group different barcode sequences (normally containing 1 mismatch) to be the same barcode 4. Filter reads by cell barcode quality (General tab) 5. Filter reads by UMI quality (General tab) To open this module, user can go to Analysis | NGS | Single Cell RNA-Seq | Filter Single Cell Raw Reads . Click Add to find all 32 files, pay attention to the files names, and make sure you are loading the .prepReads.fastq.gz files. Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default. In this window, user can provide a ValidBarcode list if they have such list to verify valid barcode sequence, and provide a barcode remap file to group different barcode sequence to be the same barcode. For out tutorial project, the valid barcode list can be found in the GEO website: https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE85241&format=file&file=GSE85241%5Freadme%5Fdemultiplexing%5FCel%2Dseq%5Fdata%2Epdf%2Egz . To make it more convenient, we have created a validbarcode.txt file on our server and user can go to this link ( http://omicsoft.com/downloads/data/Tutorial/Help/SCTest/ ) to download the GSE85241_ValidBarcode.txt to your local folder. Browse to load the downloaded GSE85241_validbarcode.txt file. Check the option for Filter reads with cell barcode quality and Filter reads with UMI quality . Leave the box for \u201cReads are paired\u201d empty, and check Read2 for Single end read source , as our fastq data is originated from paired end data and Read2 is read source. Click Send To Queue to run the module on server. When the job is done, user will be able to see 5 files generated for each sample: The prepReads.filter.fastq.gz file and filterReads.filter.tag.gz files will be used for the following analysis. User can move the rest of the files into a sub-folder for better management.","title":"Filter Raw reads"}]}